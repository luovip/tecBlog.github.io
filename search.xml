<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>containerd容器原理与实战</title>
      <link href="/2025/06/03/rong-qi-ji-zhu/containerd-rong-qi-yuan-li-yu-shi-zhan/"/>
      <url>/2025/06/03/rong-qi-ji-zhu/containerd-rong-qi-yuan-li-yu-shi-zhan/</url>
      
        <content type="html"><![CDATA[<h1 id="1-云原生与容器运行时"><a href="#1-云原生与容器运行时" class="headerlink" title="1 云原生与容器运行时"></a>1 云原生与容器运行时</h1><h2 id="1-1-云原生概述"><a href="#1-1-云原生概述" class="headerlink" title="1.1 云原生概述"></a>1.1 云原生概述</h2><p>  云原生是充分利用云计算的优势，在云计算中构建、部署和管理现代引用程序的软件方法</p><p>  CloudNative=Cloud + Native，其中，Cloud表示应用程序位于云中、Native表示应用程序从设计之初就考虑云的环境</p><p>  云原生的特征为：DevOps、持续交付、微服务、容器技术</p><p>  <strong>DevOPs</strong>：是一个组合词，即Dev+Ops，表示开发和运维之间的协作</p><p>  <strong>持续交付</strong>：持续交付是相对于传统瀑布式开发模型而言的，特征是不停机更新</p><p>  <strong>微服务</strong>：微服务是相对于单体应用的，每个微服务可独立于同一应用程序中的其他服务进行部署、升级、扩展和重启，使服务高内聚、低耦合，使得变更更容易</p><p>  <strong>容器技术</strong>：容器技术课提供更快的启动速度和更高的效率，容器技术是云原生的根基、没有容器技术就没有云原生</p><h2 id="1-2-云原生技术栈"><a href="#1-2-云原生技术栈" class="headerlink" title="1.2 云原生技术栈"></a>1.2 云原生技术栈</h2><p>  云原生技术栈是用于构建、管理和运行云原生应用程序的云原生技术分层：</p><p>  云原生技术栈中的几个重要组成部分：容器编排引擎、容器运行时、容器存储、容器网络</p><p>  <strong>容器编排引擎</strong>：容器编排引擎就是Kubernetes，向上对接容器管理平台，提供容器编排接口，向下通过容器运行时接口、容器存储接口、容器网络接口打通与物理基础设施的联动，作为全局资源的调度指挥官。</p>]]></content>
      
      
      <categories>
          
          <category> 容器技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> containerd容器原理与实战 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes企业级运维</title>
      <link href="/2025/06/01/kubernetes/kubernetes-qi-ye-ji-yun-wei/"/>
      <url>/2025/06/01/kubernetes/kubernetes-qi-ye-ji-yun-wei/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Kubernetes概述"><a href="#1-Kubernetes概述" class="headerlink" title="1 Kubernetes概述"></a>1 Kubernetes概述</h1>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes企业级运维 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes网络系统原理</title>
      <link href="/2025/05/30/kubernetes/kubernetes-wang-luo-xi-tong-yuan-li/"/>
      <url>/2025/05/30/kubernetes/kubernetes-wang-luo-xi-tong-yuan-li/</url>
      
        <content type="html"><![CDATA[<h1 id="1-网络通信基础"><a href="#1-网络通信基础" class="headerlink" title="1 网络通信基础"></a>1 网络通信基础</h1>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes网络系统原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>podman容器</title>
      <link href="/2025/05/28/rong-qi-ji-zhu/podman-rong-qi/"/>
      <url>/2025/05/28/rong-qi-ji-zhu/podman-rong-qi/</url>
      
        <content type="html"><![CDATA[<h1 id="1-容器的概念"><a href="#1-容器的概念" class="headerlink" title="1 容器的概念"></a>1 容器的概念</h1><h2 id="1-1-容器技术介绍"><a href="#1-1-容器技术介绍" class="headerlink" title="1.1 容器技术介绍"></a>1.1 容器技术介绍</h2><p>  软件应用通常依赖于运行时环境(runtimeenvironment)提供的系统库、配置文件或服务</p><p>  传统软件应用的运行时环境安装在物理主机或虚拟机上运行的操作系统中。然后，管理员在操作系统上安装应用依赖项</p><p>  在红帽企业Linux中，诸如RPM等打包系统可协助管理员管理应用依赖项。安装httpd软件包时，RPM系统会确保同时安装该软件包的正确库和其他依赖项</p><p>  传统方式部署软件应用的主要弊端是这些依赖项会受到运行时环境的束缚，应用需要的支持软件的版本可能比操作系统提供的软件更旧或更新，同一系统上的两个应用可能需要同一软件互不兼容的不同版本，解决这些冲突的方式之一是将应用打包并作为容器进行部署</p><p>  容器是由一个或多个与系统其余部分隔离的进程组成的集合，软件容器是打包应用以简化其部署和管理的一种方式</p><p>  以实体集装箱为例。集装箱是打包和装运货物的标准方式。作为一个箱子进行标记、装载、卸载，以及从一个位置运输到另一个位置。集装箱中的内容与其他集装箱的内容隔离，因此互不影响。这些基本原则也适用于软件容器</p><h2 id="1-2-容器技术的核心"><a href="#1-2-容器技术的核心" class="headerlink" title="1.2 容器技术的核心"></a>1.2 容器技术的核心</h2><p>  红帽企业Linux通过运用以下核心技术来支持容器:</p><p>   1.用于资源管理的控制组(cgroups)</p><p>   2.用于进程隔离的命名空间</p><p>   3.加强安全边界的SELinux和Seccomp安全计算模式</p><h2 id="1-3-容器和虚拟机的差异"><a href="#1-3-容器和虚拟机的差异" class="headerlink" title="1.3 容器和虚拟机的差异"></a><strong>1.3 容器和虚拟机的差异</strong></h2><p>  1.容器提供许多与虚拟机相同的益处，如安全、存储和网络隔离等</p><p>  2.这两种技术都将其应用库和运行时资源与主机操作系统或虚拟机监控程序隔离开</p><p>  3.容器和虚拟机以不同的方式与硬件和底层操作系统交互</p><p>  4.虚拟机具有以下特征:</p><p>   4.1 使多个操作系统能够同时在一个硬件平台上运行</p><p>   4.2 使用虚拟机监控程序将硬件分为多个虚拟硬件系统</p><p>   4.3 需要一个完整的操作系统环境来支持该应用</p><p>  5.容器具有以下特征:</p><p>   5.1 直接在操作系统上运行，从而跨系统上的所有容器共享资源</p><p>   5.2 共享主机的内核，但它将应用进程与系统其余部分隔离开来</p><p>   5.3 与虚拟机相比，它需要的硬件资源要少得多，因此容器的启动速度也更快</p><p>   5.4 包括所有依赖项，如系统和编程依赖项，以及配置设置</p><h2 id="1-4-Rootless和Rootful容器"><a href="#1-4-Rootless和Rootful容器" class="headerlink" title="1.4 Rootless和Rootful容器"></a><strong>1.4 Rootless和Rootful容器</strong></h2><p>  在容器主机上，特权用户运行的容器称为Rootful容器、非特权用户运行的容器称为Rootless容器</p><p>  Rootless容器不允许使用通常为特权用户保留的系统资源，例如访问受限目录、在受限端口(1024以下的端口)上发布网络服务，此功能可防止潜在攻击者获取容器主机上的root特权</p><p>  可使用root用户身份直接运行容器，但如果有漏洞允许攻击者破坏容器，这样做会削弱系统的安全性</p><h2 id="1-5-设计基于容器的架构"><a href="#1-5-设计基于容器的架构" class="headerlink" title="1.5 设计基于容器的架构"></a><strong>1.5 设计基于容器的架构</strong></h2><p>  容器是重复利用托管应用并使其可以移植的有效方式</p><p>  容器可以轻松地从一个环境迁移到另一个环境，如从开发环境迁移到生产环境</p><p>  可以保存一个容器的多个版本，并根据需要快速访问每个版本</p><p>  容器通常是临时的，可将运行中容器所生成的数据永久保存到持久存储中，但容器本身通常会在需要时运行，然后停止并被删除，下次需要该特定容器时，将启动新的容器进程</p><p>  可以在单个容器中安装含有多个服务的复杂软件应用。例如，Web服务器可能需要使用数据库和消息传递系统。不过，将一个容器用于多个服务会难以管理</p><p>  更好的设计是在单独的容器中运行每个组件、Web服务器、数据库和消息传递系统。这样，更新和维护单个应用组件不会影响其他组件或应用堆栈</p><h1 id="2-容器镜像和注册表"><a href="#2-容器镜像和注册表" class="headerlink" title="2 容器镜像和注册表"></a>2 容器镜像和注册表</h1><p>  运行容器必须使用容器镜像：</p><p>  1.容器镜像是包含编码步骤的静态文件，充当创建容器的蓝图</p><p>  2.容器镜像打包应用及其所有依赖项，如系统库、编程语言运行时和库以及其他配置设置</p><p>  3.容器镜像根据规范构建，如开放容器项目(OCI)镜像格式规范。这些规范定义容器镜像的格式，以及镜像支持的容器主机操作系统和硬件架构的元数据</p><p>  4.容器注册表是用于存储和检索容器镜像的存储库。开发人员将容器镜像推送或上传到容器注册表中，可以从注册表中将这些容器镜像拉取或下载到本地系统，以用于运行容器。可使用包含第三方镜像的公共注册表，也可使用贵组织控制的私有注册表</p><p>  5.容器镜像来源很重要。和任何其他软件包一样，必须知道是否可以信任容器镜像中的代码。对于是否及如何提供、评估和测试提交给它们的容器镜像，不同的注册表具有不同的策略</p><p>  红帽通过两个主容器注册表分发认证容器镜像，可以使用红帽登录凭据来访问这两个注册表:</p><p>  1.utility.redhat.io: 适用于基于官方红帽产品的容器</p><p>  2.utilityconnect.redhat,com:适用于基于第三方产品的容器</p><p>  3.红帽容器目录(<a href="https://access.redhat.com/containers)%E6%8F%90%E4%BE%9B%E4%BA%86%E4%B8%80%E4%B8%AA%E5%9F%BA%E4%BA%8EWeb%E7%9A%84%E7%95%8C%E9%9D%A2%EF%BC%8C%E9%80%9A%E8%BF%87%E5%AE%83%E5%8F%AF%E4%BB%A5%E6%90%9C%E7%B4%A2%E8%BF%99%E4%BA%9B%E6%B3%A8%E5%86%8C%E8%A1%A8%E4%B8%AD%E7%9A%84%E8%AE%A4%E8%AF%81%E5%86%85%E5%AE%B9">https://access.redhat.com/containers)提供了一个基于Web的界面，通过它可以搜索这些注册表中的认证内容</a></p><h2 id="2-1-安装容器"><a href="#2-1-安装容器" class="headerlink" title="2.1 安装容器"></a>2.1 安装容器</h2><p>  使用的镜像仓库浏览器访问为: <a href="https://utility/">https://utility</a> 账号&amp;密码是:admin/redhat321</p><p>  镜像对应的地址为:utility.lab.example.com</p><pre class=" language-language-bash"><code class="language-language-bash">[kiosk@foundation0 ~]$ cat /etc/hosts127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4::1         localhost localhost.localdomain localhost6 localhost6.localdomain6### rht-vm-hosts file listing the entries to be appended to /etc/hosts172.25.250.254 bastion.lab.example.com bastion172.25.250.10  servera.lab.example.com servera172.25.250.11  serverb.lab.example.com serverb172.25.250.220 utility.lab.example.com utility172.25.250.9   workstation.lab.example.com workstation# 登录servera请使用ssh方式，不要使用su切换。[root@foundation0 ~]# ssh root@servera[root@servera ~]# ssh student@localhost[student@servera ~]$ sudo dnf -y install container-tools    # 安装podman容器 [student@servera ~]$ podman --version</code></pre><h2 id="2-2-登录容器"><a href="#2-2-登录容器" class="headerlink" title="2.2 登录容器"></a>2.2 登录容器</h2><p>  需要红帽开发人员账户才能从红帽注册表下载镜像。可以使用podman login命令对注册表进行身份验证。如果不向podman login命令提供注册表URL，它会向默认配置的注册表进行身份验证</p><pre class=" language-language-bash"><code class="language-language-bash">$ podman login --help# 登录方法一(交互)：$ podman login utility.lab.example.com Username: adminPassword: redhat321Login Succeeded!# 登录方法二(非交互)： #$ podman login utility.lab.example.com -u admin -p redhat321  # 生产环境中是有https验证的Login Succeeded![student@servera ~]$ podman login -u admin -p redhat321 utility.lab.example.comError: authenticating creds for "utility.lab.example.com": pinging container registry utility.lab.example.com: Get "https://utility.lab.example.com/v2/": tls: failed to verify certificate: x509: certificate is not valid for any names, but wanted to match utility.lab.example.com# 如果出现以上报错，是要求https验证，需要通过选项--tls-verify进行手动关闭$ podman login utility.lab.example.com -u admin -p redhat321 --tls-verify=false[student@servera ~]$ podman login --help[student@servera ~]$ podman login -u admin -p redhat321 utility.lab.example.com --tls-verify=falseLogin Succeeded!# 登录方法三(非交互):# 使用podman login命令的--username和--password-sdtin选项，指定用于登录注册表的用户和密码# --password-stdin选项从stdin读取密码# 红帽建议不要使用--password选项直接提供密码，因为此选项会将密码存储在日志文件中$ echo redhat321 | podman login -u admin --password-stdin utility.lab.example.com  Login Succeeded!</code></pre><h2 id="2-3-验证容器的登录"><a href="#2-3-验证容器的登录" class="headerlink" title="2.3 验证容器的登录"></a>2.3 验证容器的登录</h2><p>  要验证是否已登录到某一注册表，请使用 podman login命令的–get-login选项</p><p>  退出登录：podman logout</p><pre class=" language-language-bash"><code class="language-language-bash">$ podman login --get-login   # 查看登录的用户admin[student@servera ~]$ podman login utility.lab.example.com --get-login    # 指定仓库地址，查看登录用户admin[student@servera ~]$ podman logout utility.lab.example.com  # 登出Removed login credentials for utility.lab.example.com</code></pre><h2 id="2-4-配置容器注册表"><a href="#2-4-配置容器注册表" class="headerlink" title="2.4 配置容器注册表"></a><strong>2.4 配置容器注册表</strong></h2><p>  容器注册表的默认配置文件是： /etc/containers/registries.conf</p><pre class=" language-language-bash"><code class="language-language-bash">[student@servera ~]$ sudo vim /etc/containers/registries.conf[sudo] password for student: student#第22行 指定可搜索的镜像仓库地址，如果使用完全合格域名，此处可以留空unqualified-search-registries = ["utility.lab.example.com","registry.access.redhat.com","registry.redhat.io","docker.io"][[utility]]   #第24行 解除注释开启以下功能insecure = true    #false/true 开启https安全验证/关闭安全验证blocked = false    #第40行 需要过滤掉的镜像仓库地址location = "utility.lab.example.com" #第56行 指定容器注册表位置# $注意 ~/.config/containers/registries.conf目录设置会覆盖/etc/containers/registries.conf# 推荐：【student】$ mkdir -p ~/.config/containers$ cp /etc/containers/registries.conf ~/.config/containers/registries.conf$ vim ~/.config/containers/registries.confunqualified-search-registries = ["utility.lab.example.com"] [[utility]]   insecure = true blocked = false    location = "utility.lab.example.com" # 登录容器注册表[student@servera ~]$ podman login -u admin -p redhat321 utility.lab.example.comLogin Succeeded!# 根据仓库地址搜索镜像[student@servera ~]$ podman search utility.lab.example.com/# 如果只访问本地仓库，unqualified-search-registries = ["utility.lab.example.com"]默认即可，但要需要访问外网，需要用root用户修改vim /etc/resolv.conf文件内容添加nameserver 8.8.8.8 优先解析。# 阿里容器 i2kldsde.mirror.aliyuncs.com</code></pre><h2 id="2-5-容器文件构建容器镜像"><a href="#2-5-容器文件构建容器镜像" class="headerlink" title="2.5 容器文件构建容器镜像"></a>2.5 容器文件构建容器镜像</h2><p>  容器文件是一种文本文件，内含用于构建容器镜像的指令</p><p>  容器文件通常具有定义其文件和目录所在路径或URL的上下文。生成的容器镜像由只读层组成，每一层代表容器文件中的一条指令</p><p>  以下是一个容器文件示例，它使用utility.access.redhat.com注册表中的UBI镜像,安装python3 软件包，并将hello字符串打印到控制台</p><pre class=" language-language-bash"><code class="language-language-bash">$ cat ContainerfileFROM utility.access.redhat.com/ubi8/ubi:latestRUN dnf install -y python3CMD["/bin/bash"，"-c"，"echo hello"]</code></pre><h2 id="2-6-规模化容器管理"><a href="#2-6-规模化容器管理" class="headerlink" title="2.6 规模化容器管理"></a>2.6 规模化容器管理</h2><p>  新应用越来越多地使用容器来实施功能组件，这些容器提供应用的其他部分使用的服务</p><p>  组织管理越来越多的容器，可能很快就会不堪重负</p><p>  在生产中大规模部署容器需要一个能够应对以下挑战的环境：</p><p>   1.平台必须确保提供必要服务的容器的可用性</p><p>   2.环境必须通过增加或减少运行中的容器实例，并对流量进行负载平衡，从而应对应用的使用高峰</p><p>   3.平台必须检测容器或主机的故障，并相应地作出反应</p><p>   4.开发人员可能需要自动工作流，以便透明、安全地向客户交付新的应用版本</p><p>  Kubernetes是一项编排服务，可以使在容器主机集群中部署、管理和扩展基于容器的应用变得更加轻而易举</p><p>  Kubernetes通过负载平衡器将流量重定向到容器，以便可以扩展提供服务的容器数量</p><p>  Kubernetes支持用户定义的健康检查，以便监控您的容器，并在容器出现故障时将其重新启动</p><p>  红帽提供了一个名为红帽OpenShift 的kubernetes发行版。OpenShift是基于Kubernetes基础架构构建的一组模块化组件和服务，为开发人员提供的额外功能包括基于Web的远程管理、多租户、监控与审计、高级安全功能、应用生命周期管理和自助服务实例等</p><h1 id="3-部署容器"><a href="#3-部署容器" class="headerlink" title="3 部署容器"></a><strong>3 部署容器</strong></h1><h2 id="3-1-Podman实用程序"><a href="#3-1-Podman实用程序" class="headerlink" title="3.1 Podman实用程序"></a>3.1 Podman实用程序</h2><p>  Podman是来自container-tools元数据包的全功能容器引警，用于管理开放容器计划(OCI)容器和镜像</p><p>  podman实用程序的运作不使用守护进程，因此开发人员无需系统上的特权用户帐户来启动或停止容器</p><p>  Podman提供多个子命令来与容器和镜像交互</p><p>  Podman的命令如下表：</p><table><thead><tr><th align="left">命令</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">podman build</td><td align="left">使用容器文件构建容器镜像</td></tr><tr><td align="left">podman run</td><td align="left">在新容器中运行命令</td></tr><tr><td align="left">podman images</td><td align="left">列出本地存储中的镜像</td></tr><tr><td align="left">podman ps</td><td align="left">打印有关容器的信息</td></tr><tr><td align="left">podman inspect</td><td align="left">显示容器、镜像、卷、网络或容器集的配置</td></tr><tr><td align="left">podman pull</td><td align="left">从注册表下载镜像</td></tr><tr><td align="left">podman cp</td><td align="left">在容器和本地文件系统之间复制文件或目录</td></tr><tr><td align="left">podman exec</td><td align="left">在运行中的容器内执行命令</td></tr><tr><td align="left">podman rm</td><td align="left">删除一个或多个容器</td></tr><tr><td align="left">podman rmi</td><td align="left">删除一个或多个本地存储的镜像</td></tr><tr><td align="left">podman search</td><td align="left">在注册表中搜索镜像</td></tr></tbody></table><p>  有关各个子命令使用帮助手册的更多信息，将子命令附加到podman命令，并用连字符将两者分隔。例如，podman-build帮助手册介绍了podman build子命令的用法</p><h2 id="3-2-安装容器实用工具"><a href="#3-2-安装容器实用工具" class="headerlink" title="3.2 安装容器实用工具"></a>3.2 安装容器实用工具</h2><p>  container-tools软件包包含与容器和容器镜像交互所需的实用程序</p><p>  若要在系统上下载、运行和比较容器，使用dnf install命令来安装container-tools元软件包</p><p>  使用dnf info命令查看container-tools软件包的版本和内容</p><pre class=" language-language-bash"><code class="language-language-bash">[student@servera ~]$ sudo dnf -y install container-tools    # 安装podman容器 [student@servera ~]$ podman --version[student@servera ~]$ dnf info container-tools</code></pre><p>  container-tools元数据包提供所需的podman和skope实用程序，用于完成分配的任务</p><h2 id="3-3-从注册表下载容器镜像文件"><a href="#3-3-从注册表下载容器镜像文件" class="headerlink" title="3.3 从注册表下载容器镜像文件"></a>3.3 从注册表下载容器镜像文件</h2><p>  1.确保podman实用程序已配置为从utility.lab.example.com注册表搜索和下载容器</p><p>  2.podman info命令显示podman实用程序的配置信息，包括其配置的注册表</p><pre class=" language-language-bash"><code class="language-language-bash">[student@servera ~]$ podman info</code></pre><p>  podman search命令使用registries.conf文件中指定的注册表列表搜索匹配的名称镜像。默认情况下，Podman在所有非限定搜索注册表中执行搜索</p><p>  使用podman search命令，显示包含python-38软件包的已配置注册表的镜像列表</p><pre class=" language-language-bash"><code class="language-language-bash"># 在注册表中搜索镜像[student@servera ~]$ podman search utility.lab.example.com/# 从注册表中下载镜像[student@servera ~]$ podman pull utility.lab.example.com/ubi7/ubi# 列出本地存储中的镜像[student@servera ~]$ podman imagesREPOSITORY                                 TAG         IMAGE ID      CREATED      SIZEutility.lab.example.com/ubi7/ubi           latest      87dd8ec61bbc  4 years ago  215 MB# 镜像信息注解:1.REPOSITORY    仓库地址2.TAG           标记，latest最近版本3.IMAGE ID      镜像ID，ID号唯一，保证镜像唯一性4.CREATED       创建时间；5.SIZE          镜像大小</code></pre><h2 id="3-4-从容器文件创建容器镜像"><a href="#3-4-从容器文件创建容器镜像" class="headerlink" title="3.4 从容器文件创建容器镜像"></a>3.4 从容器文件创建容器镜像</h2><p>  您获得了以下容器文件，用于在 python36-app目录中创建容器镜像</p><pre class=" language-language-bash"><code class="language-language-bash">$ cat Containerfile FROM utility.access.redhat.com/ubi8/ubi:latestRUN dnf install -y python36CMD["/bin/bash"，"-c"，"sleep infinity"]# 此容器文件是教材中例子默认报错，可以使用下面的容器文件[student@servera ~]$ vim ContainerfileFROM utility.lab.example.com/ubi9/ubi:latestRUN echo -e '[rhel-9.3-for-x86_64-baseos-rpms]\nbaseurl = http://content.example.com/rhel9.3/x86_64/dvd/BaseOS\nenabled = true\ngpgcheck = false\nname = Red Hat Enterprise Linux 9.3 BaseOS (dvd)\n[rhel-9.3-for-x86_64-appstream-rpms]\nbaseurl = http://content.example.com/rhel9.3/x86_64/dvd/AppStream\nenabled = true\ngpgcheck = false\nname = Red Hat Enterprise Linux 9.3 Appstream (dvd)'>/etc/yum.repos.d/rhel_dvd.repoRUN yum install --disablerepo=* --enablerepo=rhel-9.3-for-x86_64-baseos-rpms --enablerepo=rhel-9.3-for-x86_64-appstream-rpms -y python3CMD ["/bin/bash", "-c", "sleep infinity"]</code></pre><p>  以上容器文件使用utility.lab.example.com/ubi9/ubi:latest镜像作为基础镜像。容器文件而后将安装python36软件包，并运行sleep infinity bash命令来防止容器退出</p><p>  通常，容器运行一个进程，然后在该进程完成后退出。sleep infinity命令可防止容器退出因为该进程永远不会完成，然后可以在容器内进行测试、开发和调试</p><p>  在检查容器文件后，可以使用podman build命令来构建镜像。podman build命令的语法如下所示：</p><pre class=" language-language-bash"><code class="language-language-bash">$ podman build -t NAME:TAG  DIR[student@servera ~]$ podman build -t rhel7:2.0 .[student@servera ~]$ podman imagesREPOSITORY                                 TAG         IMAGE ID      CREATED         SIZElocalhost/rhel7                            2.0         98d0b6385a00  40 seconds ago  238 MButility.lab.example.com/ubi9/ubi           latest      8d2a8803cfca  12 months ago   219 MButility.lab.example.com/ubi7/ubi           latest      87dd8ec61bbc  4 years ago     215 MButility.lab.example.com/rhel8/mariadb-103  latest      11a47e0fbed0  4 years ago     572 MB# 以上输出的最后一行显示了容器镜像ID。大多数Podman命令使用容器镜像ID的前12个字符来指代容器镜像，可以将此短ID或者容器或容器镜像的名称，作为大多数Podman命令的参数# 注解:-t,--tag name 生成镜像的名称NAME:新镜像的名称标签:新镜像的标签。如果未指定标签，则镜像自动标记为latestDIR:工作目录路径。容器文件必须位于工作目录中。如果工作目录是当前目录，则可以用点(.)来指定它。使用-f标志指定与当前目录不同的目录</code></pre><p>  使用podman inspect命令来查看容器镜像的低级别信息，并验证其内容是否符合容器要求:</p><pre class=" language-language-bash"><code class="language-language-bash">[student@servera ~]$ podman inspect localhost/rhel7:2.0</code></pre><p>  podman inspect命令的输出显示reqistry.access.redhat.com/ubi8/ubi:latest基础镜像、用于安装python36 软件包的dnf命令，以及在运行时执行以防止容器退出的sleep infinity bash命令</p><h1 id="4-运行容器"><a href="#4-运行容器" class="headerlink" title="4 运行容器"></a>4 运行容器</h1><p>  现在已拥有所需的容器镜像，可以使用它们来运行容器。容器可以处于以下状态之一!</p><p>   1.Created：已创建好但尚未启动的容器</p><p>   2.运行中：与其进程一起运行的容器</p><p>   3.已停止：其进程已停止的容器</p><p>   4.Paused：其进程已暂停的容器，不支持 Rootless容器</p><p>   5.Deleted：其进程处于已死状态的容器</p><p>  podman ps命令列出系统上正在运行的容器</p><p>  使用podman ps -a来命令查看计算机中的所有容器 (已创建、已停止、已暂停或正在运行)</p><p>  可使用podman create命令来创建容器，以便稍后运行。若要创建容器，请使用容器localhost/rhel7:2.0镜像的ID。也可以使用–name<br>选项设置名称来标识容器。此命令的输出是容器的长ID，如果不指定–name选项，会自动生成一个容器名称</p><pre class=" language-language-bash"><code class="language-language-bash">$ podman create --name python36 dd6ca291f097# 使用podman ps和podman ps -a命令来验证容器是否已创建但尚未启动$ podman ps -a$ podman ps # 运行podman start命令。可以使用名称或容器ID来启动容器。此命令的输出是容器的名称$ podman start python36$ podman ps</code></pre><h2 id="4-1-从远程存储库运行容器"><a href="#4-1-从远程存储库运行容器" class="headerlink" title="4.1 从远程存储库运行容器"></a>4.1 从远程存储库运行容器</h2><p>  可使用podman run命令，在一个步骤中创建并运行容器。podman run命令在容器内运行进程，此进程将启动新容器</p><p>  可使用podman run命令的-d选项以分离模式运行容器，这将在后台运行容器，而不是在会话的前台运行</p><p>  在python36容器的示例中，您不需要提供容器运行所提的命令，原因是为该容器创建镜像的容器文件中已提供了sleep infinity 命令</p><pre class=" language-language-bash"><code class="language-language-bash"># podman run -t：终端     -i：交互    -d：放在后台    --name：指定容器的名称，如果不指定，会自动产生名称[student@servera ~]$ podman run -it utility.lab.example.com/ubi7/ubi[student@servera ~]$ podman psCONTAINER ID  IMAGE                                    COMMAND     CREATED             STATUS             PORTS       NAMES537b1f1fbb6d  utility.lab.example.com/ubi7/ubi:latest  /bin/bash   About a minute ago  Up About a minute              objective_antonelli#实验前可以提前下载镜像至本地 #podman search utility.lab.example.com/#podman pull utility.lab.example.com/ubi8/ubi#podman images[student@servera ~]$ podman run -it --name rhel9 utility.lab.example.com/ubi9/ubi[student@servera ~]$ podman run -di --name rhel9-1 utility.lab.example.com/ubi9/ubi[student@servera ~]$ podman psCONTAINER ID  IMAGE                                    COMMAND     CREATED         STATUS         PORTS       NAMES537b1f1fbb6d  utility.lab.example.com/ubi7/ubi:latest  /bin/bash   5 minutes ago   Up 5 minutes               objective_antonellifb45a06e2271  utility.lab.example.com/ubi9/ubi:latest  /bin/bash   56 seconds ago  Up 57 seconds              rhel9-1# ctrl+d退出后再查看容器的状态[student@servera ~]$ podman exec -ti rhel9-1 /bin/bash[student@servera ~]$ podman run -d --name rhel9-2 utility.lab.example.com/ubi9/ubi sleep infinity[student@servera ~]$ podman psCONTAINER ID  IMAGE                                    COMMAND         CREATED         STATUS         PORTS       NAMESfb45a06e2271  utility.lab.example.com/ubi9/ubi:latest  /bin/bash       5 minutes ago   Up 5 minutes               rhel9-1c4f7f4d72747  utility.lab.example.com/ubi9/ubi:latest  sleep infinity  34 seconds ago  Up 34 seconds              rhel9-2</code></pre><h2 id="4-2-容器中的环境隔离"><a href="#4-2-容器中的环境隔离" class="headerlink" title="4.2 容器中的环境隔离"></a>4.2 容器中的环境隔离</h2><p>  每个容器都有自己的文件系统、网络和进程。查看ps命令的输出，并在主机和运行中容器之间进行比较，就会注意到隔离功能</p><p>  在本地计算机上运行ps -ax命令，该命令将返回具有许多进程的预期结果</p><pre class=" language-language-bash"><code class="language-language-bash">[student@servera ~]$ ps -ax[student@servera ~]$ podman run -di --name python36-db utility.lab.example.com/rhel8/mariadb-103f4c3d26df7bd3614e6b4954ae6ed485046128afc89a95cba20c834b2ba0327ff[student@servera ~]$ podman ps -aCONTAINER ID  IMAGE                                             COMMAND         CREATED         STATUS                     PORTS       NAMES850618efbece  utility.lab.example.com/ubi9/ubi:latest           /bin/bash       9 hours ago     Exited (0) 9 hours ago                 rhel9fb45a06e2271  utility.lab.example.com/ubi9/ubi:latest           /bin/bash       9 hours ago     Up 9 hours                             rhel9-1c4f7f4d72747  utility.lab.example.com/ubi9/ubi:latest           sleep infinity  9 hours ago     Up 9 hours                             rhel9-2f4c3d26df7bd  utility.lab.example.com/rhel8/mariadb-103:latest  run-mysqld      22 minutes ago  Exited (1) 22 minutes ago              python36-db</code></pre><h2 id="4-3-容器内执行命令"><a href="#4-3-容器内执行命令" class="headerlink" title="4.3 容器内执行命令"></a>4.3 容器内执行命令</h2><p>  podman exec命令可在运行中的容器内执行命令，该命令取容器的名称或ID作为第一个参数，并将下列参数作为要在容器内运行的命令</p><p>  使用podman exec命令查看rhel7容器中正在运行的进程</p><p>  ps aux命令的输出看起来有所不同，因为它运行与本地计算机不同的进程</p><p>  使用sh -c命令来封装要在容器中执行的命令</p><p>  ps ax &gt; /tmp/process-data.log命令被解释为要在容器中执行的命令。如果不封装命令，则Podman可能会将大于号字符(&gt;)解释为podman命令的一部分，而不是podman exec选项的参数</p><pre class=" language-language-bash"><code class="language-language-bash">[student@servera ~]$ podman exec rhel7 ps -ax    PID TTY      STAT   TIME COMMAND      1 ?        Ss     0:00 /bin/bash      2 ?        R      0:00 ps -ax[student@servera ~]$ podman exec rhel7 sh -c 'ps -a > /tmp/process_data.log'[student@servera ~]$ podman exec rhel7 sh -c 'echo China > /test.txt'[student@servera ~]$ podman exec -ti rhel7 /bin/bash[root@2d4b030f4141 /]# ls /bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  test.txt  tmp  usr  var[root@2d4b030f4141 /]# cat test.txtChina[root@2d4b030f4141 /]# cat /tmp/process_data.log    PID TTY          TIME CMD[root@2d4b030f4141 /]# exitexit[student@servera ~]$ # 将主机系统上安装的python版本与容器上安装的python版本进行比较[student@servera ~]$ podman exec rhel9-1 python3 --versionPython 3.9.18[student@servera ~]$ python3 --versionPython 3.9.18[student@servera ~]$ podman exec python38  python3 --versionPython 3.9.18</code></pre><h2 id="4-4-容器中的文件系统隔离"><a href="#4-4-容器中的文件系统隔离" class="headerlink" title="4.4 容器中的文件系统隔离"></a>4.4 容器中的文件系统隔离</h2><p>  开发人员可以使用文件系统隔离功能，为不同版本的编程语言编写和测试应用，无需使用多个物理机或虚拟机</p><p>  在终端上的/tmp目录中创建一个显示hello world的简单bash脚本</p><pre class=" language-language-bash"><code class="language-language-bash">[student@servera ~]$ echo "echo Hello China!" > /tmp/hello.sh[student@servera tmp]$ cd /tmp;lltotal 8-rw-r--r--. 1 student student 18 Mar  3 21:24 hello.sh-rw-r--r--. 1 student student 30 Mar  3 21:01 process_data.logdrwx------. 3 root    root    17 Mar  3 08:28 systemd-private-3f251aad6ce74edb86dddf89d56e8aed-chronyd.service-c0Zzhidrwx------. 3 root    root    17 Mar  3 08:28 systemd-private-3f251aad6ce74edb86dddf89d56e8aed-dbus-broker.service-QaiP7Ndrwx------. 3 root    root    17 Mar  3 08:28 systemd-private-3f251aad6ce74edb86dddf89d56e8aed-systemd-logind.service-iM6Zeq</code></pre><p>  /tmp/hello.sh文件位于主机计算机上，而不存在于容器内的文件系统上。如果尝试使用podmanexec来执行脚本，则会出现错误，因为容器中不存在/tmp/hello.sh脚本</p><pre class=" language-language-bash"><code class="language-language-bash">[student@servera tmp]$ stat /tmp/hello.sh  File: /tmp/hello.sh  Size: 18          Blocks: 8          IO Block: 4096   regular fileDevice: fc04h/64516d    Inode: 18159864    Links: 1Access: (0644/-rw-r--r--)  Uid: ( 1000/ student)   Gid: ( 1000/ student)Context: unconfined_u:object_r:user_tmp_t:s0Access: 2025-03-03 21:24:33.865950531 -0500Modify: 2025-03-03 21:24:33.865950531 -0500Change: 2025-03-03 21:24:33.865950531 -0500 Birth: 2025-03-03 21:24:33.865950531 -0500[student@servera tmp]$ podman exec rhel7 stat /tmp/hello.shstat: cannot stat '/tmp/hello.sh': No such file or directory</code></pre><p>  podman cp命令在主机和容器文件系统之间复制文件和文件夹。可以使用podman cp 命令将/tmp/hello.sh文件复制到python38容器:</p><pre class=" language-language-bash"><code class="language-language-bash">[student@servera ~]$ podman cp /tmp/hello.sh rhel7:/tmp/hello.sh[student@servera ~]$ podman exec rhel7 stat /tmp/hello.sh  File: '/tmp/hello.sh'  Size: 18          Blocks: 8          IO Block: 4096   regular fileDevice: 58h/88d Inode: 10261231    Links: 1Access: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)Access: 2025-03-04 02:24:34.000000000 +0000Modify: 2025-03-04 02:24:34.000000000 +0000Change: 2025-03-04 02:28:24.720471184 +0000 Birth: -</code></pre><p>  脚本复制到容器文件系统后，即可从容器内执行:</p><pre class=" language-language-bash"><code class="language-language-bash">[student@servera ~]$ podman exec rhel7 bash /tmp/hello.shHello China!</code></pre><h2 id="4-5-删除容器和镜像"><a href="#4-5-删除容器和镜像" class="headerlink" title="4.5 删除容器和镜像"></a>4.5 删除容器和镜像</h2><p>  使用podman rm和podman rmi命令删除容器和镜像</p><p>  删除容器镜像之前，必须先从该镜像移除任何现有的运行中容器</p><pre class=" language-language-bash"><code class="language-language-bash">[student@servera ~]$ podman ps -aCONTAINER ID  IMAGE                                             COMMAND         CREATED            STATUS                        PORTS       NAMES850618efbece  utility.lab.example.com/ubi9/ubi:latest           /bin/bash       10 hours ago       Exited (0) 10 hours ago                   rhel9student@servera ~]$ podman rmi utility.lab.example.com/ubi9/ubi:latestError: image used by 8e7870d50daa32c768c4301911364285a659a5383b4cdadc96b8d3b7ff411c2d: image is in use by a container: consider listing external containers and force-removing image</code></pre><p>  必须先停止容器，然后才能删除它。若要停止容器，请使用podman stop命令</p><pre class=" language-language-bash"><code class="language-language-bash">[student@servera ~]$ podman stop python38python38</code></pre><p>  停止容器后，使用podman rm命令来删除容器</p><pre class=" language-language-bash"><code class="language-language-bash">[student@servera ~]$ podman rm --help[student@servera ~]$ podman rm python38python38</code></pre><p>  当容器不再存在时，可使用podman rmi命令删除对应的镜像:</p><pre class=" language-language-bash"><code class="language-language-bash">[student@servera ~]$ podman imagesREPOSITORY                                 TAG         IMAGE ID      CREATED        SIZElocalhost/rhel7                            2.0         98d0b6385a00  11 hours ago   238 MButility.lab.example.com/ubi9/ubi           latest      8d2a8803cfca  12 months ago  219 MButility.lab.example.com/ubi7/ubi           latest      87dd8ec61bbc  4 years ago    215 MButility.lab.example.com/rhel8/mariadb-103  latest      11a47e0fbed0  4 years ago    572 MB[student@servera ~]$ podman rmi 8d2a8803cfcaError: image used by c4f7f4d727471d590f6241cccf0be0b1ef2256cc43a710594642611fe6d0be47: image is in use by a container: consider listing external containers and force-removing image[student@servera ~]$ podman rmi 98d0b6385a00Untagged: localhost/rhel7:2.0Deleted: 98d0b6385a005e09cfcee59a393cfce2fc46b56f09af6c4f87bd874f00966ed2Deleted: 53c739e51f226903b6568038c9cf563de2007f756e0a0e86e5c00604cf474f3dDeleted: 92b83aa1157f23b209f53480c6bbdf780c39490b37337bc4f4fcb1061b7c978</code></pre><h1 id="5-容器存储和网络资源"><a href="#5-容器存储和网络资源" class="headerlink" title="5 容器存储和网络资源"></a>5 容器存储和网络资源</h1><h2 id="5-1-管理容器资源"><a href="#5-1-管理容器资源" class="headerlink" title="5.1 管理容器资源"></a>5.1 管理容器资源</h2><p>  可以使用容器来运行简单的进程，然后退出。还可以配置容器以连续运行某一服务，如数据库服务器。如果持续运行服务，最终可能需要向容器添加更多资源，如持久存储或对其他网络的访问权限</p><p>  可以使用不同的策略为容器配置持久存储:</p><p>   1.对于红帽OpenShift等企业容器平台上的大型部署，可以使用复杂的存储解决方案为容器提供存储，而无需了解底层基础架构</p><p>   2.对于单个容器主机上且无需扩展的小型部署，可以通过在运行中的容器上创建要挂载的目录，从容器主机创建持久存储</p><p>  当Web服务器或数据库服务器等容器为容器主机外部的客户端提供内容时，必须为这些客户端设置通信通道，以访问容器的内容</p><p>  可以配置端口映射，以启用与容器的通信。通过端口映射，目的地为容器主机上端口的请求将被转发到容器内的端口</p><h2 id="5-2-容器的环境变量"><a href="#5-2-容器的环境变量" class="headerlink" title="5.2 容器的环境变量"></a>5.2 容器的环境变量</h2><p>  容器镜像允许在创建时传递环境变量以自定义容器</p><p>  可以使用环境变量为容器设置参数，以根据您的环境进行定制，无需创建自己的自定义镜像。通常不会修改容器镜像，因为这会向镜像添加层，或许更加难以维护</p><p>  使用podman run -d –name db01 utility.lab.example.com/rhel8/mariadb-103命令运行容器化数据库，但发现容器无法启动</p><pre class=" language-language-bash"><code class="language-language-bash">[student@servera ~]$ podman search utility.lab.example.com/     [student@servera ~]$ podman pull utility.lab.example.com/rhel8/mariadb-103[student@servera ~]$ podman imagesREPOSITORY                                 TAG         IMAGE ID      CREATED        SIZEutility.lab.example.com/rhel8/mariadb-103  latest      11a47e0fbed0  4 years ago    572 MB[student@servera ~]$ podman run -d --name db01 utility.lab.example.com/rhel8/mariadb-10329decc6e48d62506e62e503a383943709138a8f789a32dd27d2fa1761bf3ea9f# 发现容器无法启动[student@servera ~]$ podman ps -aCONTAINER ID  IMAGE           COMMAND     CREATED        STATUS                    PORTS       NAMES29decc6e48d6  utility.lab.example.com/rhel8/mariadb-103:latest  run-mysqld  2 minutes ago  Exited (1) 2 minutes ago              db01</code></pre><p>  使用podman container logs命令调查容器状态的原因</p><pre class=" language-language-bash"><code class="language-language-bash">[student@servera ~]$ podman container logs db01Warning: Can't detect memory limit from cgroupsWarning: Can't detect number of CPU cores from cgroupsWarning: Can't detect memory limit from cgroupsWarning: Can't detect number of CPU cores from cgroups=> sourcing 20-validate-variables.sh ...You must either specify the following environment variables:  MYSQL_USER (regex: '^[a-zA-Z0-9_]+$')  MYSQL_PASSWORD (regex: '^[a-zA-Z0-9_~!@#$%^&*()-=<>,.?;:|]+$')  MYSQL_DATABASE (regex: '^[a-zA-Z0-9_]+$')Or the following environment variable:  MYSQL_ROOT_PASSWORD (regex: '^[a-zA-Z0-9_~!@#$%^&*()-=<>,.?;:|]+$')Or both.Optional Settings:......</code></pre><p>  容器信息展示</p><pre class=" language-language-bash"><code class="language-language-bash"># 输出中的usage 标签提供了如何运行镜像的示例。url标签指向红帽容器目录中的一个Web页面，其中记录了环境变量以及有关如何使用容器镜像的其他信息。# 此镜像的文档显示容器将3306端口用于数据库服务。文档中还显示了以下环境变量可用于配置数据库服务:[student@servera ~]$ podman imagesREPOSITORY                                 TAG         IMAGE ID      CREATED        SIZEutility.lab.example.com/ubi9/ubi           latest      8d2a8803cfca  12 months ago  219 MButility.lab.example.com/ubi7/ubi           latest      87dd8ec61bbc  4 years ago    215 MButility.lab.example.com/rhel8/mariadb-103  latest      11a47e0fbed0  4 years ago    572 MB[student@servera ~]$ podman inspect utility.lab.example.com/rhel8/mariadb-103 | grep usage                    "usage": "podman run -d -e MYSQL_USER=user -e MYSQL_PASSWORD=pass -e MYSQL_DATABASE=db -p 3306:3306 rhel8/mariadb-103",               "usage": "podman run -d -e MYSQL_USER=user -e MYSQL_PASSWORD=pass -e MYSQL_DATABASE=db -p 3306:3306 rhel8/mariadb-103",$ skopeo inspect docker://utility.lab.example.com/rhel8/mariadb-105 | grep -B 1 Usage</code></pre><p>  mariadb镜像的环境变量</p><table><thead><tr><th align="left">变量</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">MYSQL_USER</td><td align="left">要创建的MySQL帐户的用户名</td></tr><tr><td align="left">MYSQL_PASSWORD</td><td align="left">用户帐户的密码</td></tr><tr><td align="left">MYSQL_DATABASE</td><td align="left">数据库名称</td></tr><tr><td align="left">MYSQL_ROOT_PASSWORD</td><td align="left">root用户的密码 (可选)</td></tr></tbody></table><p>  在检查了镜像的可用环境变量后，使用podman run命令-e选项将环境变量传递给容器，并使用podman ps命令来验证它是否正在运行</p><pre class=" language-language-bash"><code class="language-language-bash">[student@servera ~]$ podman rm -af29decc6e48d62506e62e503a383943709138a8f789a32dd27d2fa1761bf3ea9f[student@servera ~]$ podman ps -aCONTAINER ID  IMAGE       COMMAND     CREATED     STATUS      PORTS       NAMES[student@servera ~]$ podman run -d --name db01 -e MYSQL_USER=user -e MYSQL_PASSWORD=pass -e MYSQL_DATABASE=db utility.lab.example.com/rhel8/mariadb-10341a62ff2efd7f268e52d6f6a0a9b503411824c5f4391b86dae5d3f01376cb896# 容器启动成功[student@servera ~]$ podman ps  -aCONTAINER ID  IMAGE                                             COMMAND     CREATED        STATUS        PORTS       NAMES41a62ff2efd7  utility.lab.example.com/rhel8/mariadb-103:latest  run-mysqld  8 seconds ago  Up 8 seconds              db01</code></pre><h2 id="5-3-容器持久存储"><a href="#5-3-容器持久存储" class="headerlink" title="5.3 容器持久存储"></a>5.3 容器持久存储</h2><p>  默认情况下运行容器时，所有内容都使用基于容器的镜像</p><p>  鉴于容器镜像的寿命短，用户或应用写入的所有新数据在移除容器后都会丢失</p><p>  若要持久保留数据，可以将容器中的主机文件系统内容与–volume(-v)选项搭配使用。在容器中使用此卷类型时，必须考虑文件系统级别的权限<br>  MariaDB容器镜像中，mysql用户必须拥有/var/lib/mysql目录，就如同MariaDB在主机上运行时一样</p><p>  打算挂载到容器中的目录必须具有mysql作为用户和组所有者(或mysql用户的UID/GID，如果主机上没有安装MariaDB)</p><p>  如果以root用户身份运行容器，则主机上的UID和GID与容器内的UID和GID匹配</p><p>  可使用podman unshare命令在用户命名空间内运行命令。要获取用户命名空间的UID映射，请使用podman unshare cat命令</p><pre class=" language-language-bash"><code class="language-language-bash">[student@servera ~]$ podman unshare cat /proc/self/uid_map         0       1000          1         1     100000      65536[student@servera ~]$ podman unshare cat /proc/self/gid_map         0       1000          1         1     100000      65536</code></pre><p>  以上输出显示：</p><p>   1.容器中的root用户 (UID和GID为0)映射到主机计算机上的用户(UID和GID为1000)</p><p>   2.容器中的UID和GID1映射到主机计算机上的UID和GID 100000</p><p>   3.1后的每个UID和GID以1增量递增。例如，容器内的UID和GID30映射到主机计算机上的UID和GID100029</p><p>   4.可使用podman exec命令查看使用临时存储运行的容器内的mysql用户UID和GID:</p><pre class=" language-language-bash"><code class="language-language-bash">[student@servera ~]$ podman exec -it db01 grep mysql /etc/passwdmysql:x:27:27:MySQL Server:/var/lib/mysql:/sbin/nologin</code></pre><p>  将/home/user/db_data目录挂载到db01容器中，以在容器的/var/lib/mysql目录中提供持久存储</p><p>  创建/home/user/db_data目录，并使用podmanunshare命令将27的用户命名空间UID和GID设置为该目录的所有者</p><pre class=" language-language-bash"><code class="language-language-bash">[student@servera ~]$ mkdir /home/student/db_data[student@servera ~]$ ll -d /home/student/db_datadrwxr-xr-x. 2 student student 6 Mar  4 00:43 /home/student/db_data[student@servera ~]$ ll -d -n /home/student/db_datadrwxr-xr-x. 2 1000 1000 6 Mar  4 00:43 /home/student/db_data[student@servera ~]$ podman unshare chown 27:27 /home/student/db_data/[student@servera ~]$ ll -d /home/student/db_datadrwxr-xr-x. 2 100026 100026 6 Mar  4 00:43 /home/student/db_data</code></pre><p>  容器中的UID和GID 27映射到主机计算机上的UID和GID100026</p><p>  可使用ll -d命令查看/home/student/db_data目录的所有权来验证映射</p><p>  现在已设置了正确的文件系统级权限，可使用podman run 命令-v选项来挂载目录:</p><pre class=" language-language-bash"><code class="language-language-bash">[student@servera ~]$ podman rm -af41a62ff2efd7f268e52d6f6a0a9b503411824c5f4391b86dae5d3f01376cb896[student@servera ~]$ podman run -d --name db01 -e MYSQL_USER=user -e MYSQL_PASSWORD=pass -e MYSQL_DATABASE=db -v /home/student/db_data/:/var/lib/mysql  utility.lab.example.com/rhel8/mariadb-10354279d1fff7f3b679dd9d4efb7bfa28a626f41f7d07bea50a445ec2392c8cb02# db01容器未在运行[student@servera ~]$ podman ps -aCONTAINER ID  IMAGE                                             COMMAND     CREATED        STATUS                    PORTS       NAMES54279d1fff7f  utility.lab.example.com/rhel8/mariadb-103:latest  run-mysqld  6 minutes ago  Exited (1) 6 minutes ago              db01$ podman run -d --name db01 \-e MYSQL_USER=user \-e MYSQL_PASSWORD=pass \-e MYSQL_DATABASE=db \-e MYSQL_ROOT_PASSWORD=redhat \-v /home/student/db_data/:/var/lib/mysql \utility.lab.example.com/rhel8/mariadb-103</code></pre><p>  podman container logs命令显示/var/lib/mysql/data目录的权限错误：</p><pre class=" language-language-bash"><code class="language-language-bash">[student@servera ~]$ podman container logs db01Warning: Can't detect memory limit from cgroupsWarning: Can't detect number of CPU cores from cgroupsWarning: Can't detect memory limit from cgroupsWarning: Can't detect number of CPU cores from cgroups=> sourcing 20-validate-variables.sh ...=> sourcing 25-validate-replication-variables.sh ...=> sourcing 30-base-config.sh ...---> 05:58:29     Processing basic MySQL configuration files ...=> sourcing 60-replication-config.sh ...=> sourcing 70-s2i-config.sh ...---> 05:58:29     Processing additional arbitrary  MySQL configuration provided by s2i ...=> sourcing 40-paas.cnf ...=> sourcing 50-my-tuning.cnf ...---> 05:58:29     Initializing database ...---> 05:58:29     Running mysql_install_db ...mkdir: cannot create directory '/var/lib/mysql/data': Permission deniedFatal error Can't create database directory '/var/lib/mysql/data'# 发生此错误的原因是，主机上/home/user/db\_data目录中设置的SELinux上下文不正确</code></pre><h2 id="5-4-容器存储的SELinux上下文"><a href="#5-4-容器存储的SELinux上下文" class="headerlink" title="5.4 容器存储的SELinux上下文"></a>5.4 容器存储的SELinux上下文</h2><p>  必须先设置container_file_t SELinux上下文类型，然后才能将该目录作为持久存储挂载到容器。如果目录没有container_file_t SELinux 上下文，则容器无法访问该目录</p><p>  可以将Z选项附加到podman run命令-v选项的参数，以自动设置目录的SELinux上下文</p><p>  /home/student/db_data挂载为/var/lib/mysql目录的持久存储时，可使用podman run -v /home/student/db_data:/var/lib/mysql:Z命令设置该目录的SELinux上下文</p><pre class=" language-language-bash"><code class="language-language-bash">[student@servera ~]$ podman run -d --name db01 -e MYSQL_USER=user -e MYSQL_PASSWORD=pass -e MYSQL_DATABASE=db -v /home/student/db_data/:/var/lib/mysql:Z utility.lab.example.com/rhel8/mariadb-1036195fc399b1f6ae8f5b9d3f436c02bb5d6b093b597949dc968b2a64f6e7d023c[student@servera ~]$ ll -dZ /home/student/db_data/drwxr-xr-x. 3 100026 100026 system_u:object_r:container_file_t:s0:c428,c988 36 Mar  4 01:26 /home/student/db_data/$ podman run -d --name db01 \-e MYSQL_USER=user \-e MYSQL_PASSWORD=pass \-e MYSQL_DATABASE=db \-e MYSQL_ROOT_PASSWORD=redhat \-v /home/student/db_data:/var/lib/mysql:Z utility.lab.example.com/rhel8/mariadb-103</code></pre><h2 id="5-5-分配端口映射到容器"><a href="#5-5-分配端口映射到容器" class="headerlink" title="5.5 分配端口映射到容器"></a>5.5 分配端口映射到容器</h2><p>  要提供对容器的网络访问权限，客户端必须连接到容器主机上的端口，这些端口将网络流量传递到容器中的端口</p><p>  将容器主机上的网络端口映射到容器中的端口时，容器将接收发送到主机网络端口的网络流量</p><p>  例如，可以将容器主机上的13306端口映射到容器上的3306端口，以便与MariaDB容器通信。因此，发送到容器主机端口13306的流量将由容器中运行的MariaDB接收</p><p>  可以使用 podman run命令的-p选项设置从容器主机上13306端口到db01容器上3306端口的端口映射</p><pre class=" language-language-bash"><code class="language-language-bash">[student@servera ~]$ podman run -d --name db01 -e MYSQL_USER=user -e MYSQL_PASSWORD=pass -e MYSQL_DATABASE=db -v /home/student/db_data/:/var/lib/mysql:Z -p 13306:3306 utility.lab.example.com/rhel8/mariadb-10328202973f22d60ea4ccd096b8a321b30c7d57156a2c41d2502c1a0456c794ced[student@servera ~]$ podman ps -aCONTAINER ID  IMAGE                                             COMMAND     CREATED         STATUS         PORTS                    NAMES28202973f22d  utility.lab.example.com/rhel8/mariadb-103:latest  run-mysqld  20 seconds ago  Up 20 seconds  0.0.0.0:13306->3306/tcp  db01$ podman run -d --name db01 \-e MYSQL_USER=user \-e MYSQL_PASSWORD=pass \-e MYSQL_DATABASE=db \-e MYSQL_ROOT_PASSWORD=redhat \-p 13306:3306 \-v /home/student/db_data:/var/lib/mysql:Z \utility.lab.example.com/rhel8/mariadb-103</code></pre><p>  使用podman port命令的-a选项可显示正在使用的所有容器端口映射。还可以使用podman port db01命令显示 db01容器的映射端口</p><pre class=" language-language-bash"><code class="language-language-bash">[student@servera ~]$ podman port -a28202973f22d    3306/tcp -> 0.0.0.0:13306[student@servera ~]$ podman port db013306/tcp -> 0.0.0.0:13306</code></pre><p>  可使用firewall-cmd命令允许端口13306流量传入容器主机，以便它可以重定向到容器:</p><pre class=" language-language-bash"><code class="language-language-bash"># Rootless(特权)容器无法打开主机上特权端口1024有 以下的端口。比如-p 80:8000 ，比必须使用root才可以对其进行调整[student@servera ~]$ sudo firewall-cmd --permanent --add-port=13306/tcp[sudo] password for student: success[student@servera ~]$ sudo firewall-cmd --reloadsuccess[student@servera ~]$ sudo firewall-cmd --list-allpublic (active)  target: default  icmp-block-inversion: no  interfaces: eth0  sources:   services: cockpit dhcpv6-client ssh  ports: 13306/tcp  protocols:   forward: yes  masquerade: no  forward-ports:   source-ports:   icmp-blocks:   rich rules: # firewall-cmd --add-port=13306/tcp --permanent# firewall-cmd --reload</code></pre><h2 id="5-6-容器的网络后端"><a href="#5-6-容器的网络后端" class="headerlink" title="5.6 容器的网络后端"></a>5.6 容器的网络后端</h2><p>  Podmanv4.0支持两种容器网络后端，即Netavark和CNI</p><p>  自RHEL9起，系统默认使用Netavark。若要验证所用的网络后端，请运行以下podman info命令</p><p>  <a href="https://docs.redhat.com/zh_hans/documentation/red_hat_enterprise_linux/9/html/building_running_and_managing_containers/proc_switching-the-network-stack-from-cni-to-netavark_assembly_setting-container-network-modes">将网络堆栈从 CNI 切换到 Netavark | Red Hat Product Documentation</a></p><pre class=" language-language-bash"><code class="language-language-bash">$ podman info --format {{.Host.NetworkBackend}}netavark</code></pre><p>  主机上使用默认Podman网络的现有容器无法解析彼此的主机名，因为默认网络上未启用DNS</p><p>  使用podman network create命令创建一个支持DNS的网络：</p><p>   使用podman network create命令创建名为db_net的网络，并将子网指定为10.87.0.0/16，网关指定为10.87.0.1</p><pre class=" language-language-bash"><code class="language-language-bash">$ podman network create --gateway 10.87.0.1 --subnet 10.87.0.0/16 db_net$ podman network ls # 列出容器网络</code></pre><p>  如果不指定–gateway 或–subnet 选项，则会使用默认值创建它们</p><p>  podman network inspect 命令显示关于特定网络的信息：</p><p>   可使用podman network inspect 命令验证网关和子网的设置是否正确，以及新的dbnet网络是否启用了DNS</p><pre class=" language-language-bash"><code class="language-language-bash">$ podman network inspect db_net</code></pre><p>  podman run命令–network选项将启用DNS的db_net网络添加到新容器：</p><p>   可使用podman run命令–network选项创建连接到db_net网络的db01和client01容器</p><pre class=" language-language-bash"><code class="language-language-bash">$ podman run -d --name db01 \--network db_net \-e MYSQL_USER=user \-e MYSQL_PASSWORD=pass \-e MYSQL_DATABASE=db \-e MYSQL_ROOT_PASSWORD=redhat \-v /home/student/db_data:/var/lib/mysql:Z \-p 13306:3306 \utility.lab.example.com/rhel8/mariadb-105$ podman run -d --name client01 \--network db_net \-v /etc/yum.repos.d:/etc/yum.repos.d/ \utility.lab.example.com/ubi9-beta/ubi \sleep infinity$ podman ps -a</code></pre><p>  由于容器设计为仅具有所需的最少软件包，因此容器可能不具有测试通信所需的实用程序，如ping和ip命令。可以使用podman exec 命令在容器中安装这些实用程序</p><pre class=" language-language-bash"><code class="language-language-bash">$ podman exec client01 dnf install -y iputils iproute..output omitted..</code></pre><p>  容器现在可以通过容器名称互相ping</p><p>  可以使用podman exec命令来测试DNS解析，名称解析到为db_net网络手动设置的子网内的IP</p><pre class=" language-language-bash"><code class="language-language-bash">$ podman exec client01 ping -c4 db01PING db01.dns.podman (10.87.0.2) 56(84) bytes of data.64 bytes from 10.87.0.2 (10.87.0.2): icmp_seq=1 ttl=64 time=1.08 ms64 bytes from 10.87.0.2 (10.87.0.2): icmp_seq=2 ttl=64 time=0.082 ms64 bytes from 10.87.0.2 (10.87.0.2): icmp_seq=3 ttl=64 time=0.063 ms64 bytes from 10.87.0.2 (10.87.0.2): icmp_seq=4 ttl=64 time=0.070 ms</code></pre><p>  可以使用 podman exec命令验证每个容器中的IP地址是否与DNS解析匹配</p><pre class=" language-language-bash"><code class="language-language-bash">$ podman exec client01 ip a | grep 10.8    inet 10.87.0.3/16 brd 10.87.255.255 scope global eth0</code></pre><h2 id="5-7-多个网络连接到单个容器"><a href="#5-7-多个网络连接到单个容器" class="headerlink" title="5.7 多个网络连接到单个容器"></a>5.7 多个网络连接到单个容器</h2><p>  多个网络可以同时连接到一个容器，以帮助分隔不同类型的流量</p><p>  可以使用podman network create命令创建backend网络</p><pre class=" language-language-bash"><code class="language-language-bash">$ podman network create backend</code></pre><p>  使用podman network ls 命令查看所有Podman网络</p><pre class=" language-language-bash"><code class="language-language-bash">$ podman network lsNETWORK ID    NAME    DRIVER  a7fea510a6d1  backend bridgefe680efc5276  db01    bridge2f259bab93aa  podman  bridge</code></pre><p>  没有通过podman network create命令的–gateway和–subnet选项指定子网和网关，使用podman network inspect命令获取backend<br>网络的IP信息</p><pre class=" language-language-bash"><code class="language-language-bash">$ podman network inspect backend</code></pre><p>  在容器运行时，可以使用podman network connect命令将其他网络连接到容器</p><p>  可以使用podman network connect命令，将backend网络连接到db01和client01容器</p><pre class=" language-language-bash"><code class="language-language-bash">$ podman network connect backend db01$ podman network connect backend client01</code></pre><p>  可以使用podman inspect命令验证两个网络是否都已连接到各个容器并显示IP信息</p><pre class=" language-language-bash"><code class="language-language-bash">$ podman inspect db01$ podman inspect db01 | grep -A 34 Networks > db01$ cat db01  #查看db01的两个网络IP为10.89.0.2 ， 10.87.0.2</code></pre><p>  client01容器现在可以与两个网络上的db01容器通信，可以使用podman exec命令从cliento1容器pingdb01容器上的两个网络</p><pre class=" language-language-bash"><code class="language-language-bash">$ podman exec -ti client01 ping -c4 10.89.0.2PING 10.89.0.2 (10.89.0.2) 56(84) bytes of data.64 bytes from 10.89.0.2: icmp_seq=1 ttl=64 time=0.352 ms$ podman exec -ti client01 ping -c4 10.87.0.2PING 10.87.0.2 (10.87.0.2) 56(84) bytes of data.64 bytes from 10.87.0.2: icmp_seq=1 ttl=64 time=0.594 ms</code></pre><p>  容器内安装mariadb客户端访问容器数据库</p><pre class=" language-language-bash"><code class="language-language-bash">$ podman exec client01 dnf -y install mariadbpodman$ podman exec -ti client01 mysql -u user -ppass -h db01</code></pre><h1 id="6-系统服务管理容器"><a href="#6-系统服务管理容器" class="headerlink" title="6 系统服务管理容器"></a>6 系统服务管理容器</h1><h2 id="6-1-systemd管理小型容器"><a href="#6-1-systemd管理小型容器" class="headerlink" title="6.1 systemd管理小型容器"></a>6.1 systemd管理小型容器</h2><p>  可以运行容器来完成系统任务、获取一系列命令的输出，可能还希望运行无限期运行服务的容器，如Web服务器或数据库</p><p>  在传统环境中，特权用户通常将这些服务配置为在系统启动时运行，并使用systemctl命令进行管理</p><p>  普通用户可以创建systemd单元来配置您的Rootless容器。利用此配置，可以通过systemctl命令将容器作为常规系统服务进行管理</p><p>  基于systemd单元管理容器主要用于不需要扩展的基本和小型部署</p><p>  对于许多基于容器的应用和服务的更复杂扩展和编排，可以使用基于Kubernetes的企业编排平台，如红帽OpenShift容器平台</p><h2 id="6-2-systemd用户服务要求"><a href="#6-2-systemd用户服务要求" class="headerlink" title="6.2 systemd用户服务要求"></a>6.2 systemd用户服务要求</h2><p>  普通用户可以使用systemctl命令来启用服务，该服务在打开会话(图形界面、文本控制台或SSH)时启动，并在关闭最后一个会话时停止。</p><p>此行为与系统服务有所不同，系统服务是在系统启动时启动并在系统关机时停止</p><p>  默认情况下，当使用useradd命令创建用户帐户时，系统将使用普通用户ID范围中的下一个可用ID</p><p>  系统在/etc/subuid文件中为用户的容器保留一系列ID</p><p>  如果使用useradd命令–system选项创建用户帐户，系统不会为用户容器保留范围。因此，无法使用系统帐户启动Rootless容器</p><p>  创建一个专门的用户帐户来管理容器，使用useradd命令创建appdev-adm用户，并将redhat用作密码</p><pre class=" language-language-bash"><code class="language-language-bash">[student@servera ~]$ sudo useradd appdev-adm[sudo] password for student:student[student@servera ~]$ sudo passwd appdev-admChanging password for user appdev-adm.New password:BAD PASSWORD: The password is shorter than 8 charactersRetype new password:passwd: all authentication tokens updated successfully.</code></pre><p>  使用su命令切换到appdev-adm用户，并使用podman命令来启动</p><pre class=" language-language-bash"><code class="language-language-bash">[student@servera ~]$ su appdev-admPassword:redhat[appdev-adm@servera student]$ podman infoERRO[0000] XDG_RUNTIME_DIR directory "/run/user/1000" is not owned by the current user[root@servera ~]# su appdev-adm[appdev-adm@servera root]$ podman infoERRO[0000] XDG_RUNTIME_DIR directory "/run/user/0" is not owned by the current user</code></pre><p>  Podman是一款无状态实用程序，需要完整的登录会话</p><p>  Podman必须在SSH会话中使用，不能在sudo或su shell中使用。因此，将退出su shell，并通过SSH登录计算机</p><p>  无状态应用：</p><p>   Stateless Application指不会在会话中保存下次会话中去要的客户端数据，每个会话都像首次执行一样,不会依赖之前的数据进行响应</p><pre class=" language-language-bash"><code class="language-language-bash">[appdev-adm@servera root]$ exitexit[root@servera ~]# ssh appdev-adm@localhostappdev-adm@localhost's password:Register this system with Red Hat Insights: insights-client --registerCreate an account or view all your systems at https://red.ht/insights-dashboardLast login: Tue Mar  4 09:06:27 2025[appdev-adm@servera ~]$ podman info[appdev-adm@servera ~]$ podman login -u admin -p redhat321 utility.lab.example.comLogin Succeeded![appdev-adm@servera ~]$ podman search utility.lab.example.com/</code></pre><p>  配置容器注册表并使用您的凭据进行身份验证，可以使用以下命令运行http容器</p><pre class=" language-language-bash"><code class="language-language-bash">[appdev-adm@servera ~]$ mkdir /home/appdev-adm/nginx_web/[appdev-adm@servera ~]$ echo nginx_web_page > /home/appdev-adm/nginx_web/index.html[appdev-adm@servera ~]$ cat /home/appdev-adm/nginx_web/index.htmlnginx_web_page[appdev-adm@servera ~]$ podman run -d --name nginx -v /home/appdev-adm/nginx_web/:/usr/share/nginx/html/:Z -p 8080:80 utility.lab.example.com/library/nginx[appdev-adm@servera ~]$ podman ps -aCONTAINER ID  IMAGE                                         COMMAND               CREATED        STATUS        PORTS                 NAMES6f72fe3fc6d7  utility.lab.example.com/library/nginx:latest  nginx -g daemon o...  2 minutes ago  Up 2 minutes  0.0.0.0:8080->80/tcp  nginx[appdev-adm@servera ~]$ curl localhost:8080nginx_web_page</code></pre><h3 id="6-2-1-创建systemd用户文件"><a href="#6-2-1-创建systemd用户文件" class="headerlink" title="6.2.1 创建systemd用户文件"></a>6.2.1 创建systemd用户文件</h3><p>  在~/.confiq/svstemd/user/目录中手动定义systemd服务</p><p>  用户服务的文件语法与系统服务文件的相同，详细信息可查看systemd.unit(5)和systemd.service(5)man手册</p><p>  podman generate systemd命令为现有容器生成systemd服务文件，podman generate systemd命令使用容器作为模型创建配置文件</p><p>  podman generate systemd命令的–new选项指示podman实用程序对systemd服务进行配置，以便在该服务启动时创建容器并在该服务停止时删除容器</p><p>  使用podman generate systemd命令和–name选项来显示为nginx容器建模的systemd服务文件</p><pre class=" language-language-bash"><code class="language-language-bash">[appdev-adm@servera ~]$ man systemd.unit | grep config.*user       ~/.config/systemd/user.control/*       ~/.config/systemd/user/*       │~/.config/systemd/user.control                    │ using the dbus API ($XDG_CONFIG_HOME is used if   │       │$HOME/.config/systemd/user                        │ set, ~/.config otherwise)                         │[appdev-adm@servera ~]$ man systemd.unit[appdev-adm@servera ~]$ mkdir -p ~/.config/systemd/user/[appdev-adm@servera ~]$ cd ~/.config/systemd/user/[appdev-adm@servera ~]$ podman stop nginx        # 生成单元文件之前先停止容器nginx[appdev-adm@servera user]$ podman generate systemd -n nginx -f/home/appdev-adm/.config/systemd/user/container-nginx.service[appdev-adm@servera user]$ lscontainer-nginx.service[appdev-adm@servera user]$ systemctl --user enable --now container-nginx.serviceCreated symlink /home/appdev-adm/.config/systemd/user/default.target.wants/container-nginx.service → /home/appdev-adm/.config/systemd/user/container-nginx.service.[appdev-adm@servera ~]$ podman ps -aCONTAINER ID  IMAGE                                         COMMAND               CREATED         STATUS             PORTS                 NAMES6f72fe3fc6d7  utility.lab.example.com/library/nginx:latest  nginx -g daemon o...  26 minutes ago  Up About a minute  0.0.0.0:8080->80/tcp  nginx[appdev-adm@servera user]$ systemctl --user stop container-nginx.service[appdev-adm@servera ~]$ podman ps -aCONTAINER ID  IMAGE                                         COMMAND               CREATED         STATUS                     PORTS                 NAMES6f72fe3fc6d7  utility.lab.example.com/library/nginx:latest  nginx -g daemon o...  27 minutes ago  Exited (0) 16 seconds ago  0.0.0.0:8080->80/tcp  nginx[appdev-adm@servera user]$ systemctl --user restart container-nginx.service$ podman generate systemd -n nginxExecStart=/usr/bin/podman start nginxExecStop=/usr/bin/podman stop -t 10 nginx*$ podman generate systemd -n nginx -f$ lscontainer-nginx.service</code></pre><p>  启动时，systemd守护进程执行podman start命令来启动现有容器</p><p>  停止时，systemd守护进程执行podman stop命令来停止容器，systemd守护进程不会删除该容器</p><p>  使用上一命令并加上–new选项来比较systemd配置</p><pre class=" language-language-bash"><code class="language-language-bash">$ podman generate systemd -n nginx --newExecStartPre=/bin/rm -f %t/%n.ctr-idExecStart=/usr/bin/podman run --cidfile=%t/%n.ctr-id --cgroups=no-conmon --rm --sdnotify=conmon --replace -d --name nginx -p 8080:80 -v /home/appdev-adm/nginx_web/:/usr/share/nginx/html/:Z utility.lab.example.com/library/nginxExecStop=/usr/bin/podman stop --ignore --cidfile=%t/%n.ctr-idExecStopPost=/usr/bin/podman rm -f --ignore --cidfile=%t/%n.ctr-id#通过--new选项创建用户单元文件的方法，仅供参考$ cd ~/.config/systemd/user/$ podman generate systemd -n nginx --new -f/home/appdev-adm/.config/systemd/user/container-nginx.service</code></pre><p>  启动时，systemd守护进程执行podman run命令创建并启动新容器。此操作使用podman run命令的–rm选项，将在停止时删除容器</p><p>  停止时，systemd 执行podman stop命令以停止容器</p><p>  在systemd停止容器后，systemd将使用podman rm -f命令将其移除</p><p>  验证podman generate systemd命令的输出，并使用–files选项运行上一命令，以在当前目录中创建systemd用户文件。由于nginx容器使用持久存储，因此选择使用带有–new选项的podman generate systemd命令。然后创建~/config/systemd/user/目录并将文件移到此位置上</p><h3 id="6-2-2-管理systemd用户文件"><a href="#6-2-2-管理systemd用户文件" class="headerlink" title="6.2.2 管理systemd用户文件"></a>6.2.2 管理systemd用户文件</h3><p>  现在已创建了systemd用户文件，可以使用systemctl命令的–user选项来管理nginx容器</p><p>  首先，重新加载systemd守护进程，使systemctl命令知道新的用户文件：</p><p>   使用systemctl–user start命令启动nginx容器</p><p>   使用为容器生成的systemd用户文件的名称</p><pre class=" language-language-bash"><code class="language-language-bash">$ systemctl --user enable --now container-nginx.service#其他的管理方法，仅供参考$ systemctl --user status container-nginx.service$ systemctl --user stop container-nginx.service#建议重启验证容器是否可以 开机自启动</code></pre><p>  systemd 系统和用户服务之间使用的不同目录和命令：</p><pre class=" language-language-bash"><code class="language-language-bash">1.存储自定义单元文件     系统服务   /etc/systemd/system/unit.service                       用户服务   \~/.config/systemd/user/unit.service                         2.重新加载单元文件       系统服务   \# systemctl daemon-reload                       用户服务   \$ systemctl --user daemon-reload                       3.启动和停止服务         系统服务   \# systemctl start UNIT                                     \# systemctl stop UNIT                       用户服务   \$ systemctl --user start UNIT                                    \$ systemctl --user stop UNIT                     4.在计算机启动时启动服务  系统服务   \# systemctl enable UNIT                       用户服务   \$ loginctl enable-linger                                   \$ systemctl --user enable UNIT                    </code></pre><hr><h3 id="6-2-3-配置为系统引导时启动"><a href="#6-2-3-配置为系统引导时启动" class="headerlink" title="6.2.3 配置为系统引导时启动"></a>6.2.3 配置为系统引导时启动</h3><p>  此时systemd服务配置已就绪，可以为给定的用户运行容器。但是，如果用户从系统注销，systemd服务会在特定时间后停止容器。出现此行为的原因是，systemd服务单元是使用.user选项创建的，它在用户登录时启动服务，并在用户注销时停止服务</p><p>  可以通过运行loginctl enable-linger命令来更改此默认行为，并强制已启用的服务在服务器启动时启动，并在服务器关闭期间停止。使用loginctl命令将systemd用户服务配置为在所配置服务的最后一个用户会话关闭后保留</p><p>  使用 loginctl show-user 命令验证配置是否成功。</p><pre class=" language-language-bash"><code class="language-language-bash">[appdev-adm@servera ~]$ loginctl show-user appdev-admLinger=no[appdev-adm@servera ~]$ loginctl enable-linger[appdev-adm@servera ~]$ loginctl show-user appdev-admLinger=yes# 重启后进行测试[kiosk@foundation0 ~]$ ssh root@servera[root@servera ~]# ssh appdev-adm@localhost[appdev-adm@servera ~]$ podman ps -aCONTAINER ID  IMAGE                                         COMMAND               CREATED         STATUS             PORTS                 NAMES6f72fe3fc6d7  utility.lab.example.com/library/nginx:latest  nginx -g daemon o...  40 minutes ago  Up About a minute  0.0.0.0:8080->80/tcp  nginx</code></pre><h3 id="6-2-4-Root使用Systemd管理容器"><a href="#6-2-4-Root使用Systemd管理容器" class="headerlink" title="6.2.4 Root使用Systemd管理容器"></a>6.2.4 Root使用Systemd管理容器</h3><p>  将容器配置为以root身份运行，并使用systemd服务文件进行管理的优势是可以将这些服务文件配置为像常见systemd单元文件那样工作，而不是以特定用户身份来运行</p><p>  将服务文件设置为root的过程与前面概述的Rootless容器过程类似，但以下例外:</p><p>   1.不要创建专门的用户来管理容器</p><p>   2.服务文件必须在/etc/systemd/system目录中，而不是在~/config/systemd/user目录中</p><p>   3.使用systemctl命令管理容器，但不使用–user选项，不要以root用户身份运行loginctl enable-linger命令</p>]]></content>
      
      
      <categories>
          
          <category> 容器技术 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> podman容器 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker容器&amp;Kubernetes</title>
      <link href="/2025/05/28/kubernetes/docker-rong-qi-k8s/"/>
      <url>/2025/05/28/kubernetes/docker-rong-qi-k8s/</url>
      
        <content type="html"><![CDATA[<h1 id="1-微服务"><a href="#1-微服务" class="headerlink" title="1 微服务"></a>1 微服务</h1><p>  把一个庞大的应用拆成几个小的独立的服务，再把独立的服务串起来的一种架构设计:内聚更强，更加敏捷</p><p><img src="/images/%E5%BE%AE%E6%9C%8D%E5%8A%A1.png"></p><h2 id="1-1-应用架构的发展"><a href="#1-1-应用架构的发展" class="headerlink" title="1.1 应用架构的发展"></a>1.1 应用架构的发展</h2><p><img src="/images/%E5%BA%94%E7%94%A8%E6%9E%B6%E6%9E%84%E7%9A%84%E5%8F%91%E5%B1%95.png"></p><h2 id="1-2-传统单体架构vs微服务软件架构"><a href="#1-2-传统单体架构vs微服务软件架构" class="headerlink" title="1.2 传统单体架构vs微服务软件架构"></a>1.2 传统单体架构vs微服务软件架构</h2><p>  不同于微服务，传统的项目会包含很多功能，是一个大而全的“超级”工程</p><p>  例如：以普通架构方式实现的电商平台包含：登录、权限、会员、商品库存、订单、收藏、关注、购物车等功能的多个单一项目。随着项目业务越来越复杂、开发人员越来越多，相应开发、编译、部署、技术扩展、水平扩展都会受到限制</p><p><img src="/images/%E4%BC%A0%E7%BB%9F%E5%8D%95%E4%BD%93%E6%9E%B6%E6%9E%84vs%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84.png"></p><h2 id="1-3-基于微服务的系统架构"><a href="#1-3-基于微服务的系统架构" class="headerlink" title="1.3 基于微服务的系统架构"></a>1.3 基于微服务的系统架构</h2><p><img src="/images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84.png"></p><p>  核心思路是拆分</p><p>  单体项目的问题，通过把项目拆分成一个个小项目就可以解决</p><h2 id="1-4-微服务的特征"><a href="#1-4-微服务的特征" class="headerlink" title="1.4 微服务的特征"></a>1.4 微服务的特征</h2><p><img src="/images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%9A%84%E7%89%B9%E5%BE%81.png"></p><h2 id="1-5-单体架构"><a href="#1-5-单体架构" class="headerlink" title="1.5 单体架构"></a>1.5 单体架构</h2><p>  紧耦合面临的问题：故障影响范围大、变更成本高、无法支持大规模计算</p><p><img src="/images/%E5%8D%95%E4%BD%93%E6%9E%B6%E6%9E%84.png"></p><p>  如果需要加入模块C，需要更改模块A、B的代码，需要各个系统人员协调处理</p><h2 id="1-6-解耦架构"><a href="#1-6-解耦架构" class="headerlink" title="1.6 解耦架构"></a>1.6 解耦架构</h2><p><img src="/images/%E8%A7%A3%E8%80%A6%E6%9E%B6%E6%9E%84.png"></p><p>  解耦架构的优势：</p><p>  1.模块化，缩小故障范围</p><p>  2.降低变更成本，插入新模块不影响其他模块</p><p>  3.开发人员协作更简单</p><p>  4.易于扩展</p><h2 id="1-7-消息队列"><a href="#1-7-消息队列" class="headerlink" title="1.7 消息队列"></a>1.7 消息队列</h2><h3 id="1-7-1-传统架构"><a href="#1-7-1-传统架构" class="headerlink" title="1.7.1 传统架构"></a>1.7.1 传统架构</h3><p><img src="/images/%E4%BC%A0%E7%BB%9F%E6%9E%B6%E6%9E%84.png"></p><h3 id="1-7-2-消息队列架构"><a href="#1-7-2-消息队列架构" class="headerlink" title="1.7.2 消息队列架构"></a>1.7.2 消息队列架构</h3><p><img src="/images/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E6%9E%B6%E6%9E%84.png"></p><h2 id="1-8-微服务面临的挑战"><a href="#1-8-微服务面临的挑战" class="headerlink" title="1.8 微服务面临的挑战"></a>1.8 微服务面临的挑战</h2><table><thead><tr><th></th><th>单体架构</th><th>微服务架构</th></tr></thead><tbody><tr><td>迭代速度</td><td>较慢</td><td>快</td></tr><tr><td>部署频率</td><td>不经常部署</td><td>经常发布</td></tr><tr><td>系统性能</td><td>吞吐量小</td><td>吞吐量大</td></tr><tr><td>系统扩展性</td><td>扩展性差</td><td>扩展性好</td></tr><tr><td>技术栈多样性</td><td>单一、封闭</td><td>多样、开放</td></tr><tr><td>运维</td><td>简单</td><td>运维复杂</td></tr><tr><td>部署难度</td><td>容易部署</td><td>较难部署</td></tr><tr><td>架构复杂度</td><td>较小</td><td>复杂度高</td></tr><tr><td>查错</td><td>简单</td><td>定位问题较难</td></tr><tr><td>管理成本</td><td>主要在于开发成本</td><td>服务治理、运维</td></tr></tbody></table><h2 id="1-9-虚拟机与容器的比较"><a href="#1-9-虚拟机与容器的比较" class="headerlink" title="1.9 虚拟机与容器的比较"></a>1.9 虚拟机与容器的比较</h2><p><img src="/images/%E8%99%9A%E6%8B%9F%E6%9C%BAvs%E5%AE%B9%E5%99%A8.png"></p><table><thead><tr><th>对比模块</th><th>虚拟机</th><th>容器</th></tr></thead><tbody><tr><td>占用空间</td><td>非常大，GB级别</td><td>小，MB/KB级别</td></tr><tr><td>启用速度</td><td>慢，分钟级</td><td>快，秒级</td></tr><tr><td>运行形态</td><td>运行于Hypervisor</td><td>直接运行在宿主机内核上</td></tr><tr><td>并发性</td><td>一台宿主机上十几个，最多几 十个</td><td>上百个，甚至数百个</td></tr><tr><td>性能</td><td>低于宿主机</td><td>接近于宿主机本地进程</td></tr><tr><td>资源利用率</td><td>低</td><td>高</td></tr></tbody></table><h1 id="2-容器的基本使用"><a href="#2-容器的基本使用" class="headerlink" title="2 容器的基本使用"></a>2 容器的基本使用</h1><h2 id="2-1-容器介绍"><a href="#2-1-容器介绍" class="headerlink" title="2.1 容器介绍"></a>2.1 容器介绍</h2><p>  容器是一个可以在共享的操作系统上将应用程序以指定格式打包并运行在一个与操作系统相关联的环境中的方法</p><p>  和虚拟机相比，容器并不会打包整个操作系统，而只是打包应用程序所必须的库和设置，这将使得容器具备高效率、轻量化、系统隔离性，以上特性将会确保无论在何处部署，容器每次运行都会完全一致</p><p>  容器工具：Rkt、Containerd、Docker、Podman</p><h2 id="2-2-部署Docker"><a href="#2-2-部署Docker" class="headerlink" title="2.2 部署Docker"></a>2.2 部署Docker</h2><p>  从南京大学开源镜像站在Ubuntu上安装docker</p><p><img src="/images/docker%E5%AE%89%E8%A3%85.png"></p><h3 id="2-2-1-安装依赖"><a href="#2-2-1-安装依赖" class="headerlink" title="2.2.1 安装依赖"></a>2.2.1 安装依赖</h3><pre class=" language-language-bash"><code class="language-language-bash"># 检测系统是否安装了dockerroot@k8s-master:~# for pkg in docker.io docker-doc docker-compose podman-docker containerd runc; do sudo apt-get remove $pkg; done# 安装依赖root@k8s-master:~# sudo apt-get updateroot@k8s-master:~# sudo apt-get install ca-certificates curl gnupg</code></pre><h3 id="2-2-2-安装GPG公钥"><a href="#2-2-2-安装GPG公钥" class="headerlink" title="2.2.2 安装GPG公钥"></a>2.2.2 安装GPG公钥</h3><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# sudo install -m 0755 -d /etc/apt/keyringsroot@k8s-master:~# curl -fsSL https://mirror.nju.edu.cn/docker-ce/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpgroot@k8s-master:~# sudo chmod a+r /etc/apt/keyrings/docker.gpg</code></pre><h3 id="2-2-3-添加Docker仓库"><a href="#2-2-3-添加Docker仓库" class="headerlink" title="2.2.3 添加Docker仓库"></a>2.2.3 添加Docker仓库</h3><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# echo \  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://mirror.nju.edu.cn/docker-ce/linux/ubuntu \  "$(. /etc/os-release && echo "$VERSION_CODENAME")" stable" | \  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null</code></pre><h3 id="2-2-4-安装Docker"><a href="#2-2-4-安装Docker" class="headerlink" title="2.2.4 安装Docker"></a>2.2.4 安装Docker</h3><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# sudo apt-get updateroot@k8s-master:~# sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin# 拉取失败，因此在中国需要加速器root@k8s-master:~# sudo docker run hello-worldUnable to find image 'hello-world:latest' locallydocker: Error response from daemon: Get "https://registry-1.docker.io/v2/": context deadline exceeded (Client.Timeout exceeded while awaiting headers)Run 'docker run --help' for more information</code></pre><h3 id="2-2-5-Docker镜像加速器"><a href="#2-2-5-Docker镜像加速器" class="headerlink" title="2.2.5 Docker镜像加速器"></a>2.2.5 Docker镜像加速器</h3><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# mkdir -p /etc/dockerroot@k8s-master:~# cd /etc/dockerroot@k8s-master:/etc/docker# vim daemon.json{  "registry-mirrors": [        "https://docker.mirrors.ustc.edu.cn",        "https://mirror.baidubce.com",        "https://docker.m.daocloud.io",        "https://mirror.ccs.tencentyun.com",        "https://docker.nju.edu.cn",        "https://docker.mirrors.sjtug.sjtu.edu.cn",        "https://mirror.gcr.io",        "https://docker.registry.cyou",        "https://docker-cf.registry.cyou",        "https://dockercf.jsdelivr.fyi",        "https://docker.jsdelivr.fyi",        "https://dockertest.jsdelivr.fyi",        "https://mirror.aliyuncs.com",        "https://dockerproxy.com"  ],  "exec-opts": ["native.cgroupdriver=systemd"]}root@k8s-master:~# systemctl daemon-reloadroot@k8s-master:~# systemctl restart dockerroot@k8s-master:~# sudo docker pull hello-worldUsing default tag: latestlatest: Pulling from library/hello-worldDigest: sha256:c41088499908a59aae84b0a49c70e86f4731e588a737f1637e73c8c09d995654Status: Image is up to date for hello-world:latestdocker.io/library/hello-world:latestroot@k8s-master:~# docker imagesREPOSITORY    TAG       IMAGE ID       CREATED        SIZEhello-world   latest    74cc54e27dc4   3 months ago   10.1kB</code></pre><h3 id="2-2-6-重启Docker服务"><a href="#2-2-6-重启Docker服务" class="headerlink" title="2.2.6 重启Docker服务"></a>2.2.6 重启Docker服务</h3><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# systemctl restart dockerroot@k8s-master:~# docker infoClient: Docker Engine - Community Version:    28.1.1 Context:    default Debug Mode: false Plugins:  buildx: Docker Buildx (Docker Inc.)    Version:  v0.23.0    Path:     /usr/libexec/docker/cli-plugins/docker-buildx  compose: Docker Compose (Docker Inc.)    Version:  v2.35.1    Path:     /usr/libexec/docker/cli-plugins/docker-composeServer: Containers: 2  Running: 1  Paused: 0  Stopped: 1 Images: 2 Server Version: 28.1.1 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Using metacopy: false  Native Overlay Diff: true  userxattr: false Logging Driver: json-file Cgroup Driver: systemd Cgroup Version: 2 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 runc Default Runtime: runc Init Binary: docker-init containerd version: 05044ec0a9a75232cad458027ca83437aae3f4da runc version: v1.2.5-0-g59923ef init version: de40ad0 Security Options:  apparmor  seccomp   Profile: builtin  cgroupns Kernel Version: 6.8.0-53-generic Operating System: Ubuntu 24.04.2 LTS OSType: linux Architecture: x86_64 CPUs: 2 Total Memory: 3.777GiB Name: k8s-master ID: 6c5b4dc6-423d-47e6-a687-e75062cf4fd9 Docker Root Dir: /var/lib/docker Debug Mode: false Experimental: false Insecure Registries:  ::1/128  127.0.0.0/8 Registry Mirrors:  https://docker.mirrors.ustc.edu.cn/  https://mirror.baidubce.com/  https://docker.m.daocloud.io/  https://mirror.ccs.tencentyun.com/  https://docker.nju.edu.cn/  https://docker.mirrors.sjtug.sjtu.edu.cn/  https://mirror.gcr.io/  https://docker.registry.cyou/  https://docker-cf.registry.cyou/  https://dockercf.jsdelivr.fyi/  https://docker.jsdelivr.fyi/  https://dockertest.jsdelivr.fyi/  https://mirror.aliyuncs.com/  https://dockerproxy.com/</code></pre><h2 id="2-3-操作容器"><a href="#2-3-操作容器" class="headerlink" title="2.3 操作容器"></a>2.3 操作容器</h2><h3 id="2-3-1-创建持续运行的容器"><a href="#2-3-1-创建持续运行的容器" class="headerlink" title="2.3.1 创建持续运行的容器"></a>2.3.1 创建持续运行的容器</h3><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# docker run -d --name nginxtest nginxroot@k8s-master:~# docker psCONTAINER ID   IMAGE     COMMAND                  CREATED              STATUS              PORTS     NAMESb68184fd3b9b   nginx     "/docker-entrypoint.…"   About a minute ago   Up About a minute   80/tcp  nginxtestroot@k8s-master:~# docker ps -aCONTAINER ID   IMAGE    COMMAND                  CREATED              STATUS               PORTS     NAMESb68184fd3b9b   nginx    "/docker-entrypoint.…"   About a minute ago   Up About a minute     80/tcp  nginxtest8ea8394296ac   hello-world   "/hello"            22 minutes ago    Exited (0) 22 minutes ago   goofy_brattain</code></pre><h3 id="2-3-2-进入容器"><a href="#2-3-2-进入容器" class="headerlink" title="2.3.2 进入容器"></a>2.3.2 进入容器</h3><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# docker exec -it nginxtest /bin/bashroot@b68184fd3b9b:/# cat /etc/nginx/nginx.confroot@b68184fd3b9b:/# exitexitroot@k8s-master:~## @后的主机名在exec后发生了变化，这就是进入容器内的标志</code></pre><h3 id="2-3-3-删除容器"><a href="#2-3-3-删除容器" class="headerlink" title="2.3.3 删除容器"></a>2.3.3 删除容器</h3><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# docker psCONTAINER ID   IMAGE      COMMAND                  CREATED         STATUS        PORTS       NAMES260028d6b4a2   httpd:v1   "httpd-foreground"       5 seconds ago   Up 4 seconds   0.0.0.0:4000->80/tcp, [::]:4000->80/tcp   luoyudockerfileb68184fd3b9b   nginx      "/docker-entrypoint.…"   12 hours ago    Up 12 hours    80/tcp    nginxtestroot@k8s-master:~# docker rm -f nginxtest luoyudockerfilenginxtestluoyudockerfileroot@k8s-master:~# docker psCONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES</code></pre><h2 id="2-4-构建-使用镜像"><a href="#2-4-构建-使用镜像" class="headerlink" title="2.4 构建&amp;使用镜像"></a>2.4 构建&amp;使用镜像</h2><h3 id="2-4-1-镜像概述"><a href="#2-4-1-镜像概述" class="headerlink" title="2.4.1 镜像概述"></a>2.4.1 镜像概述</h3><p>  镜像是一个用于创建容器的只读模板，通常来讲，包含一些额外的自定义，比如说，可以构建一个基于centos的镜像，在镜像构建时，直接包含一些应用程序，比如Apache或者其他程序，构建完成后，可以直接基于这个镜像启动容器，快速获得期望的业务</p><p>  镜像可以来自公共的仓库，也可通过Dockerfile等定义文件来构建，并且把自己的镜像推送到仓库中，以备在任何地方任何时间下载使用</p><h3 id="2-4-2-公共镜像仓库"><a href="#2-4-2-公共镜像仓库" class="headerlink" title="2.4.2 公共镜像仓库"></a>2.4.2 公共镜像仓库</h3><p>  Docker公共镜像仓库：<a href="https://hub.docker.com/">https://hub.docker.com</a></p><p>  Docker Hub是一个基于云端的registry服务，这个服务允许我们连接仓库代码、建立镜像、 推送镜像等功能，提供了一个集中式的容器资源管理平台，包含了各式各样的官方镜像，例如Apache、Centos以及各种企业级应用镜像，还以星级和评分来确保镜像的可靠性和适用性</p><p><img src="/images/%E5%85%AC%E5%85%B1%E9%95%9C%E5%83%8F%E5%BA%93.png"></p><p>  打开<a href="https://hub.docker.com,注册一个docker/">https://hub.docker.com，注册一个Docker</a> ID，登陆后浏览各项功能</p><h3 id="2-4-3-镜像分层技术"><a href="#2-4-3-镜像分层技术" class="headerlink" title="2.4.3 镜像分层技术"></a>2.4.3 镜像分层技术</h3><p><img src="/images/%E9%95%9C%E5%83%8F%E5%88%86%E5%B1%82.png"></p><h3 id="2-4-4-构建镜像的方法"><a href="#2-4-4-构建镜像的方法" class="headerlink" title="2.4.4 构建镜像的方法"></a>2.4.4 构建镜像的方法</h3><p>  1.docker commit</p><p>  使用容器中发生更改的部分生成一个新的镜像，通常的使用场景为，基于普通镜像启动了容器，在容器内部署了所需的业务后，把当前的状态重新生成镜像，以便以当前状态快速部署业务所用</p><p>  2.Dockerfile 创建镜像</p><p>  从零开始构建自己所需的镜像，在创建镜像之初把所需的各种设置和所需要的各种应用程序包含进去，生成的镜像可直接用于业务部署</p><p>  3.Dockerfile高频指令集</p><p><img src="/images/dockerfile%E6%8C%87%E4%BB%A4.png"></p><h3 id="2-4-5-Dockerfile-image"><a href="#2-4-5-Dockerfile-image" class="headerlink" title="2.4.5 Dockerfile image"></a>2.4.5 Dockerfile image</h3><p>  在设计Dockerfile时应考虑以下事项：</p><p>  1.容器应该是暂时的</p><p>  2.避免安装不必要的软件包</p><p>  3.每个容器只应该有一个用途</p><p>  4.避免容器有过多的层</p><p>  5.多行排序</p><p>  6.建立缓存</p><pre class=" language-language-bash"><code class="language-language-bash"># 创建dockerfile文件root@k8s-master:~# cat > dockerfile <<EOFFROM httpdMAINTAINER luovipyu@163.comRUN echo hello luoyu dockerfile container > /usr/local/apache2/htdocs/index.htmlEXPOSE 80WORKDIR /usr/local/apache2/htdocs/EOF# 开始构建镜像root@k8s-master:~# docker build -t httpd:v1 -f dockerfile .# 查看docker镜像root@k8s-master:~# docker imagesREPOSITORY    TAG       IMAGE ID       CREATED          SIZEhttpd         v1        d6d24a446dd4   25 seconds ago   148MBnginx         latest    a830707172e8   3 weeks ago      192MBhello-world   latest    74cc54e27dc4   3 months ago     10.1kB注明：如果文件名是Dockerfile时可不指定docker build -t web:v1 .# 如果用的是containerd，dockerfile方式构建容器镜像的命令就是下面这样的nerdctl build  -t httpd:v1 -f dockerfile .nerdctl images</code></pre><h3 id="2-4-6-使用Dockerfile镜像"><a href="#2-4-6-使用Dockerfile镜像" class="headerlink" title="2.4.6 使用Dockerfile镜像"></a>2.4.6 使用Dockerfile镜像</h3><pre class=" language-language-bash"><code class="language-language-bash"># 用httpd:v1的镜像在本机4000端口上提供一个名为luoyudockerfile的容器root@k8s-master:~# docker run -d -p 4000:80 --name luoyudockerfile httpd:v1260028d6b4a2b11cd2cfca9ab6ae9d406cc8fa9afd33131db03c880cc235e68froot@k8s-master:~# docker psCONTAINER ID   IMAGE      COMMAND                  CREATED         STATUS        PORTS       NAMES260028d6b4a2   httpd:v1   "httpd-foreground"       5 seconds ago   Up 4 seconds   0.0.0.0:4000->80/tcp, [::]:4000->80/tcp   luoyudockerfileb68184fd3b9b   nginx      "/docker-entrypoint.…"   12 hours ago    Up 12 hours    80/tcp    nginxtestroot@k8s-master:~# curl http://127.0.0.1:4000hello luoyu dockerfile container# 如果用的是containerd，dockerfile方式构建容器镜像的使用命令就是下面这样的nerdctl run -d -p 4000:80 --name luoyudockerfile httpd:v1nerdctl ps</code></pre><h3 id="2-4-7-关于镜像命名"><a href="#2-4-7-关于镜像命名" class="headerlink" title="2.4.7 关于镜像命名"></a>2.4.7 关于镜像命名</h3><p>  1.镜像命名格式：REPOSITORY+TAG，使用版本号作为命名</p><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# docker imagesREPOSITORY    TAG       IMAGE ID       CREATED        SIZEhttpd         v1        d6d24a446dd4   11 hours ago   148MBnginx         latest    a830707172e8   3 weeks ago    192MBhello-world   latest    74cc54e27dc4   3 months ago   10.1kB</code></pre><p>  2.关于latest tag的说明</p><p>  如果在建立镜像时没有指定Tag，会使用默认值latest，所以，当看到一个镜像的Tag处显示latest的时候，并不一定意味着此版本是最新版，而只意味着在建立镜像的时候，没有指定Tag</p><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# docker build -t web .root@k8s-master:~# docker imagesREPOSITORY    TAG       IMAGE ID       CREATED        SIZEhttpd         v1        d6d24a446dd4   11 hours ago   148MBweb           latest    d6d24a446dd4   11 hours ago   148MBnginx         latest    a830707172e8   3 weeks ago    192MBhello-world   latest    74cc54e27dc4   3 months ago   10.1kB</code></pre><h3 id="2-4-8-删除镜像"><a href="#2-4-8-删除镜像" class="headerlink" title="2.4.8 删除镜像"></a>2.4.8 删除镜像</h3><p>  删除一个特定的镜像，需要知道该镜像的ID或者标签(repository:tag)。或者，如果只记得镜像的部分ID，可以使用这个ID来删除镜像</p><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# docker imagesREPOSITORY    TAG       IMAGE ID       CREATED        SIZEhttpd         v1        d6d24a446dd4   11 hours ago   148MBweb           latest    d6d24a446dd4   11 hours ago   148MBnginx         latest    a830707172e8   3 weeks ago    192MBhello-world   latest    74cc54e27dc4   3 months ago   10.1kBroot@k8s-master:~# docker rmi web:latestUntagged: web:latestroot@k8s-master:~# docker rmi 74cc54e27dc4Error response from daemon: conflict: unable to delete 74cc54e27dc4 (must be forced) - image is being used by stopped container 8ea8394296acroot@k8s-master:~# docker ps -aCONTAINER ID   IMAGE         COMMAND    CREATED        STATUS                    PORTS     NAMES8ea8394296ac   hello-world   "/hello"   13 hours ago   Exited (0) 13 hours ago             goofy_brattainroot@k8s-master:~# docker rm 8ea8394296acroot@k8s-master:~# docker rmi 74cc54e27dc4root@k8s-master:~# docker images\REPOSITORY   TAG       IMAGE ID       CREATED        SIZEhttpd        v1        d6d24a446dd4   11 hours ago   148MBnginx        latest    a830707172e8   3 weeks ago    192MB</code></pre><h3 id="2-4-9-私有镜像仓库"><a href="#2-4-9-私有镜像仓库" class="headerlink" title="2.4.9 私有镜像仓库"></a>2.4.9 私有镜像仓库</h3><p>  构建私有镜像存储考虑：</p><p>  1.交付时效，例如，下载并运行镜像，需要消耗带宽和时间</p><p>  2.机房是否允许接入外网</p><p>  3.镜像私密，不允许将数据放到外网</p><p>  4.内网速率更高</p><p>  什么是Registry？</p><p>  1.Registry是一个无状态、高度可扩展的服务，可以存储和分发镜像</p><p>  2.Registry是一个基于Apache License许可的开源服务</p><p>  为什么使用Registry？</p><p>  1.严格控制映像存储位置</p><p>  2.拥有完全属于自己的镜像分发渠道</p><p>  3.将镜像存储和分布紧密集成到内部开发工作流程中</p><p>  部署Registry步骤如下：如果选用Harbor，请参考Gitee文档</p><p>  1.下载Docker官方最新版的Registry镜像</p><p>  2.启动Registry容器</p><p>  3.下载测试镜像</p><p>  4.将测试镜像上传至自己的私有仓库</p><p>  5.验证从自有仓库下载并启动容器</p><h1 id="3-部署Harbor私有仓库"><a href="#3-部署Harbor私有仓库" class="headerlink" title="3 部署Harbor私有仓库"></a>3 部署Harbor私有仓库</h1><p>  在现代软件开发中，容器化应用已经成为主流，而容器镜像仓库则是确保容器镜像安全、管理和分发的重要工具。Harbor作为一款开源的企业级容器镜像仓库管理工具，不仅支持多种认证方式，还提供镜像复制、漏洞扫描和用户访问控制等功能，为企业提供了一个安全、高效的镜像管理方案</p><table><thead><tr><th>主机名</th><th>角色</th><th>IP</th><th>VMware网络类型</th><th>用户名</th><th>密码</th><th>系统</th></tr></thead><tbody><tr><td>harbor</td><td>Harbor主机</td><td>192.168.8.52</td><td>NAT</td><td>root</td><td>harbor</td><td>RHEL-9.5</td></tr></tbody></table><h2 id="3-1-RedHat9镜像源配置"><a href="#3-1-RedHat9镜像源配置" class="headerlink" title="3.1 RedHat9镜像源配置"></a>3.1 RedHat9镜像源配置</h2><h3 id="3-1-1-国内镜像源"><a href="#3-1-1-国内镜像源" class="headerlink" title="3.1.1 国内镜像源"></a>3.1.1 国内镜像源</h3><pre class=" language-language-bash"><code class="language-language-bash">[root@harbor ~]# cd /etc/yum.repos.d[root@harbor yum.repos.d]# ll-rw-r--r--. 1 root root 358 May 14 11:25 redhat.repo[root@harbor yum.repos.d]# vim aliyun_yum.repo[ali_baseos]name=ali_baseosbaseurl=https://mirrors.aliyun.com/centos-stream/9-stream/BaseOS/x86_64/os/gpgcheck=0[ali_appstream]name=ali_appstreambaseurl=https://mirrors.aliyun.com/centos-stream/9-stream/AppStream/x86_64/os/gpgcheck=0[root@harbor yum.repos.d]# yum makecache# 根据需要选择是否更新yum源[root@harbor yum.repos.d]# yum -y update</code></pre><h3 id="3-1-2-本地yum源配置"><a href="#3-1-2-本地yum源配置" class="headerlink" title="3.1.2 本地yum源配置"></a>3.1.2 本地yum源配置</h3><p>  配置本地yum源可以创建一个本地的软件包存储库，以便更快地安装、更新和管理软件包</p><pre class=" language-language-bash"><code class="language-language-bash"># 创建文件夹并将光盘挂载到新建的文件中[root@harbor ~]# mkdir -p /GuaZai/Iso[root@harbor ~]# mount /dev/sr0 /GuaZai/Isomount: /GuaZai/Iso: WARNING: source write-protected, mounted read-only.[root@harbor ~]# cd /GuaZai/Iso[root@harbor Iso]# lsAppStream  BaseOS  EFI  EULA  extra_files.json  GPL  images  isolinux  media.repo  RPM-GPG-KEY-redhat-beta  RPM-GPG-KEY-redhat-release#配置yum文件[root@harbor ~]# vim /etc/yum.repos.d/rhel9.repo[BaseOS]name=rhel9-BaseOSbaseurl=file:///GuaZai/Iso/BaseOSgpgcheck=0[Appstream]name=rhel9-Appstreambaseurl=file:///GuaZai/Iso/AppStreamgpgcheck=0# 查看仓库序列[root@harbor ~]# yum repolist# 生成yum缓存[root@harbor ~]# yum makecache</code></pre><h2 id="3-2-主机名和IP地址映射"><a href="#3-2-主机名和IP地址映射" class="headerlink" title="3.2 主机名和IP地址映射"></a>3.2 主机名和IP地址映射</h2><p>  配置Harbor主机的主机名和IP地址映射，映射文件“/etc/hosts”加入如下内容</p><pre class=" language-language-bash"><code class="language-language-bash">[root@harbor ~]# vim /etc/hosts192.168.8.52 registry.luovip.cn</code></pre><h2 id="3-3-部署Docker-CE"><a href="#3-3-部署Docker-CE" class="headerlink" title="3.3 部署Docker CE"></a>3.3 部署Docker CE</h2><pre class=" language-language-bash"><code class="language-language-bash"># 检测系统是否安装了docker并卸载旧版本的容器[root@harbor ~]# sudo dnf remove docker \                  docker-client \                  docker-client-latest \                  docker-common \                  docker-latest \                  docker-latest-logrotate \                  docker-logrotate \                  docker-engine \                  podman \                  runc# 安装依赖[root@harbor ~]# sudo yum install -y yum-utils[root@harbor ~]# sudo dnf -y install dnf-plugins-core[root@harbor ~]# sudo dnf config-manager --add-repo https://download.docker.com/linux/rhel/docker-ce.repo# 安装docker[root@harbor ~]# sudo sed -i 's+https://download.docker.com+https://mirror.nju.edu.cn/docker-ce+' /etc/yum.repos.d/docker-ce.repo[root@harbor ~]# sudo yum install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin# 查看docker状态[root@harbor ~]# sudo systemctl enable --now dockerCreated symlink /etc/systemd/system/multi-user.target.wants/docker.service → /usr/lib/systemd/system/docker.service.[root@harbor ~]# sudo systemctl status docker[root@harbor ~]# docker info                         </code></pre><h2 id="3-4-Docker镜像加速器"><a href="#3-4-Docker镜像加速器" class="headerlink" title="3.4 Docker镜像加速器"></a>3.4 Docker镜像加速器</h2><pre class=" language-language-bash"><code class="language-language-bash">[root@harbor ~]# mkdir -p /etc/docker[root@harbor ~]# cd /etc/docker[root@harbor docker]# vim /etc/docker/daemon.json{  "registry-mirrors": [        "https://docker.mirrors.ustc.edu.cn",        "https://mirror.baidubce.com",        "https://docker.m.daocloud.io",        "https://mirror.ccs.tencentyun.com",        "https://docker.nju.edu.cn",        "https://docker.mirrors.sjtug.sjtu.edu.cn",        "https://mirror.gcr.io",        "https://docker.registry.cyou",        "https://docker-cf.registry.cyou",        "https://dockercf.jsdelivr.fyi",        "https://docker.jsdelivr.fyi",        "https://dockertest.jsdelivr.fyi",        "https://mirror.aliyuncs.com",        "https://dockerproxy.com"  ],  "data-root": "/data/docker"   # 自定义Docker的镜像存储路径}[root@harbor ~]# mkdir -p /data/docker[root@harbor ~]# cp -a /var/lib/docker/* /data/docker/[root@harbor ~]# systemctl daemon-reload[root@harbor ~]# systemctl restart docker[root@harbor ~]# docker info# 测试[root@harbor ~]# docker pull nginx[root@harbor ~]# docker imagesREPOSITORY   TAG       IMAGE ID       CREATED       SIZEnginx        latest    a830707172e8   3 weeks ago   192MB</code></pre><h2 id="3-5-Compose支持"><a href="#3-5-Compose支持" class="headerlink" title="3.5 Compose支持"></a>3.5 Compose支持</h2><p>  添加Compose支持，并启动Docker服务</p><pre class=" language-language-bash"><code class="language-language-bash"># 下载docker-compose并放在/usr/local/bin下curl -L "https://github.com/docker/compose/releases/download/v2.36.0/docker-compose-linux-x86_64" -o /usr/local/bin/docker-composechmod +x /usr/local/bin/docker-composesystemctl daemon-reloadsystemctl restart docker[root@harbor ~]# docker-compose versionDocker Compose version v2.36.0# 注明：github可能会访问不了，故先从github下载到本地，再上传到服务器https://github.com/docker/compose/releases</code></pre><h2 id="3-6-下载Harbor"><a href="#3-6-下载Harbor" class="headerlink" title="3.6 下载Harbor"></a>3.6 下载Harbor</h2><pre class=" language-language-bash"><code class="language-language-bash">[root@harbor ~]# wget https://github.com/goharbor/harbor/releases/download/v2.13.0/harbor-offline-installer-v2.13.0.tgz[root@harbor ~]# tar xf harbor-offline-installer-v2.13.0.tgz -C /usr/local/bin# 使用docker load命令将解压后的tar文件加载为Docker镜像[root@harbor ~]# cd /usr/local/bin[root@harbor bin]# lltotal 72004-rwxr-xr-x. 1 root root 73731911 May 14 14:25 docker-composedrwxr-xr-x. 2 root root      123 May 14 16:33 harbor[root@harbor bin]# cd harbor[root@harbor harbor]# docker load -i harbor.v2.13.0.tar.gz</code></pre><h2 id="3-7-修改harbor-yml文件"><a href="#3-7-修改harbor-yml文件" class="headerlink" title="3.7 修改harbor.yml文件"></a>3.7 修改harbor.yml文件</h2><pre class=" language-language-bash"><code class="language-language-bash">mv harbor.yml.tmpl harbor.yml# 备份harbor.yml文件cp harbor.yml harbor.yml.bak[root@harbor ~]# vim /usr/local/bin/harbor/harbor.yml1.修改hostname为192.168.8.522.修改http的端口为823.修改harbor_admin_password为admin# 如果不启用https就注释掉12行-20行</code></pre><h2 id="3-8-安装Harbor"><a href="#3-8-安装Harbor" class="headerlink" title="3.8 安装Harbor"></a>3.8 安装Harbor</h2><pre class=" language-language-bash"><code class="language-language-bash"># 加载配置并安装[root@harbor harbor]# ./prepare[root@harbor harbor]# ./install.sh...[Step 5]: starting Harbor ...[+] Running 10/10 ✔ Network harbor_harbor        Created    0.0s                                                     ✔ Container harbor-log         Started    0.3s                                                       ✔ Container registryctl        Started    0.8s                                                     ✔ Container harbor-db          Started    1.2s                                                      ✔ Container redis              Started    1.2s                                                  ✔ Container harbor-portal      Started    1.2s                                                           ✔ Container registry           Started    1.3s                                                  ✔ Container harbor-core        Started    1.4s                                               ✔ Container harbor-jobservice  Started    2.0s                                                ✔ Container nginx              Started    2.0s                                           ✔ ----Harbor has been installed and started successfully.----</code></pre><h2 id="3-9-重启Harbor"><a href="#3-9-重启Harbor" class="headerlink" title="3.9 重启Harbor"></a>3.9 重启Harbor</h2><pre class=" language-language-bash"><code class="language-language-bash">[root@harbor harbor]# docker-compose down[root@harbor harbor]# ./prepare[root@harbor harbor]# docker-compose up -d# 浏览器访问Harbor   http://192.168.8.52:82  用户名/密码:admin/admin</code></pre><h2 id="3-10-生成服务文件"><a href="#3-10-生成服务文件" class="headerlink" title="3.10 生成服务文件"></a>3.10 生成服务文件</h2><pre class=" language-language-bash"><code class="language-language-bash">cat > /etc/systemd/system/harbor.service <<EOF[Unit]Description=HarborAfter=docker.service systemd-networkd.service systemd-resolved.serviceRequires=docker.serviceDocumentation=http://github.com/vmware/harbor[Service]Type=simpleRestart=on-failureRestartSec=5ExecStart=/usr/local/bin/docker-compose -f /usr/local/bin/harbor/docker-compose.yml upExecStop=/usr/local/bin/docker-compose -f /usr/local/bin/harbor/docker-compose.yml down[Install]WantedBy=multi-user.targetEOF[root@harbor ~]# systemctl daemon-reload[root@harbor ~]# systemctl enable harbor --now[root@harbor ~]# systemctl stop harbor[root@harbor ~]# systemctl status harbor[root@harbor ~]# systemctl start harbor[root@harbor ~]# systemctl restart harbor</code></pre><h2 id="3-11-推送镜像到Harbor"><a href="#3-11-推送镜像到Harbor" class="headerlink" title="3.11 推送镜像到Harbor"></a>3.11 推送镜像到Harbor</h2><p>  将registry.luovip.cn以及其对应的IP添加到/etc/hosts，然后将上述实验中的httpd:v1镜像，改名为带上IP:PORT形式，上传的镜像到本地仓库</p><p>  1.添加域名解析</p><pre class=" language-language-bash"><code class="language-language-bash">[root@docker ~]# vim /etc/hosts192.168.8.52 registry.luovip.cn</code></pre><p>  2.编辑文件“/usr/lib/systemd/system/docker.service”，输入以下内容。其中，my.harbor.com是Harbor主机的主机名</p><pre class=" language-language-bash"><code class="language-language-bash">[root@docker ~]# vim /usr/lib/systemd/system/docker.serviceExecStart=/usr/bin/dockerd --insecure-registry registry.luovip.cn</code></pre><p>  3.编辑“/etc/docker/daemon.json”文件，在该文件中指定私有镜像仓库地址</p><pre class=" language-language-bash"><code class="language-language-bash">[root@docker ~]# vim /etc/docker/daemon.json"insecure-registries": [        "192.168.8.52:82"  ][root@docker ~]# systemctl daemon-reload[root@docker ~]# systemctl restart docker.service</code></pre><p>  4.推送的命令</p><pre class=" language-language-bash"><code class="language-language-bash"># Docker推送命令:1.在项目中标记镜像:docker tag SOURCE_IMAGE[:TAG] 192.168.8.52:82/library/REPOSITORY[:TAG]2.推送镜像到当前项目：docker push 192.168.8.52:82/library/REPOSITORY[:TAG]Podman推送命令：1.推送镜像到当前项目：podman push IMAGE_ID 192.168.8.52:82/library/REPOSITORY[:TAG]</code></pre><p>  5.推送镜像</p><pre class=" language-language-bash"><code class="language-language-bash">[root@docker ~]# docker imagesREPOSITORY   TAG       IMAGE ID       CREATED        SIZEtomcat       latest    c6c6349a7df2   47 hours ago   468MBnginx        latest    a830707172e8   4 weeks ago    192MB[root@docker ~]# docker login 192.168.8.52:82[root@docker ~]# docker tag c6c6349a7df2 192.168.8.52:82/library/tomcat:v2[root@docker ~]# docekr images-bash: docekr: command not found[root@docker ~]# docker imagesREPOSITORY                       TAG       IMAGE ID       CREATED        SIZE192.168.8.52:82/library/tomcat   v2        c6c6349a7df2   47 hours ago   468MBtomcat                           latest    c6c6349a7df2   47 hours ago   468MBnginx                            latest    a830707172e8   4 weeks ago    192MB[root@docker ~]# docker push 192.168.8.52:82/library/tomcat:v2[root@docker ~]# docker pull 192.168.8.52:82/library/tomcat:v2</code></pre><h1 id="4-管理容器的资源"><a href="#4-管理容器的资源" class="headerlink" title="4 管理容器的资源"></a>4 管理容器的资源</h1><pre class=" language-language-bash"><code class="language-language-bash"># 创建容器并观察内存量[root@docker ~]# docker run -d --name=httpd_server httpd[root@docker ~]# docker run -d --name=httpd_tomcat tomcat[root@docker ~]# docker ps -aCONTAINER ID   IMAGE     COMMAND              CREATED         STATUS         PORTS      NAMES796227a2aac7   tomcat    "catalina.sh run"    2 minutes ago   Up 2 minutes   8080/tcp   httpd_tomcatb025ca41d951   httpd     "httpd-foreground"   3 minutes ago   Up 3 minutes   80/tcp     httpd_server[root@docker ~]# docker exec -it httpd_server grep MemTotal /proc/meminfoMemTotal:        3974748 kB[root@docker ~]# docker exec -it httpd_tomcat grep MemTotal /proc/meminfoMemTotal:        3974748 kB</code></pre><h2 id="4-1-容器的内存配额"><a href="#4-1-容器的内存配额" class="headerlink" title="4.1 容器的内存配额"></a>4.1 容器的内存配额</h2><p>  根据以上得出结论，每个容器的内存量，全部等于物理宿主机的内存总量，这意味这更好的性能，但同时也意味着一旦业务需求上升，将有可能发生资源争用，这通常在运维规划时，应当极力避免</p><p>  容器可使用的内存：物理内存和交换空间(Swap)</p><p>  Docker默认没有设置内存限制。可以通过相关选项限制设置：</p><p>  1.-m(–memory)：设置容器可用的最大内存，该值最低为4MB</p><p>  2.–memory-swap：允许容器置入磁盘交换空间中的内存大小</p><h3 id="4-1-1-用户内存限制"><a href="#4-1-1-用户内存限制" class="headerlink" title="4.1.1 用户内存限制"></a>4.1.1 用户内存限制</h3><p>  Docker提供4种方式设置容器的用户内存使用:</p><p>  1.对容器内存使用无限制（两个选项都不使用）</p><p>  2.设置内存限制并取消<a href="https://so.csdn.net/so/search?q=%E4%BA%A4%E6%8D%A2%E7%A9%BA%E9%97%B4&amp;spm=1001.2101.3001.7020">交换空间</a>内存限制</p><pre class=" language-language-bash"><code class="language-language-bash">#使用300内存和尽可能多的交换空间[root@docker ~]# docker run -it -m 300M --memory-swap -1 ubuntu /bin/bash</code></pre><p>  3.只设置内存限制</p><pre class=" language-language-bash"><code class="language-language-bash"> # 300MB的内存和300MB的交换空间 # 默认情况下虚拟内存总量将设置为内存大小的两倍，因此容器能使用300M的交换空间[root@docker ~]# docker run -it -m 300M ubuntu /bin/bash</code></pre><p>  4.同时设置内存和交换空间</p><pre class=" language-language-bash"><code class="language-language-bash"># 300MB的内存和700MB的交换空间[root@docker ~]# docker run -it -m 300M --memory-swap 700m ubuntu /bin/bash</code></pre><h3 id="4-1-2-内核内存限制"><a href="#4-1-2-内核内存限制" class="headerlink" title="4.1.2 内核内存限制"></a>4.1.2 内核内存限制</h3><p>  内核内存不能交换到磁盘中，无法使用交换空间，消耗过多可能导致其阻塞系统服务</p><pre class=" language-language-bash"><code class="language-language-bash"># 在500MB的内存中，可以使用最高50MB的内核内存[root@docker ~]# docker run -it -m 500M --kernel-memory 50M ubuntu /bin/bash# 只可以使用50MB的内核内存[root@docker ~]# docker run -it --kernel-memory 50M ubuntu /bin/bash</code></pre><h3 id="4-1-3-内存预留实现软限制"><a href="#4-1-3-内存预留实现软限制" class="headerlink" title="4.1.3 内存预留实现软限制"></a>4.1.3 内存预留实现软限制</h3><p>  使用–memory-reservation选项设置内存预留，它是一种内存软限制，允许更多的内存共享。设置后，Docker将检测内存争用或内存不足，并强制容器将其内存消耗限制为预留值</p><p>  内存预留值应当始终低于硬限制，作为一个软限制功能，内存预留并不能保证不会超过限制</p><pre class=" language-language-bash"><code class="language-language-bash"># 限制内存为500MB，内存预留值(软限制)为200MB。# 当容器消耗内存大于200MB、小于500MB时，下一次系统内存回收将尝试将容器内存缩减到200MB以下[root@docker ~]# docker run -it -m 500M --memory-reservation 200M ubuntu /bin/bashdocker run –it –m 500M --memory-reservation 200M ubuntu /bin/bash# 设置内存软限制为1GB[root@docker ~]# docker run -it —-memory-reservation 1G ubuntu /bin/bash</code></pre><h2 id="4-2-容器的CPU配额"><a href="#4-2-容器的CPU配额" class="headerlink" title="4.2 容器的CPU配额"></a>4.2 容器的CPU配额</h2><p>  默认情况下，所有容器都可以使用相同的CPU资源，并且没有任何限制，这和内存问题一样，一旦CPU需求业务上升，同样会引起CPU资源的争用，但是和内存指定绝对量的不同，CPU是通过指定相对权重值来进行的配额</p><p>  使用–cpu-shares参数对CPU来进行配额分配，默认情况下，这个值为1024</p><p>  当前容器中的业务空闲时，其他的容器有权利使用其空闲的CPU周期，这将确保业务的性能</p><p>  CPU限额的分配，只有在物理机资源不足的时候才会生效，并且是根据不同的优先级进行的，当其他容器空闲时，忙碌的容器可以获得全部可用的CPU资源</p><h3 id="4-2-1-CPU份额限制"><a href="#4-2-1-CPU份额限制" class="headerlink" title="4.2.1 CPU份额限制"></a>4.2.1 CPU份额限制</h3><p>  -c(–cpu-shares)选项将CPU份额权重设置为指定的值</p><p>  默认值为1024，如果设置为0，系统将忽略该值并使用默认值1024</p><h3 id="4-2-2-CPU周期限制"><a href="#4-2-2-CPU周期限制" class="headerlink" title="4.2.2 CPU周期限制"></a>4.2.2 CPU周期限制</h3><p>  –cpu-period选项(以μs为单位)设置CPU周期以限制容器CPU资源的使用</p><p>  默认的CFS(完全公平调度器)周期为100ms(100000μs)</p><p>  通常将–cpu-period与–cpu-quota这两个选项配合使用：</p><pre class=" language-language-bash"><code class="language-language-bash"># 如果只有1个CPU，则容器可以每50ms(50000μs)获得50%(25000/50000)的CPU运行时间[root@docker ~]# docker run -it --cpu-period=50000 --cpu-quota=25000 ubuntu /bin/bash# 可用--cpus选项指定容器的可用CPU资源来达到同样的目的# --cpus选项值是一个浮点数，默认值为0.000，表示不受限制# 上述可改为[root@docker ~]# docker run -it --cpus=0.5 ubuntu /bin/bash# --cpu-period和--cpu-quota选项都是以1个CPU为基准</code></pre><h3 id="4-2-3-CPU放置限制"><a href="#4-2-3-CPU放置限制" class="headerlink" title="4.2.3 CPU放置限制"></a>4.2.3 CPU放置限制</h3><p>  –cpuset-cpus选项限制容器进程在指定的CPU上执行</p><pre class=" language-language-bash"><code class="language-language-bash"># 容器中的进程可以在cpu1和cpu3上执行[root@docker ~]# docker run -it --cpuset-cpus="1,3" ubuntu:14.04 /bin/bash# 容器中的进程可以在cpu0、cpu1和cpu 2上执行[root@docker ~]# docker run -it --cpuset-cpus="0-2" ubuntu:14.04 /bin/bash</code></pre><h3 id="4-2-4-CPU配额限制"><a href="#4-2-4-CPU配额限制" class="headerlink" title="4.2.4 CPU配额限制"></a>4.2.4 CPU配额限制</h3><p>  –cpu-quota选项限制容器的CPU配额，默认值为0表示容器占用100%的CPU资源个CPU</p><p>  CFS用于处理进程执行的资源分配，是由内核使用的默认Linux调度程序。将此值设置50000意味着限制容器至多使用CPU资源的50%，对于多个CPU而言，调整–cpu-quota选项必要的</p><h2 id="4-3-容器的I-O配额"><a href="#4-3-容器的I-O配额" class="headerlink" title="4.3 容器的I/O配额"></a>4.3 容器的I/O配额</h2><p>  默认情况下，所有容器都可以使用相同的I/O资源(500权重)，并且没有任何限制，这和内存、 CPU问题一样，一旦I/O需求业务上升，硬盘读写会变得非常迟缓，所以为了更好的提供服务，也应该对容器使用硬盘方面进行调整</p><p>  块I/O带宽(Block I/O Bandwidth，Blkio)是另一种可以限制容器使用的资源</p><p>  块I/O指磁盘的写，Docker可通过设置权重限制每秒字节数(B/s)和每秒I/O次数(IO/s)的方式控制容器读写盘的带宽</p><h3 id="4-3-1-设置块I-O权重"><a href="#4-3-1-设置块I-O权重" class="headerlink" title="4.3.1 设置块I/O权重"></a>4.3.1 设置块I/O权重</h3><p>  –blkio-weight选项更改比例(原默认为500)，设置相对于所有其他正在运行的容器的块I/O带宽权重</p><pre class=" language-language-bash"><code class="language-language-bash"># 创建两个有不同块I/O带宽权重的容器[root@docker ~]# docker run -it --name c1 --blkio-weight 300 ubuntu /bin/bash[root@docker ~]# docker run -it --name c2 --blkio-weight 600 ubuntu /bin/bash在以下案例中，权重为600的容器将比300的在I/O能力方面多出两倍:[root@docker ~]# docker run -d --name 300io --blkio-weight 300 httpd[root@docker ~]# docker run -d --name 600io --blkio-weight 600 httpd命令测试I/O性能:[root@docker ~]# time dd if=/dev/zero of=test.out bs=1M count=10241024+0 records in1024+0 records out1073741824 bytes (1.1 GB, 1.0 GiB) copied, 4.05265 s, 265 MB/sreal    0m4.055suser    0m0.000ssys     0m4.036s注：此设定在I/O争用时，才会体现</code></pre><h3 id="4-3-2-限制设备读写速率"><a href="#4-3-2-限制设备读写速率" class="headerlink" title="4.3.2 限制设备读写速率"></a>4.3.2 限制设备读写速率</h3><p>  Docker根据两类指标限制容器的设备读写速率：一类是每秒字节数，另一类是每秒I/O次数</p><p>  1.限制每秒字节数</p><p>  –device-read-bps选项限制指定设备的读取速率，即每秒读取的字节数</p><pre class=" language-language-bash"><code class="language-language-bash"># 创建一个容器，并限制对/dev/mapper/rhel-swap设备的读取速率为每秒1MB[root@docker ~]# docker run -it --device-read-bps /dev/mapper/rhel-swap:1mb ubuntudocker run -it --device-read-bps /dev/sda:1mb ubuntu# 类似地，可使用--device-write-bps选项限制指定设备的写入速率。格式： <设备>:<速率值>[单位]</code></pre><p>  2.限制每秒I/O次数</p><p>  –device-read-iops和–device-write-iops选项制指定设备的读取和写入速率，用每秒I/O次数表示</p><pre class=" language-language-bash"><code class="language-language-bash"># 创建一个容器，限制它对/dev/mapper/rhel-swap设备的读取速率为每秒1000次[root@docker ~]# docker run -it --device-read-iops /dev/mapper/rhel-swap:1000 ubuntu</code></pre><h2 id="4-4-容器底层技术实现"><a href="#4-4-容器底层技术实现" class="headerlink" title="4.4 容器底层技术实现"></a>4.4 容器底层技术实现</h2><p>  对容器使用的内存、CPU和块I/O带宽资源的限制具体是由控制组(Cgroup)的相应子系统来实现的</p><p>  1.memory子系统设置控制组中的住务所使用的内存限制</p><p>  2.cpu子系统通过调度程序提供对CPU的控制组任务的访问</p><p>  3.blkio子系统为块设备(如磁盘、固态硬盘、USB等)设置输入和输出限制</p><p>  在docker run命令中使用–cpu-shares、–memory、–device-read-bps等选项实际上就是在配置控制组，相关的配置文件保存在/sys/fs/cgroup目录中</p><h3 id="4-4-1-资源限制的底层实现"><a href="#4-4-1-资源限制的底层实现" class="headerlink" title="4.4.1 资源限制的底层实现"></a>4.4.1 资源限制的底层实现</h3><p>  Linux通过cgroup来分配进程使用的CPU、memory、I/O资源的配额，可以通过/sys/fs/cgroup/下面的设定来查看容器的配额部分</p><pre class=" language-language-bash"><code class="language-language-bash"># 启动一个容器，设置内存限额为300MB，CPU权重为512[root@docker ~]# docker run --rm -d -p 8080:80 -m 300M --cpu-shares=512 httpd1dc9a3907b6b82521addd810d52d2514c6ab5fed1e274f03a90e5a1454d16a49# 动态更改容器的资源限制# docker update命令可以动态地更新容器配置，其语法：docker update [选项] 容器 [容器...][root@docker ~]# docker update -m 500M --cpu-shares=10245 1dc9a3907b6b82521addd810d52d2514c6ab5fed1e274f03a90e5a1454d16a491dc9a3907b6b82521addd810d52d2514c6ab5fed1e274f03a90e5a1454d16a49</code></pre><h3 id="4-4-2-容器的隔离底层实现"><a href="#4-4-2-容器的隔离底层实现" class="headerlink" title="4.4.2 容器的隔离底层实现"></a>4.4.2 容器的隔离底层实现</h3><p>  每个容器貌似都有自己独立的根目录以及/etc、/var等目录，而且貌似都有自己的独立网卡，但事实上物理宿主机只有一个网卡，那么容器之间是怎么实现的“独立性”的呢？</p><p>  Linux使用namespace技术来实现了容器间的资源隔离，namespace管理着宿主机中的全局唯一资源，并且可以让每个容器都会认为自己拥有且只有自己在使用资源，namespace一共有6种，分别为：mount、UTS、IPC、PID、Network、User</p><h3 id="4-4-3-namespace"><a href="#4-4-3-namespace" class="headerlink" title="4.4.3 namespace"></a>4.4.3 namespace</h3><p>  Mount namespace让容器看上去拥有整个文件系统，容器有自己的根目录</p><p>  UTS namespace可以让容器有自己的主机名，默认情况下，容器的主机名是它本身的短ID，可通过-h或者–hostname设置主机名</p><p>  IPC namespace可以让容器拥有自己的共享内存和信号量来实现进程间通信</p><p>  PID namespace让容器拥有自己的进程树，可以在容器中执行ps命令查看</p><p>  Network namespace可以让容器拥有自己独立的网卡、IP、路由等资源</p><p>  User namespace 让容器能够管理自己的用户，而不是和宿主机公用/etc/passwd</p><h1 id="5-容器原生网络与存储"><a href="#5-容器原生网络与存储" class="headerlink" title="5 容器原生网络与存储"></a>5 容器原生网络与存储</h1><h2 id="5-1-容器原生网络"><a href="#5-1-容器原生网络" class="headerlink" title="5.1 容器原生网络"></a>5.1 容器原生网络</h2><p>  docker原生提供了以下几种网络，如果对原生网络不满意，还可以创建自定义网络<br>  原生网络分为：none、bridge、host，这些网络在docker安装的时候会自动创建，可以通过以下命令来查看</p><pre class=" language-language-bash"><code class="language-language-bash">[root@docker ~]# docker network lsNETWORK ID     NAME      DRIVER    SCOPEf85881372579   bridge    bridge    local668aba04b5b0   host      host      local3fa8ef65ab94   none      null      local</code></pre><p>  如果容器使用的是none网络，那么此容器将不具备常规理解上的网卡，只具备lo网络，如果要使用这个网络，在创建容器时，指定–network=none即可</p><p>  None网络是比较封闭的网络，对一些安全要求比较高并且不需要联网的场景，可以用none网络，比如手机上接收的验证码、随机数生成等场景，就可以放在none网络中以避免被窃取</p><p>  Host网络是一个共享宿主机网络栈的一个容器共享网络，可以通过–network=host在创建容器 的时候指定host网络，处于host网络模式的容器，网络配置和宿主机是完全一样的，也就是说，在容器中可以看到宿主机的所有网卡，并且主机名也是宿主机的，这最大的好处就是性能很高，传输速率特别好，但是宿主机上已经使用的端口，容器就不可以使用</p><h2 id="5-2-容器和层"><a href="#5-2-容器和层" class="headerlink" title="5.2 容器和层"></a>5.2 容器和层</h2><p>  容器和镜像最大的不同在于最顶上的可写层，所有在容器中的数据写入和修改都会直接存储到这个可写层中，这就意味着，当容器被删除时，可写层中的数据就丢失了，虽然每个容器都有自己不同的可写层，但是容器底层的镜像却是可以同时共享的</p><p><img src="/images/%E5%AE%B9%E5%99%A8%E5%92%8C%E5%B1%82.png"></p><h2 id="5-3-主流存储驱动"><a href="#5-3-主流存储驱动" class="headerlink" title="5.3 主流存储驱动"></a>5.3 主流存储驱动</h2><p>  在容器设计和使用的时候，在容器的可写层中写入的数据是非常少的，但在运维中大部分数据是必须要具备持久化保存的能力，所以在容器中引入了多种的存储驱动来解决上面说的可写层数据的易失性</p><p>  目前主流受支持的存储驱动有：</p><p><img src="/images/%E5%AD%98%E5%82%A8%E9%A9%B1%E5%8A%A8.png"></p><h2 id="5-4-Copy-on-write策略"><a href="#5-4-Copy-on-write策略" class="headerlink" title="5.4 Copy-on-write策略"></a>5.4 Copy-on-write策略</h2><p><img src="/images/Copy-on-write.png"></p><h2 id="5-5-容器数据管理"><a href="#5-5-容器数据管理" class="headerlink" title="5.5 容器数据管理"></a>5.5 容器数据管理</h2><p>  容器中持久化数据一般采用两种存储方式：</p><p>   1.volume</p><p>   2.bind mount</p><p><img src="/images/%E6%8C%81%E4%B9%85%E5%8C%96%E6%95%B0%E6%8D%AE.png"></p><h1 id="6-Kubernetes"><a href="#6-Kubernetes" class="headerlink" title="6 Kubernetes"></a>6 Kubernetes</h1><h2 id="6-1-K8S的概念"><a href="#6-1-K8S的概念" class="headerlink" title="6.1 K8S的概念"></a>6.1 K8S的概念</h2><p>  Kubernetes是一个可移植的、可扩展的开源平台，用于管理容器化的工作负载和服务，可促进声明式配置和自动化</p><p>  Kubernetes拥有一个庞大且快速增长的生态系统。Kubernetes 的服务、支持和工具广泛可用</p><p><img src="/images/k8s.png"></p><h2 id="6-2-K8S的特点"><a href="#6-2-K8S的特点" class="headerlink" title="6.2 K8S的特点"></a>6.2 K8S的特点</h2><p>  Kubernetes具有以下几个特点：</p><p>   1.可移植: 支持公有云、私有云、混合云、多重云（multi-cloud）</p><p>   2.可扩展: 模块化、插件化、可挂载、可组合</p><p>   3.自动化: 自动部署、自动重启、自动复制、自动伸缩/扩展</p><h2 id="6-3-K8S的作用"><a href="#6-3-K8S的作用" class="headerlink" title="6.3 K8S的作用"></a>6.3 K8S的作用</h2><p>  Kubernetes的主要职责是容器编排(Container Orchestration)，即在一组服务器上启动、 监控、回收容器，在满足排程的同时，保证容器可以健康的运行</p><p><img src="/images/k8s%E7%9A%84%E4%BD%9C%E7%94%A8.png"></p><h2 id="6-4-K8S的整体架构"><a href="#6-4-K8S的整体架构" class="headerlink" title="6.4 K8S的整体架构"></a>6.4 K8S的整体架构</h2><p><img src="/images/k8s%E7%9A%84%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84.png"></p><h3 id="6-4-1-Master节点"><a href="#6-4-1-Master节点" class="headerlink" title="6.4.1 Master节点"></a>6.4.1 Master节点</h3><p>1.kube-apiserver</p><p>  API服务器是Kubernetes控制面的前端</p><p>  Kubernetes API服务器的主要实现是kube-apiserver</p><p>  kube-apiserver设计上考虑了水平伸缩，可通过部署多个实例进行伸缩。 可以运行kube-apiserver的多个实例，并在这些实例之间平衡流</p><p>2.etcd</p><p>  etcd是兼具一致性和高可用性的键值数据库，可以作为保存Kubernetes所有集群数据的后台数据库</p><p>3.cloud-controller-manager</p><p>  cloud-controller-manager仅运行特定于云平台的控制回路</p><p>  如果在自己的环境中运行Kubernetes，或者在本地计算机中运行学习环境， 所部署的环境中不需要云控制器管理器</p><p>4.kube-scheduler</p><p>  控制平面组件，负责监视新创建的、未指定运行节点（node）的 Pods，选择节点让 Pod 在上面运行</p><p>5.kube-controller-manager</p><p>  这些控制器包括:</p><p>  节点控制器（Node Controller）: 负责在节点出现故障时进行通知和响应</p><p>  任务控制器（Job controller）: 监测代表一次性任务的Job对象，然后创建Pods来运行这些任务直至完成</p><p>  端点控制器（Endpoints Controller）: 填充端点(Endpoints)对象(即加入 Service 与 Pod)</p><p>  服务帐户和令牌控制器（Service Account &amp; Token Controllers）: 为新的命名空间创建默认帐户和API访问令牌</p><h3 id="6-4-2-Node节点"><a href="#6-4-2-Node节点" class="headerlink" title="6.4.2 Node节点"></a>6.4.2 Node节点</h3><p>1.kubelet</p><p>  一个在集群中每个节点（node）上运行的代理，保证容器（containers）都运行在Pod中</p><p>2.kube-proxy</p><p>  kube-proxy是集群中每个节点上运行的网络代理， 实现Kubernetes服务(Service)概念的一部分</p><p>  kube-proxy 维护节点上的网络规则。这些网络规则允许从集群内部或外部的网络会话与Pod进行网络通信</p><p>  如果操作系统提供了数据包过滤层并可用的话，kube-proxy会通过它来实现网络规则。否则， kube-proxy仅转发流量本身</p><p>3.容器运行时（Container Runtime）</p><p>  Kubernetes支持多个容器运行环境: Docker、 containerd、CRI-O以及任何实现Kubernetes CRI (容器运行环境接口)</p><h3 id="6-4-3-插件-Addons"><a href="#6-4-3-插件-Addons" class="headerlink" title="6.4.3 插件(Addons)"></a>6.4.3 插件(Addons)</h3><p>  插件使用Kubernetes资源（DaemonSet、 Deployment等）实现集群功能。 因为这些插件提供集群级别的功能，插件中命名空间域的资源属于kube-system命名空间</p><p>  1.Core-dns：为整个集群提供DNS服务</p><p>  2.Ingress Controller：为service提供外网访问入口</p><p>  3.Dashboard: 提供图形化管理界面</p><p>  4.Flannel/ Calico ：为kubernetes提供方便的网络规划服务</p><h1 id="7-Kubernetes集群部署"><a href="#7-Kubernetes集群部署" class="headerlink" title="7 Kubernetes集群部署"></a>7 Kubernetes集群部署</h1><h2 id="7-1-Kubernetes的安装流程"><a href="#7-1-Kubernetes的安装流程" class="headerlink" title="7.1 Kubernetes的安装流程"></a>7.1 Kubernetes的安装流程</h2><h3 id="7-1-1-先决条件"><a href="#7-1-1-先决条件" class="headerlink" title="7.1.1 先决条件"></a>7.1.1 先决条件</h3><p>  1.最小配置：2G内存2核CPU</p><p>  2.集群中的所有机器的网络彼此均能相互连接(公网和内网都可以)</p><p>  3.节点之中不可以有重复的主机名、MAC 地址或product_uuid</p><p>  4.禁用交换分区</p><p>  5.开启机器上的某些端口</p><h3 id="7-1-2-安装runtime"><a href="#7-1-2-安装runtime" class="headerlink" title="7.1.2 安装runtime"></a>7.1.2 安装runtime</h3><p>  默认情况下，Kubernetes使用容器运行时接口（Container Runtime Interface，CRI） 与所选择的容器运行时交互</p><p>  如果不指定运行时，则kubeadm会自动尝试检测到系统上已经安装的运行时， 方法是扫描一组众所周知的Unix域套接字，docker启用shim来对接K8S</p><p>  运行时的域套接字：<br>  Docker unix:///var/run/cri-dockerd.sock</p><p>  containerd /run/containerd/containerd.sock</p><p>  CRI-O /var/run/crio/crio.sock</p><h3 id="7-1-3-安装kubeadm、kubelet和kubectl"><a href="#7-1-3-安装kubeadm、kubelet和kubectl" class="headerlink" title="7.1.3 安装kubeadm、kubelet和kubectl"></a>7.1.3 安装kubeadm、kubelet和kubectl</h3><p>  需要在每台机器上安装以下软件包：</p><p>  kubeadm：用来初始化集群的指令</p><p>  kubelet：在集群中的每个节点上用来启动Pod和容器等</p><p>  kubectl：用来与集群通信的命令行工具</p><p>  确保它们与通过kubeadm安装的控制平面的版本相匹配。 不然可能会导致一些预料之外的错误和问题。 然而，控制平面与kubelet间的相差一个次要版本不一致是支持的，但kubelet的版本不可以超过API服务器的版本。 例如，1.7.0 版本的kubelet可以完全兼容1.8.0版本的API 服务器，反之则不可以</p><h3 id="7-1-4-检查所需端口"><a href="#7-1-4-检查所需端口" class="headerlink" title="7.1.4 检查所需端口"></a>7.1.4 检查所需端口</h3><p>1.控制平面</p><table><thead><tr><th align="left">协议</th><th align="left">方向</th><th align="left">端口范围</th><th align="left">作用</th><th align="left">使用者</th></tr></thead><tbody><tr><td align="left">TCP</td><td align="left">入站</td><td align="left">6443</td><td align="left">Kubernetes API服务器</td><td align="left">所有组件</td></tr><tr><td align="left">TCP</td><td align="left">入站</td><td align="left">2379-2380</td><td align="left">etcd服务器客户端API</td><td align="left">kube-apiserver,etcd</td></tr><tr><td align="left">TCP</td><td align="left">入站</td><td align="left">10250</td><td align="left">Kubelet API</td><td align="left">kubelet自身、控制平面组件</td></tr><tr><td align="left">TCP</td><td align="left">入站</td><td align="left">10251</td><td align="left">kube-scheduler</td><td align="left">kube-scheduler自身</td></tr><tr><td align="left">TCP</td><td align="left">入站</td><td align="left">10252</td><td align="left">kube-controller-manager</td><td align="left">kube-controller-manager自身</td></tr></tbody></table><p>2.工作节点</p><table><thead><tr><th align="left">协议</th><th align="left">方向</th><th align="left">端口范围</th><th align="left">作用</th><th align="left">使用者</th></tr></thead><tbody><tr><td align="left">TCP</td><td align="left">入站</td><td align="left">10250</td><td align="left">Kubelet API</td><td align="left">kubelet自身、控制平面组件</td></tr><tr><td align="left">TCP</td><td align="left">入站</td><td align="left">30000-32767</td><td align="left">NodePort服务</td><td align="left">所有组件</td></tr></tbody></table><h3 id="7-1-5-Iptables桥接流量"><a href="#7-1-5-Iptables桥接流量" class="headerlink" title="7.1.5 Iptables桥接流量"></a>7.1.5 Iptables桥接流量</h3><p>  为了让Linux节点上的iptables能够正确地查看桥接流量，需要确保sysctl配置中将net.bridge.bridge-nf-call-iptables设置为1</p><p><img src="/images/iptables.png"></p><h3 id="7-1-6-环境准备"><a href="#7-1-6-环境准备" class="headerlink" title="7.1.6 环境准备"></a>7.1.6 环境准备</h3><p>  本K8S集群使用3台机器(ubuntu)进行部署，各节点信息如下表：</p><p>  注明：使用的容器为Docker</p><table><thead><tr><th align="left">主机名</th><th align="left">角色</th><th align="left">IP</th><th align="left">VMware网络类型</th><th align="left">用户名</th><th align="left">密码</th><th align="left">互联网连接</th></tr></thead><tbody><tr><td align="left">k8s-master</td><td align="left">控制平面</td><td align="left">192.168.8.3</td><td align="left">NAT</td><td align="left">vagrant root</td><td align="left">vagrant vargrant</td><td align="left">是</td></tr><tr><td align="left">k8s-worker1</td><td align="left">数据平面</td><td align="left">192.168.8.4</td><td align="left">NAT</td><td align="left">vagrant root</td><td align="left">vagrant vargrant</td><td align="left">是</td></tr><tr><td align="left">k8s-worker2</td><td align="left">数据平面</td><td align="left">192.168.8.5</td><td align="left">NAT</td><td align="left">vagrant root</td><td align="left">vagrant vargrant</td><td align="left">是</td></tr></tbody></table><p>准备DNS解析：</p><p>  这一步需要在所有机器上完成</p><pre class=" language-language-bash"><code class="language-language-bash"># 这一步需要在所有机器上完成cat >> /etc/hosts <<EOF192.168.8.3 k8s-master192.168.8.4 k8s-worker1192.168.8.5 k8s-worker2192.168.30.133 registry.xiaohui.cnEOF</code></pre><h2 id="7-2-Docker-CE-部署"><a href="#7-2-Docker-CE-部署" class="headerlink" title="7.2 Docker CE 部署"></a>7.2 Docker CE 部署</h2><h3 id="7-2-1-添加Docker仓库"><a href="#7-2-1-添加Docker仓库" class="headerlink" title="7.2.1 添加Docker仓库"></a>7.2.1 添加Docker仓库</h3><p>  这一步要在所有机器上完成：</p><pre class=" language-language-bash"><code class="language-language-bash"># 安装依赖sudo apt-get updatesudo apt-get install -y ca-certificates curl gnupg lsb-release# 添加公钥到系统sudo mkdir -p /etc/apt/keyringscurl -fsSL https://mirrors.nju.edu.cn/docker-ce/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg# 添加仓库到系统echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://mirrors.nju.edu.cn/docker-ce/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null# 判断仓库是否已做好sudo apt-get update</code></pre><h3 id="7-2-2-安装Docker-CE"><a href="#7-2-2-安装Docker-CE" class="headerlink" title="7.2.2 安装Docker CE"></a>7.2.2 安装Docker CE</h3><p>  这一步要在所有机器上完成：</p><pre class=" language-language-bash"><code class="language-language-bash">sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin# 部署完Docker CE之后，还需要cri-docker shim才可以和Kubernetes集成</code></pre><h3 id="7-2-3-CRI-Docker部署"><a href="#7-2-3-CRI-Docker部署" class="headerlink" title="7.2.3 CRI-Docker部署"></a>7.2.3 CRI-Docker部署</h3><p>  这一步要在所有机器上完成：</p><pre class=" language-language-bash"><code class="language-language-bash"># 下载cri-dockerwget http://hub.gitmirror.com/https://github.com/Mirantis/cri-dockerd/releases/download/v0.3.17/cri-dockerd_0.3.17.3-0.ubuntu-jammy_amd64.deb# 安装cri-dockerdpkg -i cri-dockerd_0.3.17.3-0.ubuntu-jammy_amd64.deb</code></pre><h3 id="7-2-4-Docker镜像加速器"><a href="#7-2-4-Docker镜像加速器" class="headerlink" title="7.2.4 Docker镜像加速器"></a>7.2.4 Docker镜像加速器</h3><p>  这一步要在所有机器上完成：</p><pre class=" language-language-bash"><code class="language-language-bash">vim /etc/docker/daemon.json{  "registry-mirrors": [        "https://docker.mirrors.ustc.edu.cn",        "https://mirror.baidubce.com",        "https://docker.m.daocloud.io",        "https://mirror.ccs.tencentyun.com",        "https://docker.nju.edu.cn",        "https://docker.mirrors.sjtug.sjtu.edu.cn",        "https://mirror.gcr.io",        "https://docker.registry.cyou",        "https://docker-cf.registry.cyou",        "https://dockercf.jsdelivr.fyi",        "https://docker.jsdelivr.fyi",        "https://dockertest.jsdelivr.fyi",        "https://mirror.aliyuncs.com",        "https://dockerproxy.com"  ],  "exec-opts": ["native.cgroupdriver=systemd"]}systemctl daemon-reloadsystemctl restart docker</code></pre><h3 id="7-2-5-将镜像指引到国内"><a href="#7-2-5-将镜像指引到国内" class="headerlink" title="7.2.5 将镜像指引到国内"></a>7.2.5 将镜像指引到国内</h3><p>  这一步要在所有机器上完成：</p><pre class=" language-language-bash"><code class="language-language-bash">cp /lib/systemd/system/cri-docker.service /etc/systemd/system/cri-docker.servicesed -i 's/ExecStart=.*/ExecStart=\/usr\/bin\/cri-dockerd --container-runtime-endpoint fd:\/\/ --network-plugin=cni --pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com\/google_containers\/pause:3.10/' /etc/systemd/system/cri-docker.servicesystemctl daemon-reloadsystemctl restart cri-docker.servicesystemctl enable cri-docker.service</code></pre><h2 id="7-3-Kubernetes部署"><a href="#7-3-Kubernetes部署" class="headerlink" title="7.3 Kubernetes部署"></a>7.3 Kubernetes部署</h2><h3 id="7-3-1-关闭swap分区"><a href="#7-3-1-关闭swap分区" class="headerlink" title="7.3.1 关闭swap分区"></a>7.3.1 关闭swap分区</h3><p>  这一步要在所有机器上完成：</p><pre class=" language-language-bash"><code class="language-language-bash"># 实时关闭swapoff -a# 永久关闭sed -i 's/.*swap.*/#&/' /etc/fstab</code></pre><h3 id="7-3-2-允许iptables检查桥接流量"><a href="#7-3-2-允许iptables检查桥接流量" class="headerlink" title="7.3.2 允许iptables检查桥接流量"></a>7.3.2 允许iptables检查桥接流量</h3><p>  这一步要在所有机器上完成：</p><pre class=" language-language-bash"><code class="language-language-bash">cat <<EOF | sudo tee /etc/modules-load.d/k8s.confbr_netfilterEOFmodprobe br_netfiltercat <<EOF | sudo tee /etc/sysctl.d/k8s.confnet.bridge.bridge-nf-call-ip6tables = 1net.bridge.bridge-nf-call-iptables = 1net.ipv4.ip_forward = 1EOFsudo sysctl --system</code></pre><h3 id="7-3-3-安装kubeadm"><a href="#7-3-3-安装kubeadm" class="headerlink" title="7.3.3 安装kubeadm"></a>7.3.3 安装kubeadm</h3><p>  这一步要在所有机器上完成：</p><pre class=" language-language-bash"><code class="language-language-bash"># 安装依赖apt-get update && apt-get install -y apt-transport-https curl# 安装K8S软件包仓库-阿里云cat > /etc/apt/sources.list.d/k8s.list <<EOFdeb https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.32/deb /EOF# 安装软件包仓库的公钥curl -fsSL https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.32/deb/Release.key | apt-key add -# 更新软件包的仓库索引apt-get update# 开始安装apt-get install -y kubelet kubeadm kubectl# 操作系统所有软件包升级时将忽略kubelet、kubeadm、kubectlapt-mark hold kubelet kubeadm kubectl</code></pre><h3 id="7-3-4-添加命令自动补齐"><a href="#7-3-4-添加命令自动补齐" class="headerlink" title="7.3.4 添加命令自动补齐"></a>7.3.4 添加命令自动补齐</h3><p>  这一步要在所有机器上完成：</p><pre class=" language-language-bash"><code class="language-language-bash">kubectl completion bash > /etc/bash_completion.d/kubectlkubeadm completion bash > /etc/bash_completion.d/kubeadmsource /etc/bash_completion.d/kubectlsource /etc/bash_completion.d/kubeadm</code></pre><h3 id="7-3-5-集成CRI-Docker"><a href="#7-3-5-集成CRI-Docker" class="headerlink" title="7.3.5 集成CRI-Docker"></a>7.3.5 集成CRI-Docker</h3><p>  这一步要在所有机器上完成：</p><pre class=" language-language-bash"><code class="language-language-bash">crictl config --set runtime-endpoint unix:///run/cri-dockerd.sockcrictl images</code></pre><h3 id="7-3-6-集群部署"><a href="#7-3-6-集群部署" class="headerlink" title="7.3.6 集群部署"></a>7.3.6 集群部署</h3><p>  kubeadm.yaml中name字段必须在网络中可被解析，也可以将解析记录添加到集群中所有机器的/etc/hosts中</p><p>  初始化集群部署的操作只能在k8s-master上执行</p><pre class=" language-language-bash"><code class="language-language-bash"># 初始化配置kubeadm config print init-defaults > kubeadm.yamlsed -i 's/.*advert.*/  advertiseAddress: 192.168.8.3/g' kubeadm.yamlsed -i 's/.*name.*/  name: k8s-master/g' kubeadm.yamlsed -i 's|imageRepo.*|imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers|g' kubeadm.yamlsed -i "/^\\s*networking:/a\\  podSubnet: 172.16.0.0/16" kubeadm.yaml# 注意下面的替换，只有在集成的是CRI-Docker时才需要执行，Containerd不需要sed -i 's/  criSocket.*/  criSocket: unix:\/\/\/run\/cri-dockerd.sock/' kubeadm.yaml# 模块加载modprobe br_netfilter # 集群初始化kubeadm init --config kubeadm.yamlYour Kubernetes control-plane has initialized successfully!......kubeadm join 192.168.8.3:6443 --token abcdef.0123456789abcdef \        --discovery-token-ca-cert-hash sha256:c2546a856290440a8ccaf9223c14fd1c2098ac74f4a584acf5f3c5a373005207                # 授权管理权限mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config# 查看集群状态root@k8s-master:~# kubectl get nodesNAME         STATUS     ROLES           AGE   VERSIONk8s-master   NotReady   control-plane   62m   v1.32.5</code></pre><h3 id="7-3-7-部署Calico网络插件"><a href="#7-3-7-部署Calico网络插件" class="headerlink" title="7.3.7 部署Calico网络插件"></a>7.3.7 部署Calico网络插件</h3><p>  Calico网络插件部署的操作在所有节点上执行</p><pre class=" language-language-bash"><code class="language-language-bash"># 使用operator安装calico组件-可能会失败# 以下为github的地址，可能会失败root@k8s-master:~# kubectl create -f https://raw.gitmirror.com/projectcalico/calico/refs/tags/v3.29.3/manifests/tigera-operator.yaml# 解决办法：# 1.获取Calico images到本地    见Calico.txt    # 2.发布本地的yaml到集群-masterkubectl create -f https://www.linuxcenter.cn/files/cka/cka-yaml/tigera-operator-calico-3.29.3.yamlroot@k8s-master:~# kubectl get pod -ANAMESPACE         NAME                                 READY   STATUS    RESTARTS   AGEkube-system       coredns-76fccbbb6b-l7jq9             0/1     Pending   0          163mkube-system       coredns-76fccbbb6b-nd68g             0/1     Pending   0          163mkube-system       etcd-k8s-master                      1/1     Running   0          163mkube-system       kube-apiserver-k8s-master            1/1     Running   0          163mkube-system       kube-controller-manager-k8s-master   1/1     Running   0          163mkube-system       kube-proxy-mcwv7                     1/1     Running   0          163mkube-system       kube-scheduler-k8s-master            1/1     Running   0          163mtigera-operator   tigera-operator-75b4cd596c-9hjml     1/1     Running   0          7m5s</code></pre><h3 id="7-3-8-设置calico在集群的网段"><a href="#7-3-8-设置calico在集群的网段" class="headerlink" title="7.3.8 设置calico在集群的网段"></a>7.3.8 设置calico在集群的网段</h3><p>  这一步在k8s-master上执行</p><pre class=" language-language-bash"><code class="language-language-bash"># 使用下面的自定义资源设置一下calico在集群中的网段# 以下为github的地址，可能会失败root@k8s-master:~# wget https://raw.gitmirror.com/projectcalico/calico/refs/tags/v3.29.3/manifests/custom-resources.yaml# 3.使用下面的地址执行root@k8s-master:~# wget https://www.linuxcenter.cn/files/cka/cka-yaml/custom-resources-calico-3.29.3.yamlroot@k8s-master:~# mv custom-resources-calico-3.29.3.yaml custom-resources.yaml</code></pre><h3 id="7-3-9-确认资源的地址"><a href="#7-3-9-确认资源的地址" class="headerlink" title="7.3.9 确认资源的地址"></a>7.3.9 确认资源的地址</h3><p>  这一步在k8s-master上执行</p><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# vim custom-resources.yaml# This section includes base Calico installation configuration.# For more information, see: https://docs.tigera.io/calico/latest/reference/installation/api#operator.tigera.io/v1.InstallationapiVersion: operator.tigera.io/v1kind: Installationmetadata:  name: defaultspec:  # Configures Calico networking.  calicoNetwork:    ipPools:    - name: default-ipv4-ippool      blockSize: 26      cidr: 172.16.0.0/16      #这里换成上面规定好的172.16.0.0/16      encapsulation: VXLANCrossSubnet      natOutgoing: Enabled      nodeSelector: all()---# This section configures the Calico API server.# For more information, see: https://docs.tigera.io/calico/latest/reference/installation/api#operator.tigera.io/v1.APIServerapiVersion: operator.tigera.io/v1kind: APIServermetadata:  name: defaultspec: {}</code></pre><h3 id="7-3-10-自定义资源发布到集群"><a href="#7-3-10-自定义资源发布到集群" class="headerlink" title="7.3.10 自定义资源发布到集群"></a>7.3.10 自定义资源发布到集群</h3><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# kubectl apply -f custom-resources.yamlroot@k8s-master:~# kubectl get nodesNAME         STATUS   ROLES           AGE    VERSIONk8s-master   Ready    control-plane   173m   v1.32.5root@k8s-master:~# kubectl get pod -ANAMESPACE          NAME                                       READY   STATUS    RESTARTS   AGEcalico-apiserver   calico-apiserver-6499c768c8-wvrnt          1/1     Running   0          60scalico-apiserver   calico-apiserver-6499c768c8-zmvh6          1/1     Running   0          60scalico-system      calico-kube-controllers-85fb6564b7-gtsfr   1/1     Running   0          60scalico-system      calico-node-4mqfj                          1/1     Running   0          60scalico-system      calico-typha-65d47d7478-ttzx6              1/1     Running   0          60scalico-system      csi-node-driver-7j8pf                      2/2     Running   0          60skube-system        coredns-76fccbbb6b-l7jq9                   1/1     Running   0          172mkube-system        coredns-76fccbbb6b-nd68g                   1/1     Running   0          172mkube-system        etcd-k8s-master                            1/1     Running   0          172mkube-system        kube-apiserver-k8s-master                  1/1     Running   0          172mkube-system        kube-controller-manager-k8s-master         1/1     Running   0          172mkube-system        kube-proxy-mcwv7                           1/1     Running   0          172mkube-system        kube-scheduler-k8s-master                  1/1     Running   0          172mtigera-operator    tigera-operator-75b4cd596c-9hjml           1/1     Running   0          16m</code></pre><h3 id="7-3-11-加入Worker节点"><a href="#7-3-11-加入Worker节点" class="headerlink" title="7.3.11 加入Worker节点"></a>7.3.11 加入Worker节点</h3><p>  加入节点操作需在所有的worker节点完成，这里要注意，Worker节点需要完成以下先决条件才能执行kubeadm join</p><p>   1.Docker、CRI-Docker 部署</p><p>   2.Swap分区关闭</p><p>   3.iptables桥接流量的允许</p><p>   4.安装kubeadm等软件</p><p>   5.集成CRI-Docker</p><p>   6.所有节点的/etc/hosts中互相添加对方的解析</p><p>  如果时间长忘记了join参数，可以在master节点上用以下方法重新生成</p><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# kubeadm token create --print-join-commandkubeadm join 192.168.8.3:6443 --token 5mffg7.lq7ujh6vot0jzrci --discovery-token-ca-cert-hash sha256:c2546a856290440a8ccaf9223c14fd1c2098ac74f4a584acf5f3c5a373005207</code></pre><p>  如果有多个CRI对象，在worker节点上执行以下命令加入节点时，指定CRI对象，案例如下：</p><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-worker1:~# kubeadm token create --print-join-commandkubeadm join 192.168.8.3:6443 --token 5mffg7.lq7ujh6vot0jzrci --discovery-token-ca-cert-hash sha256:c2546a856290440a8ccaf9223c14fd1c2098ac74f4a584acf5f3c5a373005207failed to load admin kubeconfig: open /root/.kube/config: no such file or directoryTo see the stack trace of this error execute with --v=5 or higherfound multiple CRI endpoints on the host. Please define which one do you wish to use by setting the 'criSocket' field in the kubeadm configuration file: unix:///var/run/containerd/containerd.sock, unix:///var/run/cri-dockerd.sockTo see the stack trace of this error execute with --v=5 or higher# 加入两个节点1.节点worker1root@k8s-worker1:~# kubeadm join 192.168.8.3:6443 --token 5mffg7.lq7ujh6vot0jzrci --discovery-token-ca-cert-hash sha256:c2546a856290440a8ccaf9223c14fd1c2098ac74f4a584acf5f3c5a373005207 --cri-socket=unix:///var/run/cri-dockerd.sock2.节点worker2root@k8s-worker2:~#  kubeadm join 192.168.8.3:6443 --token 5mffg7.lq7ujh6vot0jzrci --discovery-token-ca-cert-hash sha256:c2546a856290440a8ccaf9223c14fd1c2098ac74f4a584acf5f3c5a373005207 --cri-socket=unix:///var/run/cri-dockerd.sock3.查看各节点状态root@k8s-master:~# kubectl get nodesNAME          STATUS   ROLES           AGE     VERSIONk8s-master    Ready    control-plane   3h28m   v1.32.5k8s-worker1   Ready    <none>          2m2s    v1.32.5k8s-worker2   Ready    <none>          2m2s    v1.32.54.查看pod信息root@k8s-master:~# kubectl get pod -ANAMESPACE          NAME                                       READY   STATUS    RESTARTS   AGEcalico-apiserver   calico-apiserver-6499c768c8-wvrnt          1/1     Running   0          37mcalico-apiserver   calico-apiserver-6499c768c8-zmvh6          1/1     Running   0          37mcalico-system      calico-kube-controllers-85fb6564b7-gtsfr   1/1     Running   0          37mcalico-system      calico-node-4mqfj                          1/1     Running   0          37mcalico-system      calico-node-rkd6k                          1/1     Running   0          3m37scalico-system      calico-node-vxflh                          1/1     Running   0          3m37scalico-system      calico-typha-65d47d7478-cmrtt              1/1     Running   0          3m28scalico-system      calico-typha-65d47d7478-ttzx6              1/1     Running   0          37mcalico-system      csi-node-driver-7j8pf                      2/2     Running   0          37mcalico-system      csi-node-driver-nhg4c                      2/2     Running   0          3m37scalico-system      csi-node-driver-z6p7p                      2/2     Running   0          3m37skube-system        coredns-76fccbbb6b-l7jq9                   1/1     Running   0          3h29mkube-system        coredns-76fccbbb6b-nd68g                   1/1     Running   0          3h29mkube-system        etcd-k8s-master                            1/1     Running   0          3h29mkube-system        kube-apiserver-k8s-master                  1/1     Running   0          3h29mkube-system        kube-controller-manager-k8s-master         1/1     Running   0          3h29mkube-system        kube-proxy-8n6x5                           1/1     Running   0          3m37skube-system        kube-proxy-mcwv7                           1/1     Running   0          3h29mkube-system        kube-proxy-xk4h4                           1/1     Running   0          3m37skube-system        kube-scheduler-k8s-master                  1/1     Running   0          3h29mtigera-operator    tigera-operator-75b4cd596c-9hjml           1/1     Running   0          52m</code></pre><p>  注意上描述命令最后的–cri-socket参数，在系统中部署了docker和cri-docker时，必须明确指明此参数，并将此参数指向我们的cri-docker，不然命令会报告有两个重复的CRI的错误</p><p>  在k8s-master机器上执行以下内容给节点打上角色标签，k8s-worker1和k8s-worker2分别打上了worker1和worker2的标签</p><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# kubectl label nodes k8s-worker1 node-role.kubernetes.io/worker1=node/k8s-worker1 labeledroot@k8s-master:~# kubectl label nodes k8s-worker2 node-role.kubernetes.io/worker2=node/k8s-worker2 labeledroot@k8s-master:~# kubectl get nodesNAME          STATUS   ROLES           AGE     VERSIONk8s-master    Ready    control-plane   3h33m   v1.32.5k8s-worker1   Ready    worker1         7m37s   v1.32.5k8s-worker2   Ready    worker2         7m37s   v1.32.5</code></pre><h3 id="7-3-12-重置集群"><a href="#7-3-12-重置集群" class="headerlink" title="7.3.12 重置集群"></a>7.3.12 重置集群</h3><p>  如果在安装好集群的情况下，想重复练习初始化集群，或者包括初始化集群报错在内的任何原因，想重新初始化集群时，可以用下面的方法重置集群，重置后，集群就会被删除，可以用于重新部署，一般来说，这个命令仅用于k8s-master这个节点</p><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# kubeadm reset --cri-socket=unix:///var/run/cri-dockerd.sock# 根据提示，手工完成文件和规则的清理   清理后就可以重新部署集群了root@k8s-master:~# rm -rf /etc/cni/net.droot@k8s-master:~# iptables -Froot@k8s-master:~# rm -rf $HOME/.kube/config</code></pre><h3 id="7-3-13-标签和注解"><a href="#7-3-13-标签和注解" class="headerlink" title="7.3.13 标签和注解"></a>7.3.13 标签和注解</h3><p>  标签(Labels)和注解(Annotations)是附加到Kubernetes 对象(比如Pods)上的键值对</p><p>  标签旨在用于指定对用户有意义的标识属性，但不直接对核心系统有语义含义。可以用来选择对象和查找满足某些条件的对象集合</p><p>  注解不用于标识和选择对象。有效的注解键分为两部分： 可选的前缀和名称，以斜杠（/）分隔。 名称段是必需项，并且必须在63个字符以内</p><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# kubectl get node --show-labelsNAME          STATUS   ROLES           AGE     VERSION   LABELSk8s-master    Ready    control-plane   4h11m   v1.32.5   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-master,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=,node.kubernetes.io/exclude-from-external-load-balancers=k8s-worker1   Ready    worker1         45m     v1.32.5   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-worker1,kubernetes.io/os=linux,node-role.kubernetes.io/worker1=k8s-worker2   Ready    worker2         45m     v1.32.5   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=k8s-worker2,kubernetes.io/os=linux,node-role.kubernetes.io/worker2=root@k8s-master:~# kubectl get nodesNAME          STATUS   ROLES           AGE     VERSIONk8s-master    Ready    control-plane   4h11m   v1.32.5k8s-worker1   Ready    worker1         45m     v1.32.5k8s-worker2   Ready    worker2         45m     v1.32.5</code></pre><h1 id="8-Kubernetes的语法"><a href="#8-Kubernetes的语法" class="headerlink" title="8 Kubernetes的语法"></a>8 Kubernetes的语法</h1><p>  kubectl [command] [TYPE] [NAME] [flags]<br>  command：指定要对一个或多个资源执行的操作，例如create、get、describe、delete<br>  TYPE：指定资源类型，资源类型不区分大小写，可以指定单数、复数或缩写形式<br>  NAME：指定资源的名称，名称区分大小写<br>  fags：指定可选的参数。例如，可以使用-s或-server参数指定Kubernetes API服务器的地址和端口</p><p><img src="/images/k8s%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B.png"></p><h2 id="8-1-Yaml语法"><a href="#8-1-Yaml语法" class="headerlink" title="8.1 Yaml语法"></a>8.1 Yaml语法</h2><p><img src="/images/yaml%E8%AF%AD%E6%B3%95.png"></p><p>  注意每个层级之间的点（.），在YAML文件中，每个层级之间一般用两个空格来表</p><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# kubectl explain Pod.metadataKIND:       PodVERSION:    v1FIELD: metadata <ObjectMeta>...</code></pre><h3 id="8-1-1-生成YAML文件框架"><a href="#8-1-1-生成YAML文件框架" class="headerlink" title="8.1.1 生成YAML文件框架"></a>8.1.1 生成YAML文件框架</h3><p>  通过在创建资源时加上—dry-run=client –o yaml来生成YAML文件框架，可以用重定向到文件的方式生成文件，只需要稍作修改即可</p><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# kubectl create deployment --image httpd deployname --dry-run=client -o yamlapiVersion: apps/v1kind: Deploymentmetadata:  creationTimestamp: null  labels:    app: deployname  name: deploynamespec:  replicas: 1  selector:    matchLabels:      app: deployname  strategy: {}  template:    metadata:      creationTimestamp: null      labels:        app: deployname    spec:      containers:      - image: httpd        name: httpd        resources: {}status: {}# 重定向到文件root@k8s-master:~# kubectl create deployment --image httpd deployname --dry-run=client -o yaml > k8s.yml</code></pre><h3 id="8-1-2-apiVersion"><a href="#8-1-2-apiVersion" class="headerlink" title="8.1.2 apiVersion"></a>8.1.2 apiVersion</h3><p>Alpha:</p><p>  1.版本名称包含了alpha</p><p>  2.可能是有缺陷的。启用该功能可能会带来问题，默认是关闭的</p><p>  3.支持的功能可能在没有通知的情况下随时删除</p><p>  4.API的更改可能会带来兼容性问题，但是在后续的软件发布中不会有任何通知</p><p>  5.由于bugs风险的增加和缺乏长期的支持，推荐在短暂的集群测试中使用。</p><p>Beta:</p><p>  1.版本名称包含了beta</p><p>  2.代码已经测试过。启用该功能被 认为是安全的，功能默认已启用</p><p>  3.所有已支持的功能不会被删除，细节可能会发生变化</p><p>  4.对象的模式和/或语义可能会在后续的beta测试版或稳定版中以不兼容的方式进行更改。</p><p>  5.建议仅用于非业务关键型用途，因为后续版本中可能存在不兼容的更改。 如果有多个可以独立升级的集群，则可以放宽此限制</p><p>Stable：</p><p>  1.版本名称是 vX，其中X是整数</p><p>  2.功能的稳定版本将出现在许多后续版本的发行软件中</p><p>  3.有时候也会被称为GA或者毕业等词汇</p><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# kubectl api-resourcesNAME                 SHORTNAMES    APIVERSION                   NAMESPACED      KINDbindings                           v1                           true            Bindingcomponentstatuses    cs            v1                           false           ComponentStatusconfigmaps           cm            v1                           true            ConfigMapendpoints            ep            v1                           true            Endpointsevents               ev            v1                           true            Eventlimitranges          limits        v1                           true            LimitRangenamespaces           ns            v1                           false           Namespacenodes                no            v1                           false           Node...# 可以使用单数、复数、缩写root@k8s-master:~# kubectl get configmapsNAME               DATA   AGEkube-root-ca.crt   1      5h17mroot@k8s-master:~# kubectl get cmNAME               DATA   AGEkube-root-ca.crt   1      5h17mroot@k8s-master:~# kubectl get configmapNAME               DATA   AGEkube-root-ca.crt   1      5h17m</code></pre><h2 id="8-2-Namespace"><a href="#8-2-Namespace" class="headerlink" title="8.2 Namespace"></a>8.2 Namespace</h2><p>  Kubernetes支持多个虚拟集群，它们底层依赖于同一个物理集群。 这些虚拟集群被称为命名空间，它适用于存在很多跨多个团队或项目的用户的场景，命名空间为名称提供了一个范围</p><p>  资源的名称需要在名字空间内是唯一的，但不能跨名字空间</p><p>  名字空间不能相互嵌套，每个Kubernetes资源只能在一个名字空间中</p><p>  命名空间是在多个用户之间通过资源配额划分集群资源的一种方法</p><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# kubectl get namespaceNAME               STATUS   AGEcalico-apiserver   Active   3h18mcalico-system      Active   3h18mdefault            Active   6h10mkube-node-lease    Active   6h10mkube-public        Active   6h10mkube-system        Active   6h10mtigera-operator    Active   3h33mroot@k8s-master:~# kubectl get podNo resources found in default namespace.root@k8s-master:~# kubectl get pod -n kube-systemNAME                                 READY   STATUS    RESTARTS   AGEcoredns-76fccbbb6b-l7jq9             1/1     Running   0          6h14mcoredns-76fccbbb6b-nd68g             1/1     Running   0          6h14metcd-k8s-master                      1/1     Running   0          6h15mkube-apiserver-k8s-master            1/1     Running   0          6h14mkube-controller-manager-k8s-master   1/1     Running   0          6h15mkube-proxy-8n6x5                     1/1     Running   0          169mkube-proxy-mcwv7                     1/1     Running   0          6h14mkube-proxy-xk4h4                     1/1     Running   0          169mkube-scheduler-k8s-master            1/1     Running   0          6h15m</code></pre><h3 id="8-2-1-命令行创建"><a href="#8-2-1-命令行创建" class="headerlink" title="8.2.1 命令行创建"></a>8.2.1 命令行创建</h3><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# kubectl create namespace luovipnamespace/luovip createdroot@k8s-master:~# kubectl get namespaceNAME               STATUS   AGEcalico-apiserver   Active   3h26mcalico-system      Active   3h26mdefault            Active   6h18mkube-node-lease    Active   6h18mkube-public        Active   6h18mkube-system        Active   6h18mluovip             Active   7stigera-operator    Active   3h41m</code></pre><h3 id="8-2-2-YAML文件创建"><a href="#8-2-2-YAML文件创建" class="headerlink" title="8.2.2 YAML文件创建"></a>8.2.2 YAML文件创建</h3><pre class=" language-language-bash"><code class="language-language-bash">cat > namespace.yml <<EOFapiVersion: v1kind: Namespacemetadata:  name: luovipyuEOFroot@k8s-master:~# kubectl create -f namespace.ymlnamespace/luovipyu createdroot@k8s-master:~# kubectl get namespaceNAME               STATUS   AGEcalico-apiserver   Active   3h33mcalico-system      Active   3h33mdefault            Active   6h25mkube-node-lease    Active   6h25mkube-public        Active   6h25mkube-system        Active   6h25mluovip             Active   6m54sluovipyu           Active   26stigera-operator    Active   3h48m</code></pre><h3 id="8-2-3-删除namespace"><a href="#8-2-3-删除namespace" class="headerlink" title="8.2.3 删除namespace"></a>8.2.3 删除namespace</h3><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# kubectl delete namespace luovipyu   # 会删除名字空间下的所有内容namespace "luovipyu" deletedroot@k8s-master:~# kubectl create -f namespace.ymlnamespace/luovipyu createdroot@k8s-master:~# cat namespace.ymlapiVersion: v1kind: Namespacemetadata:  name: luovipyuroot@k8s-master:~# kubectl get namespaceNAME               STATUS   AGEcalico-apiserver   Active   3h39mcalico-system      Active   3h39mdefault            Active   6h30mkube-node-lease    Active   6h30mkube-public        Active   6h30mkube-system        Active   6h30mluovip             Active   12mluovipyu           Active   13stigera-operator    Active   3h54m</code></pre><h3 id="8-2-4-创建带有namespace属性的资源"><a href="#8-2-4-创建带有namespace属性的资源" class="headerlink" title="8.2.4 创建带有namespace属性的资源"></a>8.2.4 创建带有namespace属性的资源</h3><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# kubectl run httpd --image=httpd --namespace=luovipyupod/httpd createdroot@k8s-master:~# kubectl get pod -n luovipyuNAME    READY   STATUS             RESTARTS   AGEhttpd   1/1     Running            0          18snginx   0/1     ImagePullBackOff   0          106s# 每次查询和创建资源都需要带–namespace=luovipyu挺麻烦，可以设置默认值root@k8s-master:~# kubectl config set-context --current --namespace=luovipyuContext "kubernetes-admin@kubernetes" modified.root@k8s-master:~# kubectl config view | grep namespace    namespace: luovipyuroot@k8s-master:~# kubectl get podNAME    READY   STATUS             RESTARTS   AGEhttpd   1/1     Running            0          3m3snginx   0/1     ImagePullBackOff   0          4m31s# 删除namespace会删除其下所有资源，但如果要删除已经切换为默认值的namespace时，可能会卡住，所以先把默认值切换为其他，然后再删除root@k8s-master:~# kubectl config set-context --current --namespace=defaultContext "kubernetes-admin@kubernetes" modified.root@k8s-master:~# kubectl delete namespaces luovip luovipyunamespace "luovip" deletednamespace "luovipyu" deletedroot@k8s-master:~# kubectl get namespaceNAME               STATUS   AGEcalico-apiserver   Active   3h49mcalico-system      Active   3h49mdefault            Active   6h41mkube-node-lease    Active   6h41mkube-public        Active   6h41mkube-system        Active   6h41mtigera-operator    Active   4h4m</code></pre><h2 id="8-3-CRD自定义资源"><a href="#8-3-CRD自定义资源" class="headerlink" title="8.3 CRD自定义资源"></a>8.3 CRD自定义资源</h2><p>  CRD（Custom Resource Definition，自定义资源定义）是Kubernetes提供的一种扩展机制，允许用户通过YAML文件定义自定义资源类型，并将其注册到Kubernetes API中，使其与内置资源（如Pod、 Deployment）一样被管理</p><p>  本质：CRD是对自定义资源的元数据描述，定义了资源的名称、结构、版本、作用域等<br>  作用：扩展Kubernetes API，支持用户自定义资源的管理和自动化操作</p><p>CRD核心字段：</p><table><thead><tr><th align="left">字段</th><th align="left">说明</th><th align="left">示例</th></tr></thead><tbody><tr><td align="left">apiVersion</td><td align="left">CRD的API版本，固定为apiextensions.k8s.io/v1</td><td align="left">apiVersion:apiextensions.k8s.io/v1</td></tr><tr><td align="left">kind</td><td align="left">资源类型，固定为CustomResourceDefinition</td><td align="left">kind: CustomResourceDefinition</td></tr><tr><td align="left">metadata</td><td align="left">元数据，如名称、命名空间等(名称需符合DNS子域名规则)</td><td align="left">name:crontabs.stable.example.com</td></tr><tr><td align="left">spec</td><td align="left">核心配置，包括 API组、版本、资源范围 (Namespaced/Cluster)、字段验证规则等</td><td align="left">group: stable.example.com</td></tr><tr><td align="left">versions</td><td align="left">支持的API版本列表，需指定至少一个存储版本( storage:true)</td><td align="left">version:[v1][@ref)</td></tr><tr><td align="left">names</td><td align="left">资源的复数形式、单数形式、简称等(如plural:crontabs)</td><td align="left">plural: crontabs</td></tr><tr><td align="left">scope</td><td align="left">资源作用域，Namespaced(命名空间级别)或Cluster(集群级别)</td><td align="left">scope: Namespaced</td></tr></tbody></table><h3 id="8-3-1-CRD介绍"><a href="#8-3-1-CRD介绍" class="headerlink" title="8.3.1 CRD介绍"></a>8.3.1 CRD介绍</h3><p>  K8S资源类型不止有namespace，还有很多，不过那都是系统自带的，现在我们来看看怎么自定义k8s中的资源</p><p>1.什么是CRD？</p><p>  CRD（Custom Resource Definition）是 Kubernetes 提供的一种机制，允许用户定义自己的资源类型</p><p>  这些自定义资源可以像 Kubernetes 原生资源（如 Pod、Service、Deployment 等）一样被管理。<br>2.为什么需要CRD？</p><p>  扩展 Kubernetes API：Kubernetes 的原生资源可能无法满足所有用户的需求。CRD 允许用户定义自己的资源类型，从而扩展 Kubernetes 的功能。</p><p>  管理复杂应用：有些应用可能需要管理一些特定的资源，这些资源不属于Kubernetes原生支持的范围。通过CRD可以将这些资源纳入 Kubernetes的管理范围，实现统一的资源管理</p><p>3.CRD的作用</p><p>  定义资源结构：CRD 允许你定义资源的结构，包括其字段和数据类型</p><p>  管理资源生命周期：Kubernetes 将为你管理这些自定义资源的生命周期，包括创建、更新、删除等操作</p><p>  集成 Kubernetes 生态系统：CRD 可以与 Kubernetes 的其他组件（如控制器、操作符等）集成，实现更复杂的业务逻辑</p><p>  在Kubernetes 的自定义资源定义（CRD）中，CRD 本身只定义了资源的结构和 API，但它不会直接执行任何创建、更新或删除操作。这些操作需要通过一个控制器（Controller）来实现。控制器是一个独立的程序，它监听 CRD 的变化，并根据这些变化执行实际的操作</p><h3 id="8-3-2-查询CRD以及API资源"><a href="#8-3-2-查询CRD以及API资源" class="headerlink" title="8.3.2 查询CRD以及API资源"></a>8.3.2 查询CRD以及API资源</h3><p>  1.先看看系统中的api资源都有哪些，然后创建一个</p><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# kubectl api-resourcesNAME                 SHORTNAMES    APIVERSION                   NAMESPACED      KINDbindings                           v1                           true            Bindingcomponentstatuses    cs            v1                           false           ComponentStatusconfigmaps           cm            v1                           true            ConfigMapendpoints            ep            v1                           true            Endpointsevents               ev            v1                           true            Eventlimitranges          limits        v1                           true            LimitRangenamespaces           ns            v1                           false           Namespacenodes                no            v1                           false           Node...</code></pre><p>  2.查看现在都有哪些自定义资源</p><pre class=" language-language-bash"><code class="language-language-bash"># 以下资源不属于K8s，但是k8s是有的root@k8s-master:~# kubectl get crdNAME                                                  CREATED ATadminnetworkpolicies.policy.networking.k8s.io         2025-05-17T03:05:26Zapiservers.operator.tigera.io                         2025-05-17T03:05:26Zbgpconfigurations.crd.projectcalico.org               2025-05-17T03:05:26Zbgpfilters.crd.projectcalico.org                      2025-05-17T03:05:26Zbgppeers.crd.projectcalico.org                        2025-05-17T03:05:26Zblockaffinities.crd.projectcalico.org                 2025-05-17T03:05:26Zcaliconodestatuses.crd.projectcalico.org              2025-05-17T03:05:26Zclusterinformations.crd.projectcalico.org             2025-05-17T03:05:26Zfelixconfigurations.crd.projectcalico.org             2025-05-17T03:05:26Zglobalnetworkpolicies.crd.projectcalico.org           2025-05-17T03:05:26Zglobalnetworksets.crd.projectcalico.org               2025-05-17T03:05:26Zhostendpoints.crd.projectcalico.org                   2025-05-17T03:05:26Zimagesets.operator.tigera.io                          2025-05-17T03:05:26Zinstallations.operator.tigera.io                      2025-05-17T03:05:26Zipamblocks.crd.projectcalico.org                      2025-05-17T03:05:26Zipamconfigs.crd.projectcalico.org                     2025-05-17T03:05:26Zipamhandles.crd.projectcalico.org                     2025-05-17T03:05:26Zippools.crd.projectcalico.org                         2025-05-17T03:05:26Zipreservations.crd.projectcalico.org                  2025-05-17T03:05:26Zkubecontrollersconfigurations.crd.projectcalico.org   2025-05-17T03:05:26Znetworkpolicies.crd.projectcalico.org                 2025-05-17T03:05:26Znetworksets.crd.projectcalico.org                     2025-05-17T03:05:26Ztiers.crd.projectcalico.org                           2025-05-17T03:05:26Ztigerastatuses.operator.tigera.io                     2025-05-17T03:05:26Z</code></pre><h3 id="8-3-3-创建CRD以及API资源"><a href="#8-3-3-创建CRD以及API资源" class="headerlink" title="8.3.3 创建CRD以及API资源"></a>8.3.3 创建CRD以及API资源</h3><p>  1.创建一个自己的crd，crd将注册为api资源</p><pre class=" language-language-bash"><code class="language-language-bash">cat > crd.yaml <<-'EOF'apiVersion: apiextensions.k8s.io/v1kind: CustomResourceDefinitionmetadata:  # 名字必需与下面的 spec 字段匹配，并且格式为 '<名称的复数形式>.<组名>'  name: crontabs.stable.example.comspec:  # 组名称，用于 REST API：/apis/<组>/<版本>  group: stable.example.com  # 列举此 CustomResourceDefinition 所支持的版本  versions:    - name: v1      # 每个版本都可以通过 served 标志来独立启用或禁止      served: true      # 其中一个且只有一个版本必需被标记为存储版本      storage: true      schema:        openAPIV3Schema:          type: object          properties:            spec:              type: object              properties:                cronSpec:                  type: string                image:                  type: string                replicas:                  type: integer  # 可以是 Namespaced 或 Cluster  scope: Namespaced  names:    # 名称的复数形式，用于 URL：/apis/<组>/<版本>/<名称的复数形式>    plural: crontabs    # 名称的单数形式，作为命令行使用时和显示时的别名    singular: crontab    # kind 通常是单数形式的驼峰命名（CamelCased）形式。你的资源清单会使用这一形式。    kind: CronTab    # shortNames 允许你在命令行使用较短的字符串来匹配资源    shortNames:    - ctEOFroot@k8s-master:~# kubectl apply -f crd.yamlcustomresourcedefinition.apiextensions.k8s.io/crontabs.stable.example.com created</code></pre><p>  2.再看就会有自己的crd资源和api资源了</p><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# kubectl get crdNAME                                                  CREATED AT...crontabs.stable.example.com                           2025-05-17T06:16:04Z...root@k8s-master:~# kubectl api-resources | grep crontabsNAME          SHORTNAMES                      APIVERSION                          NAMESPACED   KINDcrontabs      ct                              stable.example.com/v1               true         CronTabroot@k8s-master:~# kubectl describe crd crontabs.stable.example.com</code></pre><h3 id="8-3-4-查询API资源结构与参数"><a href="#8-3-4-查询API资源结构与参数" class="headerlink" title="8.3.4 查询API资源结构与参数"></a>8.3.4 查询API资源结构与参数</h3><p>  既然已经注册为api资源，来看看能否explain字段？</p><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# kubectl explain crontabsGROUP:      stable.example.comKIND:       CronTabVERSION:    v1DESCRIPTION:    <empty>FIELDS:  apiVersion    <string>  kind  <string>  metadata      <ObjectMeta>  spec  <Object>...# 查看有哪些specroot@k8s-master:~# kubectl explain crontabs.specGROUP:      stable.example.comKIND:       CronTabVERSION:    v1FIELD: spec <Object>DESCRIPTION:    <empty>FIELDS:  cronSpec      <string>    <no description>  image <string>    <no description>  replicas      <integer>    <no description># 一切正常，看来已经创建了自定义资源，接下来就是等开发人员通过编程等方式创建operator等控制器，来使用我们的资源了</code></pre><h1 id="9-Pod"><a href="#9-Pod" class="headerlink" title="9 Pod"></a>9 Pod</h1><h2 id="9-1-关于pod"><a href="#9-1-关于pod" class="headerlink" title="9.1 关于pod"></a>9.1 关于pod</h2><p>  Pod由一个或多个紧密耦合的容器组成</p><p>  它们之间共享网络、存储等资源</p><p>  pod是Kubernetes中最小的工作单元</p><p>  Pod中的容器会一起启动和停止</p><h2 id="9-2-Pod生命周期"><a href="#9-2-Pod生命周期" class="headerlink" title="9.2 Pod生命周期"></a>9.2 Pod生命周期</h2><p>  Pod遵循一个预定义的生命周期，起始于Pending阶段，如果至少其中有一个主要容器正常启动，则进入Running，之后取决于Pod中是否有容器以失败状态结束而进入Succeeded或者Failed阶段。但有时集群节点之间出现网络故障，无法获取Pod状态时，就会出现Unknown状态</p><h2 id="9-3-创建Pod"><a href="#9-3-创建Pod" class="headerlink" title="9.3 创建Pod"></a>9.3 创建Pod</h2><p>  1.一个Pod中只有一个业务容器</p><pre class=" language-language-bash"><code class="language-language-bash"># 1.yml文件创建podcat > pod.yml <<EOFapiVersion: v1kind: Podmetadata:  name: luovippodspec:  containers:  - name: hello    image: httpd    imagePullPolicy: IfNotPresent    command: ['sh', '-c', 'echo "Hello, China!" && sleep 3600']  restartPolicy: OnFailureEOFroot@k8s-master:~# kubectl create -f pod.ymlpod/luovippod createdroot@k8s-master:~# kubectl get podNAME        READY   STATUS    RESTARTS   AGEluovippod   1/1     Running   0          5sroot@k8s-master:~# kubectl logs luovippodHello, China!root@k8s-master:~# kubectl delete pod luovippod    删除pod# 2.命令行创建podroot@k8s-master:~# kubectl run luoyupod --image=nginx --port=80pod/luoyupod createdroot@k8s-master:~# kubectl get podNAME        READY   STATUS    RESTARTS   AGEluovippod   1/1     Running   0          7m56sluoyupod    1/1     Running   0          3m38sroot@k8s-master:~# kubectl get pod -o wideNAME        READY   STATUS    RESTARTS   AGE     IP              NODE          NOMINATED NODE   READINESS GATESluovippod   1/1     Running   0          8m6s    172.16.194.71   k8s-worker1   <none>           <none>luoyupod    1/1     Running   0          3m48s   172.16.194.72   k8s-worker1   <none>           <none></code></pre><p>  2.一个Pod中有多个业务容器</p><pre class=" language-language-bash"><code class="language-language-bash">cat > multicontainer.yml <<EOFapiVersion: v1kind: Podmetadata:  name: podspec:  containers:  - name: nginx    image: nginx    imagePullPolicy: IfNotPresent    command: ['sh', '-c', 'echo "Hello, luoyu!" && sleep 3600']  - name: httpd    image: httpd    imagePullPolicy: IfNotPresent    ports:      - name: web        containerPort: 80  restartPolicy: OnFailureEOFroot@k8s-master:~# kubectl create -f multicontainer.ymlpod/pod createdroot@k8s-master:~# kubectl get podNAME        READY   STATUS    RESTARTS   AGEluovippod   1/1     Running   0          18mluoyupod    1/1     Running   0          14mpod         2/2     Running   0          9sroot@k8s-master:~# kubectl get -f multicontainer.yml -o wideNAME   READY   STATUS    RESTARTS   AGE   IP             NODE          NOMINATED NODE   READINESS GATESpod    2/2     Running   0          68s   172.16.126.3   k8s-worker2   <none>           <none>root@k8s-master:~# curl 172.16.126.3</code></pre><h2 id="9-4-修改Pod"><a href="#9-4-修改Pod" class="headerlink" title="9.4 修改Pod"></a>9.4 修改Pod</h2><pre class=" language-language-bash"><code class="language-language-bash"># 直接修改yaml文件，然后执行以下命令kubectl apply -f pod.yml# 编辑Etcd数据kubectl edit pod luovippod# patch参数kubectl get pod luovippod -o jsonkubectl get pod luovippod -o json | grep cnlxh注明：工作中的修改pod一般时k8s会创建新的pod并删除旧的pod</code></pre><h2 id="9-5-进入pod中的容器"><a href="#9-5-进入pod中的容器" class="headerlink" title="9.5 进入pod中的容器"></a>9.5 进入pod中的容器</h2><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# kubectl get pod -o wideNAME        READY   STATUS    RESTARTS   AGE   IP              NODE          NOMINATED NODE   READINESS GATESluovippod   1/1     Running   0          37m   172.16.194.71   k8s-worker1   <none>           <none>luoyupod    1/1     Running   0          33m   172.16.194.72   k8s-worker1   <none>           <none>pod         2/2     Running   0          19m   172.16.126.3    k8s-worker2   <none>           <none>root@k8s-master:~# kubectl exec -it pod -c httpd  -- /bin/bashroot@pod:/usr/local/apache2# echo MyCity is ChengDu! > htdocs/index.htmlroot@pod:/usr/local/apache2# exitexitroot@k8s-master:~# curl http://172.16.126.3MyCity is ChengDu!#参数说明： 1、-c 参数可以指定需要进入pod中的哪个容器 2、-- 是K8S命令和预期容器内部执行命令的连接符 3、/bin/sh是指进入容器中执行什么命令  4、退出执行exit</code></pre><h2 id="9-6-Init类型容器"><a href="#9-6-Init类型容器" class="headerlink" title="9.6 Init类型容器"></a>9.6 Init类型容器</h2><p>  Init容器是一种特殊容器，在Pod内的应用容器启动之前运行，如果Pod的Init容器失败，kubelet会不断地重启该 Init 容器直到该容器成功为止。 然而，如果 Pod 对应的 restartPolicy 值为 “Never”，并且 Pod的 Init 容器失败， 则 Kubernetes 会将整个 Pod 状态设置为失败</p><p>  Init容器与普通的容器非常像，除了如下两点：</p><p>   1.正常情况下，它们最终都会处于completed状态</p><p>   2.每个都必须在下一个启动之前成功完成</p><pre class=" language-language-bash"><code class="language-language-bash"># 根据安排，myapp-container的容器将等待两个init结束之后才会启动，也就是40秒之后才会启动cat > init.yml <<EOFapiVersion: v1kind: Podmetadata:  name: initpd  labels:    app: myappspec:  containers:  - name: myapp-container    image: busybox    imagePullPolicy: IfNotPresent    command: ['sh', '-c', 'echo The app is running! && sleep 3600']  initContainers:  - name: init-myservice    image: busybox    imagePullPolicy: IfNotPresent    command: ['sh', '-c', "sleep 20"]  - name: init-mydb    image: busybox    imagePullPolicy: IfNotPresent    command: ['sh', '-c', "sleep 20"]EOFroot@k8s-master:~# kubectl create -f init.ymlpod/initpd created# -w参数可以实时查看pod的状态变化root@k8s-master:~# kubectl get -f init.yml -wNAME     READY   STATUS     RESTARTS   AGEinitpd   0/1     Init:0/2   0          19sinitpd   0/1     Init:1/2   0          21sinitpd   0/1     Init:1/2   0          22sinitpd   0/1     PodInitializing   0          42sinitpd   1/1     Running           0          43sroot@k8s-master:~# kubectl get pod -wNAME        READY   STATUS     RESTARTS   AGEinitpd      0/1     Init:1/2   0          34sluovippod   1/1     Running    0          56mluoyupod    1/1     Running    0          51mpod         2/2     Running    0          37mroot@k8s-master:~# kubectl get podsNAME        READY   STATUS    RESTARTS   AGEinitpd      1/1     Running   0          104sluovippod   1/1     Running   0          57mluoyupod    1/1     Running   0          52mpod         2/2     Running   0          39m</code></pre><h2 id="9-7-Sidecar类型容器"><a href="#9-7-Sidecar类型容器" class="headerlink" title="9.7 Sidecar类型容器"></a>9.7 Sidecar类型容器</h2><p>  一般来讲，Sidecar容器可以：</p><p>   1.日志代理/转发，例如 fluentd</p><p>   2.Service Mesh，比如 Istio，Linkerd</p><p>   3.代理，比如 Docker Ambassador</p><p>   4.探活：检查某些组件是不是正常工作</p><p>   5.其他辅助性的工作，比如拷贝文件，下载文件等</p><p><img src="/images/Sidecar.png"></p><pre class=" language-language-bash"><code class="language-language-bash"># 两个容器挂载了同一个目录，一个容器负责写入数据，一个容器负责对外展示cat > sidecar.yml <<EOFapiVersion: v1kind: Podmetadata:  name: sidecarpodspec:  containers:  - name: httpd    image: httpd    imagePullPolicy: IfNotPresent    volumeMounts:      - mountPath: /usr/local/apache2/htdocs/        name: luoyuvolume  - name: busybox    image: busybox    imagePullPolicy: IfNotPresent    command: ['sh', '-c', 'echo "Hello sidecar" > /usr/local/apache2/htdocs/index.html && sleep 3600']    volumeMounts:      - mountPath: /usr/local/apache2/htdocs/        name: luoyuvolume  restartPolicy: OnFailure  volumes:    - name: luoyuvolume      emptyDir: {}EOFroot@k8s-master:~# kubectl create -f sidecar.ymlpod/sidecarpod createdroot@k8s-master:~# kubectl get -f sidecar.yml -o wideNAME         READY   STATUS    RESTARTS   AGE   IP              NODE       NOMINATED NODE   READINESS GATESsidecarpod   2/2     Running   0          9s    172.16.194.74   k8s-worker1   <none>           <none>root@k8s-master:~# curl http://172.16.194.74Hello sidecar</code></pre><h2 id="9-8-静态Pod"><a href="#9-8-静态Pod" class="headerlink" title="9.8 静态Pod"></a>9.8 静态Pod</h2><p>  静态 Pod 在指定的节点上由 kubelet 守护进程直接管理，不需要 API 服务器监管。 与由控制面管理的Pod（例如，Deployment） 不同；kubelet 监视每个静态 Pod（在它崩溃之后重新启动）</p><p>  静态 Pod 永远都会绑定到一个指定节点上的 Kubelet</p><p>  kubelet 会尝试通过 Kubernetes API 服务器为每个静态 Pod 自动创建一个 mirror Pod。 这意味着节点上运行的静态 Pod 对 API 服务来说是可见的，但是不能通过 API 服务器来控制。 Pod 名称将把以连字符开头的节点主机名作为后缀</p><p>  运行中的 kubelet 会定期扫描配置的目录中的变化， 并且根据文件中出现/消失的 Pod 来添加/删除Pod</p><p>1.查找静态pod的编写路径</p><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# systemctl status kubelet...    Drop-In: /usr/lib/systemd/system/kubelet.service.d             └─10-kubeadm.conf...root@k8s-master:~# tail /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf[Service]...Environment="KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml"...root@k8s-master:~# grep -i static /var/lib/kubelet/config.yamlstaticPodPath: /etc/kubernetes/manifests</code></pre><p>2.编写静态pod</p><pre class=" language-language-bash"><code class="language-language-bash">cat > static.yml <<EOFapiVersion: v1kind: Podmetadata:  name: staticpodspec:  containers:  - name: hello    image: busybox    imagePullPolicy: IfNotPresent    command: ['sh', '-c', 'echo "Hello, lixiaohui!" && sleep 3600']  restartPolicy: OnFailureEOF# 把这个yaml文件复制到/etc/kubernetes/manifests，然后观察pod列表，然后把yaml文件移出此文件夹，再观察pod列表root@k8s-master:~# cp static.yml /etc/kubernetes/manifests/root@k8s-master:~# kubectl get podNAME                   READY   STATUS      RESTARTS   AGEinitpd                 1/1     Running     0          40mluovippod              0/1     Completed   0          95mluoyupod               1/1     Running     0          91mpod                    1/2     NotReady    0          77msidecarpod             2/2     Running     0          31mstaticpod-k8s-master   1/1     Running     0          12s# 删除/etc/kubernetes/manifests文件中的yml文件，再观察pod列表root@k8s-master:~# rm -rf /etc/kubernetes/manifests/static.ymlroot@k8s-master:~# kubectl get podNAME         READY   STATUS      RESTARTS   AGEinitpd       1/1     Running     0          41mluovippod    0/1     Completed   0          97mluoyupod     1/1     Running     0          92mpod          1/2     NotReady    0          78msidecarpod   2/2     Running     0          32m# 维持集群运行的文件如下：root@k8s-master:/etc/kubernetes/manifests# lsetcd.yaml  kube-apiserver.yaml  kube-controller-manager.yaml  kube-scheduler.yaml  static.yml</code></pre><h2 id="9-9-Pod删除"><a href="#9-9-Pod删除" class="headerlink" title="9.9 Pod删除"></a>9.9 Pod删除</h2><p>  kubectl delete pod –all会删除所有pod</p><p>  kubectl delete pod pod名称—删除指定的pod</p><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# kubectl get podsNAME                   READY   STATUS    RESTARTS   AGEinitpd                 1/1     Running   0          13mluovippod              1/1     Running   0          9m23sluoyupod               1/1     Running   0          169mpod                    2/2     Running   0          7m51ssidecarpod             2/2     Running   0          27sstaticpod-k8s-master   1/1     Running   0          2sroot@k8s-master:~# kubectl delete pod luovippodroot@k8s-master:~# kubectl delete pod -allroot@k8s-master:~# kubectl get podsNo resources found in default namespace.root@k8s-master:~# kubectl get pod -n kube-systemNAME                                 READY   STATUS    RESTARTS   AGEcoredns-76fccbbb6b-l7jq9             1/1     Running   0          35hcoredns-76fccbbb6b-nd68g             1/1     Running   0          35hetcd-k8s-master                      1/1     Running   0          35hkube-apiserver-k8s-master            1/1     Running   0          35hkube-controller-manager-k8s-master   1/1     Running   0          35hkube-proxy-8n6x5                     1/1     Running   0          32hkube-proxy-mcwv7                     1/1     Running   0          35hkube-proxy-xk4h4                     1/1     Running   0          32hkube-scheduler-k8s-master            1/1     Running   0          35h</code></pre><h1 id="10-Kubernetes控制器"><a href="#10-Kubernetes控制器" class="headerlink" title="10 Kubernetes控制器"></a>10 Kubernetes控制器</h1><h2 id="10-1-什么是控制器"><a href="#10-1-什么是控制器" class="headerlink" title="10.1 什么是控制器"></a>10.1 什么是控制器</h2><p>  当你设置了温度，告诉了空调遥控器你的期望状态（Desired State）。 房间的实际温度是当前状态（Current State）。 通过对遥控器的开关控制，遥控器让其当前状态接近期望状态<br>  在 Kubernetes 中，控制器通过监控集群的公共状态，并致力于将当前状态转变为期望的状态</p><p>  作为设计原则之一，Kubernetes 使用了很多控制器，每个控制器管理集群状态的一个特定方面。 最常见的一个特定的控制器使用一种类型的资源作为它的期望状态， 控制器管理控制另外一种类型的资源向它的期望状态演化</p><h2 id="10-2-Replica-Set概念"><a href="#10-2-Replica-Set概念" class="headerlink" title="10.2 Replica Set概念"></a>10.2 Replica Set概念</h2><p>  ReplicationController确保在任何时候都有特定数量的Pod副本处于运行状态。 换句话说，ReplicationController 确保一个 Pod 或一组同类的 Pod 总是可用的<br>  ReplicaSet的目的是维护一组在任何时候都处于运行状态的 Pod 副本的稳定集合。 因此，它通常用来保证给定数量的、完全相同的 Pod 的可用性。</p><p>说明： 现在推荐使用配置ReplicaSet的Deployment来建立副本管理机制</p><h2 id="10-3-Replica-Set-工作原理"><a href="#10-3-Replica-Set-工作原理" class="headerlink" title="10.3 Replica Set 工作原理"></a>10.3 Replica Set 工作原理</h2><p>  RepicaSet是通过一组字段来定义的，包括一个用来识别可获得的 Pod 的集合的选择算符、一个用来标明应该维护的副本个数的数值、一个用来指定应该创建新 Pod 以满足副本个数条件时要使用的 Pod 模板等等。 每个 ReplicaSet 都通过根据需要创建和 删除 Pod 以使得副本个数达到期望值， 进而实现其存在价值。当 ReplicaSet 需要创建新的 Pod 时，会使用所提供的 Pod 模板</p><p>  1.ReplicaSet也需要apiVersion、kind和metadata字段</p><p>  2.Pod 选择算符：.spec.selector 字段是一个标签选择算符。在 ReplicaSet 中，.spec.template.metadata.labels 的值必须与 spec.selector 值 相匹配，否则该配置会被API拒绝</p><p>  3.可以通过设置 .spec.replicas 来指定要同时运行的 Pod个数。 ReplicaSet 创建、删除 Pods 以与此值匹配</p><h2 id="10-4-ReplicaSet使用"><a href="#10-4-ReplicaSet使用" class="headerlink" title="10.4 ReplicaSet使用"></a>10.4 ReplicaSet使用</h2><p>  使用nginx镜像创建具有3个pod的RS,并分配合适的标签</p><h3 id="10-4-1-创建yml文件"><a href="#10-4-1-创建yml文件" class="headerlink" title="10.4.1 创建yml文件"></a>10.4.1 创建yml文件</h3><pre class=" language-language-bash"><code class="language-language-bash">cat > rs.yml <<EOFapiVersion: apps/v1kind: ReplicaSetmetadata:  name: nginxrstest  labels:    app: nginxrstestspec:  replicas: 3  selector:    matchLabels:      app: nginxrstest  template:    metadata:      labels:        app: nginxrstest    spec:      containers:      - name: nginx        image: nginx        imagePullPolicy: IfNotPresent        ports:          - name: http            containerPort: 80        imagePullPolicy: IfNotPresentEOF</code></pre><h3 id="10-4-2-操作ReplicaSet"><a href="#10-4-2-操作ReplicaSet" class="headerlink" title="10.4.2 操作ReplicaSet"></a>10.4.2 操作ReplicaSet</h3><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# kubectl create -f rs.ymlroot@k8s-master:~# kubectl get rsNAME          DESIRED   CURRENT   READY   AGEnginxrstest   3         3         3       3m45sroot@k8s-master:~# kubectl get pod --show-labelsNAME                READY   STATUS    RESTARTS   AGE    LABELSnginxrstest-5bvpr   1/1     Running   0          7m1s   app=nginxrstestnginxrstest-9d86s   1/1     Running   0          7m1s   app=nginxrstestnginxrstest-k79cw   1/1     Running   0          7m1s   app=nginxrstest# 被动高可用root@k8s-master:~# kubectl delete pod --allpod "nginxrstest-5bvpr" deletedpod "nginxrstest-9d86s" deletedpod "nginxrstest-k79cw" deletedroot@k8s-master:~# kubectl get replicasets.apps,podsNAME                          DESIRED   CURRENT   READY   AGEreplicaset.apps/nginxrstest   3         3         3       12mNAME                    READY   STATUS    RESTARTS   AGEpod/nginxrstest-86dd7   1/1     Running   0          3m6spod/nginxrstest-bbzxd   1/1     Running   0          3m6spod/nginxrstest-ndgxg   1/1     Running   0          3m6s# 扩容root@k8s-master:~# kubectl scale replicaset nginxrstest --replicas 4replicaset.apps/nginxrstest scaledroot@k8s-master:~# kubectl get replicasets.apps nginxrstestNAME          DESIRED   CURRENT   READY   AGEnginxrstest   4         4         4       16mroot@k8s-master:~# kubectl get replicasets.apps,pods -o wide# 删除root@k8s-master:~# kubectl delete replicasets.apps nginxrstestreplicaset.apps "nginxrstest" deletedroot@k8s-master:~# kubectl get podNo resources found in default namespace.</code></pre><h2 id="10-5-Deployment"><a href="#10-5-Deployment" class="headerlink" title="10.5 Deployment"></a>10.5 Deployment</h2><p>  ReplicaSet确保任何时间都有指定数量的Pod副本在运行。 然而，Deployment是一个更高级的概念，它管理ReplicaSet，并向Pod提供声明式的更新以及许多其他有用的功能。 因此，建议使用 Deployment 而不是直接使用 ReplicaSet，除非需要自定义更新业务流程或根本不需要更新<br>  这实际上意味着，可能永远不需要操作ReplicaSet对象：而是使用Deployment，并在spec部分定义应用</p><p><img src="/images/Deployment.png"></p><h3 id="10-5-1-创建yml文件"><a href="#10-5-1-创建yml文件" class="headerlink" title="10.5.1 创建yml文件"></a>10.5.1 创建yml文件</h3><pre class=" language-language-bash"><code class="language-language-bash">cat > deployment.yml <<EOFapiVersion: apps/v1kind: Deploymentmetadata:  name: nginx-deployment  labels:    app: nginxspec:  replicas: 3  selector:    matchLabels:      app: nginx  template:    metadata:      labels:        app: nginx    spec:      containers:      - name: nginx        image: nginx:1.16.1        imagePullPolicy: IfNotPresent        ports:        - containerPort: 80EOF</code></pre><h3 id="10-5-2-创建Deployment"><a href="#10-5-2-创建Deployment" class="headerlink" title="10.5.2 创建Deployment"></a>10.5.2 创建Deployment</h3><pre class=" language-language-bash"><code class="language-language-bash"># 使用nginx镜像创建具有3个副本的Deployment，并分配合适的属性# 发现deployment管理了一个RS，而RS又实现了3个podroot@k8s-master:~# kubectl create -f deployment.ymldeployment.apps/nginx-deployment createdroot@k8s-master:~# kubectl get deployment.appsNAME               READY   UP-TO-DATE   AVAILABLE   AGEnginx-deployment   3/3     3            3           20s# kubectl get pods --show-labels(可选)  Deployment控制器将pod-template-hash标签添加到Deployment所创建或收留的每个ReplicaSet，此标签可确保Deployment的子 ReplicaSets不重叠root@k8s-master:~# kubectl get pods --show-labelsNAME                               READY   STATUS    RESTARTS   AGE   LABELSnginx-deployment-8d94c585f-ngm9d   1/1     Running   0          51s   app=nginx,pod-template-hash=8d94c585fnginx-deployment-8d94c585f-wf4mc   1/1     Running   0          51s   app=nginx,pod-template-hash=8d94c585fnginx-deployment-8d94c585f-wjzkw   1/1     Running   0          51s   app=nginx,pod-template-hash=8d94c585froot@k8s-master:~# kubectl get deployments.apps,replicasets.apps,pods -l app=nginxNAME                               READY   UP-TO-DATE   AVAILABLE   AGEdeployment.apps/nginx-deployment   3/3     3            3           2m20sNAME                                         DESIRED   CURRENT   READY   AGEreplicaset.apps/nginx-deployment-8d94c585f   3         3         3       2m20sNAME                                   READY   STATUS    RESTARTS   AGEpod/nginx-deployment-8d94c585f-ngm9d   1/1     Running   0          2m20spod/nginx-deployment-8d94c585f-wf4mc   1/1     Running   0          2m20spod/nginx-deployment-8d94c585f-wjzkw   1/1     Running   0          2m20s</code></pre><h3 id="10-5-3-更新Deployment"><a href="#10-5-3-更新Deployment" class="headerlink" title="10.5.3 更新Deployment"></a>10.5.3 更新Deployment</h3><p>  1.将deployment的镜像更改一次</p><pre class=" language-language-bash"><code class="language-language-bash"># Deployment的更新策略root@k8s-master:~# kubectl get deployments.apps nginx-deployment -o yamlapiVersion: apps/v1kind: Deployment...  strategy:    rollingUpdate:      maxSurge: 25%      maxUnavailable: 25%    type: RollingUpdate...root@k8s-master:~# kubectl set image deployments/nginx-deployment nginx=nginx:1.17.1 --recordFlag --record has been deprecated, --record will be removed in the futuredeployment.apps/nginx-deployment image updated# 查看更新的进度---更新过程是多了一个replicasetroot@k8s-master:~# kubectl rollout status deployment/nginx-deploymentWaiting for deployment "nginx-deployment" rollout to finish: 1 out of 3 new replicas have been updated...Waiting for deployment "nginx-deployment" rollout to finish: 1 out of 3 new replicas have been updated...Waiting for deployment "nginx-deployment" rollout to finish: 1 out of 3 new replicas have been updated...Waiting for deployment "nginx-deployment" rollout to finish: 2 out of 3 new replicas have been updated...Waiting for deployment "nginx-deployment" rollout to finish: 2 out of 3 new replicas have been updated...Waiting for deployment "nginx-deployment" rollout to finish: 2 out of 3 new replicas have been updated...Waiting for deployment "nginx-deployment" rollout to finish: 1 old replicas are pending termination...Waiting for deployment "nginx-deployment" rollout to finish: 1 old replicas are pending termination...deployment "nginx-deployment" successfully rolled outroot@k8s-master:~# kubectl get deployments.apps,replicasets.apps,pods -l app=nginxNAME                               READY   UP-TO-DATE   AVAILABLE   AGEdeployment.apps/nginx-deployment   3/3     3            3           5m43sNAME                                          DESIRED   CURRENT   READY   AGEreplicaset.apps/nginx-deployment-5d457cdfc8   3         3         3       84sreplicaset.apps/nginx-deployment-8d94c585f    0         0         0       5m43sNAME                                    READY   STATUS    RESTARTS   AGEpod/nginx-deployment-5d457cdfc8-7whnx   1/1     Running   0          66spod/nginx-deployment-5d457cdfc8-b7njk   1/1     Running   0          84spod/nginx-deployment-5d457cdfc8-x4zv8   1/1     Running   0          55s</code></pre><p>  2.更新的策略</p><pre class=" language-language-bash"><code class="language-language-bash"># 首先创建了一个新的Pod，然后删除了一些旧的Pods， 并创建了新的Pods。不会杀死老Pods，直到有足够的数量新的Pods已经出现# 在足够数量的旧Pods被杀死前并没有创建新Pods。确保至少2个Pod可用，同时最多总共4个pod可用# Deployment可确保在更新时仅关闭一定数量的Pod。默认情况下确保至少所需Pods 75%处于运行状态（最大不可用比例为 25%）root@k8s-master:~# kubectl describe deployments.apps nginx-deployment</code></pre><h3 id="10-5-4-回滚Deployment"><a href="#10-5-4-回滚Deployment" class="headerlink" title="10.5.4 回滚Deployment"></a>10.5.4 回滚Deployment</h3><p>  假设在更新时犯错误了，将镜像名称命名设置为nginx:1.172，而不是nginx:1.17.2，发现永远无法更新成功，此时就需要回退</p><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# kubectl set image deployments/nginx-deployment nginx=nginx:1.172 --recordFlag --record has been deprecated, --record will be removed in the futuredeployment.apps/nginx-deployment image updatedroot@k8s-master:~# kubectl rollout status deployment/nginx-deploymentWaiting for deployment "nginx-deployment" rollout to finish: 1 out of 3 new replicas have been updated...# 镜像拉取失败root@k8s-master:~# kubectl get podsNAME                                READY   STATUS             RESTARTS   AGEnginx-deployment-5d457cdfc8-7whnx   1/1     Running            0          7m50snginx-deployment-5d457cdfc8-b7njk   1/1     Running            0          8m8snginx-deployment-5d457cdfc8-x4zv8   1/1     Running            0          7m39snginx-deployment-6b7d6c469c-zcjps   0/1     ImagePullBackOff   0          92s# 开始回滚1.查看历史版本root@k8s-master:~# kubectl rollout history deployments/nginx-deploymentdeployment.apps/nginx-deploymentREVISION  CHANGE-CAUSE1         <none>2         kubectl set image deployments/nginx-deployment nginx=nginx:1.17.1 --record=true3         kubectl set image deployments/nginx-deployment nginx=nginx:1.172 --record=true2.查看某个版本root@k8s-master:~# kubectl rollout history deployment.v1.apps/nginx-deployment --revision=2deployment.apps/nginx-deployment with revision #2Pod Template:  Labels:       app=nginx        pod-template-hash=5d457cdfc8  Annotations:  kubernetes.io/change-cause: kubectl set image deployments/nginx-deployment nginx=nginx:1.17.1 --record=true  Containers:   nginx:    Image:      nginx:1.17.1    Port:       80/TCP    Host Port:  0/TCP    Environment:        <none>    Mounts:     <none>  Volumes:      <none>  Node-Selectors:       <none>  Tolerations:  <none>3.回滚到某个版本root@k8s-master:~# kubectl rollout undo deployments/nginx-deployment --to-revision=2deployment.apps/nginx-deployment rolled backroot@k8s-master:~# kubectl rollout status deployment/nginx-deploymentdeployment "nginx-deployment" successfully rolled outroot@k8s-master:~# kubectl get deployment.appsNAME               READY   UP-TO-DATE   AVAILABLE   AGEnginx-deployment   3/3     3            3           23m</code></pre><h3 id="10-5-5-伸缩Deployment"><a href="#10-5-5-伸缩Deployment" class="headerlink" title="10.5.5 伸缩Deployment"></a>10.5.5 伸缩Deployment</h3><p>  将指定的deployment副本更改为10</p><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# kubectl scale deployments/nginx-deployment --replicas=10deployment.apps/nginx-deployment scaledroot@k8s-master:~# kubectl get deployments.apps,replicasets.apps -l app=nginxNAME                               READY   UP-TO-DATE   AVAILABLE   AGEdeployment.apps/nginx-deployment   10/10   10           10          25mNAME                                          DESIRED   CURRENT   READY   AGEreplicaset.apps/nginx-deployment-5d457cdfc8   10        10        10      21mreplicaset.apps/nginx-deployment-6b7d6c469c   0         0         0       14mreplicaset.apps/nginx-deployment-8d94c585f    0         0         0       25mroot@k8s-master:~# kubectl delete deployments.apps nginx-deployment</code></pre><h2 id="10-6-DaemonSet"><a href="#10-6-DaemonSet" class="headerlink" title="10.6 DaemonSet"></a>10.6 DaemonSet</h2><p>  DaemonSet确保全部（或某些）节点上运行一个 Pod 的副本。 当有节点加入集群时， 也会为他们新增一个 Pod 。 当有节点从集群移除时，这些 Pod 也会被回收。删除DaemonSet将会删除它创建的所有Pod</p><p>  DaemonSet 的一些典型用法：</p><p>  1.在每个节点上运行集群守护进程</p><p>  2.在每个节点上运行日志收集守护进程</p><p>  3.在每个节点上运行监控守护进程</p><p><img src="/images/DaemonSet.png"></p><p>使用busybox镜像，在每一个节点上都运行一个pod：</p><pre class=" language-language-bash"><code class="language-language-bash">cat > daemonset.yml <<EOFapiVersion: apps/v1kind: DaemonSetmetadata:  name: luovip  labels:    daemonset: testspec:  selector:    matchLabels:      name: testpod  template:    metadata:      labels:        name: testpod    spec:      containers:      - name: hello        image: busybox        imagePullPolicy: IfNotPresent        command: ['sh', '-c', 'sleep 3600']EOFroot@k8s-master:~# kubectl create -f daemonset.ymldaemonset.apps/luovip createdroot@k8s-master:~# kubectl get daemonsets.appsNAME     DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGEluovip   2         2         2       2            2           <none>          19sroot@k8s-master:~# kubectl get pod -o wideNAME      READY   STATUS    RESTARTS   AGE   IP               NODE          NOMINATED NODE   READINESS GATESluovip-bxkmh      1/1     Running   0          95s   172.16.126.33    k8s-worker2   <none>           <none>luovip-fj5mz      1/1     Running   0          95s   172.16.194.105   k8s-worker1   <none>           <none>...root@k8s-master:~# kubectl delete -f daemonset.yml</code></pre><p>  DaemonSet总结：</p><p>  1.默认情况下， DaemonSet会在所有Node上创建一个Pod</p><p>  2.如果将运行的pod删除，DaemonSet会自动启动一个新的</p><p>  3.当有新节点加入集群时，会自动向其部署Pod</p><p>  4.当节点离开集群时，其上的节点会销毁，而不会跑到其他节点上</p><h2 id="10-7-StatefulSet"><a href="#10-7-StatefulSet" class="headerlink" title="10.7 StatefulSet"></a>10.7 StatefulSet</h2><p>  StatefulSet管理基于相同容器规约的一组 Pod。但和Deployment不同的是， StatefulSet为它们的每个Pod维护了一个有粘性的 ID。这些 Pod 是基于相同的规约来创建的， 但是不能相互替换：无论怎么调度，每个 Pod 都有一个永久不变的 ID<br>  StatefulSets 对于需要满足以下一个或多个需求的应用程序很有价值：</p><p>  1.稳定的、唯一的网络标识符</p><p>  2.稳定的、持久的存储</p><p>  3.有序的、优雅的部署和缩放</p><p>  4.有序的、自动的滚动更新</p><p><img src="/images/StatefulSet.png"></p><h3 id="10-7-1-创建yml文件"><a href="#10-7-1-创建yml文件" class="headerlink" title="10.7.1 创建yml文件"></a>10.7.1 创建yml文件</h3><p>  使用nginx镜像，创建一个副本数为3的有状态应用，并挂载本地目录到容器中</p><pre class=" language-language-bash"><code class="language-language-bash">cat > statefulset.yml <<EOFapiVersion: apps/v1kind: StatefulSetmetadata:  name: webspec:  selector:    matchLabels:      app: nginx  serviceName: "nginx"  replicas: 3  template:    metadata:      labels:        app: nginx    spec:      containers:      - name: nginx        image: nginx:1.17.2        imagePullPolicy: IfNotPresent        ports:        - containerPort: 80          name: web        volumeMounts:        - name: www          mountPath: /usr/share/nginx/html      volumes:         - name: www           emptyDir: {}EOF</code></pre><h3 id="10-7-2-操作StatefulSet"><a href="#10-7-2-操作StatefulSet" class="headerlink" title="10.7.2 操作StatefulSet"></a>10.7.2 操作StatefulSet</h3><pre class=" language-language-bash"><code class="language-language-bash"># 发现创建的过程是有次序的，这也验证了有状态应用的启动顺序root@k8s-master:~# kubectl create -f statefulset.ymlstatefulset.apps/web createdroot@k8s-master:~# kubectl get pods -wNAME                                READY   STATUS    RESTARTS   AGEweb-0                               0/1     Pending   0          0sweb-0                               0/1     Pending   0          0sweb-0                               0/1     ContainerCreating   0          1sweb-0                               0/1     ContainerCreating   0          1sweb-0                               0/1     ErrImagePull        0          82sweb-0                               0/1     ImagePullBackOff    0          96sweb-0                               1/1     Running             0          108sweb-1                               0/1     Pending             0          0sweb-1                               0/1     Pending             0          0sweb-1                               0/1     ContainerCreating   0          0sweb-1                               0/1     ContainerCreating   0          0sweb-1                               1/1     Running             0          11sweb-2                               0/1     Pending             0          0sweb-2                               0/1     Pending             0          0sweb-2                               0/1     ContainerCreating   0          0sweb-2                               0/1     ContainerCreating   0          0sweb-2                               1/1     Running             0          1sroot@k8s-master:~# kubectl get podsNAME                                READY   STATUS    RESTARTS   AGEweb-0                               1/1     Running   0          3m36sweb-1                               1/1     Running   0          108sweb-2                               1/1     Running   0          97sroot@k8s-master:~# kubectl delete -f statefulset.ymlstatefulset.apps "web" deleted</code></pre><h2 id="10-8-Job"><a href="#10-8-Job" class="headerlink" title="10.8 Job"></a>10.8 Job</h2><p>  不断打印CKA JOB字符串，失败最多重试4次</p><pre class=" language-language-bash"><code class="language-language-bash">cat > job.yml <<EOFapiVersion: batch/v1kind: Jobmetadata:  name: pispec:  template:    spec:      containers:      - name: pi        image: busybox        imagePullPolicy: IfNotPresent        command: ["sh",  "-c", "while true;do echo CKA JOB;done"]      restartPolicy: Never  backoffLimit: 4EOFroot@k8s-master:~# kubectl create -f job.ymljob.batch/pi createdroot@k8s-master:~# kubectl get jobs,podsNAME           STATUS    COMPLETIONS   DURATION   AGEjob.batch/pi   Running   0/1           10s        10sNAME           READY   STATUS    RESTARTS   AGEpod/pi-rglzp   1/1     Running   0          10sroot@k8s-master:~# kubectl logs pi-rglzpCKA JOBCKA JOBCKA JOB...root@k8s-master:~# kubectl delete -f job.ymljob.batch "pi" deleted</code></pre><h2 id="10-9-CronJob"><a href="#10-9-CronJob" class="headerlink" title="10.9 CronJob"></a>10.9 CronJob</h2><p>  每分钟打印一次指定字符串</p><pre class=" language-language-bash"><code class="language-language-bash">cat > cronjob.yml <<EOFapiVersion: batch/v1kind: CronJobmetadata:  name: cronjobtestspec:  schedule: "*/1 * * * *"  jobTemplate:    spec:      template:        spec:          containers:          - name: hello            image: busybox            imagePullPolicy: IfNotPresent            command:            - /bin/sh            - -c            - date; echo Hello from the Kubernetes cluster          restartPolicy: OnFailureEOFroot@k8s-master:~# kubectl create -f cronjob.ymlcronjob.batch/cronjobtest createdroot@k8s-master:~# kubectl get cronjobs,podNAME                        SCHEDULE      TIMEZONE   SUSPEND   ACTIVE   LAST SCHEDULE   AGEcronjob.batch/cronjobtest   */1 * * * *   <none>     False     0        34s             35sNAME                             READY   STATUS      RESTARTS   AGEpod/cronjobtest-29127403-mb9qx   0/1     Completed   0          34sroot@k8s-master:~# kubectl logs cronjobtest-29127403-mb9qxMon May 19 08:43:01 UTC 2025Hello from the Kubernetes clusterroot@k8s-master:~# kubectl get cronjobs,podNAME                        SCHEDULE      TIMEZONE   SUSPEND   ACTIVE   LAST SCHEDULE   AGEcronjob.batch/cronjobtest   */1 * * * *   <none>     False     0        9s              2m10sNAME                             READY   STATUS      RESTARTS   AGEpod/cronjobtest-29127403-mb9qx   0/1     Completed   0          2m9spod/cronjobtest-29127404-9jmbj   0/1     Completed   0          69spod/cronjobtest-29127405-h5cc7   0/1     Completed   0          9s# 关于展示的任务次数的显示等的修改root@k8s-master:~# kubectl explain cronjob.specroot@k8s-master:~# kubectl delete -f cronjob.ymlcronjob.batch "cronjobtest" deleted</code></pre><h1 id="11-Service-服务发现"><a href="#11-Service-服务发现" class="headerlink" title="11 Service 服务发现"></a>11 Service 服务发现</h1><h2 id="11-1-Service"><a href="#11-1-Service" class="headerlink" title="11.1 Service"></a>11.1 Service</h2><p>  Pod是非永久性资源，每个Pod都有自己的IP地址</p><p>  如果一组Pod（称为“后端”）为集群内的其他Pod（称为“前端”）提供功能， 那么前端如何找出并跟踪要连接的IP地址，以便前端可以使用提供工作负载的后端部分</p><p><img src="/images/Service.png"></p><h2 id="11-2-Service类型"><a href="#11-2-Service类型" class="headerlink" title="11.2 Service类型"></a>11.2 Service类型</h2><p>  ClusterIP：通过集群的内部IP暴露服务，选择该值时服务只能够在集群内部访问。 这也是默认的ServiceType<br>  NodePort：通过每个节点上的IP和静态端口（NodePort）暴露服务。 NodePort服务会路由到自动创建的ClusterIP服务。 通过请求 &lt;节点 IP&gt;:&lt;节点端口&gt;，可以从集群的外部访问一个NodePort服务<br>  LoadBalancer：使用云提供商的负载均衡器向外部暴露服务。 外部负载均衡器可以将流量路由到自动创建的NodePort服务和ClusterIP 服务上<br>  ExternalName：通过返回CNAME和对应值，可以将服务映射到externalName字段的内容（例如，foo.bar.example.com）。 无需创建任何类型代理</p><p><img src="/images/Service%E8%AE%BF%E9%97%AE.png"></p><h2 id="11-3-iptables代理模式的Service"><a href="#11-3-iptables代理模式的Service" class="headerlink" title="11.3 iptables代理模式的Service"></a>11.3 iptables代理模式的Service</h2><p>  kube-proxy会监视Kubernetes 控制节点对Service对象和Endpoints对象的添加和移除。 对每个Service，它会配置iptables规则，从而捕获到达该Service的clusterIP和端口的请求，进而将请求重定向到 Service 的一组后端中的某个Pod上面。 对于每个Endpoints对象，它也会配置iptables规则，这个规则会选择一个后端组合<br>  默认的策略是，kube-proxy在iptables模式下随机选择一个后端<br>  使用iptables处理流量具有较低的系统开销，因为流量由Linux netfilter处理， 而无需在用户空间和内核空间之间切换。 这种方法也可能更可靠</p><h2 id="11-4-IPVS代理模式的Service"><a href="#11-4-IPVS代理模式的Service" class="headerlink" title="11.4 IPVS代理模式的Service"></a>11.4 IPVS代理模式的Service</h2><p>  在ipvs模式下，kube-proxy监视Kubernetes服务和端点，调用netlink接口相应地创建IPVS规则， 并定期将IPVS规则与Kubernetes服务和端点同步。 该控制循环可确保IPVS 状态与所需状态匹配。访问服务时，IPVS将流量定向到后端Pod之一<br>  IPVS代理模式基于类似于iptables模式的netfilter挂钩函数， 但是使用哈希表作为基础数据结构，并且在内核空间中工作。 这意味着，与 iptables模式下的kube-proxy相比，IPVS模式下的kube-proxy重定向通信的延迟要短，并且在同步代理规则时具有更好的性能。 与其他代理模式相比，IPVS模式还支持更高的网络流量吞吐量</p><h2 id="11-5-生成Service"><a href="#11-5-生成Service" class="headerlink" title="11.5 生成Service"></a>11.5 生成Service</h2><h3 id="11-5-1-准备后端Pod"><a href="#11-5-1-准备后端Pod" class="headerlink" title="11.5.1 准备后端Pod"></a>11.5.1 准备后端Pod</h3><p>  用nginx镜像准备一个3副本的deployment作为后端，并开放80端口</p><pre class=" language-language-bash"><code class="language-language-bash">cat > deployment-service.yml <<EOFapiVersion: apps/v1kind: Deploymentmetadata:  name: nginx-deployment-servicetest  labels:    app: nginxspec:  replicas: 3  selector:    matchLabels:      app: nginx  template:    metadata:      labels:        app: nginx    spec:      containers:      - name: nginx        image: nginx:1.16.1        imagePullPolicy: IfNotPresent        ports:        - containerPort: 80EOFroot@k8s-master:~# kubectl create -f deployment-service.ymldeployment.apps/nginx-deployment-servicetest createdroot@k8s-master:~# kubectl get pods -o wideNAME      READY   STATUS    RESTARTS   AGE   IP        NODE          NOMINATED NODE   READINESS GATESnginx-deployment-servicetest-8d94c585f-6ktj9 1/1  Running 0 13s 172.16.126.35 k8s-worker2 <none>   <none>nginx-deployment-servicetest-8d94c585f-jclrr 1/1  Running 0 13s 172.16.194.117 k8s-worker1 <none>     <none>nginx-deployment-servicetest-8d94c585f-wgztv 1/1  Running 0 13s 172.16.194.116 k8s-worker1   <none>  <none>root@k8s-master:~# curl 172.16.126.35</code></pre><h3 id="11-5-2-命令行生成Service"><a href="#11-5-2-命令行生成Service" class="headerlink" title="11.5.2 命令行生成Service"></a>11.5.2 命令行生成Service</h3><pre class=" language-language-bash"><code class="language-language-bash"># 用kubectl expose的命令创建一个针对deployment的服务，并查询endpoint是否准备就绪root@k8s-master:~# kubectl expose deployment nginx-deployment-servicetest --port=9000 --name=luoyuservice --target-port=80 --type=NodePortservice/luoyuservice exposedroot@k8s-master:~# kubectl get service,endpointsNAME                   TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGEservice/kubernetes     ClusterIP   10.96.0.1      <none>        443/TCP          2d13hservice/luoyuservice   NodePort    10.105.8.223   <none>        9000:32646/TCP   26sNAME                     ENDPOINTS                                              AGEendpoints/kubernetes     192.168.8.3:6443                                       2d13hendpoints/luoyuservice   172.16.126.35:80,172.16.194.116:80,172.16.194.117:80   26sroot@k8s-master:~# curl http://192.168.8.3:32646...<title>Welcome to nginx!</title>root@k8s-master:~# kubectl delete service luoyuserviceservice "luoyuservice" deleted</code></pre><h2 id="11-6-ClusterIP类型的Service"><a href="#11-6-ClusterIP类型的Service" class="headerlink" title="11.6 ClusterIP类型的Service"></a>11.6 ClusterIP类型的Service</h2><p>  ClusterIP是默认的Service类型，对外提供8000端口，并把流量引流到具有app: nginx的后端80端口上</p><pre class=" language-language-bash"><code class="language-language-bash">cat > clusterip.yml <<EOFapiVersion: v1kind: Servicemetadata:  name: my-servicespec:  selector:    app: nginx  ports:    - protocol: TCP      port: 8000      targetPort: 80EOFroot@k8s-master:~# kubectl create -f clusterip.ymlservice/my-service createdroot@k8s-master:~# kubectl get service,endpointsNAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGEservice/kubernetes   ClusterIP   10.96.0.1       <none>        443/TCP    3d2hservice/my-service   ClusterIP   10.101.56.206   <none>        8000/TCP   2m35sNAME                   ENDPOINTS                                              AGEendpoints/kubernetes   192.168.8.3:6443                                       3d2hendpoints/my-service   172.16.126.35:80,172.16.194.116:80,172.16.194.117:80   2m35sroot@k8s-master:~# curl 10.101.56.206:8000...<title>Welcome to nginx!</title>root@k8s-master:~# kubectl delete -f clusterip.ymlservice "my-service" deleted</code></pre><h2 id="11-7-NodePort类型的Service"><a href="#11-7-NodePort类型的Service" class="headerlink" title="11.7 NodePort类型的Service"></a>11.7 NodePort类型的Service</h2><p>  Type: NodePort将会在节点的特定端口上开通服务，指定了端口为31788</p><pre class=" language-language-bash"><code class="language-language-bash">cat > nodeport.yml <<EOFapiVersion: v1kind: Servicemetadata:  name: nodeservicespec:  type: NodePort  selector:    app: nginx  ports:    - protocol: TCP      port: 8000      targetPort: 80      nodePort: 31788EOFroot@k8s-master:~# kubectl create -f nodeport.ymlservice/nodeservice createdroot@k8s-master:~# kubectl get service,endpointsNAME                  TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGEservice/kubernetes    ClusterIP   10.96.0.1        <none>        443/TCP          3d3hservice/nodeservice   NodePort    10.102.124.139   <none>        8000:31788/TCP   27sNAME                    ENDPOINTS                                              AGEendpoints/kubernetes    192.168.8.3:6443                                       3d3hendpoints/nodeservice   172.16.126.35:80,172.16.194.116:80,172.16.194.117:80   27s# 因为是nodeport，所以用节点IProot@k8s-master:~# curl 192.168.8.4:31788...<title>Welcome to nginx!</title>root@k8s-master:~# kubectl delete -f nodeport.ymlservice "nodeservice" deleted</code></pre><h2 id="11-8-Headless类型的Service"><a href="#11-8-Headless类型的Service" class="headerlink" title="11.8 Headless类型的Service"></a>11.8 Headless类型的Service</h2><h3 id="11-8-1-服务实现"><a href="#11-8-1-服务实现" class="headerlink" title="11.8.1 服务实现"></a>11.8.1 服务实现</h3><p>  在此类型的Service中，将不会只返回Service IP，会直接返回众多Pod 的IP地址，所以需要进入pod中用集群内DNS进行测试</p><pre class=" language-language-bash"><code class="language-language-bash">cat > headless.yml <<EOFapiVersion: v1kind: Servicemetadata:  name: headlessspec:  clusterIP: None  selector:    app: nginx  ports:    - protocol: TCP      port: 8000      targetPort: 80EOFroot@k8s-master:~# kubectl create -f headless.ymlservice/headless createdroot@k8s-master:~# kubectl get service,endpointsNAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)    AGEservice/headless     ClusterIP   None         <none>        8000/TCP   25sservice/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP    3d3hNAME                   ENDPOINTS                                              AGEendpoints/headless     172.16.126.35:80,172.16.194.116:80,172.16.194.117:80   25sendpoints/kubernetes   192.168.8.3:6443                                       3d3h</code></pre><h3 id="11-8-2-测试Headless服务发现"><a href="#11-8-2-测试Headless服务发现" class="headerlink" title="11.8.2 测试Headless服务发现"></a>11.8.2 测试Headless服务发现</h3><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# kubectl run --rm --image=busybox:1.28 -it testpodIf you don't see a command prompt, try pressing enter./ # nslookup headlessServer:    10.96.0.10Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.localName:      headlessAddress 1: 172.16.194.117 172-16-194-117.headless.default.svc.cluster.localAddress 2: 172.16.194.116 172-16-194-116.headless.default.svc.cluster.localAddress 3: 172.16.126.35 172-16-126-35.headless.default.svc.cluster.local/ # exitSession ended, resume using 'kubectl attach testpod -c testpod -i -t' command when the pod is runningpod "testpod" deletedroot@k8s-master:~# kubectl delete -f headless.ymlservice "headless" deleted</code></pre><p>服务的DNS记录名称为：</p><p>  servicename.namespace.svc.cluster.local</p><p>deployment中Pod的DNS记录名称为：</p><p>  podIP.servicename.namespace.svc.cluster.local</p><p>Client访问服务时，可以使用DNS记录便捷抵达服务，甚至与服务在同一namespace时，直接用 servicename进行访问</p><h2 id="11-9-LoadBalancer类型的Service"><a href="#11-9-LoadBalancer类型的Service" class="headerlink" title="11.9 LoadBalancer类型的Service"></a>11.9 LoadBalancer类型的Service</h2><h3 id="11-9-1-部署metallb负载均衡"><a href="#11-9-1-部署metallb负载均衡" class="headerlink" title="11.9.1 部署metallb负载均衡"></a>11.9.1 部署metallb负载均衡</h3><p>1.先部署一个metallb controller和Speaker：</p><p>  1.metallb controller用于负责监听Kubernetes Service的变化，当服务类型被设置为LoadBalancer时，Controller会从一个预先配置的IP地址池中分配一个 IP地址给该服务，并管理这个IP地址的生命周期</p><p>  2.Speaker负责将服务的 IP 地址通过标准的路由协议广播到网络中，确保外部流量能够正确路由到集群中的服务</p><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# kubectl apply -f https://www.linuxcenter.cn/files/cka/cka-yaml/metallb-native.yaml</code></pre><p>2.定义一组由负载均衡对外分配的IP地址范围</p><pre class=" language-language-bash"><code class="language-language-bash">cat > ippool.yml <<-EOFapiVersion: metallb.io/v1beta1kind: IPAddressPoolmetadata:  name: lxh-ip-pool-192-168-8-10-100  namespace: metallb-systemspec:  addresses:  - 192.168.8.10-192.168.8.100EOFroot@k8s-master:~# kubectl apply -f ippool.ymlipaddresspool.metallb.io/lxh-ip-pool-192-168-8-10-100 created</code></pre><p>3.在 Layer 2 模式下用于控制如何通过 ARP（Address Resolution Protocol）或 NDP（Neighbor Discovery Protocol）协议宣告服务的 IP 地址，使得这些 IP 地址在本地网络中可解析</p><pre class=" language-language-bash"><code class="language-language-bash">cat > l2Advertisement.yml <<-EOFapiVersion: metallb.io/v1beta1kind: L2Advertisementmetadata:  name: l2-myippool  namespace: metallb-systemspec:  ipAddressPools:  - lxh-ip-pool-192-168-8-10-100EOFroot@k8s-master:~# kubectl apply -f l2Advertisement.ymll2advertisement.metallb.io/l2-myippool created</code></pre><h3 id="11-9-2-部署LoadBalancer服务"><a href="#11-9-2-部署LoadBalancer服务" class="headerlink" title="11.9.2 部署LoadBalancer服务"></a>11.9.2 部署LoadBalancer服务</h3><p>  负载均衡准备好之后，创建LoadBalancer类型的服务</p><pre class=" language-language-bash"><code class="language-language-bash">cat > loadbalancer.yml <<-EOFapiVersion: v1kind: Servicemetadata:  name: loadbalance-servicespec:  selector:    app: nginx  ports:    - protocol: TCP      port: 80      targetPort: 80  type: LoadBalancerEOFroot@k8s-master:~# kubectl apply -f loadbalancer.ymlservice/loadbalance-service created# 获取服务看看是否分配到了负载均衡IP  从输出上看，分配到了192.168.8.10root@k8s-master:~# kubectl get serviceNAME                  TYPE           CLUSTER-IP     EXTERNAL-IP    PORT(S)        AGEkubernetes            ClusterIP      10.96.0.1      <none>         443/TCP        3d4hloadbalance-service   LoadBalancer   10.99.147.16   192.168.8.10   80:30972/TCP   10s# 用负载均衡IP访问root@k8s-master:~# curl 192.168.8.10...<title>Welcome to nginx!</title># 删除service资源root@k8s-master:~# kubectl delete -f loadbalancer.ymlservice "loadbalance-service" deleted</code></pre><h2 id="11-10-Ingress"><a href="#11-10-Ingress" class="headerlink" title="11.10 Ingress"></a>11.10 Ingress</h2><p>  Ingress公开了从集群外部到集群内服务的HTTP和HTTPS路由</p><p>  流量路由由Ingress资源上定义的规则控制</p><p>  Ingress可以提供负载均衡、SSL卸载和基于名称的虚拟托管，为了让Ingress资源工作，集群必须有一个正在运行的Ingress控制器</p><p><img src="/images/Ingress.png"></p><h3 id="11-10-1-Ingress控制器部署"><a href="#11-10-1-Ingress控制器部署" class="headerlink" title="11.10.1 Ingress控制器部署"></a>11.10.1 Ingress控制器部署</h3><p>  Ingress需要Ingress控制器支持，先部署控制器</p><pre class=" language-language-bash"><code class="language-language-bash"># 拉取v1.1.0版本的yaml文件# 使用如下路径下载-可能会失败wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.1.0/deploy/static/provider/baremetal/deploy.yamlroot@k8s-master:~# wget https://www.linuxcenter.cn/files/cka/cka-yaml/ingressdeploy.yaml# 从阿里云的镜像仓库上面拉取镜像docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/nginx-ingress-controller:v1.12.1docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-webhook-certgen:v1.5.2# 在Kubernetes Ingress 的使用场景中，尤其是使用Ingress-Nginx作为 Ingress Controller 时，kube-webhook-certgen工具被用来创建和更新用于TLS认证的证书。这些证书被用于确保 Webhook 与 Kubernetes API 服务器之间的通信是安全的# 修改ingressdeploy.yaml文件440行改为 image: registry.cn-hangzhou.aliyuncs.com/google_containers/nginx-ingress-controller:v1.12.1542行改为image: registry.cn-hangzhou.aliyuncs.com/google_containers/kube-webhook-certgen:v1.5.2596行改为 image: registry.cn-hangzhou.aliyuncs.com/google_containers/kube-webhook-certgen:v1.5.2root@k8s-master:~# kubectl apply -f ingressdeploy.yamlroot@k8s-master:~# kubectl get pod -n ingress-nginxNAME                                   READY   STATUS      RESTARTS   AGEingress-nginx-admission-create-k9smq   0/1     Completed   0          17mingress-nginx-admission-patch-46hk7    0/1     Completed   2          17mingress-nginx-controller-47nzv         1/1     Running     0          17mingress-nginx-controller-svcpx         1/1     Running     0          17m# admission相关pod状态为Completed为正常</code></pre><h3 id="11-10-2-Ingress路径类型"><a href="#11-10-2-Ingress路径类型" class="headerlink" title="11.10.2 Ingress路径类型"></a>11.10.2 Ingress路径类型</h3><p>  Ingress中的每个路径都需要有对应的路径类型，未明确设置pathType的路径无法通过合法性检查。当前支持的路径类型有三种：</p><p>  1.ImplementationSpecific：对于这种路径类型，匹配方法取决于IngressClass。 具体实现可以将其作为单独的pathType处理或者与Prefix或 Exact类型作相同处理</p><p>  2.Exact：精确匹配URL路径，且区分大小写</p><p>  3.Prefix：基于以 / 分隔的URL路径前缀匹配。匹配区分大小写，并且对路径中的元素逐个完成。 路径元素指的是由/分隔符分隔的路径中的标签列表。 如果每个p都是请求路径p的元素前缀，则请求与路径p匹配</p><h3 id="11-10-3-Ingress的使用"><a href="#11-10-3-Ingress的使用" class="headerlink" title="11.10.3 Ingress的使用"></a>11.10.3 Ingress的使用</h3><p>  用nginx镜像生成一个3副本的Pod，并通过Service提供服务，然后再用ingress，以特定域名的方式对外暴露</p><pre class=" language-language-bash"><code class="language-language-bash">cat > ingress.yml <<EOFapiVersion: apps/v1kind: Deploymentmetadata:  name: nginx-deployment-ingress  labels:    app: nginxspec:  replicas: 3  selector:    matchLabels:      app: nginx  template:    metadata:      labels:        app: nginx    spec:      containers:      - name: nginx        image: nginx:1.16.1        imagePullPolicy: IfNotPresent        ports:        - containerPort: 80---apiVersion: v1kind: Servicemetadata:  name: ingressservicespec:  selector:    app: nginx  ports:    - protocol: TCP      port: 80      targetPort: 80---apiVersion: networking.k8s.io/v1kind: Ingressmetadata:  name: luovipspec:  ingressClassName: nginx  rules:    - host: www.luovip.com      http:        paths:          - pathType: Prefix            path: "/"            backend:              service:                name: ingressservice                port:                  number: 80EOFroot@k8s-master:~# kubectl create -f ingress.ymldeployment.apps/nginx-deployment-ingress createdservice/ingressservice createdingress.networking.k8s.io/luovip createdroot@k8s-master:~# kubectl get deployments,service,ingressNAME                                           READY   UP-TO-DATE   AVAILABLE   AGEdeployment.apps/nginx-deployment-ingress       3/3     3            3           38sdeployment.apps/nginx-deployment-servicetest   3/3     3            3           24hNAME                     TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGEservice/ingressservice   ClusterIP   10.98.162.124   <none>        80/TCP    38sservice/kubernetes       ClusterIP   10.96.0.1       <none>        443/TCP   3d13hNAME                               CLASS   HOSTS            ADDRESS                   PORTS   AGEingress.networking.k8s.io/luovip   nginx   www.luovip.com   192.168.8.4,192.168.8.5   80      38s# 把上述ADDRESS部分的IP和域名绑定解析root@k8s-master:~# echo 192.168.8.4 www.luovip.com >> /etc/hostsroot@k8s-master:~# curl http://www.luovip.comroot@k8s-master:~# kubectl delete -f ingress.yml</code></pre><h2 id="11-11-Gateway-API"><a href="#11-11-Gateway-API" class="headerlink" title="11.11 Gateway API"></a>11.11 Gateway API</h2><h3 id="11-11-1-Gateway-API-基本介绍"><a href="#11-11-1-Gateway-API-基本介绍" class="headerlink" title="11.11.1 Gateway API 基本介绍"></a>11.11.1 Gateway API 基本介绍</h3><p>  Kubernetes Gateway API 是一种新的 API 规范，旨在提供一种在 Kubernetes 中管理网关和负载均衡器的标准方法。它被设计为 Ingress API 的替代方案，提供更丰富的功能和更好的扩展性,Gateway API 的核心思想是通过使用可扩展的、角色导向的、协议感知的配置机制来提供网络服务。</p><p>  Gateway API 包括几个核心组件：</p><p>  1.<strong>GatewayClass</strong>：定义一组具有配置相同的网关，由实现该类的控制器管理。</p><p>  2.<strong>Gateway</strong>：定义流量处理基础设施（例如云负载均衡器）的一个实例。</p><p>  3.<strong>Route</strong>：描述了特定协议的规则，用于将请求从 Gateway 映射到 Kubernetes 服务。目前，HTTPRoute 是比较稳定的版本，而 TCPRoute、UDPRoute、GRPCRoute、TLSRoute 等也在开发中。</p><p><strong>GatewayClass</strong></p><p>  <strong>定义</strong>：类似于Ingress 中的 IngressClass，定义了一组共享通用配置和行为的 Gateway 集合，类似于选择一种负载均衡的实现类型</p><p>  <strong>作用</strong>：每个 GatewayClass 必须关联一个控制器（Controller），控制器负责处理 GatewayClass 和 Gateway 对象的变动，并创建或更新对应的网关和路由配置</p><p>  <strong>特点</strong>：一般由第三方网关组件安装时自动创建，不需要人工手动创建</p><p>  类似于阿里云负载均衡中的<strong>负载均衡实例类型选择</strong>。在阿里云中，用户可以选择应用型负载均衡（ALB）、网络型负载均衡（NLB）或传统型负载均衡（CLB），每种类型都有其特定的配置和功能</p><p><strong>Gateway</strong></p><p>  <strong>定义</strong>：描述了流量被分配到集群中服务的方式，是 GatewayClass 的具体实现。</p><p>  <strong>作用</strong>：负责流量接入以及往后转发。创建 Gateway 资源时，会根据 GatewayClass 生成对应的 Pod</p><p>  <strong>特点</strong>：可以由管理员直接创建，也可以由控制 GatewayClass 的 Controller 创建</p><p>  类似于阿里云负载均衡中的<strong>具体负载均衡实例</strong>。在阿里云中，用户创建一个负载均衡实例后，可以配置监听端口、协议等</p><p><strong>Route</strong></p><p>  <strong>定义</strong>：描述了通过网关的流量如何映射到服务，例如 HTTPRoute 可以基于请求路径、主机名等条件将流量转发到不同的后端服务</p><p>  <strong>作用</strong>：定义了流量的路由规则，将流量根据特定条件（如路径、请求头等）转发到不同的后端服务</p><p>  <strong>类型</strong>：目前 Gateway API 提供了五种不同协议的 Route，分别是 HTTPRoute、TLSRoute、TCPRoute、UDPRoute 和 GRPCRoute</p><p>  类似于阿里云负载均衡中的<strong>转发规则</strong>。在阿里云中，用户可以配置基于域名、路径、HTTP Header 等条件的转发规则</p><p>以下是使用 Gateway 和 HTTPRoute 将 HTTP 流量路由到服务的简单示例：</p><p><img src="/images/gateway-request-flow.png"></p><p>在此示例中，实现为反向代理的 Gateway 的请求数据流如下：</p><p>  1.客户端开始准备 URL 为 <a href="http://test.lixiaohui.com/">http://test.lixiaohui.com</a> 的 HTTP 请求</p><p>  2.客户端的 DNS 解析器查询目标名称并了解与 Gateway 关联的一个或多个 IP 地址的映射。</p><p>  3.客户端向 Gateway IP 地址发送请求；反向代理接收 HTTP 请求并使用 Host: 标头来匹配基于 Gateway 和附加的 HTTPRoute 所获得的配置。</p><p>  4.可选的，反向代理可以根据 HTTPRoute 的匹配规则进行请求头和（或）路径匹配。</p><p>  5.可选地，反向代理可以修改请求；例如，根据 HTTPRoute 的过滤规则添加或删除标头。</p><p>  6.最后，反向代理将请求转发到一个或多个后端。</p><p>安装网址：<a href="https://docs.nginx.com/nginx-gateway-fabric/installation/installing-ngf/manifests/">https://docs.nginx.com/nginx-gateway-fabric/installation/installing-ngf/manifests/</a></p><h3 id="11-1-2-Gateway-API实验"><a href="#11-1-2-Gateway-API实验" class="headerlink" title="11.1.2 Gateway API实验"></a>11.1.2 Gateway API实验</h3><p>  <strong>实验步骤</strong>：</p><p>  1.需要先做metallb，由metalb给service提供外部负载均衡IP</p><p>  2.部署nginx Fabric，为GatewayAPI做后端流量处理组件</p><p>  3.创建一个基于Fabric的gatewayClass</p><p>  4.创建一个gateway，并监听在80端口，并关联刚创建的gatewayClass</p><p>  5.创建一个httpRoute，此处定义客户端访问的域名和路径</p><p>  <strong>实验效果</strong>：外部客户端可以用浏览器打开<code>http://test.luovip.com</code> 并返回我们的nginx业务网站内容</p><p><strong>1.部署 Gateway API CRD</strong></p><p>  这一步用于扩展K8S功能，以便于支持Gateway API</p><pre class=" language-language-bash"><code class="language-language-bash"># 方法1：root@k8s-master:~# kubectl apply -f https://www.linuxcenter.cn/files/cka/gatewayapi/experimental-install.yaml# 方法2：root@k8s-master:~# wget https://www.linuxcenter.cn/files/cka/gatewayapi/experimental-install.yamlroot@k8s-master:~# kubectl apply -f experimental-install.yaml</code></pre><p>2.<strong>部署Fabric自定义资源</strong></p><pre class=" language-language-bash"><code class="language-language-bash"># 方法1：root@k8s-master:~# kubectl apply -f https://www.linuxcenter.cn/files/cka/gatewayapi/nginx-fabric-crds.yaml# 方法2：root@k8s-master:~# wget https://www.linuxcenter.cn/files/cka/gatewayapi/nginx-fabric-crds.yamlroot@k8s-master:~# kubectl apply -f nginx-fabric-crds.yaml</code></pre><p>3.<strong>部署Fabric</strong></p><p>  这一步部署的Fabric用于处理后端流量处理</p><pre class=" language-language-bash"><code class="language-language-bash"># 方法1：root@k8s-master:~# kubectl apply -f https://www.linuxcenter.cn/files/cka/gatewayapi/nginx-fabric-deploy.yaml# 方法2：root@k8s-master:~# wget https://www.linuxcenter.cn/files/cka/gatewayapi/nginx-fabric-deploy.yamlroot@k8s-master:~# kubectl apply -f nginx-fabric-deploy.yaml# 镜像使用：ghcr.io/nginx/nginx-gateway-fabric:1.6.2ghcr.io/nginx/nginx-gateway-fabric/nginx:1.6.2可以使用国内南京大学的加速站点进行（在此感谢南京大学镜像站点团队提供的帮助），具体为将上述镜像替换为下面：ghcr.nju.edu.cn/nginx/nginx-gateway-fabric:1.6.2ghcr.nju.edu.cn/nginx/nginx-gateway-fabric/nginx:1.6.2# 参考：NGINX Gateway Fabric离线部署笔记https://blog.51cto.com/huanghai/13946410#等它部署好之后，看看pod起来没root@k8s-master:~# kubectl get pod -n nginx-gateway -o wideroot@k8s-master:~# kubectl get pods -n nginx-gatewayNAME                            READY   STATUS    RESTARTS      AGEnginx-gateway-9cbb9b466-85ktc   2/2     Running   1 (56s ago)   72s# 这里将会自动创建基于nginx的GatewayClassroot@k8s-master:~# kubectl get gatewayclasses.gateway.networking.k8s.ioNAME    CONTROLLER                                   ACCEPTED   AGEnginx   gateway.nginx.org/nginx-gateway-controller   True       17m</code></pre><p>4.<strong>部署应用</strong></p><p>  这里的应用是模拟公司的常规业务，稍后用于对外提供服务</p><pre class=" language-language-bash"><code class="language-language-bash">cat > deployment-service.yml <<EOFapiVersion: apps/v1kind: Deploymentmetadata:  name: k8sgateway-luoviptest  labels:    app: nginxspec:  replicas: 1  selector:    matchLabels:      app: nginx  template:    metadata:      labels:        app: nginx    spec:      containers:      - name: nginx        image: nginx        imagePullPolicy: IfNotPresent        ports:        - containerPort: 80EOF</code></pre><p>5.<strong>为了稳定pod的访问，用service的方式做了一个内部暴露</strong></p><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# kubectl create -f deployment-service.ymldeployment.apps/k8sgateway-luoviptest createdroot@k8s-master:~# kubectl expose deployment k8sgateway-lxhtest --port=9000 --name=lxhservice --target-port=80service/lxhservice exposed</code></pre><p>6.<strong>业务应用</strong></p><p>  1.创建一个名为luovip-gateway的gateway并关联了一个名为nginx的gatewayClass，这个gateway提供了一个监听在80端口的http协议的监听器，这个监听器接收来自任何namespace以luovip.com为后缀的所有请求<br><strong>  2</strong>.创建一个名为luovip-http的httpRoute，并关联我们的gateway，本次httpRoute提供了test.luovip.com的域名根目录的请求入口，并将流量导入到一个名为luovipservice的9000端口</p><pre class=" language-language-bash"><code class="language-language-bash">cat > gatewayandhttproute.yml <<-EOFapiVersion: gateway.networking.k8s.io/v1kind: Gatewaymetadata:  name: luovip-gatewayspec:  gatewayClassName: nginx  listeners:  - name: default    hostname: "*.luovip.com"    port: 80    protocol: HTTP    allowedRoutes:      namespaces:        from: All---apiVersion: gateway.networking.k8s.io/v1kind: HTTPRoutemetadata:  name: luovip-httpspec:  parentRefs:  - name: luovip-gateway  hostnames: ["test.luovip.com"]  rules:  - matches:    - path:        type: PathPrefix        value: /    backendRefs:    - name: lxhservice      port: 9000EOFroot@k8s-master:~# kubectl apply -f gatewayandhttproute.yml# gateway已经从负载均衡中，拿到了外部IP地址---192.168.8.10root@k8s-master:~# kubectl get service -n nginx-gatewayNAME            TYPE           CLUSTER-IP      EXTERNAL-IP    PORT(S)                      AGEnginx-gateway   LoadBalancer   10.108.91.177   192.168.8.10   80:31093/TCP,443:30287/TCP   35m# 服务后端也有endpointroot@k8s-master:~# kubectl get endpoints -n nginx-gatewayNAME            ENDPOINTS                          AGEnginx-gateway   172.16.126.3:443,172.16.126.3:80   37m# 查看gateway和httprouteroot@k8s-master:~# kubectl get gatewaysNAME             CLASS   ADDRESS        PROGRAMMED   AGEluovip-gateway   nginx   192.168.8.10   True         9m14sroot@k8s-master:~# kubectl get httprouteNAME          HOSTNAMES             AGEluovip-http   ["test.luovip.com"]   9m29s# 访问测试root@k8s-master:~# echo 192.168.8.10 test.luovip.com >> /etc/hostsroot@k8s-master:~# curl http://test.luovip.com</code></pre><h1 id="12-健康检查"><a href="#12-健康检查" class="headerlink" title="12 健康检查"></a>12 健康检查</h1><h2 id="12-1-探测器概述"><a href="#12-1-探测器概述" class="headerlink" title="12.1 探测器概述"></a>12.1 探测器概述</h2><p>  kubelet使用<strong>存活探测器</strong>(liveness probes)来知道什么时候要重启容器。 例如，存活探测器可以捕捉到死锁（应用程序在运行，但是无法继续执行后面的步骤）。 这样的情况下重启容器有助于让应用程序在有问题的情况下更可用。<br>  kubelet使用<strong>就绪探测器</strong>(readiness  probes)可以知道容器什么时候准备好了并可以开始接受请求流量， 当一个 Pod 内的所有容器都准备好了，才能把这个 Pod 看作就绪了。 在 Pod 还没有准备好的时候，会从 Service 的负载均衡器中被剔除的。<br>  kubelet 使用<strong>启动探测器</strong>(startup  probes)可以知道应用程序容器什么时候启动了。 可以控制容器在启动成功后再进行存活性和就绪检查， 确保这些存活、就绪探测器不会影响应用程序的启动。 这可以用于对慢启动容器进行存活性检测，避免它们在启动运行之前就被杀掉。</p><p>顺序：1.启动探针工作完成—如果启动探针没完成，存活和就绪是不会开始的</p><p>​            2.存活、就绪探针开始工作</p><h2 id="12-2-Liveness-Probes"><a href="#12-2-Liveness-Probes" class="headerlink" title="12.2  Liveness Probes"></a>12.2  Liveness Probes</h2><h3 id="12-2-1-文件存活检测"><a href="#12-2-1-文件存活检测" class="headerlink" title="12.2.1 文件存活检测"></a>12.2.1 文件存活检测</h3><p>  创建一个名为liveness的容器，并在其中执行文件的创建，休眠，然后再删除文件的操作，然后用livenessProbe来检测</p><pre class=" language-language-bash"><code class="language-language-bash">cat > liveness.yml <<EOFapiVersion: v1kind: Podmetadata:  labels:    test: liveness  name: liveness-execspec:  containers:  - name: liveness    image: busybox    imagePullPolicy: IfNotPresent    args:    - /bin/sh    - -c    - touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 600    livenessProbe:      exec:        command:        - cat        - /tmp/healthy      initialDelaySeconds: 5      periodSeconds: 5EOF</code></pre><p>参数解释：</p><p>  1.periodSeconds 字段指定了 kubelet 应该每 5 秒执行一次存活探测。</p><p>  2.initialDelaySeconds 字段告诉 kubelet 在执行第一次探测前应该等待 5 秒。</p><p>  3.kubelet 在容器内执行命令 cat /tmp/healthy 来进行探测。</p><p>  4.如果命令执行成功并且返回值为 0，kubelet 就会认为这个容器是健康存活的。</p><p>  5.如果这个命令返回非 0 值，kubelet 会杀死这个容器并重新启动它。</p><p>  这个容器生命周期的前 30 秒， /tmp/healthy 文件是存在的。 所以在这最开始的 30 秒内，执行命令 cat /tmp/healthy 会返回成功代码。 30 秒之后，执行命令 cat /tmp/healthy 就会返回失败代码。</p><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# kubectl create -f liveness.ymlpod/liveness-exec created# 每30秒在pod事件中就会显示存活探测器失败了，下方信息显示这个容器被杀死并且被重建了5次root@k8s-master:~# kubectl get -f liveness.yml -o wideNAME            READY   STATUS    RESTARTS      AGE     IP  NODE          NOMINATED NODE   READINESS GATESliveness-exec   1/1     Running   5 (26s ago)   6m41s   172.16.194.68   k8s-worker1   <none>     <none>root@k8s-master:~# kubectl describe pod liveness-exec...Events:  Type     Reason     Age                     From               Message  ----     ------     ----                    ----               -------  Normal   Scheduled  9m10s                   default-scheduler  Successfully assigned default/liveness-exec to k8s-worker1  Normal   Pulling    9m9s                    kubelet            Pulling image "busybox"  Normal   Pulled     9m6s                    kubelet            Successfully pulled image "busybox" in 3.226s (3.226s including waiting). Image size: 4277910 bytes.  Normal   Created    2m55s (x6 over 9m6s)    kubelet            Created container: liveness  Normal   Started    2m55s (x6 over 9m6s)    kubelet            Started container liveness  Warning  Unhealthy  2m10s (x18 over 8m35s)  kubelet            Liveness probe failed: cat: can't open '/tmp/healthy': No such file or directory  Normal   Killing    2m10s (x6 over 8m25s)   kubelet            Container liveness failed liveness probe, will be restarted  Warning  BackOff    21s (x8 over 100s)      kubelet            Back-off restarting failed container liveness in pod liveness-exec_default(b092160d-80d5-4edb-a593-726922c425e4)  Normal   Pulled     6s (x6 over 7m55s)      kubelet            Container image "busybox" already present on machineroot@k8s-master:~# kubectl delete -f liveness.yml</code></pre><h3 id="12-2-2-HTTP存活检测"><a href="#12-2-2-HTTP存活检测" class="headerlink" title="12.2.2 HTTP存活检测"></a>12.2.2 HTTP存活检测</h3><p>  以httpget的形式访问容器中的/luovip页面，根据返回代码来判断是否正常</p><pre class=" language-language-bash"><code class="language-language-bash">cat > httpget.yml <<EOFapiVersion: v1kind: Podmetadata:  name: httpspec:  containers:  - name: httpd    image: httpd:2.2    imagePullPolicy: IfNotPresent    livenessProbe:      httpGet:        path: /luovip        port: 80        httpHeaders:        - name: Custom-Header          value: Awesome      initialDelaySeconds: 3      periodSeconds: 3  restartPolicy: OnFailureEOF</code></pre><p>参数解释：</p><p>  1.periodSeconds 字段指定了 kubelet 每隔 3 秒执行一次存活探测。</p><p>  2.initialDelaySeconds 字段告诉 kubelet 在执行第一次探测前应该等待 3 秒。</p><p>  3.kubelet 会向容器内运行的服务发送一个 HTTP GET 请求来执行探测。 如果服务器上 /PATH 路径下的处理程序返回成功代码，则 kubelet 认为容器是健康存活的。</p><p>  4.如果处理程序返回失败代码，则 kubelet 会杀死这个容器并且重新启动它。</p><p>  5.任何大于或等于 200 并且小于 400 的返回代码标示成功，其它返回代码都标示失败。</p><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# kubectl create -f httpget.ymlpod/http createdroot@k8s-master:~# kubectl get -f httpget.ymlNAME   READY   STATUS    RESTARTS   AGEhttp   1/1     Running   0          17sroot@k8s-master:~# kubectl get podsNAME   READY   STATUS      RESTARTS   AGEhttp   0/1     Completed   2          4m40sroot@k8s-master:~# kubectl describe pod http...Events:  Type     Reason     Age                  From               Message  ----     ------     ----                 ----               -------  Normal   Scheduled  2m22s                default-scheduler  Successfully assigned default/http to k8s-worker1  Normal   Pulling    2m22s                kubelet            Pulling image "httpd:2.2"  Normal   Pulled     2m7s                 kubelet            Successfully pulled image "httpd:2.2" in 14.839s (14.839s including waiting). Image size: 171293537 bytes.  Normal   Created    109s (x3 over 2m7s)  kubelet            Created container: httpd  Normal   Started    109s (x3 over 2m7s)  kubelet            Started container httpd  Normal   Pulled     109s (x2 over 118s)  kubelet            Container image "httpd:2.2" already present on machine  Warning  Unhealthy  100s (x9 over 2m4s)  kubelet            Liveness probe failed: HTTP probe failed with statuscode: 404  Normal   Killing    100s (x3 over 118s)  kubelet            Container httpd failed liveness probe, will be restarted  Warning  BackOff    100s                 kubelet            Back-off restarting failed container httpd in pod http_default(8d1f374c-ba01-4a4b-a8b1-dbba11736ccf)root@k8s-master:~# kubectl delete -f httpget.yml</code></pre><h2 id="12-3-ReadinessProbe"><a href="#12-3-ReadinessProbe" class="headerlink" title="12.3 ReadinessProbe"></a>12.3 ReadinessProbe</h2><h3 id="12-3-1-TCP存活检测"><a href="#12-3-1-TCP存活检测" class="headerlink" title="12.3.1 TCP存活检测"></a>12.3.1 TCP存活检测</h3><p>  1.TCP 检测的配置和 HTTP 检测非常相似，同时使用就绪和存活探测器。</p><p>  2.kubelet 会在容器启动 5 秒后发送第一个就绪探测。 这会尝试连接容器的800端口。如果探测成功，这个Pod会被标记为就绪状态，kubelet将继续每隔 10 秒运行一次检测。</p><p>  3.除了就绪探测，这个配置包括了一个存活探测。 kubelet 会在容器启动 15 秒后进行第一次存活探测。 与就绪探测类似，会尝试连接器的800端口。 如果存活探测失败，这个容器会被重新启动。</p><pre class=" language-language-bash"><code class="language-language-bash">cat > readiness.yml <<EOFapiVersion: v1kind: Podmetadata:  name: tcpcheckspec:  containers:  - name: httpd    image: httpd:2.2    imagePullPolicy: IfNotPresent    ports:      - name: webport        protocol: TCP        containerPort: 80    readinessProbe:      tcpSocket:        port: 800      initialDelaySeconds: 5      periodSeconds: 10    livenessProbe:      tcpSocket:        port: 800      initialDelaySeconds: 15      periodSeconds: 20  restartPolicy: OnFailureEOFroot@k8s-master:~# kubectl create -f readiness.ymlroot@k8s-master:~# kubectl get podsNAME       READY   STATUS    RESTARTS     AGEtcpcheck   0/1     Running   1 (3s ago)   64sroot@k8s-master:~# kubectl describe pod tcpcheck...Events:  Type     Reason     Age                  From               Message  ----     ------     ----                 ----               -------  Normal   Scheduled  2m23s                default-scheduler  Successfully assigned default/tcpcheck to k8s-worker1  Normal   Pulled     22s (x3 over 2m22s)  kubelet            Container image "httpd:2.2" already present on machine  Normal   Created    22s (x3 over 2m22s)  kubelet            Created container: httpd  Normal   Started    22s (x3 over 2m22s)  kubelet            Started container httpd  Normal   Killing    22s (x2 over 82s)    kubelet            Container httpd failed liveness probe, will be restarted  Warning  Unhealthy  2s (x7 over 2m2s)    kubelet            Liveness probe failed: dial tcp 172.16.194.70:800: connect: connection refused  Warning  Unhealthy  1s (x14 over 2m10s)  kubelet            Readiness probe failed: dial tcp 172.16.194.70:800: connect: connection refused# 可以看到，pod对外提供了80端口，但是我们一直在检测800端口，所以这个pod的检测是失败的root@k8s-master:~# kubectl delete -f readiness.ymlpod "tcpcheck" deleted</code></pre><h2 id="12-4-StartupProbe"><a href="#12-4-StartupProbe" class="headerlink" title="12.4 StartupProbe"></a>12.4 StartupProbe</h2><p>  1.有时候，会有一些现有的应用程序在启动时需要较多的初始化时间。 要不影响对引起探测死锁的快速响应，这种情况下，设置存活探测参数是要技巧的。 技巧就是使用一个命令来设置启动探测，针对HTTP 或者 TCP 检测，可以通过设置 failureThreshold * periodSeconds 参数来保证有足够长的时间应对糟糕情况下的启动时间。<br>  2.应用程序将会有最多 30秒(3 * 10 = 30s) 的时间来完成它的启动。 一旦启动探测成功一次，存活探测任务就会接管对容器的探测，对容器死锁可以快速响应。 如果启动探测一直没有成功，容器会在 30 秒后被杀死，并且根据 restartPolicy 来设置 Pod 状态。</p><pre class=" language-language-bash"><code class="language-language-bash">cat > startup.yml <<EOFapiVersion: v1kind: Podmetadata:  name: startprobespec:  containers:  - name: httpd    image: httpd:2.2    imagePullPolicy: IfNotPresent    ports:      - name: webport        protocol: TCP        containerPort: 80    readinessProbe:      tcpSocket:        port: 80      initialDelaySeconds: 5      periodSeconds: 10    startupProbe:      httpGet:        path: /        port: 800      initialDelaySeconds: 5      failureThreshold: 3      periodSeconds: 10  restartPolicy: OnFailureEOF</code></pre><p>Probe参数:</p><p>Probe 有很多配置字段，可以使用这些字段精确的控制存活和就绪检测的行为：</p><p>  1.initialDelaySeconds：容器启动后要等待多少秒后存活和就绪探测器才被初始化，默认是 0 秒，最小值是 0</p><p>  2.periodSeconds：执行探测的时间间隔（单位是秒）。默认是 10 秒。最小值是 1</p><p>  3.timeoutSeconds：探测的超时后等待多少秒。默认值是 1 秒。最小值是 1</p><p>  4.successThreshold：探测器在失败后，被视为成功的最小连续成功数。默认值是 1。 存活和启动探测的这个值必须是 1。最小值是 1</p><p>  5.failureThreshold：当探测失败时，Kubernetes 的重试次数。 存活探测情况下的放弃就意味着重新启动容器。 就绪探测情况下的放弃 Pod 会被打上未就绪的标签。默认值是 3。最小值是 1</p><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# kubectl create -f startup.ymlpod/startprobe createdroot@k8s-master:~# kubectl get -f startup.ymlNAME         READY   STATUS    RESTARTS   AGEstartprobe   0/1     Running   0          7sroot@k8s-master:~# kubectl describe -f startup.yml...Events:  Type     Reason     Age                From               Message  ----     ------     ----               ----               -------  Normal   Scheduled  52s                default-scheduler  Successfully assigned default/startprobe to k8s-worker1  Normal   Pulled     22s (x2 over 52s)  kubelet            Container image "httpd:2.2" already present on machine  Normal   Created    22s (x2 over 52s)  kubelet            Created container: httpd  Normal   Started    22s (x2 over 52s)  kubelet            Started container httpd  Normal   Killing    22s                kubelet            Container httpd failed startup probe, will be restarted  Warning  Unhealthy  2s (x5 over 42s)   kubelet            Startup probe failed: Get "http://172.16.194.71:800/": dial tcp 172.16.194.71:800: connect: connection refused# 可以发现由于故意写成了800端口，检测失败，容器一直无法就绪root@k8s-master:~# kubectl delete -f startup.yml</code></pre><h2 id="12-5-探针检测顺序与优先级"><a href="#12-5-探针检测顺序与优先级" class="headerlink" title="12.5 探针检测顺序与优先级"></a>12.5 探针检测顺序与优先级</h2><p>  在 Kubernetes 中，<strong>startupProbe</strong>、<strong>livenessProbe</strong> 和 <strong>readinessProbe</strong>是用于监控和管理容器健康状况的探针，每种探针在容器生命周期中的不同阶段发挥不同的作用。以下是这三种探针的检测顺序和优先级：</p><h3 id="12-5-1-startupProbe"><a href="#12-5-1-startupProbe" class="headerlink" title="12.5.1 startupProbe"></a>12.5.1 startupProbe</h3><p>  <strong>检测顺序</strong>：startupProbe是在容器启动时首先执行的探针。它用于判断应用是否已成功启动，并且只在启动期间运行。</p><p>  <strong>优先级</strong>：如果配置了 startupProbe，Kubernetes会忽略 livenessProbe和readinessProbe直到 startupProbe成功。startupProbe成功</p><p>​                       后，livenessProbe和 readinessProbe才会开始运行。</p><p>  <strong>目的</strong>：用于处理启动时间较长的应用程序，确保应用在完全启动之前不会因 livenessProbe 的失败而被重启。</p><h3 id="12-5-2-livenessProbe"><a href="#12-5-2-livenessProbe" class="headerlink" title="12.5.2 livenessProbe"></a>12.5.2 livenessProbe</h3><p>  <strong>检测顺序</strong>：在 startupProbe成功之后，livenessProbe 开始执行。它定期检查容器是否处于健康状态。</p><p>  <strong>优先级</strong>：如果配置了 startupProbe，livenessProbe只有在startupProbe成功之后才开始运行。如果未配置 startupProbe， </p><p>​                       livenessProbe在容器启动后立即开始运行。</p><p>  <strong>目的</strong>：用于检测容器是否仍然处于健康状态。如果 livenessProbe失败，Kubernetes 会重启该容器。</p><h3 id="12-5-3-readinessProbe"><a href="#12-5-3-readinessProbe" class="headerlink" title="12.5.3 readinessProbe"></a>12.5.3 readinessProbe</h3><p>  <strong>检测顺序</strong>：在 startupProbe成readinessProbe开始执行。它定期检查容器是否已准备好接收流量。</p><p>  <strong>优先级</strong>：如果配置了startupProbe，readinessProbe只有在 startupProbe成功之后才开始运行。如果未配置 startupProbe，</p><p>​                       readinessProbe在容器启动后立即开始运行。</p><p>  <strong>目的</strong>：用于判断容器是否可以接收请求。如果 readinessProbe 失败，容器将从服务的端点列表中移除，不再接收新的流量。</p><h3 id="12-5-4-总结"><a href="#12-5-4-总结" class="headerlink" title="12.5.4 总结"></a>12.5.4 总结</h3><p>  <strong>顺序</strong>：startupProbe-&gt; livenessProbe-&gt; readinessProbe</p><p>  <strong>优先级</strong>：</p><p>  startupProbe优先于其他两个探针。如果配置了 startupProbe，必须先通过 startupProbe检测，livenessProbe和 readinessProbe才会启动。</p><p>  livenessProbe和readinessProbe在startupProbe成功后同时开始运行，没有严格的优先级区分，但它们的作用不同，livenessProbe用于重启失败的容器，readinessProbe 用于控制流量。</p><h2 id="12-6-优雅关闭"><a href="#12-6-优雅关闭" class="headerlink" title="12.6 优雅关闭"></a>12.6 优雅关闭</h2><p>  从 Kubernetes 1.22 开始，terminationGracePeriodSeconds 特性被开启，在杀死容器时，Pod停止获得新的流量。但在Pod中运行的容器不会受到影响。直到超时发生。可以在Pod级别或者容器下具体的探针级别设定，探针会优先和覆盖Pod级别</p><p>  下面的例子中，容器将在收到结束需求是沉睡2分钟来代表业务的正常关闭，然后整个pod最多等待200秒，超过200秒，就会强制删除</p><pre class=" language-language-yml"><code class="language-language-yml">cat > grace.yml <<EOFapiVersion: v1kind: Podmetadata:  name: httpgracespec:  terminationGracePeriodSeconds: 200  containers:  - name: httpd    image: httpd:2.2    imagePullPolicy: IfNotPresent    ports:      - name: webport        protocol: TCP        containerPort: 80    lifecycle:      preStop:        exec:          command: ["/bin/sh","-c","sleep 2m"]  restartPolicy: OnFailureEOF</code></pre><pre class=" language-language-bash"><code class="language-language-bash">root@k8s-master:~# kubectl create -f grace.ymlroot@k8s-master:~# kubectl get -f grace.ymlNAME        READY   STATUS    RESTARTS   AGEhttpgrace   1/1     Running   0          9sroot@k8s-master:~# kubectl delete pod httpgrace &[1] 34690root@k8s-master:~# pod "httpgrace" deletedroot@k8s-master:~# jobs[1]+  Running                 kubectl delete pod httpgrace &# Terminating表示终结中root@k8s-master:~# kubectl get podNAME        READY   STATUS        RESTARTS   AGEhttpgrace   1/1     Terminating   0          2m21sroot@k8s-master:~# kubectl describe pod httpgrace...Events:  Type    Reason     Age    From               Message  ----    ------     ----   ----               -------  Normal  Scheduled  2m51s  default-scheduler  Successfully assigned default/httpgrace to k8s-worker1  Normal  Pulled     2m50s  kubelet            Container image "httpd:2.2" already present on machine  Normal  Created    2m50s  kubelet            Created container: httpd  Normal  Started    2m50s  kubelet            Started container httpd  Normal  Killing    81s    kubelet            Stopping container httpd  root@k8s-master:~# kubectl get podNo resources found in default namespace.</code></pre><h1 id="13-Kubernetes持久存储"><a href="#13-Kubernetes持久存储" class="headerlink" title="13 Kubernetes持久存储"></a>13 Kubernetes持久存储</h1><p>  Container 中的文件在磁盘上是临时存放的，这给 Container 中运行的较重要的应用 程序带来一些问题：</p><p>  1.当容器崩溃时文件丢失。kubelet 会重新启动容器， 但容器会以干净的状态重启</p><p>  2.会在同一 Pod中运行多个容器并共享文件时出现</p><p>  <strong>Kubernetes 卷（Volume） 这一抽象概念能够解决这两个问题</strong></p><h2 id="13-1-数据卷"><a href="#13-1-数据卷" class="headerlink" title="13.1 数据卷"></a>13.1 数据卷</h2><p>  Kubernetes 支持很多类型的卷</p><p>  Pod 可以同时使用任意数目的卷类型</p><p>  临时卷类型的生命周期与 Pod 相同，但持久卷可以比 Pod 的存活期长</p><p>  当 Pod 不再存在时，Kubernetes 也会销毁临时卷；不过 Kubernetes 不会销毁 持久卷。对于给定 Pod 中任何类型的卷，在容器重启期间数据都不会丢失。<br>  使用卷时, 在 .spec.volumes 字段中设置为 Pod 提供的卷，并在 .spec.containers[*].volumeMounts 字段中声明卷在容器中的挂载位置</p><h2 id="13-2-emptyDir"><a href="#13-2-emptyDir" class="headerlink" title="13.2 emptyDir"></a>13.2 emptyDir</h2><p>  当 Pod 分派到某个 Node 上时，emptyDir 卷会被创建，并且在 Pod 在该节点上运行期间，卷一直存在。 就像其名称表示的那样，卷最初是空的。 尽管 Pod 中的容器挂载 emptyDir 卷的路径可能相同也可能不同，这些容器都可以读写 emptyDir 卷中相同的文件。 当 Pod 因为某些原因被从节点上删除时，emptyDir 卷中的数据也会被永久删除。<br>  容器崩溃并不会导致 Pod 被从节点上移除，因此容器崩溃期间 emptyDir 卷中的数据是安全的</p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker容器&amp;Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NGINX</title>
      <link href="/2025/03/01/linux/nginx-de-shi-yong/"/>
      <url>/2025/03/01/linux/nginx-de-shi-yong/</url>
      
        <content type="html"><![CDATA[<h1 id="1-NGINX介绍"><a href="#1-NGINX介绍" class="headerlink" title="1 NGINX介绍"></a>1 NGINX介绍</h1><h2 id="1-1-基本概念"><a href="#1-1-基本概念" class="headerlink" title="1.1 基本概念"></a>1.1 基本概念</h2><h3 id="1-1-1-什么是NGINX"><a href="#1-1-1-什么是NGINX" class="headerlink" title="1.1.1 什么是NGINX"></a>1.1.1 什么是NGINX</h3><p>  NGINX（发音为“engine-x”）是一个高性能的开源Web服务器、反向代理服务器、负载均衡器和邮件代理服务器。它由俄罗斯程序员Igor Sysoev于2002年开始开发。NGINX的设计初衷是为了解决C10k问题（即同时处理一万个并发连接的问题），因此它采用了异步、事件驱动的架构，使其在处理大量并发连接时具有极高的效率和稳定性。</p><h3 id="1-1-2-NGINX的主要特点"><a href="#1-1-2-NGINX的主要特点" class="headerlink" title="1.1.2 NGINX的主要特点"></a>1.1.2 NGINX的主要特点</h3><p>  1.<strong>高并发处理能力</strong>：NGINX以其高效的连接处理能力著称，能够在低内存消耗的情况下同时处理数万个并发连接。这使得它非常适合用于高流量的网站和应用。</p><p>  2.<strong>轻量级和高性能</strong>：NGINX的设计使其能够以较少的系统资源提供高性能的服务。它的内存占用低，启动速度快，且能够处理大量的静态和动态内容。</p><p>  3.<strong>灵活的配置</strong>：NGINX的配置文件采用模块化和层级结构，用户可以根据需要灵活地配置各种功能，如反向代理、负载均衡、缓存等。配置文件的语法简洁明了，便于管理和维护。</p><p>  4.<strong>跨平台支持</strong>：NGINX支持多种操作系统，包括Linux、Windows、macOS、BSD等，用户可以在不同的环境中轻松部署和运行NGINX。</p><p>  5.<strong>模块化架构</strong>：NGINX的模块化架构使得用户可以根据需求加载或卸载不同的模块，扩展其功能。例如，可以通过第三方模块实现额外的功能，如防火墙、认证、日志分析等。</p><p>  6.<strong>丰富的社区和生态系统</strong>：作为一个流行的开源项目，NGINX拥有一个活跃的开发者社区和广泛的用户群体。社区不断贡献新的模块、插件和工具，使得NGINX的功能不断扩展和完善。</p><h3 id="1-1-3-NGINX的应用场景"><a href="#1-1-3-NGINX的应用场景" class="headerlink" title="1.1.3 NGINX的应用场景"></a>1.1.3 NGINX的应用场景</h3><p>  1.<strong>Web服务器</strong>：NGINX可以作为一个静态内容的Web服务器，用于提供HTML、CSS、JavaScript、图像等静态文件。它以处理并发请求的高效能力而闻名，能够在低内存使用的情况下处理大量并发连接。</p><p>  2.<strong>反向代理服务器</strong>：NGINX可以作为反向代理服务器，接受客户端请求并将其转发到一个或多个后端服务器。这种功能特别适用于负载均衡和提高可用性，能够将流量分散到多个服务器上，从而提高系统的整体性能和可靠性。</p><p>  3.<strong>负载均衡器</strong>：NGINX可以用于HTTP、HTTPS、TCP和UDP的负载均衡。它支持多种负载均衡算法（如轮询、加权轮询、IP哈希等），能够在后端服务器之间分配请求，从而优化资源使用和响应时间。</p><p>  4.<strong>邮件代理服务器</strong>：NGINX还可以作为IMAP、POP3和SMTP的邮件代理服务器，提供邮件服务的负载均衡和安全性。</p><p>  5.<strong>HTTP缓存</strong>：NGINX可以缓存静态和动态内容，减少后端服务器的负载，提高响应速度。它支持多种缓存策略，可以灵活配置缓存行为。</p><p>  6.<strong>安全功能</strong>：NGINX支持SSL/TLS加密，可以用于保护传输数据的安全性。同时，它还支持访问控制和限流功能，能够有效防止恶意攻击和滥用。</p><p>  7.<strong>大型网站和内容分发网络（CDN）</strong>：由于其高效的静态内容处理能力和出色的并发处理性能，NGINX广泛应用于大型网站和内容分发网络中。</p><p>  8.<strong>微服务架构</strong>：在微服务架构中，NGINX常用于服务间的反向代理和负载均衡，确保服务的高可用性和伸缩性。</p><p>  9.<strong>API网关</strong>：NGINX可以用作API网关，处理API请求的路由、认证和速率限制等功能。</p><p>  NGINX作为一个功能强大、灵活性高的服务器软件，广泛应用于现代Web架构中，适用于各种规模的网站和应用。从小型网站到大型企业级系统，NGINX都能够提供卓越的性能和可靠性。</p><h2 id="1-2-NGINX和Apache的比较"><a href="#1-2-NGINX和Apache的比较" class="headerlink" title="1.2 NGINX和Apache的比较"></a>1.2 NGINX和Apache的比较</h2><h3 id="1-2-1-性能和架构"><a href="#1-2-1-性能和架构" class="headerlink" title="1.2.1 性能和架构"></a>1.2.1 性能和架构</h3><p>  <strong>NGINX</strong>：采用异步、事件驱动的架构，能够高效处理大量并发连接。NGINX在处理静态内容和反向代理时表现尤为出色。</p><p>  <strong>Apache</strong>：采用多线程和多进程模型，默认使用的是基于进程的MPM（Multi-Processing Module）架构。Apache在处理动态内容（如PHP）时通常表现良好，但在高并发情况下可能不如NGINX高效。</p><h3 id="1-2-2-资源消耗"><a href="#1-2-2-资源消耗" class="headerlink" title="1.2.2 资源消耗"></a>1.2.2 资源消耗</h3><p>  <strong>NGINX</strong>：由于其事件驱动的架构，NGINX在处理大量并发连接时占用的内存和CPU资源较少，更适合高流量的场景。</p><p>  <strong>Apache</strong>：基于进程的架构在处理高并发时可能需要更多的内存和CPU资源，但其模块化设计和灵活性使其在某些特定应用中表现更好。</p><h3 id="1-2-3-配置和模块"><a href="#1-2-3-配置和模块" class="headerlink" title="1.2.3 配置和模块"></a>1.2.3 配置和模块</h3><p>  <strong>NGINX</strong>：配置文件简洁、清晰，模块化设计可以根据需要加载或卸载模块。NGINX的核心模块相对较少，但可以通过第三方模块扩展功能。</p><p>  <strong>Apache</strong>：拥有丰富的模块库，可以通过配置文件启用或禁用各种模块。配置文件语法灵活，但可能相对复杂。</p><h3 id="1-2-4-静态和动态内容处理"><a href="#1-2-4-静态和动态内容处理" class="headerlink" title="1.2.4 静态和动态内容处理"></a>1.2.4 静态和动态内容处理</h3><p>  <strong>NGINX</strong>：在处理静态内容（如HTML、CSS、图像）时表现非常出色，具有较高的性能。动态内容处理通常通过FastCGI、uwsgi等外部处理器来实现。</p><p>  <strong>Apache</strong>：在处理动态内容（如PHP、Perl）时表现良好，因为它可以直接通过其模块（如mod_php、mod_perl）处理动态请求。</p><h3 id="1-2-5-反向代理和负载均衡"><a href="#1-2-5-反向代理和负载均衡" class="headerlink" title="1.2.5 反向代理和负载均衡"></a>1.2.5 反向代理和负载均衡</h3><p>  <strong>NGINX</strong>：内置强大的反向代理和负载均衡功能，支持多种负载均衡算法，如轮询、加权轮询、IP哈希等，非常适合用于分布式系统和微服务架构。</p><p>  <strong>Apache</strong>：也支持反向代理和负载均衡功能，但配置相对复杂，性能可能不如NGINX高效。</p><h3 id="1-2-6-社区和支持"><a href="#1-2-6-社区和支持" class="headerlink" title="1.2.6 社区和支持"></a>1.2.6 社区和支持</h3><p>  <strong>NGINX</strong>：拥有活跃的开源社区，提供丰富的文档和教程。商业版NGINX Plus提供额外的功能和支持服务。</p><p>  <strong>Apache</strong>：Apache HTTP Server项目由Apache Software Foundation维护，拥有长期的用户基础和丰富的资源支持，社区非常活跃。</p><h3 id="1-2-7-安全性"><a href="#1-2-7-安全性" class="headerlink" title="1.2.7 安全性"></a>1.2.7 安全性</h3><p>  <strong>NGINX</strong>：默认配置下具有较高的安全性，支持SSL/TLS加密、访问控制和限流功能，有效防止DDoS攻击和滥用。</p><p>  <strong>Apache</strong>：通过配置和模块可以实现多种安全功能，如SSL/TLS加密、身份验证和访问控制，安全性较高。</p><h3 id="1-2-8-使用场景"><a href="#1-2-8-使用场景" class="headerlink" title="1.2.8 使用场景"></a>1.2.8 使用场景</h3><p>  <strong>NGINX</strong>：适用于高并发的静态内容服务、反向代理、负载均衡和缓存等场景，尤其在高流量的网站和应用中表现优异。</p><p>  <strong>Apache</strong>：适用于需要灵活处理动态内容的网站和应用，模块化设计使其能够适应多种应用需求。</p><h2 id="1-3-NGINX的两种部署方法比较"><a href="#1-3-NGINX的两种部署方法比较" class="headerlink" title="1.3 NGINX的两种部署方法比较"></a>1.3 NGINX的两种部署方法比较</h2><p>  <strong>Linux</strong>是最常见的NGINX安装环境，支持通过包管理器和源代码编译安装。</p><p>  Linux提供了丰富的工具和资源，便于NGINX的配置和管理，源码包安装和包管理器安装各有优劣，选择哪种方式应根据具体的需求和使用场景来决定。</p><p>  一般来说，如果需要对NGINX进行深度定制和优化，并且具备足够的技术能力，可以选择源码包安装；如果你追求安装和维护的简便性，包管理器安装则是一个更好的选择。</p><h3 id="1-3-1-灵活性与自定义"><a href="#1-3-1-灵活性与自定义" class="headerlink" title="1.3.1 灵活性与自定义"></a>1.3.1 灵活性与自定义</h3><p>  <strong>源码包安装</strong>：</p><p>  <strong>优点</strong>：</p><p>  1.<strong>高度灵活</strong>：可根据需要定制NGINX的编译选项和模块。可以选择只编译需要的模块，减少内存和CPU占用。</p><p>  <strong>2.自定义模块</strong>：可以编译和安装第三方模块，这在需要特殊功能时非常有用。</p><p>  <strong>缺点</strong>：</p><p>  <strong>1.复杂性</strong>：编译和安装过程复杂，需要处理依赖项和配置选项。</p><p>  <strong>2.时间消耗</strong>：编译过程耗时较长，尤其是在资源有限的系统上。</p><p>  <strong>包管理器安装</strong>：</p><p>  <strong>优点</strong>：</p><p>  <strong>1.简单快捷</strong>：通过包管理器（如apt、yum、brew等）可以快速安装NGINX，并自动处理依赖项。</p><p>  <strong>2.易于管理</strong>：包管理器提供了统一的工具来管理软件的安装、升级和卸载，方便维护。</p><p>  <strong>缺点</strong>：</p><p>  <strong>1.灵活性有限</strong>：安装的NGINX版本和模块通常是预编译的，不能进行深度定制。</p><p>  <strong>2.版本控制</strong>：可能无法立即获取到最新版本，需要等待包管理器维护者更新软件库。</p><h3 id="1-3-2-性能与优化"><a href="#1-3-2-性能与优化" class="headerlink" title="1.3.2 性能与优化"></a>1.3.2 性能与优化</h3><p>  <strong>源码包安装</strong>：</p><p>  <strong>优点</strong>：</p><p>  <strong>1.性能优化</strong>：可以根据系统环境和具体需求，进行编译时的优化配置，从而提升性能。</p><p>  <strong>2.精细控制</strong>：可以关闭不需要的模块，减小可执行文件的体积，提高执行效率。</p><p>  <strong>缺点</strong>：</p><p>  <strong>1.调试复杂</strong>：由于是手动编译的版本，出现问题时需要自己调试和解决。</p><p>  <strong>包管理器安装</strong>：</p><p>  <strong>优点</strong>：</p><p>  <strong>1.稳定性高</strong>：包管理器提供的版本通常经过了充分测试，具备较高的稳定性。</p><p>  <strong>2.社区支持</strong>：使用包管理器安装的版本更容易获得社区支持和帮助。</p><p>  <strong>缺点</strong>：</p><p>  <strong>1.性能优化有限</strong>：预编译版本的性能优化程度不如手动编译。</p><h3 id="1-3-3-升级与维护"><a href="#1-3-3-升级与维护" class="headerlink" title="1.3.3 升级与维护"></a>1.3.3 升级与维护</h3><p>  <strong>源码包安装</strong>：</p><p>  <strong>优点</strong>：</p><p>  <strong>1.定制升级</strong>：可以针对需要的版本进行升级，灵活选择新版本特性。</p><p>  <strong>2.独立维护</strong>：可以独立管理不同版本，适合高级用户和特殊需求。</p><p>  <strong>缺点</strong>：</p><p>  <strong>1.维护成本高</strong>：每次升级都需要重新编译和配置，耗时且复杂。</p><p>  <strong>包管理器安装</strong>：</p><p>  <strong>优点</strong>：</p><p>  <strong>1.自动升级</strong>：包管理器通常提供自动升级功能，可以方便地保持软件的最新状态。</p><p>  <strong>2.低维护成本</strong>：包管理器处理依赖项和配置文件的变更，降低维护工作量。</p><p>  <strong>缺点</strong>：</p><p>  <strong>1.定制性差</strong>：无法选择特定版本或特定功能进行升级。</p><h1 id="2-NGINX快速部署"><a href="#2-NGINX快速部署" class="headerlink" title="2 NGINX快速部署"></a>2 NGINX快速部署</h1><h2 id="2-1-环境介绍"><a href="#2-1-环境介绍" class="headerlink" title="2.1 环境介绍"></a>2.1 环境介绍</h2><table><thead><tr><th>操作系统</th><th>IP地址</th><th>NGINX版本</th></tr></thead><tbody><tr><td>Red Hat Enterprise Linux release 9.6</td><td>192.168.8.53</td><td>1.28.0</td></tr></tbody></table><h2 id="2-2-RedHat9的有关配置"><a href="#2-2-RedHat9的有关配置" class="headerlink" title="2.2 RedHat9的有关配置"></a>2.2 RedHat9的有关配置</h2><h3 id="2-2-1-网络设置"><a href="#2-2-1-网络设置" class="headerlink" title="2.2.1 网络设置"></a>2.2.1 网络设置</h3><pre class=" language-language-bash"><code class="language-language-bash"># 查看虚拟机网路适配器设置[root@RhelHost1 ~]# vim /etc/NetworkManager/system-connections/ens160.nmconnection# 添加DNS[root@RhelHost1 ~]# vim /etc/resolv.conf# Generated by NetworkManagernameserver 8.8.8.8nameserver 8.8.4.4# 重启网卡[root@RhelHost1 ~]# nmcli connection down ens160[root@RhelHost1 ~]# nmcli connection up ens160</code></pre><h3 id="2-2-1-国内镜像源"><a href="#2-2-1-国内镜像源" class="headerlink" title="2.2.1 国内镜像源"></a>2.2.1 国内镜像源</h3><pre class=" language-language-bash"><code class="language-language-bash">[root@RhelHost1 ~]# cd /etc/yum.repos.d[root@RhelHost1 yum.repos.d]# vim aliyun_yum.repo[ali_baseos]name=ali_baseosbaseurl=https://mirrors.aliyun.com/centos-stream/9-stream/BaseOS/x86_64/os/gpgcheck=0[ali_appstream]name=ali_appstreambaseurl=https://mirrors.aliyun.com/centos-stream/9-stream/AppStream/x86_64/os/gpgcheck=0[root@RhelHost1 ~]# yum makecache# 根据需要选择是否更新yum源[root@RhelHost1 ~]# yum -y update</code></pre><h3 id="2-2-2-本地yum源配置"><a href="#2-2-2-本地yum源配置" class="headerlink" title="2.2.2 本地yum源配置"></a>2.2.2 本地yum源配置</h3><p>  配置本地yum源可以创建一个本地的软件包存储库，以便更快地安装、更新和管理软件包</p><pre class=" language-language-bash"><code class="language-language-bash"># 创建文件夹并将光盘挂载到新建的文件中[root@RhelHost1 ~]# mkdir -p /GuaZai/Iso[root@RhelHost1 ~]# mount /dev/sr0 /GuaZai/Isomount: /GuaZai/Iso: WARNING: source write-protected, mounted read-only.[root@RhelHost1 ~]# cd /GuaZai/Iso[root@RhelHost1 Iso]# lsAppStream  BaseOS  EFI  EULA  extra_files.json  GPL  images  isolinux  media.repo  RPM-GPG-KEY-redhat-beta  RPM-GPG-KEY-redhat-release#配置yum文件[root@RhelHost1 ~]# vim /etc/yum.repos.d/rhel9.repo[BaseOS]name=rhel9-BaseOSbaseurl=file:///GuaZai/Iso/BaseOSgpgcheck=0[Appstream]name=rhel9-Appstreambaseurl=file:///GuaZai/Iso/AppStreamgpgcheck=0# 查看仓库序列[root@RhelHost1 ~]# yum repolist# 生成yum缓存[root@RhelHost1 ~]# yum makecache</code></pre><h2 id="2-3-准备软件包仓库"><a href="#2-3-准备软件包仓库" class="headerlink" title="2.3 准备软件包仓库"></a>2.3 准备软件包仓库</h2><p>  向系统添加了一个名为<strong>nginx</strong>的仓库</p><pre class=" language-language-bash"><code class="language-language-bash"># 仓库地址 https://nginx.org/packagescat > /etc/yum.repos.d/nginx.repo <<EOF[nginx]name=nginx repobaseurl=https://nginx.org/packages/rhel/9/x86_64/gpgcheck=0enabled=1EOF# 尝试生成仓库索引，如果可以成功，就说明仓库可用[root@RhelHost1 ~]# dnf makecacheali_baseos                                                         12 kB/s | 3.9 kB     00:00ali_appstream                                                      32 kB/s | 4.4 kB     00:00nginx repo                                                         21 kB/s | 52 kB      00:02rhel9-BaseOS                                                       2.7 MB/s| 2.7 kB     00:00rhel9-Appstream                                                    3.1 MB/s| 3.2 kB     00:00</code></pre><h2 id="2-4-安装NGINX软件"><a href="#2-4-安装NGINX软件" class="headerlink" title="2.4 安装NGINX软件"></a>2.4 安装NGINX软件</h2><pre class=" language-language-bash"><code class="language-language-bash"># 从输出看，已经从nginx仓库中，安装了1.28.0[root@RhelHost1 ~]# dnf install nginx -y... Verifying        : nginx-2:1.28.0-1.el9.ngx.x86_64                                                                                              1/1Installed products updated.Installed:  nginx-2:1.28.0-1.el9.ngx.x86_64Complete!</code></pre><h2 id="2-5-准备测试页面"><a href="#2-5-准备测试页面" class="headerlink" title="2.5 准备测试页面"></a>2.5 准备测试页面</h2><p>  nginx的服务默认需要将网页放到**/usr/share/nginx/html<strong>目录中，首页需要以</strong>index.html<strong>或者</strong>index.htm**命名</p><p>  准备一个内容为<strong>Hello nginx, I’m China</strong>的网页作为其首页</p><pre class=" language-language-bash"><code class="language-language-bash">[root@RhelHost1 ~]# echo "Hello nginx, I'm China" > /usr/share/nginx/html/index.html[root@RhelHost1 ~]# cat /usr/share/nginx/html/index.htmlHello nginx, I'm China</code></pre><h2 id="2-6-启用并启动服务"><a href="#2-6-启用并启动服务" class="headerlink" title="2.6 启用并启动服务"></a>2.6 启用并启动服务</h2><p>  用<strong>enable –now</strong>的语法，将nginx的服务执行enable和start操作，以便于马上启动nginx服务，并通知服务器，将nginx服务在开机时自动启动</p><pre class=" language-language-bash"><code class="language-language-bash">[root@RhelHost1 ~]# systemctl enable nginx --nowCreated symlink /etc/systemd/system/multi-user.target.wants/nginx.service → /usr/lib/systemd/system/nginx.service.[root@RhelHost1 ~]# systemctl status nginx</code></pre><h2 id="2-7-开通防火墙"><a href="#2-7-开通防火墙" class="headerlink" title="2.7 开通防火墙"></a>2.7 开通防火墙</h2><pre class=" language-language-bash"><code class="language-language-bash">[root@RhelHost1 ~]# firewall-cmd --add-service=http --permanentsuccess[root@RhelHost1 ~]# firewall-cmd --reloadsuccess</code></pre><h2 id="2-8-访问测试网页"><a href="#2-8-访问测试网页" class="headerlink" title="2.8 访问测试网页"></a>2.8 访问测试网页</h2><pre class=" language-language-bash"><code class="language-language-bash">[root@RhelHost1 ~]# curl http://192.168.8.53Hello nginx, I'm China</code></pre><h2 id="2-9-优雅重载NGINX"><a href="#2-9-优雅重载NGINX" class="headerlink" title="2.9 优雅重载NGINX"></a>2.9 优雅重载NGINX</h2><p>  如果后续修改了配置文件，可用下面的方法优雅重载nginx，比如下面告诉nginx来重新加载配置文件，而不中断服务</p><pre class=" language-language-bash"><code class="language-language-bash"># 给nginx发送reload信号，可在不中断nginx进程的情况下重载配置文件[root@RhelHost1 ~]# nginx -s reload</code></pre><h1 id="3-NGINX实现负载均衡"><a href="#3-NGINX实现负载均衡" class="headerlink" title="3 NGINX实现负载均衡"></a>3 NGINX实现负载均衡</h1><h2 id="3-1-环境介绍"><a href="#3-1-环境介绍" class="headerlink" title="3.1 环境介绍"></a>3.1 环境介绍</h2><table><thead><tr><th>操作系统</th><th>IP地址</th><th>主机名</th><th>NGINX版本</th><th>角色</th></tr></thead><tbody><tr><td>Red Hat Enterprise Linux release 9.6</td><td>192.168.8.53</td><td>loadbalance.luovip.cn</td><td>1.28.0</td><td>负载均衡</td></tr><tr><td>Red Hat Enterprise Linux release 9.6</td><td>192.168.8.54</td><td>web1.luovip.cn</td><td>1.28.0</td><td>普通业务服务器</td></tr><tr><td>Red Hat Enterprise Linux release 9.6</td><td>192.168.8.55</td><td>web2.luovip.cn</td><td>1.28.0</td><td>普通业务服务器</td></tr></tbody></table><h2 id="3-2-环境架构图"><a href="#3-2-环境架构图" class="headerlink" title="3.2 环境架构图"></a>3.2 环境架构图</h2><p>  在这个架构中，NGINX负载均衡器loadbalance.luovip.cn（IP地址192.168.8.53）负责将请求分发到两台普通业务服务器web1.luovip.cn（IP地址192.168.8.54）和web2.luovip.cn（IP地址192.168.8.55）</p><pre><code>                              +------------------------+                              | loadbalance.luovip.cn  |                              |      192.168.8.53      |                              |        (NGINX)         |                              +------------------------+                                         |                                         |               +-------------------------+-------------------------+               |                                                   |               |                                                   |+------------------------+                           +------------------------+|     web1.luovip.cn     |                           |     web2.luovip.cn     ||      192.168.8.54       |                           |      192.168.8.55       ||      (业务服务器)       |                           |      (业务服务器)       |+------------------------+                           +------------------------+</code></pre><h2 id="3-3-实验先决条件"><a href="#3-3-实验先决条件" class="headerlink" title="3.3 实验先决条件"></a>3.3 实验先决条件</h2><h3 id="3-3-1-准备hosts文件"><a href="#3-3-1-准备hosts文件" class="headerlink" title="3.3.1 准备hosts文件"></a>3.3.1 准备hosts文件</h3><p>  需要在所有机器上完成准备，以便能用名称互相解析和访问</p><pre class=" language-language-bash"><code class="language-language-bash"># 以下命令在架构中的三台主机中执行cat > /etc/hosts <<EOF192.168.8.53 loadbalance.luovip.cn loadbalance192.168.8.54 web1.luovip.cn web1192.168.8.55 web2.luovip.cn web2EOF</code></pre><h3 id="3-3-2-部署业务服务器"><a href="#3-3-2-部署业务服务器" class="headerlink" title="3.3.2 部署业务服务器"></a>3.3.2 部署业务服务器</h3><p>  在两台业务服务器上部署Nginx，需要让每个服务器上的页面显示不同的内容以区分主机，每个主机需开通防火墙</p><p>1.部署web1.luovip.cn这台主机，IP为：192.168.8.54</p><pre class=" language-language-bash"><code class="language-language-bash"># 准备软件包仓库cat > /etc/yum.repos.d/nginx.repo <<EOF[nginx]name=nginx repobaseurl=https://nginx.org/packages/rhel/9/x86_64/gpgcheck=0enabled=1EOF[root@RhelHost2 ~]# dnf makecache# 安装NGINX软件[root@RhelHost2 ~]# dnf install nginx -y# 准备测试页面[root@RhelHost2 ~]# echo "Hello nginx, I'm web1.luovip.cn" > /usr/share/nginx/html/index.html# 启用并启动服务[root@RhelHost2 ~]# systemctl enable nginx --nowCreated symlink /etc/systemd/system/multi-user.target.wants/nginx.service → /usr/lib/systemd/system/nginx.service.# 开通防火墙[root@RhelHost2 ~]# firewall-cmd --add-service=http --permanentsuccess[root@RhelHost2 ~]# firewall-cmd --reloadsuccess# 访问测试页[root@RhelHost2 ~]# curl http://192.168.8.54Hello nginx, I'm web1.luovip.cn</code></pre><p>2.部署web2.luovip.cn这台主机，IP为：192.168.8.55</p><pre class=" language-language-bash"><code class="language-language-bash"># 准备软件包仓库cat > /etc/yum.repos.d/nginx.repo <<EOF[nginx]name=nginx repobaseurl=https://nginx.org/packages/rhel/9/x86_64/gpgcheck=0enabled=1EOF[root@RhelHost3 ~]# dnf makecache# 安装NGINX软件[root@RhelHost3 ~]# dnf install nginx -y# 准备测试页面[root@RhelHost3 ~]# echo "Hello nginx, I'm web2.luovip.cn" > /usr/share/nginx/html/index.html# 启用并启动服务[root@RhelHost3 ~]# systemctl enable nginx --nowCreated symlink /etc/systemd/system/multi-user.target.wants/nginx.service → /usr/lib/systemd/system/nginx.service.# 开通防火墙[root@RhelHost3 ~]# firewall-cmd --add-service=http --permanentsuccess[root@RhelHost3 ~]# firewall-cmd --reloadsuccess# 访问测试页[root@RhelHost3 ~]# curl http://192.168.8.55Hello nginx, I'm web2.luovip.cn</code></pre><h2 id="3-4-基本概念"><a href="#3-4-基本概念" class="headerlink" title="3.4 基本概念"></a>3.4 基本概念</h2><p>  NGINX不仅是一个高性能的Web服务器，同时还提供了强大的负载均衡功能。它支持基于HTTP、HTTPS、TCP和UDP协议的负载均衡，为不同的应用场景提供了解决方案。在开源版本的NGINX中，提供了被动的健康检查，这有助于减少上游服务器的压力。而在NGINX Plus版本中，除了被动健康检查，还提供了主动健康检查功能。</p><p>  主动健康检查每隔一段时间就会向上游服务器发起连接或请求，以确保服务器的健康状态。这虽然会带来一定的系统负载，但能够更及时地发现问题，并提供更高的服务可用性。</p><h2 id="3-5-负载均衡的应用"><a href="#3-5-负载均衡的应用" class="headerlink" title="3.5 负载均衡的应用"></a>3.5 负载均衡的应用</h2><p>  以下所有关于负载均衡的例子，都在loadbalance服务器执行，192.168.8.56不需要准备，仅用于示意</p><h3 id="3-5-1-HTTP-负载均衡"><a href="#3-5-1-HTTP-负载均衡" class="headerlink" title="3.5.1 HTTP 负载均衡"></a>3.5.1 HTTP 负载均衡</h3><p>  在这个配置中：</p><p>  <strong>upstream load</strong>：定义了一个名为load的上游服务器组。</p><p>  <strong>server 192.168.8.54:80 weight=1 max_fails=3 fail_timeout=3s</strong>：定义了第一台后端服务器，权重为1，最大失败次数为3，超时时间为3秒。</p><p>  <strong>server 192.168.8.55:80 weight=2 max_fails=3 fail_timeout=3s</strong>：定义了第二台后端服务器，权重为2，最大失败次数为3，超时时间为3秒。</p><p>  <strong>server 192.168.8.56:80 backup max_fails=3 fail_timeout=3s</strong>：定义了备份服务器，最大失败次数为3，超时时间为3秒。</p><p>  <strong>server_name loadbalance.luovip.cn</strong>：设置了虚拟主机名。</p><p>  <strong>proxy_pass <a href="http://load/">http://load</a></strong>：将请求转发到上游服务器组。</p><pre class=" language-language-bash"><code class="language-language-bash"># 将以下代码在loadbalance服务器执行，让nginx重新加载配置文件生效cat > /etc/nginx/conf.d/httpha.conf <<EOFupstream load { server 192.168.8.54:80 weight=1 max_fails=3 fail_timeout=3s; server 192.168.8.55:80 weight=2 max_fails=3 fail_timeout=3s; server 192.168.8.56:80 backup max_fails=3 fail_timeout=3s;}server { listen 80; server_name loadbalance.luovip.cn; location / { proxy_pass http://load; }}EOF</code></pre><p>第三个服务器后面的backup可以是以下的几种：</p><table><thead><tr><th>选项</th><th>含义</th></tr></thead><tbody><tr><td>down</td><td>目前宕机，不参与负载均衡</td></tr><tr><td>backup</td><td>当具有权重的正常服务器全宕机后，此服务器将启用</td></tr><tr><td>max_fails</td><td>最大请求失败次数</td></tr><tr><td>fail_timeout</td><td>超过最大失败次数后，暂停多长时间</td></tr><tr><td>max_conns</td><td>最大连接数</td></tr></tbody></table><pre class=" language-language-bash"><code class="language-language-bash"># 让nginx重新加载配置文件生效 nginx -t表示检查配置[root@RhelHost1 ~]# nginx -tnginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successful[root@RhelHost1 ~]# nginx -s reload</code></pre><p>  测试负载均衡效果，需要将SELinux的布尔值打开，或者关闭SELinux，不然nginx将无法作为负载均衡工作</p><pre class=" language-language-bash"><code class="language-language-bash"># 临时关闭SELinux[root@RhelHost1 ~]# setenforce 0# 将SELinux的布尔值打开[root@RhelHost1 ~]# setsebool -P httpd_can_network_relay on# 可以看到，当多次访问loadbalance的时候，会返回不同主机上的内容[root@RhelHost1 ~]# curl http://loadbalance.luovip.cnHello nginx, I'm web2.luovip.cn[root@RhelHost1 ~]# curl http://loadbalance.luovip.cnHello nginx, I'm web1.luovip.cn</code></pre><h3 id="3-5-2-TCP-负载均衡"><a href="#3-5-2-TCP-负载均衡" class="headerlink" title="3.5.2 TCP 负载均衡"></a>3.5.2 TCP 负载均衡</h3><p>  nginx 使用stream模块来完成TCP端口负载均衡，所以需要在主配置文件中打开stream功能，并将stream配置文件单独存储，方便管理</p><pre class=" language-language-bash"><code class="language-language-bash">[root@RhelHost1 ~]# vim /etc/nginx/nginx.confuser  nginx;worker_processes  auto;error_log  /var/log/nginx/error.log notice;pid        /run/nginx.pid;events {    worker_connections  1024;}http {...stream {    include /etc/nginx/stream.conf.d/*.conf;}# 从上面的配置文件中可看出，将stream功能的配置文件放入了/etc/nginx/stream.conf.d/，这个位置需要建出来[root@RhelHost1 ~]# mkdir /etc/nginx/stream.conf.d/[root@RhelHost1 ~]# vim /etc/nginx/stream.conf.d/tcp.confupstream backend {    server 192.168.8.54:22 weight=1 max_fails=3 fail_timeout=30s; # 业务服务器1，SSH端口22    server 192.168.8.55:22 weight=2 max_fails=3 fail_timeout=30s; # 业务服务器2，SSH端口22    server 192.168.8.56:22 backup max_fails=3 fail_timeout=30s;   # 备份服务器，SSH端口22}server {    listen 3000; # 将负载均衡器监听端口更改为3000    proxy_pass backend;}</code></pre><p>  以上配置文件主要是用于实现基于 TCP 协议的负载均衡，特别是针对 SSH 流量。NGINX 监听 3000 端口的连接请求，然后根据配置的权重和健康检查机制，将请求转发到后端的 SSH 服务器（<code>192.168.8.54</code>、<code>192.168.8.55</code> 和 <code>192.168.8.56</code>）</p><p><strong>upstream backend</strong>：定义了一个名为 <strong>backend</strong>的上游服务器组。</p><p><strong>server 192.168.8.4:22 weight=1 max_fails=3 fail_timeout=30s</strong>：</p><p>  192.168.8.4:22：服务器的 IP 和端口号（SSH端口 22）</p><p>  weight=1：设置此服务器的权重为1，表示流量分配到此服务器的比例较低</p><p>  max_fails=3：如果服务器失败次数超过3次，则认为服务器不可用</p><p>  fail_timeout=30s：在30秒内，如果服务器连续失败达到 max_fails，则将其标记为不可用。</p><p>其他服务器配置（<code>192.168.8.55</code> 和 <code>192.168.8.56</code>）类似，只是权重和角色（备份服务器）不同。</p><p>listen 3000：NGINX 监听 3000 端口，所有进入 3000 端口的 TCP 请求都会被处理。</p><p>proxy_pass backend<code>：将接收到的流量转发到上游服务器组 </code>backend</p><pre class=" language-language-bash"><code class="language-language-bash">[root@RhelHost1 ~]# nginx -tnginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successful[root@RhelHost1 ~]# nginx -s reload# 测试[root@RhelHost1 ~]# nc -vz loadbalance.luovip.cn 3000Ncat: Version 7.92 ( https://nmap.org/ncat )Ncat: Connected to 192.168.8.53:3000.Ncat: 0 bytes sent, 0 bytes received in 0.01 seconds.</code></pre><h3 id="3-5-3-UDP负载均衡"><a href="#3-5-3-UDP负载均衡" class="headerlink" title="3.5.3 UDP负载均衡"></a>3.5.3 UDP负载均衡</h3><p>  listen 的端口号之后指明为UDP即可，基本配置和上面的TCP很像</p><pre class=" language-language-bash"><code class="language-language-bash">cat > /etc/nginx/stream.conf.d/udp-dns.conf <<EOFupstream dns_servers {    server 192.168.8.54:53 weight=1 max_fails=3 fail_timeout=30s; # 业务服务器1，DNS端口53    server 192.168.8.55:53 weight=2 max_fails=3 fail_timeout=30s; # 业务服务器2，DNS端口53    server 192.168.8.56:53 backup max_fails=3 fail_timeout=30s;   # 备份服务器，DNS端口53}server {    listen 53 udp; # 监听 UDP 53 端口    proxy_pass dns_servers;}EOF</code></pre><p><strong>upstream dns_servers</strong>：定义一个名为 dns_servers的上游服务器组，其中包含了三个后端服务器。每个服务器配置了 IP 地址、端口、权重、最大失败次数和失败超时时间。</p><p><strong>server</strong>：</p><p>  listen 53 udp：NGINX 监听 UDP 53 端口（通常用于 DNS 服务）</p><p>  proxy_pass dns_servers：将接收到的 UDP 流量转发到上游服务器组 dns_servers</p><pre class=" language-language-bash"><code class="language-language-bash">[root@RhelHost1 ~]# nginx -tnginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successful[root@RhelHost1 ~]# nginx -s reload</code></pre><h2 id="3-6-不同负载均衡类型配置示意"><a href="#3-6-不同负载均衡类型配置示意" class="headerlink" title="3.6 不同负载均衡类型配置示意"></a>3.6 不同负载均衡类型配置示意</h2><p>  NGINX的负载均衡类型：最少连接、最少时间、轮询调度、通用哈希、随机调度、IP哈希</p><p>  1.<strong>最少连接（Least Connections）</strong>：</p><p>  将新请求分配给当前活动连接数最少的后端服务器。适用于请求处理时间较长的场景。</p><p>  配置示例：</p><pre class=" language-language-bash"><code class="language-language-bash">upstream backend {    least_conn;    server backend1.example.com;    server backend2.example.com;}</code></pre><p>  2.<strong>最少时间（Least Time）</strong>：</p><p>  根据请求处理时间，将新请求分配给响应时间最短且当前活动连接数最少的后端服务器。适用于需要快速响应的场景。</p><p>  配置示例（需要 NGINX Plus）：</p><pre class=" language-language-bash"><code class="language-language-bash">upstream backend {    least_time header;    server backend1.example.com;    server backend2.example.com;}</code></pre><p>  3.<strong>轮询调度（Round Robin）</strong>：</p><p>  将新请求按照循环顺序分配给后端服务器。适用于大多数场景。</p><p>  配置示例（默认配置）：</p><pre class=" language-language-bash"><code class="language-language-bash">upstream backend {    server backend1.example.com;    server backend2.example.com;}</code></pre><p>  4.<strong>通用哈希（Generic Hash）</strong>：</p><p>  基于用户定义的哈希方法，将请求分配给特定的后端服务器。适用于需要特定规则进行流量分配的场景。</p><p>  配置示例：</p><pre class=" language-language-bash"><code class="language-language-bash">upstream backend {    hash $request_uri;    server backend1.example.com;    server backend2.example.com;}</code></pre><p>  5.<strong>随机调度（Random with Two Choices）</strong>：</p><p>  随机选择两台后端服务器，然后将请求分配给其中负载较小的一台。适用于需要均匀分配负载的场景。</p><p>  配置示例（需要 NGINX Plus）：</p><pre class=" language-language-bash"><code class="language-language-bash">upstream backend {    random two least_conn;    server backend1.example.com;    server backend2.example.com;}</code></pre><p>  6.<strong>IP哈希（IP Hash）</strong>：</p><p>  基于客户端 IP 地址的哈希值，将请求分配给特定的后端服务器。适用于需要保持会话一致性的场景。</p><p>  配置示例：</p><pre class=" language-language-bash"><code class="language-language-bash">upstream backend {    ip_hash;    server backend1.example.com;    server backend2.example.com;}</code></pre><h1 id="4-NGINX实现流量按比例分流"><a href="#4-NGINX实现流量按比例分流" class="headerlink" title="4 NGINX实现流量按比例分流"></a>4 NGINX实现流量按比例分流</h1>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NGINX </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Shell脚本</title>
      <link href="/2024/08/28/zi-dong-hua-yun-wei/shell-jiao-ben/"/>
      <url>/2024/08/28/zi-dong-hua-yun-wei/shell-jiao-ben/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> 自动化运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Shell脚本 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux的基础服务</title>
      <link href="/2024/07/28/linux/linux-de-ji-chu-fu-wu/"/>
      <url>/2024/07/28/linux/linux-de-ji-chu-fu-wu/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux的基础服务 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库基础</title>
      <link href="/2024/05/14/shu-ju-ku/shu-ju-ku-ji-chu/"/>
      <url>/2024/05/14/shu-ju-ku/shu-ju-ku-ji-chu/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ansible的基本使用</title>
      <link href="/2024/04/28/zi-dong-hua-yun-wei/ansible-de-ji-ben-shi-yong/"/>
      <url>/2024/04/28/zi-dong-hua-yun-wei/ansible-de-ji-ben-shi-yong/</url>
      
        <content type="html"><![CDATA[<h1 id="1-介绍Ansible"><a href="#1-介绍Ansible" class="headerlink" title="1 介绍Ansible"></a>1 介绍Ansible</h1><p>  Ansible是python开发的、开源的批量自动化运维工具</p><p>  官方网站：<a href="https://www.ansible.com、https//docs.ansible.com/">https://www.ansible.com、https://docs.ansible.com/</a></p><p><img src="/images/ansible.png"></p><h2 id="1-1-Ansible的概念和架构"><a href="#1-1-Ansible的概念和架构" class="headerlink" title="1.1 Ansible的概念和架构"></a>1.1 Ansible的概念和架构</h2><p>  通过inventor定义Managed node，并由SSH与python进行连通：</p><p>  1.管理机上管理被管机</p><p>  2.inventory(清单)分组被管机</p><p>  3.基于SSH、PowerShell进行PUSH ad-hoc或基于YML文件Playbook</p><p>  4.Python模块、插件、API</p><p><img src="/images/ansible%E6%9E%B6%E6%9E%84.png"></p><h2 id="1-2-Absible的优势"><a href="#1-2-Absible的优势" class="headerlink" title="1.2 Absible的优势"></a>1.2 Absible的优势</h2><p>  简单明了：Ansible playbook，更好的对任务进行排序编写</p><p>  功能强大：3000多个模块，配置管理、工作流自动化、网络自动化</p><p>  无需代理：通过SSH管理，而puppet、saltstack需要装客户端</p><p>  与其他系统轻松集成，如jenkins</p><p>  跨平台支持：win、linux、unix、网络设备，虚拟机、物理机、云主机、容器</p><h2 id="1-3-Ansible自动化平台2"><a href="#1-3-Ansible自动化平台2" class="headerlink" title="1.3 Ansible自动化平台2"></a>1.3 Ansible自动化平台2</h2><p>  1.Ansible自动化平台2-Ansible Core</p><p>   包含多个不同的组件，共同提供了一整套集成的自动化工具和资源</p><p>   提供用于运行Ansible Playbook的基本功能</p><p>   定义了用于在YAML文本文件中编写Ansible Playbook的自动化语言</p><p>   提供了自动化代码所需的关键功能，如循环、条件和其他Ansible命令</p><p>   提供了驱动自动化所需的框架和基本命令行工具</p><p>   在ansible-core RPM软件包及其ee-minimal-rhel8和ee-supported-rhel8自动化执行环境中提供Ansible Core 2.13</p><p>  2.Ansible自动化平台2-Ansible内容集合</p><p>   在过去，Ansible提供了大量模块作为核心软件包的一部分;这种方法在Ansible社区中被称为“自带电池”</p><p>   Ansible中包含的模块数量呈指数级增长。这导致了支持方面的一些挑战，特别是因为用户有时希望使用比Ansible特定版本中附带模块版本更早或更高的模块</p><p>   开发人员决定将大多数模块重新整理为单独的Ansible collection(内容集合)，这些资源collection相关的模块角色和插件构成，由同一组开发人员提供支持</p><p>   Ansible Core本身仅限于由ansible.builtin、Ansible collection(内容集合)提供的一小组模块，该集合始终是Ansible Core的一部分</p><p>   订阅红帽Ansible自动化平台2后，可获得红帽提供的120多个认证内容集合的访问权限，另外还可通过AnsibleGalaxy获得很多受社区支持的集合</p><p>  3.Ansible自动化平台2概述-自动化内容导航器</p><p>   红帽Ansible自动化平台2还可提供新的顶级工具(自动化内容导航(ansble-navigator))来开发和测试Ansible Playbook。该工具可取代并扩展多个命令行实用程序的功能，包括ansible-playbook、ansible-inventory、ansible-config</p><p>   通过在容器中运行playbook，将运行Ansible的控制节点与运行它的自动化执行环境分隔开来。这样一来，可以更轻松地为自动化代码提供完整的工作环境，以部署到生产环境中</p><p>  4.Ansible自动化平台2-自动化执行环境</p><p>   自动化执行环境是一种容器镜像，包含Ansible Core、Ansible内容集合以及运行playbook所需的任何Python库、可执行文件或其他依赖项</p><p>   使用ansible-navigator运行playbook时，可选择用于运行该playbook的自动化执行环境</p><p>   当代码运行时，可以向自动化控制器提供playbook和自动化执行环境，并且也知道其具有正确运行playbook所需的一切</p><p><img src="/images/%E8%87%AA%E5%8A%A8%E5%8C%96%E6%89%A7%E8%A1%8C%E7%8E%AF%E5%A2%83.png"></p><p>  5.Ansible自动化平台2-准备控制节点</p><p>   要运行Ansible Playbook，需在控制节点安装自动化内容导航器(ansible-navigator)，然后下载执行环境</p><p>   由Ansible托管的主机无需安装ansible-navigator，该工具只需安装在运行Ansible Playbook的控制节点</p><p>   安装ansible-core软件包前，先要在控制节点上安装Python3.8或更高版本</p><p>   需要有效的红帽Ansible自动化平台订阅，才能在控制节点上安装自动化内容导航器</p><p>   如果已在红帽客户门户中为您的组织激活了简单内容访问，则无需再将订阅连接到系统</p><h1 id="2-部署Ansible"><a href="#2-部署Ansible" class="headerlink" title="2 部署Ansible"></a>2 部署Ansible</h1><h2 id="2-1-安装Ansible"><a href="#2-1-安装Ansible" class="headerlink" title="2.1 安装Ansible"></a>2.1 安装Ansible</h2><h3 id="2-1-1-安装自动化内容导航器"><a href="#2-1-1-安装自动化内容导航器" class="headerlink" title="2.1.1 安装自动化内容导航器"></a>2.1.1 安装自动化内容导航器</h3><pre class=" language-language-bash"><code class="language-language-bash"># 登录workstation后默认为student普通用户，根据实际使用和考试结合建议使用普通用户操作# 方法1:[kiosk@foundation0 ~]$ ssh student@workstation# 方法2:[kiosk@foundation0 ~]$ ssh root@workstation[root@workstation ~]$ ssh student@localhost# 控制节点上安装自动化内容导航器    - workstation[student@workstation ~]$ sudo dnf search ansible   #搜索ansible关键字的软件包，方便查找ansible的软件[student@workstation ~]$ sudo dnf -y install ansible-navigator.noarch ansible-core.x86_64[student@workstation ~]$ rpm -q ansible-navigatoransible-navigator-2.1.0-1.el9ap.noarch[student@workstation ~]$ rpm -q ansible-coreansible-core-2.13.0-2.el9ap.x86_64[student@workstation ~]$ rpm -qc ansible-core/etc/ansible/ansible.cfg    # 默认全局配置文件/etc/ansible/hosts          # 默认全局清单文件[student@workstation ~]$ rpm -qc ansible-navigator</code></pre><h3 id="2-1-2-检查Ansible版本"><a href="#2-1-2-检查Ansible版本" class="headerlink" title="2.1.2 检查Ansible版本"></a>2.1.2 检查Ansible版本</h3><pre class=" language-language-bash"><code class="language-language-bash"># 检查ansible的版本[student@workstation ~]$ ansible --versionansible [core 2.13.0]  config file = /etc/ansible/ansible.cfg...[student@workstation ~]$ ansible-navigator --versionansible-navigator 2.1.0# 安装ansible后会提供导航器配置文件[student@workstation ~]$ ls -a.   .ansible               .ansible-navigator.yml  .bash_logout   .bashrc  .config  Documents  .grading  .jupyter  Music  Pictures  .ssh       .venv..  ansible-navigator.log  .bash_history           .bash_profile  .cache   Desktop  Downloads  .ipython  .local    .npm   Public    Templates  Videos[student@workstation ~]$ cat .ansible-navigator.yml---ansible-navigator:  execution-environment:    image: utility.lab.example.com/ee-supported-rhel8:latest    pull:      policy: missing</code></pre><h3 id="2-1-3-登录镜像仓库"><a href="#2-1-3-登录镜像仓库" class="headerlink" title="2.1.3 登录镜像仓库"></a>2.1.3 登录镜像仓库</h3><pre class=" language-language-bash"><code class="language-language-bash"># 配置镜像仓库不进行https验证[student@workstation ~]$ mkdir ~/.config/containers # ~/.config/containers等价于/home/student/.config/containers[student@workstation ~]$ cp /etc/containers/registries.conf ~/.config/containers[student@workstation ~]$ vim ~/.config/containers/registries.confunqualified-search-registries = ["utility.lab.example.com"]  # 22行[[registry]]  # 24行insecure = true  # 37行blocked = false   # 40行location = "utility.lab.example.com"  # 56行# 登录容器镜像服务器，为下载自动化执行环境容器镜像做准备[student@workstation ~]$ podman --versionpodman version 4.0.2[student@workstation ~]$ podman login -u admin -p redhat utility.lab.example.comLogin Succeeded!# 下载自动化内容导航器或使用ansible-navigator命令自动下载[student@workstation ~]$ ansible-navigator collections    [student@workstation ~]$ ansible-navigator images   # 查看下载的镜像环境</code></pre><h2 id="2-2-构建Ansible清单"><a href="#2-2-构建Ansible清单" class="headerlink" title="2.2 构建Ansible清单"></a>2.2 构建Ansible清单</h2><h3 id="2-2-1-默认的清单文件"><a href="#2-2-1-默认的清单文件" class="headerlink" title="2.2.1 默认的清单文件"></a>2.2.1 默认的清单文件</h3><pre class=" language-language-bash"><code class="language-language-bash"># 清单定义Ansible管理的主机集合。主机可以分配到组中进行集中管理。组可以包含子组，主机也可以是多个组的成员# 清单还可以设置应用到它所定义的主机和组的变量# 定义主机清单可采用两种方式:  1.使用文本文件定义静态主机清单  2.通过外部信息提供程序，使用Ansible插件按需生成动态主机清单# 系统默认清单在/etc/ansibile/hosts# 举例:# [嵌套组名:children]，嵌套组内只能包含组，不包含主机[test]servera[web]serverb.example.com[webservers]web[1:50].example.com   # 表示从web1到web50，共计50台主机[servers:children]  # 表示servers组是一个超级组，包含test和web两个组(嵌套)testwebwebservers# 指定清单范围格式：通配符或正则表达式的方法[START:END]                  #开始:结束范围192.168.[0:15].[0:255]       #表示   192.168.0.0-192.168.15.255server[a:c].example.com      #表示   a-cserver[01:15].example.com    #表示   server01.example.com-server15.example.comall：                        #表示   所有主机ungrouped:                   #表示   指定组/未分配组的主机      </code></pre><h3 id="2-2-2-自定义清单文件"><a href="#2-2-2-自定义清单文件" class="headerlink" title="2.2.2 自定义清单文件"></a>2.2.2 自定义清单文件</h3><p>  1.创建工作目录</p><pre class=" language-language-bash"><code class="language-language-bash"># 当使用特权用户管理Ansible时，可以在家目录中为其创建工作目录# 目录名称可以根据业务自定义名称,后续的所有文件都放到此目录，包括配置文件、清单文件、playbook等[student@workstation ~]$ mkdir ~/ansible[student@workstation ~]$ cd ~/ansible/[student@workstation ansible]$ pwd/home/student/ansible# 查看清单实例文件[student@workstation ansible]$ ansible-doc -t inventory -l[student@workstation ansible]$ ansible-doc -t inventory ini[student@workstation ~]$ ansible-navigator doc -t inventory ini</code></pre><p>  2.编辑自定义清单文件</p><pre class=" language-language-bash"><code class="language-language-bash">[student@workstation ansible]$ vim inventoryservera                    # 未在组内的主机[web]                      # 主机组，主机组名称需要使用中括号括起来[]，web是组名称server[b:c]                # 主机组成员，web组内的主机 表示两个主机serverb至serverc172.25.250:[10:15][db]server[d:z].lab.example.com# 嵌套组名servers是自定义的，:children是固定语法，表示web、db在servers组中，嵌套组成员应为组，不应为主机[servers:children]  webdb# 不要在清单里书写无用的符号，及一些特殊符号。主机名称不要和主机组冲突，组名尽量不要用数字开头</code></pre><p>  3.验证清单</p><pre class=" language-language-bash"><code class="language-language-bash"># 使用ansible-navigator或ansible-inventory命令验证计算机是否存在于清单中  1.ansible-navigator inventory以stdout模式运行  2.第一条传统Ansible的验证方式，第二条使用Ansible自动化平台2的方式-RHEL8 & 9-i inventory  # 指定清单文件的位置--list-hosts  # 列出清单中的主机  --graph       # 通过ansible-inventory命令列出清单整个pattern$ ansible all -i inventory --list-hosts$ ansible-inventory --graph -i inventory  [student@workstation ansible]$ ansible-inventory --graph -i /home/student/ansible/inventory-RHEL 9$ ansible-navigator inventory -i inventory  -m stdout --list$ ansible-navigator inventory -i inventory  -m stdout --graph$ ansible-navigator inventory -i inventory  -m stdout --graph webservers重要：清单中含有名称相同的主机和主机组，ansible命令显示警告并以主机作为其目标，组被忽略</code></pre><h3 id="2-2-3-覆盖清单位置"><a href="#2-2-3-覆盖清单位置" class="headerlink" title="2.2.3 覆盖清单位置"></a>2.2.3 覆盖清单位置</h3><pre class=" language-language-bash"><code class="language-language-bash"># 安装ansible软件后，在/etc/ansible/hosts位置提供一个默认主机清单，属于全局管理范围# 特权用户管理时可以为其在工作目录中创建清单，在工作目录中使用ansible时，且优先度最高/home/student/ansible/inventory   # 用于针对某个用户设置清单/etc/ansible/hosts                  # 用于全局设置[student@workstation /]$ ansible-inventory --graph@all:  |--@ungrouped:[student@workstation /]$ pwd/[student@workstation ansible]$ ansible-inventory --graph@all:  |--@ungrouped:[student@workstation ansible]$ pwd/home/student/ansible</code></pre><h3 id="2-2-4-多清单"><a href="#2-2-4-多清单" class="headerlink" title="2.2.4 多清单"></a>2.2.4 多清单</h3><pre class=" language-language-bash"><code class="language-language-bash"># 一个用户可以有一个或多个清单文件，若同时使用，可将多个清单文件放置在清单目录中，清单目录需自行创建，名称自定义[student@workstation ansible]$ vim inventoryservera[web]serverbserverc[db]serverd[servers:children]webdb[student@workstation ansible]$ ansible-inventory --graph -i inventory[student@workstation ansible]$ cp inventory inventory2       #额外创建一份清单名为inventory2# [student@workstation ansible]$ echo servere > inventory2   #inventory2内指定一个主机servere[student@workstation ansible]$ vim inventory2                servere[student@workstation ansible]$ mkdir invdir                   #创建清单存储目录，名称自定义[student@workstation ansible]$ mv inv* invdir/                #将所有清单移动至清单存储目录mv: cannot move 'invdir' to a subdirectory of itself, 'invdir/invdir'[student@workstation ansible]$ ls invdir/inventory  inventory2[student@workstation ansible]$ ansible-inventory --graph -i invdir/  #查看主机模式结构</code></pre><h2 id="2-3-管理Ansible配置文件"><a href="#2-3-管理Ansible配置文件" class="headerlink" title="2.3 管理Ansible配置文件"></a>2.3 管理Ansible配置文件</h2><h3 id="2-3-1-配置Ansible"><a href="#2-3-1-配置Ansible" class="headerlink" title="2.3.1 配置Ansible"></a>2.3.1 配置Ansible</h3><pre class=" language-language-bash"><code class="language-language-bash"># 安装Ansible软件后，自动生成配置文件   /etc/ansible/ansible.cfg  用于配置多个Ansible工具的行为   ~/.ansible-navigator.yml  用于更改ansible-navigator命令默认选项[student@workstation ansible]$ rpm -qc ansible-core/etc/ansible/ansible.cfg/etc/ansible/hosts[student@workstation ~]$ ls -a.         ansible                 .bash_history  .bashrc  Desktop    .grading  .lesshst  .npm      .ssh       Videos..        ansible-navigator.log   .bash_logout   .cache   Documents  .ipython  .local    Pictures  Templates  .viminfo.ansible  .ansible-navigator.yml  .bash_profile  .config  Downloads  .jupyter  Music     Public    .venv[student@workstation ~]$ ls -a ~/.ansible-navigator.yml/home/student/.ansible-navigator.yml</code></pre><h3 id="2-3-2-管理Ansible设置"><a href="#2-3-2-管理Ansible设置" class="headerlink" title="2.3.2 管理Ansible设置"></a>2.3.2 管理Ansible设置</h3><table><thead><tr><th align="left">指令</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">inventory</td><td align="left">指定清单文件的路径。</td></tr><tr><td align="left">remote_user</td><td align="left">指定Ansible用于连接受管主机的用户名。如果未指定，则使用当前用户的名称。(在由ansible-navigator 运行的基于容器的自动化执行环境中，始终为 root。)</td></tr><tr><td align="left">ask_pass</td><td align="left">指示是否提示输入SSH 密码。 (可以是 false，如果使用SSH公钥身份验证，则此为默认值。)</td></tr><tr><td align="left">become</td><td align="left">指定连接后是否在受管主机上自动切换用户(一般切换为root)。这也可以通过play来指定</td></tr><tr><td align="left">become_method</td><td align="left">指定如何切换用户(通常为 sudo，此为默认值，但也可选择su)</td></tr><tr><td align="left">become_user</td><td align="left">指定要在受管主机上切换到哪个用户(通常为 root，此为默认值)</td></tr><tr><td align="left">become_ask_pass</td><td align="left">指示是否提示输入become_method参数密码。默认为false</td></tr></tbody></table><h3 id="2-3-3-管理配置文件"><a href="#2-3-3-管理配置文件" class="headerlink" title="2.3.3 管理配置文件"></a>2.3.3 管理配置文件</h3><p>  1.自定义配置文件</p><pre class=" language-language-bash"><code class="language-language-bash"># 在工作目录中生成ansible的配置文件[student@workstation ~]$ cat /etc/ansible/ansible.cfg | grep ansible.cfg#               $ ansible-config init --disabled > ansible.cfg...[student@workstation ~]$ ansible-config init --disabled > /home/student/ansible/ansible.cfg[student@workstation ~]$ cd /home/student/ansible/[student@workstation ansible]$ lsansible.cfg  inventory [student@workstation ansible]$ ansible --versionansible [core 2.13.0]  config file = /home/student/ansible/ansible.cfg# Ansible的配置文件(ansible.cfg)由几部分组成，含有以键值对形式定义的设置、标题以方括号括起# 对于基本操作，使用以下两部分:1.[defaults]---用于设置Ansible操作的默认值2.[privilege_escalation]---用于配置Ansible如何在受管主机上执行特权升级    [student@workstation ansible]$ vim ansible.cfg[defaults]inventory=/home/student/ansible/inventory    #139行  工作目录清单位置remote_user=student                             #222行  远程用户可选root或普通用户 host_key_checking=false                         #318行  不进行公钥记录[privilege_escalation]                        #搜/become，n向下查找 或 输入:430become=true                                    #430行  开启特权功能，#become_ask_pass=False                        #433行  远程免特权密码，需要对端添加sudo免密#become_method=sudo                            #442行  远程功能启用sudo#become_user=root                            #445行  特权用户为root备注:剪切操作 dd+p# 验证配置文件是否书写正确[student@workstation ansible]$ ansible-inventory --graph   # 取消对清单的指定  #为servera~d主机设置sudo免密。[workstation][student@workstation ansible]$ for i in {a..d};do ssh root@server$i 'sed -i s/^%wheel.*$/"%wheel  ALL=(ALL) NOPASSWD: ALL"/ /etc/sudoers';done[student@workstation ansible]$ for i in {a..d};do ssh root@server$i 'grep ^%wheel /etc/sudoers';done# 测试远程部署[student@workstation ansible]$ ansible all -m pingserverd | SUCCESS => {    "ansible_facts": {        "discovered_interpreter_python": "/usr/bin/python3"    },    "changed": false,    "ping": "pong"}...</code></pre><p>  2.配置文件的优先级</p><pre class=" language-language-bash"><code class="language-language-bash">$ /etc/ansible/ansible.cfg           #默认路径$ ~/.ansible.cfg                       #家目录$ ~/ansible/ansible.cfg              #ansible为工作目录(练习和考试时使用)$ grep  ANSIBLE_CONFIG /etc/profile  #环境变量export  ANSIBLE_CONFIG=/opt/ansible.cfg   （此时/opt下需要有ansible.cfg配置文件）source /etc/profile   加载# 优先级 ：变量＞当前目录＞用户家目录＞/etc</code></pre><p>  3.指定远程用户</p><pre class=" language-language-bash"><code class="language-language-bash"># 其他指定远程用户及密码的方法# 方法1：ansible.cfgremote_user=rootinventory[all:vars]ansible_password=redhat# 方法二：inventory[all:vars]ansible_user=rootansible_password=redhat</code></pre><h3 id="2-3-4-管理自动化内容导航器"><a href="#2-3-4-管理自动化内容导航器" class="headerlink" title="2.3.4 管理自动化内容导航器"></a>2.3.4 管理自动化内容导航器</h3><p>  1.创建自动化内容导航器</p><pre class=" language-language-bash"><code class="language-language-bash">#可以为ansible-navigator创建配置文件以覆盖其配置设置的默认值，采用JSON(json)或YAML(yml或yam)格式#自动化内容导航器按以下顺序查找配置文件，并使用它找到的第一个文件:1.如果设置了ANSIBLE NAVIGATOR_CONFIG环境变量，则使用所指定位置处的配置文件2.当前Ansible项目目录中的ansible-navigator.yml文件3.~/.ansible-navigator.yml文件(主目录中)。请注意，其文件名开头有一个“点”#与Ansible配置文件一样，每个项目都可以有自己的自动化内容导航器设置文件 #创建导航器配置文件[student@workstation ~]$ rpm -ql ansible-navigator | grep temp[student@workstation ~]$ vim /usr/lib/python3.9/site-packages/ansible_navigator/package_data/settings-sample.template.yml</code></pre><p>  2.配置自动化内容导航器</p><pre class=" language-language-bash"><code class="language-language-bash">[student@workstation ~]$ vim ~/.ansible-navigator.yml---ansible-navigator:  execution-environment:    image: utility.lab.example.com/ee-supported-rhel8:latest    pull:      policy: missing    # 容器镜像下载策略 missing系统里有就不下载，否则下载$ vim ~/.ansible-navigator.yml   ---ansible-navigator:  execution-environment:    image: utility.lab.example.com/ee-supported-rhel8:latest    pull:      arguments:      - "--tls-verify=false"      policy: missing  playbook-artifact:    enable: false   #关闭运行playbook时生成日志 执行剧本所产生的日志，执行一次记录一次</code></pre><h3 id="2-3-5-ansible的远程连接"><a href="#2-3-5-ansible的远程连接" class="headerlink" title="2.3.5 ansible的远程连接"></a>2.3.5 ansible的远程连接</h3><pre class=" language-language-bash"><code class="language-language-bash">#anisble远程连接时的必要条件1.配置链接：如何选择远程的用户2.清单位置：相对路径、绝对路径、多清单等。3.链接设置: remote_user= ，~/.ansible-navigator.yml中playbook-artifact：4.ssh免密:  ssh-key-gen，ssh-copy-id5.升级特权: visudo，/etc/sudoers</code></pre><h1 id="3-编写和运行Playbook"><a href="#3-编写和运行Playbook" class="headerlink" title="3 编写和运行Playbook"></a>3 编写和运行Playbook</h1><p>  Play是针对清单中选定的主机运行的一组有序任务</p><p>  Playbook是一个文本文件，其中包含由一个或多个按特定顺序运行的play组成的列表</p><p>  临时命令可以作为一次性命令对一组目标主机运行一项简单的任务</p><p>  Playbook可以通过轻松重复的方式对一组目标主机执行多项复杂的任务</p><p><img src="/images/Playbook.png"></p><h2 id="3-1-Playbook-yaml语法"><a href="#3-1-Playbook-yaml语法" class="headerlink" title="3.1 Playbook-yaml语法"></a>3.1 Playbook-yaml语法</h2><p>  1.playbook是使用YAML语法编写的文本文件，格式为.yml</p><p>  2.严格缩进，空格</p><p>  3.YAML文件以—开头，…. 结束，可以省略</p><p>  4.使用”-“(减号加一个或多个空格)作为列表项</p><p>  5.#注释</p><pre class=" language-language-bash"><code class="language-language-bash">$ ansible-doc -l | grep yum$ ansible-doc yum                       #进入之后，搜索/EXAMPLE$ vim ~/ansible/web.yml---                                     #yaml语法，---开头- name: install httpd                   #play任务的描述：描述部分name字段是可选的选项  hosts: servera                        #主机模式：任务目标主机  tasks:                                #任务列表：下面通常为任务模块，有两格缩进  - name: Install Apache                #任务模块：注意和tasks有两格缩进，name是可选字段，模块描述    ansible.builtin.yum:                #模块名称：      name: httpd                       #模块选项1      state: latest                     #模块选项2</code></pre><h2 id="3-2-关闭运行playbook时的日志"><a href="#3-2-关闭运行playbook时的日志" class="headerlink" title="3.2 关闭运行playbook时的日志"></a>3.2 关闭运行playbook时的日志</h2><pre class=" language-language-bash"><code class="language-language-bash">[student@workstation ansible]$ vim ~/.ansible-navigator.yml---ansible-navigator:  execution-environment:    image: utility.lab.example.com/ee-supported-rhel8:latest    pull:      policy: missing  playbook-artifact:    enable: false  #关闭playbook时生成的日志</code></pre><h2 id="3-3-调整tab键缩进"><a href="#3-3-调整tab键缩进" class="headerlink" title="3.3 调整tab键缩进"></a>3.3 调整tab键缩进</h2><p><img src="/images/%E5%89%A7%E6%9C%AC%E7%BC%A9%E8%BF%9B.png"></p><p>整体缩进–方便对齐yaml语法文本缩进</p><pre class=" language-language-bash"><code class="language-language-bash">vim ~/.vimrcset tabstop=2    #将vim的tab键缩进调至两格set nu             #设置行号set autoindent   #回车时调整至上一行文本缩进  set cursorcolumn #设置竖坐标线 简写set cucset cursorline   #设置横坐标线 简写set cul:set all        #末行模式下set all 查看所有环境设置帮助#整体缩进 视图模式ctrl+v ， jjj(+G) ，I，(空格、空格)，esc#分解：1.光标放在需要调节的行上2.按ctrl+v，用方向键或G选定需要调节的列3.输入I进入插入模式4.空格空格，调节需要的缩进5.按esc同步所有列</code></pre><h2 id="3-4-查找用于任务的模块"><a href="#3-4-查找用于任务的模块" class="headerlink" title="3.4 查找用于任务的模块"></a>3.4 查找用于任务的模块</h2><p>  用Ansible进行部署任务时，可针对管理员任务需求，选择对应功能模块，通过以下方法可以查询模块帮助，以便编写临时命令及playbook</p><pre class=" language-language-bash"><code class="language-language-bash">-RHEL<=8[student@workstation ansible]$ ansible-doc -l[student@workstation ansible]$ ansible-doc -l | grep yumyum                                            Manages packages with the `y...yum_repository                                 Add or remove YUM repositori...# 查看某个模块的帮助[student@workstation ansible]$ ansible-doc yum-RHEL=9$ ansible-navigator collections$ ansible-navigator doc ansible.posix.firewalld$ ansible-navigator doc ansible.posix.firewalld -m stdout[student@workstation ansible]$ ansible-navigator collections -m stdout | grep firewalld</code></pre><h2 id="3-5-运行Playbook"><a href="#3-5-运行Playbook" class="headerlink" title="3.5 运行Playbook"></a>3.5 运行Playbook</h2><p>  运行前检查语法错误或执行空运行：</p><p>   1.检查语法错误 ansible-navigator run web.yml –syntax-check file.yml</p><p>   2.执行空运行 ansible-navigator run web.yml -C</p><p>  通常直接运行ansible-navigator run web.yml进入交互模式或添加-m stdout可将任务打印到标准输出</p><pre class=" language-language-bash"><code class="language-language-bash">#运行playbook$ ansible-navigator run web.yml    # 交互式$ ansible-navigator run web.yml -m stdout  # 非交互式</code></pre><h2 id="3-6-实施多个Play"><a href="#3-6-实施多个Play" class="headerlink" title="3.6 实施多个Play"></a>3.6 实施多个Play</h2><p>  1.Playbook是一个YAML文件，含有由一个或多个play组成的列表</p><p>  2.如果一个playbook中含有多个 play，每个play可以将其任务应用到单独的一组主机</p><p>  3.编排涉及对不同主机执行不同任务的复杂部署时会大有帮助</p><p>  4.可以这样编写playbook：对一组主机运行一个play，完成后再对另一组主机运行另一个pla</p><p>  5.Playbook中的各个play编写为playbook中的顶级列表项</p><h3 id="3-6-1-编写多个Play"><a href="#3-6-1-编写多个Play" class="headerlink" title="3.6.1 编写多个Play"></a>3.6.1 编写多个Play</h3><pre class=" language-language-bash"><code class="language-language-bash">[student@workstation ansible]$ vim install_yum.yml---- name: install yum repo  hosts: servera,serverb  - name: AppStream_REPO    ansible.builtin.yum_repository:      name: Red Hat Enterprise Linux 9 for x86_64 - AppStream (RPMs)      description: AppStream      file: rhel_AppStream      baseurl: http://content.example.com/rhel9.0/x86_64/dvd/AppStream      gpgcheck: no- name: install yum repo  hosts: serverc  tasks:  - name: BaseOS_REPO    ansible.builtin.yum_repository:      name: Red Hat Enterprise Linux 9 for x86_64 - BaseOS (RPMs)      description: BaseOS      file: rhel_BaseOS      baseurl: http://content.example.com/rhel9.0/x86_64/dvd/BaseOS      gpgcheck: no            #ansible-navigator collections,ansible-navigator doc  ansible.posix.firewalld -m stdout[student@workstation ansible]$ ansible-navigator collections -m stdout | grep firewalld[student@workstation ansible]$ ansible-navigator doc ansible.posix.firewalld -m stdout--syntax-check  [student@workstation ansible]$ ansible-navigator run install_yum.yml -m stdout --syntax-checkplaybook: /home/student/ansible/install_yum.yml-v -vv -vvv[student@workstation ansible]$ ansible-navigator run install_yum.yml -m stdout --syntax-check -v[student@workstation ansible]$ ansible-navigator run install_yum.yml -m stdout# 测试运行剧本后的结果[student@workstation ansible]$ ansible -m shell all -a 'yun -y install ftp'[student@workstation ansible]$ ansible all -m shell -a 'rpm -q ftp'# 用ansible-doc查询所有模块yum        安装软件service    管理服务shell模块  管理防火墙copy       拷贝，1有拷贝功能，2 可以将一段文本，复制到某个文件中，如文件不存在，则生成文件。uri        网站连接测试</code></pre><h3 id="3-6-2-选择模块"><a href="#3-6-2-选择模块" class="headerlink" title="3.6.2 选择模块"></a>3.6.2 选择模块</h3><table><thead><tr><th align="left">类别</th><th align="left">模块</th></tr></thead><tbody><tr><td align="left">文件</td><td align="left">ansible.builtin.copy: 将本地文件复制到受管主机 ansible.builtin.file: 设置文件的权限和其他属性 ansible.builtin.lineinfile: 确保特定行是否在文件中 ansible.posix.synchronize: 使用rsync 同步内容</td></tr><tr><td align="left">软件</td><td align="left">ansible.builtin.package: 使用操作系统自带的自动检测软件包管理器管理软件包。 ansible.builtin.dnf: 使用DNF软件包管理器管理软件包 ansible.builtin.apt: 使用APT 软件包管理器管理软件包 ansible.builtin.pip: 从PyPI管理Python 软件包。</td></tr><tr><td align="left">系统</td><td align="left">ansible.posix.firewalld: 使用firewalld 管理任意端口和服务 ansible.builtin.reboot: 重新启动计算机。 ansible.builtin.service: 管理服务 ansible.builtin.user: 添加、删除和管理用户帐户</td></tr><tr><td align="left">网络工具</td><td align="left">ansible.builtin.get_url: 通过HTTP、HTTPS或FTP 下载文件 ansible.builtin.uri: 与Web 服务交互</td></tr></tbody></table><h1 id="4-管理变量"><a href="#4-管理变量" class="headerlink" title="4 管理变量"></a>4 管理变量</h1><h2 id="4-1-变量概述"><a href="#4-1-变量概述" class="headerlink" title="4.1 变量概述"></a>4.1 变量概述</h2><h3 id="4-1-1-Ansible变量简介"><a href="#4-1-1-Ansible变量简介" class="headerlink" title="4.1.1 Ansible变量简介"></a>4.1.1 Ansible变量简介</h3><p>  Ansible支持利用变量来存储值，并在Ansible项目的所有文件中重复使用这些值</p><p>  可以简化项目的创建和维护，并减少错误的数量</p><pre class=" language-language-bash"><code class="language-language-bash"># key：vaule  # 变量可以重复的应用到项目中，简化管理，应用对象可以是：1.要创建的用户2.要安装的软件包3.要重新启动的服务4.要删除的文件5.互联网的文档等</code></pre><h3 id="4-1-2-命名变量"><a href="#4-1-2-命名变量" class="headerlink" title="4.1.2 命名变量"></a>4.1.2 命名变量</h3><p>  变量名称必须以字母开头，并且只能含有字母、数字和下划线</p><table><thead><tr><th align="left">无效变量名称</th><th align="left">有效变量名称</th></tr></thead><tbody><tr><td align="left">web server</td><td align="left">web_server</td></tr><tr><td align="left">remote.file</td><td align="left">remote_file</td></tr><tr><td align="left">1st file</td><td align="left">file_1，file1</td></tr><tr><td align="left">remoteserver $1</td><td align="left">remote_server_1,remote_server1</td></tr></tbody></table><h2 id="4-2-定义变量"><a href="#4-2-定义变量" class="headerlink" title="4.2 定义变量"></a>4.2 定义变量</h2><p>  可在Ansible项目中的多个位置定义变量</p><p>  如果在两个位置设置了同名变量，并且变量值不同，则通过优先级来决定要使用哪个值</p><p>  可以设置会影响一组主机的变量，也可以设置只会影响个别主机的变量</p><p>  有些变量是Ansible可以根据系统配置来设置的事实</p><p>  有些变量可在playbook中设置，然后影响该playbook中的一个play，或者仅影响该play中的一项任务</p><p>  可通过–extra-vars或-e选项并指定变量值</p><p>  Ansible的变量可以定义在不同位置，根据需要设定，其中也有优先度</p><table><thead><tr><th align="left">应用场景</th><th align="left">描述</th><th align="left">优先度</th></tr></thead><tbody><tr><td align="left">全局范围</td><td align="left">命令行执行临时命令时指定的变量 -e key=vaule</td><td align="left">高</td></tr><tr><td align="left">play范围</td><td align="left">playbook的Play部分或模块内部指定变量信息key: vaule</td><td align="left">中</td></tr><tr><td align="left">主机范围</td><td align="left">清单中主机或主机组指定变量（主机 优先 主机组）</td><td align="left">低</td></tr></tbody></table><h3 id="4-2-1-全局范围-命令行"><a href="#4-2-1-全局范围-命令行" class="headerlink" title="4.2.1 全局范围-命令行"></a>4.2.1 全局范围-命令行</h3><p>  清单变量可被playbook中设置的变量覆盖，这两种变量又可通过在命令行中传递参数到ansible-navigatorrun 命令来覆盖</p><p>  在命令行上设置的变量称为额外变量</p><pre class=" language-language-bash"><code class="language-language-bash">#命令行使用变量优先级最高[student@workstation ansible]$ ansible servera -m shell -a whoami -e ansible_user=root -e ansible_password=redhatservera | CHANGED | rc=0 >>root#在执行playbook时指定变量[student@workstation ansible]$ ansible-navigator run install_yum.yml -m stdout -e ansible_user=root -e ansible_password=redhat</code></pre><h3 id="4-2-2-PlAY范围-Playbook"><a href="#4-2-2-PlAY范围-Playbook" class="headerlink" title="4.2.2 PlAY范围-Playbook"></a>4.2.2 PlAY范围-Playbook</h3><p>  变量在Ansible Playbook中发挥着重要作用，可以简化playbook中变量数据的管理</p><p>  编写play时，可以定义自己的变量，然后在任务中调用这些值</p><p>  例如，可以使用值httpd来定义名为web_package的变量，任务可以使用ansible.builtin.dnf模块调用该变量来安装httpd软件包</p><pre class=" language-language-bash"><code class="language-language-bash">#playbook中可以在play位置使用vars直接定义变量，也可以通过vars_files加载包含变量的文件。#1.在playbook的play部分使用vars直接定义变量-vars[student@workstation ansible]$ vim web.yml---- name: PLAY1  hosts: servera  vars:                #vars关键字就是在playbook中设置自定义变量  - package: httpd             #key：vaule    键值间：冒号隔开，冒号后有一个空格  tasks:  - name: install {{ package }}    ansible.builtin.yum:      name: "{{ package }}" #使用变量时，变量两边有空格，并且用双大括号括起来，变量开头要加“”双引号，非变量开头不用加双引号      state: latest         [student@workstation ansible]$ ansible-navigator run web.yml -m stdout --syntax-checkplaybook: /home/student/ansible/web.yml[student@workstation ansible]$ ansible-navigator run web.yml -m stdout#2.生成变量文件-vars_files  [student@workstation ansible]$ vim /home/student/ansible/var.yml   ---package: httpd   #定义变量[student@workstation ansible]$ vim /home/student/ansible/httpd.yml---- name: PLAY2  hosts: serverb  vars_files:  - /home/student/ansible/var.yml    #vars_files 加载变量文件到剧本中  tasks:  - name: install {{ package }}    ansible.builtin.yum:      name: "{{ package }}"      state: latest      [student@workstation ansible]$ ansible-navigator run httpd.yml -m stdout --syntax-checkplaybook: /home/student/ansible/httpd.yml[student@workstation ansible]$ ansible-navigator run httpd.yml -m stdout</code></pre><h3 id="4-2-3-主机范围-清单中"><a href="#4-2-3-主机范围-清单中" class="headerlink" title="4.2.3 主机范围-清单中"></a>4.2.3 主机范围-清单中</h3><p>  直接应用于主机的清单变量分为两大类：</p><p>   1.主机变量：应用于特定主机</p><p>   2.组变量：应用于一个主机组或组主机组中的所有主机。</p><p>  主机变量优先于组变量，但playbook中定义的变量的优先级比这两者更高</p><p>  若要定义主机变量和组变量，一种方法是直接在清单文件中定义</p><pre class=" language-language-bash"><code class="language-language-bash">[student@workstation ansible]$ vim /home/student/ansible/inventory172.25.250.9   ansible_password=redhat     #给主机定义变量[test]172.25.250.10 [test:vars]               #主机组变量中vars是固定语法ansible_password=redhat   #给主机组定义变量   [prod]172.25.250.[11:12][balancers]172.25.250.13[all:vars]   #给所有主机和主机组组定义变量ansible_user=rootansible_password=redhat </code></pre><h3 id="4-2-4-目录填充主机和组变量"><a href="#4-2-4-目录填充主机和组变量" class="headerlink" title="4.2.4 目录填充主机和组变量"></a>4.2.4 目录填充主机和组变量</h3><p>  定义主机和主机组变量的首选做法是在清单文件或目录相同的工作目录中创建group_vars和host_vars两个目录，这两个目录分别包含用于定义组变量和主机变量文件</p><p>  建议在host_vars和group_vars目录定义清单变量，而不是直接在清单文件中定义它们</p><p><img src="/images/%E7%9B%AE%E5%BD%95%E5%A1%AB%E5%85%85%E4%B8%BB%E6%9C%BA%E5%92%8C%E7%BB%84%E5%8F%98%E9%87%8F.png"></p><h2 id="4-3-字典形式表示变量"><a href="#4-3-字典形式表示变量" class="headerlink" title="4.3 字典形式表示变量"></a>4.3 字典形式表示变量</h2><p>  除了将与同一元素相关的配置数据分配到多个变量外，管理员也可以使用字典</p><p>  字典是一个包含键值对的数据结构，其中的值也可以是字典</p><pre class=" language-language-bash"><code class="language-language-bash">vim vari.yml---users:  user1:    A_name: zhang    B_name: san    C_name: /home/zhangsan  user2:    A_name: li    B_name: si    C_name: /home/lisi </code></pre><h2 id="4-4-调用变量"><a href="#4-4-调用变量" class="headerlink" title="4.4 调用变量"></a>4.4 调用变量</h2><pre class=" language-language-bash"><code class="language-language-bash">#方法1：  users.user1.A_name  users.user2.B_name#方法2：  应用方法2：python字典  users['user1']['A_name']   # [student@bastion ansible]$ vim user.yml---- name: useradd  hosts: dev  vars_files:  - vari.yml  tasks:  - name: Add the user    ansible.builtin.user:      name: "{{ users.user1.A_name }}{{ users.user1.B_name }}"      home: "{{ users['user1']['C_name'] }}"</code></pre><h2 id="4-5-已注册变量捕获命令输出"><a href="#4-5-已注册变量捕获命令输出" class="headerlink" title="4.5 已注册变量捕获命令输出"></a>4.5 已注册变量捕获命令输出</h2><p>  register用来捕获命令输出或有关模块执行的其他信息，输出会保存至一个变量中</p><pre class=" language-language-bash"><code class="language-language-bash">$ vim register.yml---- name: install a packages  hosts: servera  tasks:  - name: install the latest version of Apache    ansible.builtin.yum:      name: httpd      state: latest    register: install_result  #register字段负责收集变量 install_result自定义变量名被收集变量名  - name:  message    ansible.builtin.debug:                  var: install_result     #debug模块var选项打印register获取install_result变量值#验证$ ansible-navigator run -m stdout register.yml </code></pre><h1 id="5-管理机密-vault"><a href="#5-管理机密-vault" class="headerlink" title="5 管理机密-vault"></a>5 管理机密-vault</h1><h2 id="5-1-介绍Ansible-vault"><a href="#5-1-介绍Ansible-vault" class="headerlink" title="5.1 介绍Ansible-vault"></a>5.1 介绍Ansible-vault</h2><p>  Ansible可能需要访问密码或API密钥等敏感数据，以配置受管主机</p><p>  通常信息会以纯文本形式存储在清单变量或其他Ansible文件中。但若如此，任何有权访问Ansible文件的用户或存储这些Ansible文件的版本控制系统都能够访问此敏感数据，这显然存在安全风险</p><p>  使用Ansible的Ansible Vault可以加密和解密任何由Ansible使用的数据文件</p><p>  可通过一个名为ansible-vault的命令行工具创建、编辑、加密、解密和查看文件</p><p>  Ansible Vault可以加密任何由Ansible使用的数据文件，这可能包括清单变量、playbook中含有的变量文件、在执行playbook时作为参数传递的变量文件或者Ansible角色中定义的变量</p><pre class=" language-language-bash"><code class="language-language-bash">[student@workstation ~]$ ansible-vault --helpusage: ansible-vault [-h] [--version] [-v] {create,decrypt,edit,view,encrypt,encrypt_string,rekey} ...encryption/decryption utility for Ansible data filespositional arguments:  {create,decrypt,edit,view,encrypt,encrypt_string,rekey}    create              Create new vault encrypted file     #创建密码文件    decrypt             Decrypt vault encrypted file        #解密现有密码文件    edit                Edit vault encrypted file           #编辑现有密码文件    view                View vault encrypted file           #查看加密文件    encrypt             Encrypt YAML file                   #加密现有文件    encrypt_string      Encrypt a string    rekey               Re-key a vault encrypted file       #更改加密文件的密码</code></pre><h2 id="5-2-创建与查看加密文件"><a href="#5-2-创建与查看加密文件" class="headerlink" title="5.2 创建与查看加密文件"></a>5.2 创建与查看加密文件</h2><pre class=" language-language-bash"><code class="language-language-bash">#创建加密文件-create[student@workstation ansible]$ ansible-vault create sec1.txt   #默认sec1.txt不存在，通过该命令生成New Vault password: redhatConfirm New Vault password: redhat[student@workstation ansible]$ cat sec1.txt#查看加密文件-view[student@workstation ansible]$ ansible-vault view sec1.txtVault password: redhat---This is a encrypted file!</code></pre><h2 id="5-3-编辑现有的加密文件"><a href="#5-3-编辑现有的加密文件" class="headerlink" title="5.3 编辑现有的加密文件"></a>5.3 编辑现有的加密文件</h2><pre class=" language-language-bash"><code class="language-language-bash">#编辑加密文件-edit[student@workstation ansible]$ pwd/home/student/ansible[student@workstation ansible]$ ansible-vault edit sec1.txtVault password:[student@workstation ansible]$ ansible-vault view sec1.txtVault password:---This is a encrypted file!password: redhat321</code></pre><h2 id="5-4-加密现有的文件"><a href="#5-4-加密现有的文件" class="headerlink" title="5.4 加密现有的文件"></a>5.4 加密现有的文件</h2><pre class=" language-language-bash"><code class="language-language-bash">[student@workstation ansible]$ echo China > sec2.txt   #创建文件[student@workstation ansible]$ cat sec2.txt       China#加密现有文件-encrypt[student@workstation ansible]$ ansible-vault encrypt sec2.txt   New Vault password: redhatConfirm New Vault password: redhatEncryption successful[student@workstation ansible]$ cat sec2.txt[student@workstation ansible]$ ansible-vault view sec2.txtVault password:China</code></pre><h2 id="5-5-解密现有的文件"><a href="#5-5-解密现有的文件" class="headerlink" title="5.5 解密现有的文件"></a>5.5 解密现有的文件</h2><pre class=" language-language-bash"><code class="language-language-bash">#解密现有的文件-decrypt[student@workstation ansible]$ pwd/home/student/ansible[student@workstation ansible]$ ansible-vault decrypt sec2.txtVault password: redhatDecryption successful[student@workstation ansible]$ cat sec2.txtChina</code></pre><h2 id="5-6-更改加密文件的密码"><a href="#5-6-更改加密文件的密码" class="headerlink" title="5.6 更改加密文件的密码"></a>5.6 更改加密文件的密码</h2><pre class=" language-language-bash"><code class="language-language-bash">#更改加密文件的密码-rekey[student@workstation ansible]$ pwd/home/student/ansible[student@workstation ansible]$ ansible-vault rekey sec1.txtVault password: redhat                  #旧密码 redhatNew Vault password: redhat321           #新密码 redhat321                   Confirm New Vault password: redhat321   #重复新密码 redhat321Rekey successful[student@workstation ansible]$ ansible-vault view sec1.txtVault password: redhat321---This is a encrypted file!password: redhat321</code></pre><h2 id="5-7-使用密码文件"><a href="#5-7-使用密码文件" class="headerlink" title="5.7 使用密码文件"></a>5.7 使用密码文件</h2><pre class=" language-language-bash"><code class="language-language-bash">#查看帮助[student@workstation ansible]$ pwd/home/student/ansible[student@workstation ansible]$ ansible-vault view sec1.txt --help---省略---  --vault-id VAULT_IDS  the vault identity to use  --ask-vault-password, --ask-vault-pass  ask for vault password  --vault-password-file VAULT_PASSWORD_FILES, --vault-pass-file VAULT_PASSWORD_FILES                        vault password file---省略---[student@workstation ansible]$ echo redhat321 > secret.txt  #创建密码文件[student@workstation ansible]$ cat secret.txtredhat321[student@workstation ansible]$ ansible-vault view sec1.txt --vault-id=secret.txt   #通过变量文件指定密码---This is a encrypted file!password: redhat321                     </code></pre><h2 id="5-8-密码文件记录到ansible-cfg配置文件"><a href="#5-8-密码文件记录到ansible-cfg配置文件" class="headerlink" title="5.8 密码文件记录到ansible.cfg配置文件"></a>5.8 密码文件记录到ansible.cfg配置文件</h2><p>  密码文件记录在ansible.cfg配置文件中的好处是，当执行一个使用了加密文件的playbook时，不必手工指定加密文件密码</p><pre class=" language-language-bash"><code class="language-language-bash">[student@workstation ansible]$ vim ansible.cfg          #第一次填写vault路径时，搜索`vault`关键字找该选项vault_password_file=/home/student/ansible/secret.txt    #配置文件中指定密码文件位置 [student@workstation ansible]$ ansible-vault view sec1.txt    #自动调用配置文件中密码文件---This is a encrypted file!password: redhat321#密码文件记录在配置文件中后1.加密现有文件时会直接引用[student@workstation ansible]$ ansible-vault encrypt sec2.txtEncryption successful2.更改密码时会直接覆盖[student@workstation ansible]$ ansible-vault rekey sec2.txtRekey successful3.更改密码需使用--ask-vault-password参数指定[student@workstation ansible]$ ansible-vault rekey sec2.txt --ask-vault-passwordVault password: redhatNew Vault password: redhatConfirm New Vault password: redhatRekey successful</code></pre><h1 id="6-管理事实facts"><a href="#6-管理事实facts" class="headerlink" title="6 管理事实facts"></a>6 管理事实facts</h1><p>  Ansible事实是Ansible在受管主机上自动检测到的变量</p><p>  事实中含有与主机相关的信息，可以像play中的常规变量、条件、循环或依赖于从受管主机收集的值的任何其他语句那样使用</p><p>  为受管主机收集的一些事实可能包括：主机名称、内核版本、网络接口名称、网络接口IP地址、操作系统版本、CPU数量提供的或可用的内存、存储设备的大小和可用空间</p><p>  借助事实可以方便地检索受管主机的状态，并根据该状态确定要执行的操作。例如:</p><p>   1.根据含有受管主机当前内核版本的事实运行条件任务，以此来重新启动服务器</p><p>   2.根据通过事实报告的可用内存来定义MySQL配置文件</p><p>   3.根据事实的值设置配置文件中使用的IPv4地址</p><p>  每个play在执行第一个任务之前会先自动运行setup模块来收集事实，这在Ansible2.3中报告为GatheringFacts任务或者更早版本中报告为setup。默认情况下，无需具有在play中运行setup的任务，通常会自动运行</p><p>  查看受管主机收集的事实的方式是：</p><p>   1.使用ad-hoc命令运行setup模块</p><p>   2.使用playbook运行debug模块并提取变量var: ansible facts</p><h2 id="6-1-收集事实"><a href="#6-1-收集事实" class="headerlink" title="6.1 收集事实"></a>6.1 收集事实</h2><pre class=" language-language-bash"><code class="language-language-bash"># 收集事实常用两种手段常用是临时命令ad-hoc及Playbook，事实以josn语法格式列出。收集时要找ansible_开头的事实名称# 如果变量值为散列/字典，则可以用两种语法来检索该值:ansible_default_ipv4.hostnameansible_default_ipv4.[ 'hostname' ]</code></pre><h3 id="6-1-1-临时命令-ad-hoc"><a href="#6-1-1-临时命令-ad-hoc" class="headerlink" title="6.1.1 临时命令 ad-hoc"></a>6.1.1 临时命令 ad-hoc</h3><pre class=" language-language-bash"><code class="language-language-bash">1.使用ad-hoc方式收集事实[student@workstation ansible]$ ansible -m setup all  #收集清单中所有主机的事实[student@workstation ansible]$ ansible -m setup servera -a filter=ansible_nodename  #过滤[student@workstation ansible]$ ansible -m setup serverc -a filter=*ipv4*    #过滤&模糊匹配[student@workstation ansible]$ ansible -m setup serverc > fact.txt   #将事实记录到fact.txt文件中，方便查找</code></pre><h3 id="6-1-2-PLAYBOOK-收集事实"><a href="#6-1-2-PLAYBOOK-收集事实" class="headerlink" title="6.1.2 PLAYBOOK 收集事实"></a>6.1.2 PLAYBOOK 收集事实</h3><pre class=" language-language-bash"><code class="language-language-bash">[student@workstation ansible]$ vim debug.yml---- name: debug  hosts: servera  tasks:  - ansible.builtin.debug:  #简化后可将ansible_facts去掉，二级变量开头，要保留ansible_,如：ansible_default_ipv4.address      msg: servera ip address "{{ ansible_default_ipv4.address }}"      - ansible.builtin.debug:      var: ansible_hostname [student@workstation ansible]$ ansible-navigator run debug.yml -m stdout --syntax-checkplaybook: /home/student/ansible/debug.yml[student@workstation ansible]$ ansible-navigator run debug.yml -m stdout</code></pre><h3 id="6-1-3-关闭事实"><a href="#6-1-3-关闭事实" class="headerlink" title="6.1.3 关闭事实"></a>6.1.3 关闭事实</h3><pre class=" language-language-bash"><code class="language-language-bash">[student@workstation ansible]$ vim debug.yml---- name: debug message  hosts: dev  gather_facts: on/off  true/false   # 是否关闭事实  tasks:  - debug:      msg: "{{ ansible_facts.default_ipv4.address }}"      [greg@bastion ansible]$ ansible-playbook debug.yml#如果playbook内容和事实收集没有关系，关闭可以大量减少playbook执行时间</code></pre><h2 id="6-2-魔法变量"><a href="#6-2-魔法变量" class="headerlink" title="6.2 魔法变量"></a>6.2 魔法变量</h2><p>  实时变量通常收集的是受管节点的信息，而魔法变量收集的是本机的变量值</p><pre class=" language-language-bash"><code class="language-language-bash">#inventory_hostname  列出组在清单中的主机名[student@workstation ansible]$ ansible web -m debug -a var=inventory_hostname#group_names     列出当前主机归属于哪个组[student@workstation ansible]$ ansible serverd -m debug -a var=group_names#groups    列出清单中的所有主机名称。以及所在组[student@workstation ansible]$ ansible all -m debug -a var=groups#hostvars  列出系统中所有魔法变量及所有事实变量[student@workstation ansible]$ ansible all -m debug -a var=hostvars$ https://docs.ansible.com/ansible/latest/reference_appendices/special_variables.html  #官网文档# dosc.ansible.com中搜索magic或facts</code></pre><h3 id="6-2-1-临时命令收集魔法变量值-ad-hoc"><a href="#6-2-1-临时命令收集魔法变量值-ad-hoc" class="headerlink" title="6.2.1 临时命令收集魔法变量值 ad-hoc"></a>6.2.1 临时命令收集魔法变量值 ad-hoc</h3><pre class=" language-language-bash"><code class="language-language-bash">ansible  servera -m debug -a var=inventory_hostnameansible  servera -m debug -a var=groupsansible  all -m debug -a var=group_namesansible  all -m debug -a var=hostvarsansible  servera -m debug -a var=groups.all</code></pre><h3 id="6-2-2-PLAYBOOK收集事实-魔法变量"><a href="#6-2-2-PLAYBOOK收集事实-魔法变量" class="headerlink" title="6.2.2 PLAYBOOK收集事实+魔法变量"></a>6.2.2 PLAYBOOK收集事实+魔法变量</h3><pre class=" language-language-bash"><code class="language-language-bash">[student@workstation ansible]$ vim hoc_debug.yml---- name: debug  hosts: servera  gather_facts: on  tasks:  - ansible.builtin.debug:     var: hostvars[student@workstation ansible]$ ansible-navigator run hoc_debug.yml -m stdout --syntax-checkplaybook: /home/student/ansible/hoc_debug.yml[student@workstation ansible]$ ansible-navigator run hoc_debug.yml -m stdout#重定向到文件中的意义是方便在hoc_fact.txt文件中搜索需要的值[student@workstation ansible]$ ansible-navigator run hoc_debug.yml -m stdout > hoc_fact.txt   </code></pre><h3 id="6-2-3-魔法变量hostvars"><a href="#6-2-3-魔法变量hostvars" class="headerlink" title="6.2.3 魔法变量hostvars"></a>6.2.3 魔法变量hostvars</h3><p>  临时命令与playbook收集hostvars变量值是不同的</p><p>  临时命令不会执行setup模块，所以收集不到事实，PLAYBOOK方法则可以收集到事实和魔法变量</p><pre class=" language-language-bash"><code class="language-language-bash">[student@workstation ansible]$ ansible all -m setup > all_host.txt</code></pre><h1 id="7-实施任务控制"><a href="#7-实施任务控制" class="headerlink" title="7 实施任务控制"></a>7 实施任务控制</h1><h2 id="7-1-利用循环迭代任务"><a href="#7-1-利用循环迭代任务" class="headerlink" title="7.1 利用循环迭代任务"></a>7.1 利用循环迭代任务</h2><p>  利用循环，管理员无需编写多个使用同一模块的任务</p><p>  Ansible支持使用loop关键字对一组项目迭代任务，可以配置循环以利用列表中各个项目、列表中各个文件的内容、生成的数字序列或更为复杂的结构来重复任务</p><pre class=" language-language-bash"><code class="language-language-bash">#loop字段通常在同一缩进的模块下面，对该模块生效，通过item来加载loop循环中的值或变量#帮助：搜索loop可以搜到相应语法$ https://docs.ansible.com/ansible/latest/user_guide/playbooks_loops.html</code></pre><h3 id="7-1-1-简单循环"><a href="#7-1-1-简单循环" class="headerlink" title="7.1.1 简单循环"></a>7.1.1 简单循环</h3><p>  简单循环对一组项目迭代任务</p><p>  loop 关键字添加到任务中，将应对其迭代任务的项目列表取为值</p><p>  循环变量item保存每个迭代过程中使用的值</p><pre class=" language-language-bash"><code class="language-language-bash">[student@workstation ansible]$ vim loop.yml---- name: service  hosts: servera  tasks:  - name: Start service nfs-server&chronyd    ansible.builtin.service:      name: "{{ item }}"      state: started    loop:    - nfs-server    - chronyd    [student@workstation ansible]$ ansible-navigator run loop.yml -m stdout --syntax-checkplaybook: /home/student/ansible/loop.yml[student@workstation ansible]$ ansible-navigator run loop.yml -m stdout</code></pre><h3 id="7-1-2-循环使用变量"><a href="#7-1-2-循环使用变量" class="headerlink" title="7.1.2 循环使用变量"></a>7.1.2 循环使用变量</h3><p>  在playbook中通过vars或vars files方式加载变量servers中包含循环列表，模块通过loop字段加载servers变量列表中的值</p><pre class=" language-language-bash"><code class="language-language-bash"># vars字段[student@workstation ansible]$ vim loop.yml---- name: service loop  hosts: servera  vars:    servers:    - nfs-server    - chronyd  tasks:  - name: Start service    ansible.builtin.service:      name: "{{ item }}"      state: stopped    loop: "{{ servers }}"   # vars字段也可以替换为vars_files，将变量保存至文件中，加载到Playbook  [student@workstation ansible]$ mkdir /home/student/ansible/vars/[student@workstation ansible]$ vim /home/student/ansible/vars/var.ymlservers:- nfs-server- chronyd[student@workstation ansible]$ vim loop.yml---- name: service loop  hosts: servera  vars_files:    - /home/student/ansible/vars/var.yml  tasks:  - name: Start service    ansible.builtin.service:      name: "{{ item }}"      state: stopped    loop: "{{ servers }}"[student@workstation ansible]$ ansible-navigator run loop.yml -m stdout --syntax-checkplaybook: /home/student/ansible/loop.yml[student@workstation ansible]$ ansible-navigator run loop.yml -m stdout</code></pre><h3 id="7-1-3-循环字典列表"><a href="#7-1-3-循环字典列表" class="headerlink" title="7.1.3 循环字典列表"></a>7.1.3 循环字典列表</h3><p>  1.循环字典列表保存在loop字段中</p><pre class=" language-language-bash"><code class="language-language-bash">[student@workstation ansible]$ vim loop.yml---- name: service loop  hosts: servera  tasks:  - name: Start service    ansible.builtin.user:      name: "{{ item.name }}"      comment: "{{ item.comment }}"      state: present    loop:      - name: jane        comment: tom      - name: joe        comment: harry        [student@workstation ansible]$ ansible-navigator run loop.yml -m stdout --syntax-checkplaybook: /home/student/ansible/loop.yml[student@workstation ansible]$ ansible-navigator run loop.yml -m stdout      </code></pre><p>  2.循环字典列表保存在play的vars中</p><pre class=" language-language-bash"><code class="language-language-bash">[student@workstation ansible]$ vim loop.yml---- name: service loop  hosts: servera  vars:    users:    - name: jane      comment: tom    - name: joe      comment: harry  tasks:  - name: Start service    ansible.builtin.user:      name: "{{ item.name }}"      comment: "{{ item.comment }}"      state: present    loop: "{{ users }}"[student@workstation ansible]$ ansible-navigator run loop.yml -m stdout --syntax-checkplaybook: /home/student/ansible/loop.yml[student@workstation ansible]$ ansible-navigator run loop.yml -m stdout</code></pre><p>  3.循环字典列表保存在play的vars_files中</p><pre class=" language-language-bash"><code class="language-language-bash">[student@workstation ansible]$ vim /home/student/ansible/vars/var.ymlservers:users:- name: jane  comment: tom- name: joe  comment: harry[student@workstation ansible]$ vim loop.yml---- name: service loop  hosts: servera  vars_files:  - /home/student/ansible/vars/var.yml  tasks:  - name: Start service    ansible.builtin.user:      name: "{{ item.name }}"      state: present      comment: "{{ item.comment }}"    loop: "{{ users }}" [student@workstation ansible]$ ansible-navigator run loop.yml -m stdout --syntax-checkplaybook: /home/student/ansible/loop.yml[student@workstation ansible]$ ansible-navigator run loop.yml -m stdout</code></pre><h2 id="7-2-有条件地运行任务"><a href="#7-2-有条件地运行任务" class="headerlink" title="7.2 有条件地运行任务"></a>7.2 有条件地运行任务</h2><p><img src="/images/%E6%9C%89%E6%9D%A1%E4%BB%B6%E8%BF%90%E8%A1%8C%E4%BB%BB%E5%8A%A1.png"></p><p>使用conditionals在符合特定条件时运行任务或play</p><p>  条件句可帮助区分不同的受管主机，并根据所符合的条件来分配功能角色</p><p>  Playbook变量、注册的变量和Ansible事实都可通过条件句来进行测试，可以使用比较字符串、数字数据和布尔值的运算符</p><p>  1.通常主机模式为多个节点时，可以让符合when条件的主机执行模块任务。符合条件则为真，则执行模块。否则为假，跳过模块任务</p><p>   when判断对象是模块，和模块在同一下列层次</p><p>   when判断当前模块是否执行，而不是它下面模块是否执行</p><p>   When中引用变量、facts，不需加大括号</p><p>   用于测试条件中相等的==运算符不可与变量赋值的=运算符混淆</p><p>  2.一个when语句可用于评估多个值。 可以使用and和or关键字组合条件，或使用括号分组条件</p><pre class=" language-language-bash"><code class="language-language-bash">1.or是或的关系，任意一个条件为真即可when: ansible_distribution == "RedHat" or ansible_distribution == "Fedora"2.and是与的关系，多个条件需同时为真when: ansible_distribution version == "7.5" and ansible_kernel == "3.10.0-327.el7.x86_64"3. When语句多条件的另外方式:when:   -ansible_distribution_version == "7.5"   -ansible_kernel == "3.10.0-327.el7.x86_64"4.使用括号分组条件来表达更复杂的条件语句:when:  >   ( ansible_distribution == "RedHat" and     ansible_distribution_major_version == "7")   or    ( ansible_distribution == "Fedora" and       ansible_distribution_major_version == "28")  </code></pre><h3 id="7-2-1-简单的有条件任务"><a href="#7-2-1-简单的有条件任务" class="headerlink" title="7.2.1 简单的有条件任务"></a>7.2.1 简单的有条件任务</h3><pre class=" language-language-bash"><code class="language-language-bash">[student@workstation ansible]$ vim when.yml---- name: repository  hosts: all  tasks:  - name: install the latest version of Apache    ansible.builtin.yum:      name: httpd      state: latest    when: ansible_default_ipv4.address == '172.25.250.10'    [student@workstation ansible]$ ansible-navigator run when.yml -m stdout --syntax-checkplaybook: /home/student/ansible/when.yml[student@workstation ansible]$ ansible-navigator run when.yml -m stdout#如果使用inventory_hostname这个魔法变量，要参考清单中的主机名称。node1位置，单双引号都可以识别为字符串</code></pre><h3 id="7-2-2-组合循环和有条件任务"><a href="#7-2-2-组合循环和有条件任务" class="headerlink" title="7.2.2 组合循环和有条件任务"></a>7.2.2 组合循环和有条件任务</h3><pre class=" language-language-bash"><code class="language-language-bash">[student@workstation ansible]$ vim when_loop.yml---- name: 安装软件包  hosts: all  tasks:  - name: install the latest version of Apache    ansible.builtin.yum:      name: "{{ item }}"      state: latest    loop:    - php    - mariadb    when: ansible_hostname == 'servera' or ansible_hostname == 'serverc'    [student@workstation ansible]$ ansible-navigator run when_loop.yml -m stdout --syntax-checkplaybook: /home/student/ansible/when_loop.yml[student@workstation ansible]$ ansible-navigator run when_loop.yml -m stdout</code></pre><h3 id="7-2-3-常用when条件语句"><a href="#7-2-3-常用when条件语句" class="headerlink" title="7.2.3 常用when条件语句"></a>7.2.3 常用when条件语句</h3><pre class=" language-language-bash"><code class="language-language-bash">[student@workstation ansible]$ ansible all -m debug -a var=groups[student@workstation ansible]$ ansible all -m debug -a var=group_names#变量值 == '字符串'inventory_hostname == 'node1'inventory_hostname != 'node1''"52:54:00:00:fa:0b" in ansible_default_ipv4.macaddress'ansible_default_ipv4.address == '172.25.250.11'#变量值存在  in  第二个变量inventory_hostname in groups.dev    #可以匹配组'"dev" in group_names'              #可以匹配[student@workstation ansible]$ vim when_loop3.yml---- name: repository  hosts: all  tasks:  - name: install the latest version of Apache    ansible.builtin.yum:      name: httpd      state: latest    when: '"db" in group_names'[student@workstation ansible]$ ansible-navigator run when_loop3.yml -m stdout --syntax-checkplaybook: /home/student/ansible/when_loop3.yml[student@workstation ansible]$ ansible-navigator run when_loop3.yml -m stdout#default变量查询方法#搜索引擎中搜索：filters --- Using filters to --- 搜索admin---default('admin', true) </code></pre><h1 id="8-实施处理程序"><a href="#8-实施处理程序" class="headerlink" title="8 实施处理程序"></a>8 实施处理程序</h1><p>  handlers是处理程序的一种实现，当对一个Playbook模块改动时，通过监控发现改动，并自动执行后续处理动作</p><p>  比如一种场景，当修改了服务配置文件时，需要对服务进行重启，可以在配置文件模块位置用notify监视是否修改后，用handlers中的处理程序如:service模块对其重启服务，达到修改文件便自动重启服务的效果</p><h2 id="8-1-Ansible处理程序"><a href="#8-1-Ansible处理程序" class="headerlink" title="8.1 Ansible处理程序"></a>8.1 Ansible处理程序</h2><pre class=" language-language-bash"><code class="language-language-bash">$ vim handlers.yml---- name:  hosts: servera  tasks:  - name: install the latest version of Apache    ansible.builtin.yum:      name: httpd      state: latest  - name: Copy using inline content    ansible.builtin.copy:      content: 'heihei'      dest: /var/www/html/index.html    notify: restart            #notify字段冒号后的名称restart，指向handlers中的描述为restart的模块  - name: Start firewalld    ansible.builtin.service:      name: firewalld      state: started  handlers:                            #handlers是缩进和tasks对齐  - name: restart    ansible.builtin.service:      name: httpd      state: restarted</code></pre><h2 id="8-2-执行中对错误的处理"><a href="#8-2-执行中对错误的处理" class="headerlink" title="8.2 执行中对错误的处理"></a>8.2 执行中对错误的处理</h2><p>  Ansible评估各任务的返回代码，从而确定任务是成功还是失败</p><p>  通常而言，当任务失败时，ansible将立即在该主机上终止play的其余部分并且跳过所有后续任务</p><p>  有些时候，可能希望即使在任务失败时也继续执行play</p><h3 id="8-2-1-ignore-errors"><a href="#8-2-1-ignore-errors" class="headerlink" title="8.2.1 ignore_errors"></a>8.2.1 ignore_errors</h3><p>  忽略任务失败 ignore_errors</p><pre class=" language-language-bash"><code class="language-language-bash">[student@workstation ansible]$ vim ignore_errors.yml---- name: test error  hosts: servera  tasks:  - name:  touch directory    ansible.builtin.shell: mkdir /a/b    ignore_errors: yes  - name: Add the user    ansible.builtin.user:      name: johnd      [student@workstation ansible]$ ansible-navigator run ignore_errors.yml -m stdout --syntax-check[student@workstation ansible]$ ansible-navigator run ignore_errors.yml -m stdout#也可以在任务失败时强制执行处理程序,详见教材---- name: test error  force_handlers: yes  tasks:  - xxxx    handlers:  - name: haha    ansible.builtin.service:    xxx    xxx</code></pre><h2 id="8-3-Ansible块和错误的处理"><a href="#8-3-Ansible块和错误的处理" class="headerlink" title="8.3 Ansible块和错误的处理"></a>8.3 Ansible块和错误的处理</h2><h3 id="8-3-1-block、rescue、always"><a href="#8-3-1-block、rescue、always" class="headerlink" title="8.3.1 block、rescue、always"></a>8.3.1 block、rescue、always</h3><p>  block：定义要运行的主要任务</p><p>  rescue：定义要在block子句中定义的任务失败时运行的任务</p><p>  always：定义始终都在独立运行的任务</p><pre class=" language-language-bash"><code class="language-language-bash">---- name: block  hosts: all  tasks:  - block:    - name:      ansible.builtin.yum:        name: http        state: present    rescue:    - name:      ansible.builtin.yum:        name: httpd        state: present    when: inventory_hostname == 'serverb'    always:    - name: Start service httpd, if not started      ansible.builtin.service:        name: httpd        state: started# Ansible官方文档：搜索：rescue https://docs.ansible.com/ansible/latest/user_guide/playbooks_blocks.html        </code></pre><h3 id="8-3-2-block的使用"><a href="#8-3-2-block的使用" class="headerlink" title="8.3.2 block的使用"></a>8.3.2 block的使用</h3><pre class=" language-language-bash"><code class="language-language-bash">#未使用block时：---- name: test error  hosts: all  tasks:  - name:  touch file    ansible.builtin.shell: mkdir  -p /a/b    when: inventory_hostname == "servera"  - name: Add the user    ansible.builtin.user:      name: johnd    when: inventory_hostname == "servera"#使用block时---- name: test error  hosts: all  tasks:  - block:    - name:  touch file      ansible.builtin.shell: mkdir  -p /a/b    - name: Add the user      ansible.builtin.user:        name: johnd    when: inventory_hostname == "servera"</code></pre><h1 id="9-文件部署到受管主机"><a href="#9-文件部署到受管主机" class="headerlink" title="9 文件部署到受管主机"></a>9 文件部署到受管主机</h1><h2 id="9-1-将文件复制到主机"><a href="#9-1-将文件复制到主机" class="headerlink" title="9.1 将文件复制到主机"></a>9.1 将文件复制到主机</h2><h3 id="9-1-1-文件模块"><a href="#9-1-1-文件模块" class="headerlink" title="9.1.1 文件模块"></a>9.1.1 文件模块</h3><p>  1.在被管机上创建文件和目录</p><p>  2.复制文件(或内容)到被管机 control –&gt; node1</p><p>  3.从被管机复制文件到管理机 node1 –&gt; control</p><p>  4.修改文件内容</p><p>  5.查看文件状态</p><p>  6.修改文件属性(所有者、权限、selinux)</p><p>  7.文件同步</p><p>ansible.builtin-描述文件模块：</p><table><thead><tr><th align="left">模块名</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">blockinfile</td><td align="left">插入、更新 、删除，自定义标记的多行文本块</td></tr><tr><td align="left">file</td><td align="left">设置权限、所有者、SElinux上下文及常规文件、符号连接、硬链接等</td></tr><tr><td align="left">copy</td><td align="left">远程copy，类似file，可以设置文件属性、SElinux上下文</td></tr><tr><td align="left">fetch</td><td align="left">和copy类似，相反工作方式，从远端拷贝到控制节点</td></tr><tr><td align="left">lineinfile</td><td align="left">改文件某一行时使用</td></tr><tr><td align="left">stat</td><td align="left">检测文件状态，类似linux中stat命令</td></tr><tr><td align="left">synchronize</td><td align="left">围绕rsync一个打包程序</td></tr></tbody></table><pre class=" language-language-bash"><code class="language-language-bash">#查找模块可使用命令$ ansible-doc -l | grep file$ ansible-navigator collections -m stdout | grep file$$ ansible-doc file#注意：很多模块已经不在ansible.builtin集合中了，所以需要通过ansible-navigator collections命令搜索。</code></pre><p>1.ansible.builtin.file</p><pre class=" language-language-bash"><code class="language-language-bash">- name: Change file ownership, group and permissions  ansible.builtin.file:    path: /var/www/html/index.html    owner: apache    group: apache    mode: '0644'    state: touch    setype: default_t      #(Choices: absent, directory, file, hard, link, touch)[Default: file]#file：修改文件内容，无该文件则不修改#touch：创建文件#touch，mkdir，cp，mv，rm，ln，chmod，chown，chcon</code></pre><p>2.ansible.builtin.copy</p><pre class=" language-language-bash"><code class="language-language-bash">#复制本机文件到受管节点- name: Copy file with owner and permissions  ansible.builtin.copy:    src: /srv/myfiles/foo.conf    dest: /var/www/html/index.html    owner: foo    group: foo    mode: '0644'    setype:  httpd_sys_content_t    #复制文本内容testweb至目标文件，文件不存在则创建  - name: Copy using inline content  ansible.builtin.copy:    content: "testweb"    dest: /var/www/html/index.html</code></pre><p>3.ansible.builtin.lineinfile</p><pre class=" language-language-bash"><code class="language-language-bash">[student@workstation ansible]$ ansible-doc -l | grep linelineinfile                                     Manage lines in text files[student@workstation ansible]$ ansible-doc lineinfile[student@workstation ansible]$ vim lineinfile.yml---- name: lineinfile  hosts: all  tasks:  - name: Ensure SELinux is set to enforcing mode    ansible.builtin.lineinfile:      path: /etc/selinux/config      regexp: '^SELINUX='      line: SELINUX=enforcing[student@workstation ansible]$ ansible-navigator run lineinfile.yml -m stdout --syntax-checkplaybook: /home/student/ansible/lineinfile.yml[student@workstation ansible]$ ansible-navigator run lineinfile.yml -m stdout#验证:[student@workstation ansible]$ ansible servera -m shell -a 'cat /etc/selinux/config'#docs.ansible.com 搜索引擎中搜索：filters --- Using filters to --- 搜索admin---default('admin', true) </code></pre><p>4.ansible.builtin.blockinfile</p><pre class=" language-language-bash"><code class="language-language-bash">- name: Insert/Update HTML surrounded by custom markers after <body> line  ansible.builtin.blockinfile:    path: /opt/index.html    marker: "<!-- {mark} ANSIBLE MANAGED BLOCK -->"    insertafter: "<body>"    block: |      <h1>Welcome to {{ ansible_hostname }}</h1>      <p>Last updated on {{ ansible_date_time.iso8601 }}</p></code></pre><p>5.ansible.builtin.template</p><pre class=" language-language-bash"><code class="language-language-bash">- name: Template a file to /etc/files.conf  ansible.builtin.template:    src: /mytemplates/foo.j2    dest: /etc/file.conf- name: Download foo.conf  ansible.builtin.get_url:   #该模块可以将网络上的文件，直接下载至受管节点上。    url: http://materials/hosts.j2   #源文件    dest: /opt/host.txt  #目标文件位置</code></pre><h2 id="9-2-Jinja2模板部署自定义文件"><a href="#9-2-Jinja2模板部署自定义文件" class="headerlink" title="9.2 Jinja2模板部署自定义文件"></a>9.2 Jinja2模板部署自定义文件</h2><h3 id="9-2-1-jinja2简介"><a href="#9-2-1-jinja2简介" class="headerlink" title="9.2.1 jinja2简介"></a>9.2.1 jinja2简介</h3><p>  ansible中使用jinja2模板对文件进行部署，再用template模块同步jinja2模板文件至受管节点，该模块和copy模块作用基本一样，都是把某个文件复制到被管主机上，但是区别在于template模块可以获取变量的值和使用循环</p><p>   1.管理文件通常会使用一些模块，copy，file，blockinfile，lineinfile</p><p>   2.更好的配置文件管理方式是使用jinja2语法制作模板文件来生成最终使用的配置文件</p><p>   3.jinja2模板文件内，可以通过多种方式编辑或构成，比如魔法变量、事实变量、普通字符、控制语句语法…</p><p>   4.使用jinja2模板的方法是，先构建jinja2模板，再通过template模块将j2模板同步至受管节点</p><p>   5.构建模板文件通常名称自定义，以.j2结尾，类似shell脚本的.sh、python脚本的.Py</p><h3 id="9-2-2-使用分隔符"><a href="#9-2-2-使用分隔符" class="headerlink" title="9.2.2 使用分隔符"></a>9.2.2 使用分隔符</h3><pre class=" language-language-bash"><code class="language-language-bash">1、构建jinja2模板$ vim jin.j2  #文件名用.j2结尾127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4::1         localhost localhost.localdomain localhost6 localhost6.localdomain6    #描述，为管理员做提示作用。用户不可见haha {{ ansible_hostname }}2、通过templete模块，同步模板文件至受管主机，同时收集事实变量值，将结果生成至相应文件中。$ vim temp.yml---- name: sync file  hosts: servera  tasks:  - name: Template a file to /etc/files.conf    ansible.builtin.template:      src: jin.j2      dest: /etc/myhosts$ ansible-navigator run temp.yml -m stdout3、在受管节点上查看文件结果$ ansible servera -m shell -a 'cat /etc/myhosts'servera | CHANGED | rc=0 >>hahaservera heihei servera.lab.example.com</code></pre><h3 id="9-2-3-管理模板文件"><a href="#9-2-3-管理模板文件" class="headerlink" title="9.2.3 管理模板文件"></a>9.2.3 管理模板文件</h3><pre class=" language-language-bash"><code class="language-language-bash">1、在配置文件中定义ansible_managed功能，添加描述信息：“Ansible hahaha”[greg@control ansible]$ vim ansible.cfg[defaults]ansible_managed = Ansible hahaha变量名 =  变量值2、在jinja2模板中调用该功能#vim jinja.j2     #注释客户端生成文件是不显示{{ ansible_managed }}  #{{}}描述，客户端生成文件时会显示127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</code></pre><h3 id="9-2-4-控制结构-使用循环"><a href="#9-2-4-控制结构-使用循环" class="headerlink" title="9.2.4 控制结构-使用循环"></a>9.2.4 控制结构-使用循环</h3><pre class=" language-language-bash"><code class="language-language-bash">-shellfor user in `ls /`;do    echo $userdone-jinja2{% for user in users %}   #user变量替换为users变量中的所有值，一行一个值。{{ user }}{% endfor %}#示例$ vim jinja2.j2{% for host in groups.all %}  #使用for 或if 时控制结构使用{% %}{{ host }}{% endfor %}#查看语法帮助:官网或关键词搜索示例[student@workstation ansible]$ grep -r '{%' /etc```1.文件的生成方法```bash$ vim debug.yml---- name:  hosts: all  tasks:  - ansible.builtin.debug:      var: hostvars$ ansible-navigator run debug.yml  -m stdout > 1.txt```2.生成/etc/hosts```bash# 方法1：$ vim /home/student/ansible/temp.yml127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6{% for host in groups.all %}{{ hostvars[host].ansible_default_ipv4.address }} {{ hostvars[host].ansible_nodename }} {{ hostvars[host].ansible_hostname }} {% endfor %}#方法2：vim /home/student/ansible/temp.yml---- name: sync file  hosts: all       tasks:  - name: Template a file to /etc/files.conf    ansible.builtin.template:      src: hosts.j2      dest: /etc/myhosts    when: inventory_hostname in groups.dev     #匹配dev组    $ ansible-navigator run temp.yml -m stdout$ ansible  servera -m shell -a 'cat /etc/myhosts'# 以json格式查看：{{ hostvars[i]['ansible_facts'] |  to_nice_json }}</code></pre><h1 id="10-管理大项目"><a href="#10-管理大项目" class="headerlink" title="10 管理大项目"></a>10 管理大项目</h1><h2 id="10-1-引用清单主机"><a href="#10-1-引用清单主机" class="headerlink" title="10.1 引用清单主机"></a>10.1 引用清单主机</h2><h3 id="10-1-1-使用主机模式的方式"><a href="#10-1-1-使用主机模式的方式" class="headerlink" title="10.1.1 使用主机模式的方式"></a>10.1.1 使用主机模式的方式</h3><pre class=" language-language-bash"><code class="language-language-bash">#使用主机模式的常见方式：1.[ad-hoc:]ansible dev -m shell 2.[playbook:]- name:  hosts: dev</code></pre><h3 id="10-1-2-通配符匹配多个主机"><a href="#10-1-2-通配符匹配多个主机" class="headerlink" title="10.1.2 通配符匹配多个主机"></a>10.1.2 通配符匹配多个主机</h3><pre class=" language-language-bash"><code class="language-language-bash"># 清单里使用通配符匹配多个主机[START:END]192.168.[0:15].[0:255] 表示 192.168.0.0-192.168.15.255server[a:c].example.com  表示   a-cserver[01:15].example.com  表示   server01.example.com-server15ipv6也可以通过[a:f]这种方式all： 所有主机ungrouped ： 不属于任何一个组的所有主机</code></pre><h3 id="10-1-3-主机模式其他方式"><a href="#10-1-3-主机模式其他方式" class="headerlink" title="10.1.3 主机模式其他方式"></a>10.1.3 主机模式其他方式</h3><pre class=" language-language-bash"><code class="language-language-bash">#使用特殊字符时，必须添加单引号，否则不生效hosts： '*'  和all相同   hosts：'*.example.com'hosts：'datacenter*'#列表形式hosts：servera,serverb  hosts：webserver,serverchosts：'devops,server*'#冒号：取代逗号hosts：lab,&datacenter 匹配lab组同时也属于datacenter组，顺序无所谓&符号时同时也属于的意思hosts：datacenter,!test2.example.com  表示datacenter组，但不包括test2.。。这个主机hosts：all,!datacenter1  所有组，但不包含datacenter1组</code></pre><h2 id="10-2-包含和导入文件"><a href="#10-2-包含和导入文件" class="headerlink" title="10.2 包含和导入文件"></a>10.2 包含和导入文件</h2><h3 id="10-2-1-管理大型Playbook"><a href="#10-2-1-管理大型Playbook" class="headerlink" title="10.2.1 管理大型Playbook"></a>10.2.1 管理大型Playbook</h3><pre class=" language-language-bash"><code class="language-language-bash"># 如果playbook很长很复杂，可以拆分成较小的文件便于管理，以模块化管理# 可以将多个不同功能的play，组合成一个主要的playbook，将文件中的任务列表插入play，这样可将这种模块化的play应用到不同场景playbook- httpd- php- mysql</code></pre><h3 id="10-2-2-导入Playbook"><a href="#10-2-2-导入Playbook" class="headerlink" title="10.2.2 导入Playbook"></a>10.2.2 导入Playbook</h3><pre class=" language-language-bash"><code class="language-language-bash">1.将两个playbook加入到主playbook$ vim one.yml ---- name: play1  hosts: node1  tasks:  - name: Install the latest version of Apache    ansible.builtin.yum:      name: httpd      state: latest      $ vim two.yml      ---- name: play2  hosts: node1  tasks:  - name: Make sure a service unit is running    ansible.builtin.systemd:      state: started      name: httpd      enabled: yes      2.在主playbook中和其他play交替使用$ vim main.yml ---- name: four  hosts: node1  tasks:  - ansible.builtin.debug:      msg: haha  - name: one     # 因为加载的是playbook所以需要顶头写无缩进  import_playbook: one.yml- name: two  import_playbook: two.yml</code></pre><h3 id="10-2-3-包含与导入"><a href="#10-2-3-包含与导入" class="headerlink" title="10.2.3 包含与导入"></a>10.2.3 包含与导入</h3><p>  Ansible可以支持两种方法将文件放入playbook中：<br>   包含：内容是一个动态操作。在playbook运行期间，Ansible会在内容到达时处理所包含的内容<br>   导入：内容是一个静态操作。在运行开始之前，Ansible在最初解析playbook时预处理导入的内容</p><p>1.包含</p><pre class=" language-language-bash"><code class="language-language-bash">1.使用include_tasks功能时，包含时设置的when等条件语句将确定任务是否包含在play中2.如果运行ansible-playbook --list-tasks以列出playbook中的任务，则不会显示已包含任务文件中的任务。将显示包含任务文件的任   务。相比之下，import_tasks功能不会列出导入任务文件的任务，而列出已导入任务文件中的各个任务  #（[greg@control ansible]$ ansible-playbook playbook.yml --start-at-task webserver）3.不能使用ansible-playbook --start-at-task从已包含任务文件中的任务开始执行playbook  #（[greg@control ansible]$ ansible-playbook playbook.yml --start-at-task webinstall）4.不能使用notify语句触发已包含任务文件中的处理程序名称  可以在包含整个任务文件的主playbook中触发处理程序，在这种情况下，已包含文件中的所有任务都将运行</code></pre><p>2.导入</p><pre class=" language-language-bash"><code class="language-language-bash">1.使用import_tasks功能时，导入时设置的when等条件语句将应用于导入的每个任务2.无法将循环用于import_tasks功能3.如果使用变量来指定要导入的文件的名称，则将无法使用主机或组清单变量</code></pre><p>3.使用示例</p><pre class=" language-language-bash"><code class="language-language-bash">第一个tasks任务[greg@bastion ansible]$ mkdir tasks    #tasks目录是自定义的，创建的目的只是方便存储管理tasks任务文件。[greg@bastion ansible]$ vim tasks/apache.yml  #tasks任务文件，文件中没有主机模式---- name:  ansible.builtin.yum:    name: httpd    state: latest第二个tasks任务[greg@bastion ansible]$ vim tasks/service.yml ---- name:  ansible.builtin.service:    name: httpd    enabled: yes    state: started  包含和导入的方式：[greg@bastion ansible]$ vim main.yml   #此处main.yml是一个playbook，有主机模式---- name:  hosts: node1  tasks:  - include_tasks: tasks/apache.yml    - import_tasks: tasks/service.yml</code></pre><h1 id="11-角色和collections简化Playbook"><a href="#11-角色和collections简化Playbook" class="headerlink" title="11 角色和collections简化Playbook"></a>11 角色和collections简化Playbook</h1><h2 id="11-1-描述角色结构"><a href="#11-1-描述角色结构" class="headerlink" title="11.1 描述角色结构"></a>11.1 描述角色结构</h2><pre class=" language-language-bash"><code class="language-language-bash"># Ansible中的角色是结构化的目录组成，可以根据业务需要创建不同的角色，apache的、mysql的等# 角色的优势是类似将playbook分割成更小的模块，进行模块化管理，简化playbook# 除了自行编写、使用、重用和共享角色外，也可以从其他来源获取角色以及使用分发包(如Ansible内容集合)查找角色</code></pre><h2 id="11-2-创建角色"><a href="#11-2-创建角色" class="headerlink" title="11.2 创建角色"></a>11.2 创建角色</h2><pre class=" language-language-bash"><code class="language-language-bash"># 在playbook的项目目录中创建一个角色，并将其作为playbook中某个play的一部分来运行1.yum install -y httpd            yum模块2.index.html, fcontext            copy模块3.httpd service                   service模块4.firewalld.service               service模块5.firewalld permit apache         firewalld模块# 使用web角色一键部署以上服务</code></pre><p>  创建和使用角色分四步进行：</p><p>   1.创建角色目录存储路径</p><p>   2.创建角色</p><p>   3.定义角色内容</p><p>   4.在playbook中使用角色</p><h3 id="11-2-1-角色目录存储路径"><a href="#11-2-1-角色目录存储路径" class="headerlink" title="11.2.1 角色目录存储路径"></a>11.2.1 角色目录存储路径</h3><pre class=" language-language-bash"><code class="language-language-bash"># 配置ansible.cfg文件中的roles-path,默认ansible会在roles子目录中查找角色# 可以将自己的角色安装在~/ansible/roles子目录中1.默认路径：[student@workstation ansible]$ ansible-galaxy --help[student@workstation ansible]$ ansible-galaxy role --help    #查看角色的子命令帮助[student@workstation ansible]$ ansible-galaxy role list     #新版本查看角色指令[student@workstation ansible]$ ansible-galaxy list           #旧版本查看角色指令# /usr/share/ansible/roles   -- 系统角色# /etc/ansible/roles         -- 全局角色路径[WARNING]: - the configured path /home/student/.ansible/roles does not exist.  --默认该目录不存在，需要的话可以根据需求创建`如果ansible无法找到该位置角色，会按照ansible.cfg中roles_path指定的目录中查找`2.创建角色目录存储路径  使用自定义工作目录时，创建自定义roles(角色)目录，并使用ansible.cfg中roles_path=字段指定角色路径[student@workstation ansible]$ pwd        #进入自己的工作目录/home/student/ansible[student@control ansible]$ mkdir roles    #创建存放角色的目录[student@control ansible]$ vim ansible.cfg   roles_path=/home/student/ansible/roles    #指定角色路径[student@workstation ansible]$ ansible-galaxy list  #要在工作目录中使用查看命令，调用当前工作目录配置文件中的角色路径# /home/student/ansible/roles                       #查询结果应和配置文件的roles_path字段一致   </code></pre><h3 id="11-2-2-创建角色"><a href="#11-2-2-创建角色" class="headerlink" title="11.2.2 创建角色"></a>11.2.2 创建角色</h3><pre class=" language-language-bash"><code class="language-language-bash">[student@workstation ansible]$ ansible-galaxy role init roles/apache    #创建角色- Role roles/apache was created successfully[student@workstation ansible]$ ansible-galaxy role list   #列出所有角色# /home/student/ansible/roles- apache, (unknown version)[student@workstation ansible]$ tree roles/apache/roles/apache├── defaults                  #角色默认变量│   └── main.yml├── files                     #引用的静态文件，可以是一些文件、网页模板等├── handlers                  #处理程序，通常通过模块完成的│   └── main.yml├── meta                      #作者，许可、兼容性│   └── main.yml├── README.md├── tasks                     #任务，任务的组成就是模块应用，也是角色的主要功能│   └── main.yml├── templates                 #模板文件，通常使用jinja2模板├── tests                     #测试│   ├── inventory│   └── test.yml└── vars                      #角色变量    └── main.yml8 directories, 8 files#用不到的目录可以删除，如defaults、vars、tests</code></pre><h3 id="11-2-3-定义角色内容"><a href="#11-2-3-定义角色内容" class="headerlink" title="11.2.3 定义角色内容"></a>11.2.3 定义角色内容</h3><pre class=" language-language-bash"><code class="language-language-bash">[student@control ansible]$ tree roles/apache (可选，方便查看路径信息)*[student@control ansible]$ vim roles/apache/tasks/main.yml   #在tasks目录中完善角色内容---- name: install apache     #编写角色时，任务中只有模块任务，没有PLAY  ansible.builtin.yum:    name: httpd    state: latest- name: Start service httpd  ansible.builtin.service:    name: httpd    state: started    enabled: yes- name: create web page  ansible.builtin.template:    src: jin2.j2    #jin2.j2需要手动创建    dest: /var/www/html/index.html  notify:  - restart   #需要时将调用handlers处理程序，需要手动创建，restart通知中的处理程序名要和handlers/main.yml中处理程序描述一致- name: Start service firewalld  ansible.builtin.service:    name: firewalld    state: started    enabled: yes    - name: permit apache  ansible.posix.firewalld:        service: http    permanent: yes    state: enabled    immediate: yes    #ansible-navigator collections可以查看posix集合 #ansible-navigator doc ansible.posix.firewalld -m stdout #以上25-30行客替换为如下:- name: permit apache  ansible.builtin.shell: firewall-cmd --permanent --add-service=http  - name: permit apache  ansible.builtin.shell: firewall-cmd --reload      [student@control ansible]$ vim roles/apache/templates/jin2.j2  #编写模板文件ipadd={{ ansible_default_ipv4.address }}  hostname={{ ansible_hostname }}[student@control ansible]$ vim roles/apache/handlers/main.yml   #编写处理程序---- name: restart   ansible.builtin.service:    name: httpd    state: restarted</code></pre><h3 id="11-2-4-playbook中使用角色"><a href="#11-2-4-playbook中使用角色" class="headerlink" title="11.2.4 playbook中使用角色"></a>11.2.4 playbook中使用角色</h3><pre class=" language-language-bash"><code class="language-language-bash">[student@bastion ansible]$ vim roles.yml---- name:  hosts: servera  roles:     #roles字段用来调用角色  - apache   #被调用角色的名称  - xxx[student@bastion ansible]$ ansible-navigator run -m stdout roles.yml  [student@control ansible]$ curl serveraipadd=172.25.250.10  hostname=servera</code></pre><h2 id="11-3-外部内容源部署角色"><a href="#11-3-外部内容源部署角色" class="headerlink" title="11.3 外部内容源部署角色"></a>11.3 外部内容源部署角色</h2><p>  从Git存储库或AnsibleGalaxy等外部资源中选择和检索角色，并在playbook中使用</p><p>  <a href="https://galaxy.ansible.com/">https://galaxy.ansible.com</a></p><h3 id="11-3-1-外部内容来源"><a href="#11-3-1-外部内容来源" class="headerlink" title="11.3.1 外部内容来源"></a>11.3.1 外部内容来源</h3><pre class=" language-language-bash"><code class="language-language-bash">#角色有多种获取方式：1.本地tar包安装   2.通过网络地址安装   3.通过文件同时安装网络中多个地址角色roles/requirements.yml- src： #角色网址  varsion：#角色版本  name：#安装在本地的角色名- src：  name：ansible-galaxy role install -r roles/requirements.yml -p roles-r 指定文件路径-p 指定角色安装路径roles/requirements.yml  角色安装信息，包括地址，角色名称等</code></pre><h3 id="11-3-2-角色部署"><a href="#11-3-2-角色部署" class="headerlink" title="11.3.2 角色部署"></a>11.3.2 角色部署</h3><pre class=" language-language-bash"><code class="language-language-bash">#示例：1.将phpinfo.tar,haproxy.tar上传到Linux，kiosk家目录下，用kiosk登录2.将两个角色包拷贝到foundation0的rhel9.0目录中$ ssh root@localhost cp /home/kiosk/{phpinfo.tar,haproxy.tar} /content/courses/rh294/rhel9.0/materials3.打开foundation0的浏览器输入http://172.25.254.254/materials/就可以看到两个软件包[student@workstation ansible]$ mkdir roles[student@workstation ansible]$ $ vim ansible.cfg[defaults]roles_path=/home/student/ansible/roles[student@workstation ansible]$ vim roles/requirements.yml---- src: http://172.25.254.254/materials/haproxy.tar  name: balancer- src: http://172.25.254.254/materials/phpinfo.tar  name: phpinfo[student@workstation ansible]$ ansible-galaxy install -r roles/requirements.yml [student@workstation ansible]$ ansible-galaxy list# /home/student/ansible/roles- apache, (unknown version)- balancer, (unknown version)- phpinfo, (unknown version)</code></pre><h2 id="11-4-内容集合获取角色和模块"><a href="#11-4-内容集合获取角色和模块" class="headerlink" title="11.4 内容集合获取角色和模块"></a>11.4 内容集合获取角色和模块</h2><p>  从Ansible内容集合中获取一组相关角色、补充模块和其他内容，并在playbook中使用</p><h3 id="11-4-1-Ansible内容集合"><a href="#11-4-1-Ansible内容集合" class="headerlink" title="11.4.1 Ansible内容集合"></a>11.4.1 Ansible内容集合</h3><p>  1.随着模块数量增加，管理困难。模块需要唯一名称，并保持更新</p><p>  2.借助Ansible内容集合，Ansible代码可以与模块和插件分开更新</p><p>  3.Ansible 内容集合可提供一组在playbook中使用的相关模块、角色和其他插件，便于供应商和开发人员按照自己的节奏维护和分发集合，而不受Ansible版本的影响</p><h3 id="11-4-2-Ansible内容集合的命名空间"><a href="#11-4-2-Ansible内容集合的命名空间" class="headerlink" title="11.4.2 Ansible内容集合的命名空间"></a>11.4.2 Ansible内容集合的命名空间</h3><p>  1.命名空间是集合名称的第一部分</p><p>  2.由Ansible社区维护的所有集合可能会放入community命名空间中名称类似于：</p><p>   community.crypto</p><p>   community.postgresql</p><p>   community.rabbitmq</p><p>  3.红帽直接维护和支持的Ansible内容集合可能使用redhat命名空间有：<br>   redhat.rhv<br>   redhat.satellite<br>   redhat.insights等名称</p><h3 id="11-4-3-Ansible内容集合的来源"><a href="#11-4-3-Ansible内容集合的来源" class="headerlink" title="11.4.3 Ansible内容集合的来源"></a>11.4.3 Ansible内容集合的来源</h3><p>  无论是将ansible-navigator 用于最小自动化执行环境，还是在裸机Ansible Core上使用ansible-playbook，始终至少有一个可用Ansible内容集合:ansible.builtin</p><p>  自动化执行环境可能还内置了其他自动化执行环境，例如，红帽Ansible 自动化平台2.2使用的默认执行环境ee-supported-rhel8</p><p>  如果需要其他Ansible内容集合，可以将其添加到Ansible项目的collections子目录中，可以从多个来源获取Ansible内容集合：</p><p>   1.自动化中心</p><p>   2.私有自动化中心</p><p>   3.Ansible Galaxy</p><p>   4.第三方Git存储库或存档文件</p><h3 id="11-4-4-安装Ansible内容集合"><a href="#11-4-4-安装Ansible内容集合" class="headerlink" title="11.4.4 安装Ansible内容集合"></a>11.4.4 安装Ansible内容集合</h3><pre class=" language-language-bash"><code class="language-language-bash">#配置文件ansible.cfg中设置了collections_paths选项来指定集合的默认路径：~/.ansible/collections;/usr/share/ansible/collections #如果消除这两个目录的指定，则ansible-navigator无法在这些目录的其版本中找到自动化执行环境内提供的Ansible内容集合$ ansible-galaxy collection install 集合 -p collections-p collections 选项会将该集合安装到本地collections子目录中或者不适用-p，而在ansible.cfg文件中collections_paths选项来指定集合的默认路径#集合的来源可以是：本地、互联网、git仓库</code></pre><p>1.使用要求文件安装Ansible内容集合</p><pre class=" language-language-bash"><code class="language-language-bash"># 1.将三个集合包上传到Linux，kiosk家目录下，用kiosk登录# 2.将三个集合包拷贝到foundation0的rhel9.0目录中  $ ssh root@localhost cp /home/kiosk/{community-general-5.5.0.tar.gz,redhat-insights-1.0.7.tar.gz,redhat-rhel_system_roles-1.19.3.tar.gz} /content/courses/rh294/rhel9.0/materials# 3.打开foundation0的浏览器输入http://172.25.254.254/materials/就可以看到两个软件包【workstation】1.创建存储集合的位置$ mkdir /home/student/ansible/mycollections  $ vim ansible.cfg[defaults]...  #集合默认路径不删除，额外添加当前用户工作目录中集合路径collections_path=/home/student/ansible/mycollection:~/.ansible/collections:/usr/share/ansible/collections 2.部署requirements.yml文件$ vim /home/student/ansible/mycollections/requirements.yml---collections:- name: http://172.25.254.254/materials/community-general-5.5.0.tar.gz- name: http://172.25.254.254/materials/redhat-insights-1.0.7.tar.gz- name: http://172.25.254.254/materials/redhat-rhel_system_roles-1.19.3.tar.gz3.安装集合$ ansible-galaxy collection install -r requirements.yml -p /home/student/ansible/collections/mycollections$ ansible-galaxy collection list</code></pre><h2 id="11-5-利用系统角色重用内容"><a href="#11-5-利用系统角色重用内容" class="headerlink" title="11.5 利用系统角色重用内容"></a>11.5 利用系统角色重用内容</h2><p>  编写利用红帽帽企业Linux的系统角色执行标准操作的 playbook</p><h3 id="11-5-1-内容集合安装系统角色"><a href="#11-5-1-内容集合安装系统角色" class="headerlink" title="11.5.1 内容集合安装系统角色"></a>11.5.1 内容集合安装系统角色</h3><pre class=" language-language-bash"><code class="language-language-bash">#内容集合 redhat.rhel_system_roles$ mkdir /home/student/ansible/collections$ vim /home/student/ansible/collections/requirements.yml---collectionsname: redhat.rhel system roles$ ansible-galaxy collection install -p collections/ -r home/student/ansible/collections/requirements.yml$ sudo find ./mycollection/ -name  selinux-playbook.yml #不安装角色包可以使用该条命令搜索$ find mycollection/ -name '*.yml' | grep selinux$ cp /usr/share/ansible/collections/ansible_collections/redhat/rhel_system_roles/docs/selinux/selinux-playbook.yml /home/student/ansible/selinux.yml</code></pre><h3 id="11-5-2-rpm包安装系统角色"><a href="#11-5-2-rpm包安装系统角色" class="headerlink" title="11.5.2 rpm包安装系统角色"></a>11.5.2 rpm包安装系统角色</h3><p>1.系统角色使用流程</p><pre class=" language-language-bash"><code class="language-language-bash">1.通过软件安装获得系统角色（rhel-system-roles.noarch）2.定义系统角色路径（存放角色的位置），并将其记录配置文件cd /;ansible-galaxy list   , vim ~/ansible/ansible.cfg/;roles_path=xxxx:xxxx3.使用系统角色，将系统角色添加至playbook，并修改内容4.应用</code></pre><p>2.安装系统角色</p><pre class=" language-language-bash"><code class="language-language-bash">1.安装系统帮助我们定义了一些角色，有不同的功能，需要通过安装软件包。[greg@control ansible]$ cd /[greg@control /]$ sudo yum search roles[greg@control /]$ sudo yum install -y rhel-system-roles.noarch     [greg@control /]$ ansible-galaxy list    #在根目录下查看角色路径，该路径为默认系统角色路径# /usr/share/ansible/roles     #系统角色路径- linux-system-roles.kdump, (unknown version)....- rhel-system-roles.timesync, (unknown version)# /etc/ansible/roles [WARNING]: - the configured path /home/greg/.ansible/roles does not exist.  2.定义角色路径[greg@control /]$ cd ~/ansible/   #在ansible工作目录中查看时属于greg用户定制的角色路径[greg@control ansible]$ vim ansible.cfgroles_path    = /home/greg/ansible/roles:/usr/share/ansible/roles #:冒号分割，并添加系统角色路径[greg@control ansible]$ ansible-galaxy list# /home/greg/ansible/roles                        #之前定义好的自定义角色路径- apache, (unknown version)# /usr/share/ansible/roles                      #系统角色路径- linux-system-roles.kdump, (unknown version)......- rhel-system-roles.timesync, (unknown version)3.使用系统角色，将系统角色添加至playbook并应用[greg@control ansible]$ rpm -ql rhel-system-roles.noarch | grep timesync #看README.md[greg@control ansible]$ cp /usr/share/doc/rhel-system-roles/timesync/example-timesync-playbook.yml /home/greg/ansible/timesync.yml   #找例子，并复制到工作目录中[greg@control ansible]$ vim timesync.yml      #编辑角色---- hosts: all  vars:    timesync_ntp_servers:      - hostname: 172.25.254.254        iburst: yes  roles:    - rhel-system-roles.timesync4.使用系统角色[greg@control ansible]$ ansible-playbook timesync.yml查询验证ansible all -a 'chronyc sources -v'</code></pre><h3 id="11-5-3-通过内容集合安装使用系统角色"><a href="#11-5-3-通过内容集合安装使用系统角色" class="headerlink" title="11.5.3 通过内容集合安装使用系统角色"></a>11.5.3 通过内容集合安装使用系统角色</h3><pre class=" language-language-bash"><code class="language-language-bash"># 1.timesync$ cp /usr/share/ansible/collections/ansible_collections/redhat/rhel_system_roles/docs/timesync/multiple-ntp-servers.yml  timesync.yml$ vim timesync.yml- hosts: all  vars:    timesync_ntp_servers:      - hostname: 172.25.254.254        iburst: yes  roles:    - redhat.rhel_system_roles.timesync$ ansible-navigator run timesync.yml -m stdout$ ansible all -m shell -a 'chronyc sources -v '# 2.selinux$ cp /usr/share/ansible/collections/ansible_collections/redhat/rhel_system_roles/docs/selinux/selinux-playbook.yml selinux.yml$ vim selinux.yml---- hosts: all  vars:    selinux_policy: targeted    selinux_state: permissive  roles:  - redhat.rhel_system_roles.selinux$ ansible-navigator run selinux.yml  -m stdout# 验证$ ansible all -m shell -a 'grep ^SELINUX= /etc/selinux/config'</code></pre><h2 id="11-6-通过文件安装角色"><a href="#11-6-通过文件安装角色" class="headerlink" title="11.6 通过文件安装角色"></a>11.6 通过文件安装角色</h2><pre class=" language-language-bash"><code class="language-language-bash">Ansible官网：https://docs.ansible.com/ansible/2.9/galaxy/user_guide.html#installing-roles-from-galaxyhttps://galaxy.ansible.com/nginxinc/nginx_core  #该网站可以查看角色包信息#实验需要在模拟考试环境下做，普通环境没有角色包[greg@control ansible]$ vim roles/requirements.yml  #制作角色部署文件---- src: http://materials/phpinfo.tar    #角色在网络中的路径  name: phpinfo                           #指定安装在系统中的角色名称- src: http://materials/haproxy.tar  name: balancer  [greg@control ansible]$ ansible-galaxy install --help[greg@control ansible]$ ansible-galaxy install -r roles/requirements.yml  #-r 指定角色文件[greg@control ansible]$ ansible-galaxy list   #检测# /home/greg/ansible/roles- phpinfo, (unknown version)    #查看结果- balancer, (unknown version)</code></pre><h1 id="12-对Ansible进行故障排除"><a href="#12-对Ansible进行故障排除" class="headerlink" title="12 对Ansible进行故障排除"></a>12 对Ansible进行故障排除</h1><h2 id="12-1-对playbook进行故障排除"><a href="#12-1-对playbook进行故障排除" class="headerlink" title="12.1 对playbook进行故障排除"></a>12.1 对playbook进行故障排除</h2><h3 id="12-1-1-调试Playbook"><a href="#12-1-1-调试Playbook" class="headerlink" title="12.1.1 调试Playbook"></a>12.1.1 调试Playbook</h3><pre class=" language-language-bash"><code class="language-language-bash">-rhel8ansible-playbook debug.yml -v   #显示详细信息-v -vv -vvv -vvvv-rhel9ansible-navigator run playbook.yml -m stdout -v</code></pre><h3 id="12-1-2-Debug"><a href="#12-1-2-Debug" class="headerlink" title="12.1.2 Debug"></a>12.1.2 Debug</h3><pre class=" language-language-bash"><code class="language-language-bash">#通过debug模块打印收集到的变量信息，帮助管理员了解模块执行过程及结果---- hosts: serverb  tasks:  - name: install the latest version of Apache    ansible.builtin.yum:      name: vsftpd      state: latest    register: web_install   #注册变量收集模块的执行信息  - ansible.builtin.debug:      var: web_install      #debug模块可以帮助打印出执行信息#可以一次性将hostvars收集到的所有魔法及事实变量打印出来，并可以记录到文件中[greg@control ansible]$ vim debug.yml---- name: test  hosts: node1  tasks:  - ansible.builtin.debug:      var: hostvars[greg@control ansible]$ ansible-navigator run -m stdout debug.yml > 2.txt  关闭事实收集如果要关闭收集，可以编辑配置文件gathering = explicit或者在playbook里gather_facts: yes/no  true/false</code></pre><h3 id="12-1-3-检查Playbook的错误"><a href="#12-1-3-检查Playbook的错误" class="headerlink" title="12.1.3 检查Playbook的错误"></a>12.1.3 检查Playbook的错误</h3><pre class=" language-language-bash"><code class="language-language-bash">-RHEL8$ ansible-playbook playbook.yml --syntax-checkplaybook: playbook.yml-RHEL9greg@control ansible]$ ansible-navigator run -m stdout debug.yml   --syntax-checkplaybook: /home/greg/ansible/debug.yml</code></pre><h3 id="12-1-4-检查Playbook的问题"><a href="#12-1-4-检查Playbook的问题" class="headerlink" title="12.1.4 检查Playbook的问题"></a>12.1.4 检查Playbook的问题</h3><pre class=" language-language-bash"><code class="language-language-bash">#常见语法问题name：  冒号后面要空格，内容随意hosts： all 指定的主机不在清单中，报错无parttensyntax-errors：注意格式缩进，2格缩进变量设置错误，或调用时错误（变量名写错，变量开头要加双引号）  when条件： （逻辑判断思路错误，或书写错误）</code></pre><h3 id="12-1-5-检查Playbook工件和日志文件"><a href="#12-1-5-检查Playbook工件和日志文件" class="headerlink" title="12.1.5 检查Playbook工件和日志文件"></a>12.1.5 检查Playbook工件和日志文件</h3><pre class=" language-language-bash"><code class="language-language-bash"># ansible-navigator可以生成playbook工件，以JSON格式存储与playbook的运行相关的信息# 可以将与playbook运行相关的信息记录到系统上您可写入位置处的文本文件中# RHEL9中的ansible自动开启日志功能，可通过配置文件设置及手工设置# 配置文件$ vim ~/.ansible-navigator.yml---ansible-navigator:  execution-environment:    image: utility.lab.example.com/ee-supported-rhel8:latest    pull:      policy: missing  playbook-artifact:    enable: false    # false/true 关闭/打开# 手工指定--pae  --playbook-artifact-enable</code></pre><h3 id="12-1-6-输出记录到文本文件"><a href="#12-1-6-输出记录到文本文件" class="headerlink" title="12.1.6 输出记录到文本文件"></a>12.1.6 输出记录到文本文件</h3><pre class=" language-language-bash"><code class="language-language-bash">-RHEL8&91.Ansible提供了一个内置日志基础架构，可通过ansible.cfg配置文件[defaults]部分中的log_path参数或$ANSIBLE_LOG_PATH环境变   量进行配置。在进行上面一项或两项配置后，Ansible会以文本形式将ansible-navigator命令的输出存储到所配置的日志文件中。此机制   也适用于ansible-playbook等早期的工具2.如果将Ansible配置为将日志文件写入/var/log，红帽建议您配置logrotate来管理文件</code></pre><h2 id="12-2-对Ansible受管主机进行故障排除"><a href="#12-2-对Ansible受管主机进行故障排除" class="headerlink" title="12.2 对Ansible受管主机进行故障排除"></a>12.2 对Ansible受管主机进行故障排除</h2><h3 id="12-2-1-Ansible运行临时命令"><a href="#12-2-1-Ansible运行临时命令" class="headerlink" title="12.2.1 Ansible运行临时命令"></a>12.2.1 Ansible运行临时命令</h3><pre class=" language-language-bash"><code class="language-language-bash"># ad-hoc命令可以用于简单部署场景，比如对一组目标部署一个任务，或检索受管节点的运行情况、状态等ansible all -m ping# RHEL9中默认不允许root用户登录，需要修改配置文件允许root登录。所建议使用普通用户作为远程管理用户# 解决方法,服务器端：$ vim /etc/ssh/sshd_config# PermitRootLogin prohibit-passwordPermitRootLogin yes$ systemctl  reload sshd</code></pre><h3 id="12-2-2-手动控制执行"><a href="#12-2-2-手动控制执行" class="headerlink" title="12.2.2 手动控制执行"></a>12.2.2 手动控制执行</h3><pre class=" language-language-bash"><code class="language-language-bash">$ ansible-playbook playbook.yml --step$ ansible-navigator run playbook.yml  -m stdout --stepPLAY [PLAY1] ********************************************************************************************Perform task: TASK: Gathering Facts (N)o/(y)es/(c)ontinue: n#手动输入n  y c来控制playbook中执行的步骤1.n 不执行该步骤2.y 执行该步骤3.c 继续自动执行到结束# 通过该方法可以让有问题的步骤执行，而无关紧要的步骤可以跳过不执行。达到排错的目的</code></pre><h3 id="12-2-3-从指定步骤执行任务"><a href="#12-2-3-从指定步骤执行任务" class="headerlink" title="12.2.3 从指定步骤执行任务"></a>12.2.3 从指定步骤执行任务</h3><pre class=" language-language-bash"><code class="language-language-bash">[greg@control ansible]$ ansible-playbook playbook.yml --start-at-task='Start service httpd'--start-at-task   #指定具体执行步骤，等号后面指定模块的描述，如果描述内容中有空格，建议用单或双引号引起来，表示为一个参数</code></pre><h3 id="12-2-4-烟雾测试"><a href="#12-2-4-烟雾测试" class="headerlink" title="12.2.4 烟雾测试"></a>12.2.4 烟雾测试</h3><pre class=" language-language-bash"><code class="language-language-bash"># 烟雾测试：在管理节点执行剧本，显示剧本的真实执行结果，但是不在受管节点上部署$ ansible-playbook playbook.yml --help | grep \\-C$ ansible-navigator run playbook.yml  -m stdout -C[greg@control ansible]$ vim playbook.yml---- name: PLAY1  hosts: node2  tasks:  - name: install  apache    ansible.builtin.yum:      name: httpd      state: latest  - name: Copy using inline content    ansible.builtin.copy:      content: 'test web page'      dest: /var/www/html/index.html  - name: Start service httpd    ansible.builtin.service:      name: httpd      state: started  - name: Start service firewalld    ansible.builtin.service:      name: firewalld      state: started  - name: permit apache    ansible.posix.firewalld:      service: http      permanent: yes      state: enabled      immediate: yes[greg@control ansible]$ ansible-playbook playbook.yml -C</code></pre><h3 id="12-2-5-发送脚本解决问题"><a href="#12-2-5-发送脚本解决问题" class="headerlink" title="12.2.5 发送脚本解决问题"></a>12.2.5 发送脚本解决问题</h3><pre class=" language-language-bash"><code class="language-language-bash">$ vim test.sh   #自定义脚本名及内容#!/bin/bashdate$ vim debug.yml #剧本名自定义---- name:  hosts: node1  tasks:  - name: Run a script    ansible.builtin.script: /home/greg/ansible/test.sh    #使用script模块，加脚本文件路径    register: haha   #register收集上面模块执行结果至 haha（自定义名称）的这个变量中  - ansible.builtin.debug:      var: haha   #通过debug模块将haha变量的值打印出来。$ ansible-playbook debug.yml     `如果不想写register，可以执行剧本时添加-v 类似：ansible-playbook debug.yml -v`</code></pre><h1 id="13-自动执行Linux管理任务"><a href="#13-自动执行Linux管理任务" class="headerlink" title="13 自动执行Linux管理任务"></a>13 自动执行Linux管理任务</h1><h2 id="13-1-管理软件和订阅"><a href="#13-1-管理软件和订阅" class="headerlink" title="13.1 管理软件和订阅"></a>13.1 管理软件和订阅</h2><h3 id="13-1-1-优化多软件包安装"><a href="#13-1-1-优化多软件包安装" class="headerlink" title="13.1.1 优化多软件包安装"></a>13.1.1 优化多软件包安装</h3><pre class=" language-language-bash"><code class="language-language-bash">ansible.builtin.---- name:  hosts: all  tasks:  - name: install the latest version of Apache    ansible.builtin.yum:      name: httpd   #httpd      state: latest  - name: install the latest version of Apache    ansible.builtin.yum:      name: php   #php      state: latest---------------------------------------------- name: install the latest version of Apache  ansible.builtin.yum:      name: "{{ item }}"      state: latest  loop:　    #用loop方式简化playbook    - httpd    - php      yum install -y httpdyum install -y php---------------------------------------------- name: install the latest version of Apache  ansible.builtin.yum:    name:     - httpd    - php    state: latestyum install -y httpd php--------------------------------------------- - name: ensure a list of packages installed  ansible.builtin.yum:    name: "{{ packages }}"  vars:    packages:    - httpd    - httpd-tools---------------------------------------------       # 等同于：yum install -y httpd php或 loop的这种方式，系统会执行两次独立事务，对每个事务应用一个软件包# yum模块：  state： absent删除, installed,  present确保安装  latest升级到最新版本  latest 等同  yum update name： '*'  代表所有软件包 name: "@RPM Development tools"   ansible命令里面安装包组要加@</code></pre><h3 id="13-1-2-收集已安装软件包的事实"><a href="#13-1-2-收集已安装软件包的事实" class="headerlink" title="13.1.2 收集已安装软件包的事实"></a>13.1.2 收集已安装软件包的事实</h3><pre class=" language-language-bash"><code class="language-language-bash">---- name:  hosts: node1  tasks:  - name: Gather the package facts    ansible.builtin.package_facts:      manager: auto  #- name: Print the package facts  #  ansible.builtin.debug:  #    var: ansible_facts.packages  - name: Check whether a package called foobar is installed    ansible.builtin.debug:      msg: "{{ ansible_facts.packages.zip.0.version }}"</code></pre><h3 id="13-1-3-管理软件包的其他模块"><a href="#13-1-3-管理软件包的其他模块" class="headerlink" title="13.1.3 管理软件包的其他模块"></a>13.1.3 管理软件包的其他模块</h3><pre class=" language-language-bash"><code class="language-language-bash">- name: Install httpd on RHEL 8 and 9  ansible.builtin.dnf    name: httpd    state: present- name: Install httpd on RHEL 7 and earlier  ansible.builtin.yum:    name:httpd    state:present</code></pre><h3 id="13-1-4-RPM软件包存储库"><a href="#13-1-4-RPM软件包存储库" class="headerlink" title="13.1.4 RPM软件包存储库"></a>13.1.4 RPM软件包存储库</h3><pre class=" language-language-bash"><code class="language-language-bash">$ ansible-doc -l | grep yum---- name:  hosts: node1  tasks:  - name: Add multiple repositories into the same file (1/2)    ansible.builtin.yum_repository:      name: EX294_BASE #file字段不存在时，默认用name字段代替源文件名称      description: EX294 base software      file: rhel  #file选项作用是定义yum源文件名称，无该字段时会用name字段后的值代替文件名 例如：rhel.repo      baseurl: http://content/rhel8.4/x86_64/dvd/BaseOS      gpgcheck: yes      gpgkey: http://content/rhel8.4/x86_64/dvd/RPM-GPG-KEY-redhat-release      enabled: yes        - name: Add multiple repositories into the same file (1/2)    ansible.builtin.yum_repository:      name: EX294_STREAM      description: EX294 stream software      file: rhel  #多个模块使用同一个file字段的名称时，会将源地址写入到同一个文件中。      baseurl: http://content/rhel8.4/x86_64/dvd/AppStream      gpgcheck: yes      gpgkey: http://content/rhel8.4/x86_64/dvd/RPM-GPG-KEY-redhat-release      enabled: yes  #enabled默认值为yes，考试时要写该选项。ansible模块选项和vim配置文件内容对比  vim：                ansible：      rhel.repo          file      [rhel]            * name      name=rhel         * description      baseurl=            * baseurl      gpgcheck=            * gpgcheck      gpgeky=            * gpgkey      enabled=            * enabled           #测试方法：$ ansible all -a 'yum repolist all'# 受管节点检测  $ cat rhel.repo$ ansible-doc rpm_key   - ansible.builtin.rpm_key:    state: present    key: http://apt.sw.be/RPM-GPG-KEY.dag.txt</code></pre><h2 id="13-2-管理用户和身份验证"><a href="#13-2-管理用户和身份验证" class="headerlink" title="13.2 管理用户和身份验证"></a>13.2 管理用户和身份验证</h2><h3 id="13-2-1-user模块"><a href="#13-2-1-user模块" class="headerlink" title="13.2.1 user模块"></a>13.2.1 user模块</h3><pre class=" language-language-bash"><code class="language-language-bash">#在servera上创建用户tom 附加组为group1，并设置密码为password tom: tom123用sha512方式哈希，uid =2000#user这个模块类似这些功能： useradd userdel usermod$ cat group.yml     - name:  hosts: node1  vars:  - passwordtom: tom123  tasks:  - name:  create group    ansible.builtin.group:      name: "{{ item }}"    loop:      - group1      - group2  - name: Add the    ansible.builtin.user:      name: tom            #useradd tom      comment: student     #useradd -c student      uid: 2000            #useradd -u 2000      password_expire_max: 10     #passwd -e 10      group: group1             #useradd -g group1      groups: group1,group2     #-G group1,group2      shell: /bin/bash          #-s /bin/bash      password: "{{ passwordtom | password_hash('sha512') }}"    passwd tom      #passwordtom该密码位置如果是字符串用单引号引起来，如果是变量则不需要单引号                #验证用户密码过期时间chage -l tomPassword expires                    : Jun 11, 2024#验证用户密码是否正确，可以从node2登录node1，测试node1上的tom用户ssh tom@node1Ansible网页搜索：password_hash--Using filter--网页中查找password_hash，查看密码哈希方式，一定注意是512Ansible官网：  https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html      模块中：append: yes    如果想额外添加附加群组，此选项需要yes(usermod -a -G  grouptest u1) </code></pre><h3 id="13-2-2-group模块"><a href="#13-2-2-group模块" class="headerlink" title="13.2.2 group模块"></a>13.2.2 group模块</h3><pre class=" language-language-bash"><code class="language-language-bash">[greg@bastion ansible]$ cat group.yml ---- name:  hosts: dev  tasks:  - name: Ensure group "grouptest" exists    ansible.builtin.group:      gid: 10000      name: grouptest      state: present | absent   #创建|删除 二选一#等同于：groupadd  grouptest#等同于：groupadd -g 10000 grouptest#groupdel</code></pre><h2 id="13-3-管理启动过程和调度进程"><a href="#13-3-管理启动过程和调度进程" class="headerlink" title="13.3 管理启动过程和调度进程"></a>13.3 管理启动过程和调度进程</h2><h3 id="13-3-1-at"><a href="#13-3-1-at" class="headerlink" title="13.3.1 at"></a>13.3.1 at</h3><pre class=" language-language-bash"><code class="language-language-bash">---- name:  hosts: dev  tasks:  - name: Schedule a command to execute in 20 minutes as root    ansible.posix.at:      command: ls -d / >/dev/null      count: 20      units: minutes# 默认是创建一个任务，给root，删除的    话使用选项state：absent</code></pre><h3 id="13-3-2-cron"><a href="#13-3-2-cron" class="headerlink" title="13.3.2 cron"></a>13.3.2 cron</h3><pre class=" language-language-bash"><code class="language-language-bash">[greg@bastion ansible]$ ansible-doc cron[greg@bastion ansible]$ cat cron.yml ---- name:  hosts: all  tasks:  - name: Ensure a job that runs at 2 and 5 exists.     ansible.builtin.cron:      name: "check dirs"  #描述        minute: "*/2"          #分钟      hour: "2,5"         #小时      day: 1-10           #天      user: harry      job: "ls -alh > /dev/null"     [greg@bastion ansible]$ ansible dev -m shell -a 'crontab -u harry -l'</code></pre><h3 id="13-3-3-管理服务"><a href="#13-3-3-管理服务" class="headerlink" title="13.3.3 管理服务"></a>13.3.3 管理服务</h3><pre class=" language-language-bash"><code class="language-language-bash">---- name:  hosts: dev  tasks:  - name: install the latest version of Apache    ansible.builtin.yum:      name: httpd      state: latest            - name: Start service httpd, if not started    ansible.builtin.service:      name: httpd      state: started      enabled: yes    #开机自启动</code></pre><h3 id="13-3-4-systemd"><a href="#13-3-4-systemd" class="headerlink" title="13.3.4 systemd"></a>13.3.4 systemd</h3><pre class=" language-language-bash"><code class="language-language-bash">[greg@bastion ansible]$ cat systemd.yml ---- name:  hosts: dev  tasks:  - name: install the latest version of Apache    ansible.builtin.yum:      name: httpd      state: latest  - name: Make sure a service is running    ansible.builtin.systemd:      name: httpd      state: started      enabled: yes      测试命令：ansible dev -m shell -a 'systemctl status httpd'ansible dev -m shell -a 'systemctl is-enabled httpd'# 1.reboot- name: Unconditionally reboot the machine with all defaults  reboot:  # 2.command & shell  支持更多的特殊字符$ ansible servera -m command -a 'useradd user1'$ ansible servera -a 'useradd user2'$ ansible servera -a 'echo 123456 | passwd --stdin user1'$ ansible servera -m shell -a 'echo 123456 | passwd --stdin user1'</code></pre><h2 id="13-4-管理存储"><a href="#13-4-管理存储" class="headerlink" title="13.4 管理存储"></a>13.4 管理存储</h2><table><thead><tr><th align="left">模块名</th><th align="left">linux指令</th><th align="left">Linux实施命令</th></tr></thead><tbody><tr><td align="left">community.general.parted</td><td align="left">parted</td><td align="left">parted /dev/vdb mkpart part1 2048s 1G</td></tr><tr><td align="left">community.general.lvg</td><td align="left">vgcreate</td><td align="left">vgcreate -s 16M vg100 /dev/vdb{1..2}</td></tr><tr><td align="left">community.general.lvol</td><td align="left">lvcreate</td><td align="left">lvcreate -L 100M -n lv100 vg100</td></tr><tr><td align="left">community.general.filesystem</td><td align="left">mkfs</td><td align="left">mkfs.ext4 /dev/vg100/lv100</td></tr><tr><td align="left">ansible.posix.mount</td><td align="left">/etc/fstab</td><td align="left">echo “/dev/vg100/lv100 ext4 /mnt/data defaults 0 0” &gt; /etc/fstab</td></tr></tbody></table><h3 id="13-4-1-模块管理存储"><a href="#13-4-1-模块管理存储" class="headerlink" title="13.4.1 模块管理存储"></a>13.4.1 模块管理存储</h3><p>1.纯分区无lvm逻辑卷</p><pre class=" language-language-bash"><code class="language-language-bash">1-1 分区 community.general.parted #先确保community.general集合已经安装，可通过ansibl-galaxy collection list来查看# 创建两个分区每个500M---- name: parted  hosts: node2  tasks:  - name: part 1 2048s-500M    community.general.parted:      device: /dev/vdc      number: 1      state: present      part_end: 500MiB  - name: part 2 500M-1000M    community.general.parted:      device: /dev/vdc      number: 2      state: present      part_start: 500MiB      part_end: 1GiB1-2 格式化 community.general.filesystem#两个分区都格式化为ext4文件系统，如果选择不同文件系统，可以分成两个模块。  - name: Create a ext4    community.general.filesystem:      fstype: ext4      dev: "{{ item }}"     loop:      - /dev/vdc1      - /dev/vdc21-3 挂载 ansible.posix.mount#自动创建挂载点/mnt/part1,再将/dev/vdc1写入/etc/fstab文件最后一行，并挂载。  - name: Mount DVD read-only    ansible.posix.mount:      path: /mnt/part1      #挂载点      src: /dev/vdc1        #设备      fstype: ext4            #文件系统类型      state: mounted        #参考下面解释      -挂载选项解释：# absent:     卸载并删除/etc/fstab内容  # unmounted： 卸载不删除/etc/fstab内容# present：   将挂在信息写入/etc/fstab，不挂载# mounted：   将挂在信息写入/etc/fstab，并创建挂载点及挂载# remounted： 重新挂载</code></pre><p>2.有lvm逻辑卷</p><pre class=" language-language-bash"><code class="language-language-bash">2.分区-lvm（pv,vg,lv）-格式化-挂载2-1 分区 community.general.parted #分两个区每个大约500M，/dev/vdb---- name: lv  hosts: node2  tasks:  - name: part 1 2048s-500M    community.general.parted:      device: /dev/vdb      number: 1      state: present      part_end: 500MiB  - name: part 2 500M-1000M    community.general.parted:      device: /dev/vdb      number: 2      state: present      part_start: 500MiB2-2 pv+vg community.general.vg#两个分区都加入vg，名称vg100#ansible-navigator collections -m stdout | grep vg$ 查看帮助  - name: Create a volume group vg100    community.general.lvg:      vg: vg100      pvs: /dev/vdb1,/dev/vdb2      pesize: 322-3 lv community.general.lvol#创建一个lv名为lv100，大小800M  - name: Create a logical volume lv100 size 800M    community.general.lvol:      vg: vg100      lv: lv100      size: 8002-4 格式化 community.general.filesystem#格式化为xfs文件系统 - name: Create a xfs    community.general.filesystem:      fstype: xfs      dev: /dev/vg100/lv1002-5 挂载 ansible.posix.mount#lv挂载到/mnt/data，并设置为开机自启动。  - name: /mnt/data    ansible.posix.mount:      path: /mnt/data      src: /dev/vg100/lv100      fstype: xfs      state: mounted            #整体配置---- name: lv  hosts: node2  tasks:  - name: part 1 2048s-500M    community.general.parted:      device: /dev/vdb      number: 1      state: present      part_end: 500MiB  - name: part 2 500M-1000M    community.general.parted:      device: /dev/vdb      number: 2      state: present      part_start: 500MiB  - name: Create a volume group vg100    community.general.lvg:      vg: vg100      pvs: /dev/vdb1,/dev/vdb2      pesize: 32  - name: Create a logical volume lv100 size 800M    community.general.lvol:      vg: vg100      lv: lv100      size: 800  - name: Create a xfs    community.general.filesystem:      fstype: xfs      dev: /dev/vg100/lv100  - name: /mnt/data    ansible.posix.mount:      path: /mnt/data      src: /dev/vg100/lv100      fstype: xfs      state: mounted</code></pre><h3 id="13-4-2-系统角色管理存储"><a href="#13-4-2-系统角色管理存储" class="headerlink" title="13.4.2 系统角色管理存储"></a>13.4.2 系统角色管理存储</h3><pre class=" language-language-bash"><code class="language-language-bash"># 逻辑卷角色[greg@control ansible]$ sudo find ./mycollection/ -name '*.yml' | grep storage|grep test.yml./mycollection/ansible_collections/redhat/rhel_system_roles/tests/storage/test.yml[greg@control ansible]$ cp ./mycollection/ansible_collections/redhat/rhel_system_roles/tests/storage/test.yml ./storage.yml[greg@control ansible]$ vim disk.yml$ vim storage.yml---- hosts: node4  vars:    storage_use_partitions: true  roles:    - name: redhat.rhel_system_roles.storage      storage_pools:        - name: vg100          disks:          - /dev/vdb          volumes:            - name: lv100              size: 200M              fs_type: ext4              mount_point: '/mnt/lvm100'              state: "present"            - name: lv200              size: 300M              fs_type: xfs              mount_point: '/mnt/lvm200'              state: "absent"$ ansible-navigator run storage.yml  -m stdout</code></pre><h2 id="13-5-管理网络"><a href="#13-5-管理网络" class="headerlink" title="13.5 管理网络"></a>13.5 管理网络</h2><pre class=" language-language-bash"><code class="language-language-bash">[greg@control ansible]$ sudo find ./mycollection/ -name '*.md' | grep network[greg@control ansible]$ vim ./mycollection/ansible_collections/redhat/rhel_system_roles/roles/network/README.md[greg@control ansible]$ sudo find ./mycollection/ -name '*.yml' | grep network $ vim /usr/share/doc/rhel-system-roles/collection/roles/network/README.md$ vim playbook.yml---- hosts: node5  vars:    network_connections:    - name: eth0      interface_name: eth0      type: ethernet      state: up      autoconnect: yes      ip:        address:        - 192.0.2.3/24        dns:        - 192.0.2.2        dns_search:        - example.com        dhcp4: no        gateway4: 192.0.2.1        auto6: no  roles:    - redhat.rhel_system_roles.network$ ansible-navigator run playbook.yml  -m stdout</code></pre><h1 id="14-普通用户远程管理受管主机"><a href="#14-普通用户远程管理受管主机" class="headerlink" title="14 普通用户远程管理受管主机"></a>14 普通用户远程管理受管主机</h1><h2 id="14-1-超级用户远程管理方式"><a href="#14-1-超级用户远程管理方式" class="headerlink" title="14.1 超级用户远程管理方式"></a>14.1 超级用户远程管理方式</h2><pre class=" language-language-bash"><code class="language-language-bash">vim /home/greg/ansible/ansible.cfgremote_user=roothost_key_checking = Falsevim /home/greg/ansible/inventory[all:vars]#ansible_user=rootansible_password=redhat</code></pre><h2 id="14-2-普通用户远程管理方式"><a href="#14-2-普通用户远程管理方式" class="headerlink" title="14.2 普通用户远程管理方式"></a>14.2 普通用户远程管理方式</h2><pre class=" language-language-bash"><code class="language-language-bash"># 使用greg用户远程管理受管主机【bastion】控制节点ansible.cfg[defaults]remote_user = greghost_key_checking = False[privilege_escalation]become=Truebecome_method=sudo become_user=rootbecome_ask_pass=false#管理节点ssh-keygen ssh-copy-id greg@workstationssh greg@workstation#其他受管主机上每一个主机都做如下操作[root@workstation ~]# useradd  greg[root@workstation ~]# echo redhat | passwd --stdin greg[root@workstation ~]# visudogreg    ALL=(ALL)       NOPASSWD: ALL</code></pre>]]></content>
      
      
      <categories>
          
          <category> 自动化运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Ansible的基本使用 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux进阶</title>
      <link href="/2023/05/28/linux/linux-jin-jie/"/>
      <url>/2023/05/28/linux/linux-jin-jie/</url>
      
        <content type="html"><![CDATA[<h1 id="1-提高命令行生产率"><a href="#1-提高命令行生产率" class="headerlink" title="1 提高命令行生产率"></a>1 提高命令行生产率</h1><h2 id="1-1-脚本的分类"><a href="#1-1-脚本的分类" class="headerlink" title="1.1 脚本的分类"></a>1.1 脚本的分类</h2><pre class=" language-language-bash"><code class="language-language-bash"># 系统      --------- --------------------------------Windows   *.bat,*.cmd,.vbdLinux     #!/bin/bash , chmod +x file.sh</code></pre><h2 id="1-2-创建和执行脚本"><a href="#1-2-创建和执行脚本" class="headerlink" title="1.2 创建和执行脚本"></a>1.2 创建和执行脚本</h2><h3 id="1-2-1-指定命令解释器"><a href="#1-2-1-指定命令解释器" class="headerlink" title="1.2.1 指定命令解释器"></a>1.2.1 <strong>指定命令解释器</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">[root@foundation0 ~]# vim /test.sh     #掌握#!/bin/bash                            #指定解释器为/bin/bashdateecho  "hello world"[root@foundation0 ~]# chmod +x test.sh  #赋予脚本执行权限[root@foundation0 ~]# cd /[root@foundation0 ~]# ./test.sh          #可以通过./这种相对路径方式执行脚本[root@foundation0 ~]# /root/test.sh      #或通过绝对路径方式执行脚本[root@foundation0 bin]# first.sh hello world[root@foundation0 bin]# sh first.sh hello world[root@foundation0 bin]# bash first.sh hello world[root@foundation0 bin]# source first.sh hello world[root@foundation0 bin]# . first.sh    hello world脚本中需要书写解释器#!/bin/bash，脚本内容可以是linux命令。linux系统可以通过/etc/shells查看支持的shell类型。也可以通过echo $SHELL来查看当前系统正在使用的shell类型</code></pre><h3 id="1-2-2-执行Bash-Shell"><a href="#1-2-2-执行Bash-Shell" class="headerlink" title="1.2.2 执行Bash Shell"></a>1.2.2 <strong>执行Bash Shell</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">[root@foundation0 /]# which ls[root@foundation0 /]# echo $PATH/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin练习:[root@servera ~]# lsfindfiles  test.sh[root@servera opt]# echo $PATH/root/.local/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin[root@servera opt]# mkdir /root/bin [root@servera opt]# mv /root/test.sh /root/bin/[root@servera opt]# ls /root/bin/test.sh[root@servera opt]# test.shSat Jul 13 09:49:11 PM EDT 2024</code></pre><h3 id="1-2-3-对特殊字符加引号"><a href="#1-2-3-对特殊字符加引号" class="headerlink" title="1.2.3 对特殊字符加引号"></a>1.2.3 <strong>对特殊字符加引号</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">\, '' , ""   #掌握[root@servera /]# echo $SHELL/bin/bash[root@servera /]# echo '$SHELL'$SHELL[root@servera /]# echo "$SHELL"/bin/bash[root@servera /]# echo '$SHELL world' #单引号内容是普通字符串，变量不生效$SHELL world[root@servera /]# echo "$SHELL world" #双引号内变量生效/bin/bash world【f0】[kiosk@foundation0 ~]$ echo $HOSTNAME[kiosk@foundation0 ~]$ ssh root@bastion 'touch /tmp/$HOSTNAME'     [kiosk@foundation0 ~]$ ssh root@bastion 'ls /tmp'-rw-r--r--. 1 root root  0 Jul 13 22:13 bastion.lab.example.com[kiosk@foundation0 ~]$ ssh root@bastion "touch /tmp/$HOSTNAME"     [kiosk@foundation0 ~]$ ssh root@bastion 'ls -l /tmp'total 16-rw-r--r--. 1 root root  0 Jul 13 22:13 bastion.lab.example.com-rw-r--r--. 1 root root  0 Jul 13 22:15 foundation0.ilt.example.com</code></pre><h3 id="1-2-4-与"><a href="#1-2-4-与" class="headerlink" title="1.2.4 ``与$()"></a>1.2.4 <strong>``与$()</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">`命令`   #掌握  优先执行$(命令)在shell中设置一个变量暂时使用[root@servera /]# var=`date`[root@servera /]# var=$(date)[root@servera /]# echo 'to day $var'to day $var[root@servera /]# touch $(date +%H%M%S).txt取消一个变量[root@servera /]# unset var[root@servera /]# echo $var第二个例子whoamiecho whoamiecho `whoami`echo $(whoami)dateecho `date`man datedate +%y%m%ddate +%Y%m%ddate +%Y-%m-%decho $(date +%Y-%m-%d)touch $(date +%Y-%m-%d).txtlstar -zcvf $(date +%Y-%m-%d).tar.gz /etc/lscd /既然可以通过``和$()的结果，通过echo来通过标准输出打印到屏幕上，那么我们也可以将其应用到脚本。vim os.current#!/bin/bash// echo的"-e"参数是启用反斜杠转义: echo -e "User:\t" $(whoami)echo -e "HOST:\t" `hostname`echo -e "ipv4:\t" $(ip a s eth0 | awk '/inet / {print $2}')echo -e "Memory:\t" $(free -h | awk '/Mem/ {print $2}') echo -e "Disk:\t" $(df -ht xfs | awk '/dev/ {print $4}')chmod +x os.current ./os.current </code></pre><h2 id="1-3-使用循环更高效的命令"><a href="#1-3-使用循环更高效的命令" class="headerlink" title="1.3 使用循环更高效的命令"></a><strong>1.3 使用循环更高效的命令</strong></h2><h3 id="1-3-1-for语句"><a href="#1-3-1-for语句" class="headerlink" title="1.3.1 for语句"></a>1.3.1 <strong>for语句</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">语法：for variable in list    do        command variabledone例子：for i in 1 2 3        do         echo $idone例子2：for  i in 1 2 3;do    echo $idone# echo {1..10}# echo $(seq 1 10)[root@servera ~]# echo {1..10}      #掌握1 2 3 4 5 6 7 8 9 10[root@servera ~]# echo $(seq 1 10)1 2 3 4 5 6 7 8 9 10[root@servera ~]# for i in host1 host2 host3;do echo $i;done    #掌握host1host2host3[root@servera ~]# for num in host{1..3};do echo $num;done         #掌握host1host2host3[root@servera ~]# for num in `ls /`;do echo $num;done             #掌握[root@servera ~]# cd /opt/[root@servera opt]# ls[root@servera opt]# touch file{1..3}[root@servera opt]# lsfile1  file2  file3[root@servera opt]# for i in file*;do ls $i;donefile1file2file3[root@servera opt]# vim for.sh   #(考点)#!/bin/bashfor i in 1 2 3;do    echo $idone[root@foundation0]#for i in bastion  workstation utility servera serverb;do rht-vmctl start $i;done小技巧[root@servera ~]# echo ${HOSTNAME}Oservera.lab.example.comO[root@servera ~]# echo $HOSTNAME\Oservera.lab.example.comO练习：[root@bastion /]# vim user_list.txt user1user2user3[root@servera ~]# vim user.sh#!/bin/bashfor i in `cat user_list.txt`;do        useradd testuser2         echo P@ssw0rduser2a | passwd --stdin testuser2done[root@servera ~]# sh user.sh</code></pre><h3 id="1-3-2-在脚本中使用退出代码"><a href="#1-3-2-在脚本中使用退出代码" class="headerlink" title="1.3.2 在脚本中使用退出代码"></a>1.3.2 <strong>在脚本中使用退出代码</strong></h3><p>  处理完所有内容后，脚本会退出到调用它的进程。但是，有时候可能需要加载完成之前退出脚本，比如加载遇到错误条件时。可以通过加载脚本中使用exit命令来实现这一目的</p><p>  当脚本遇到exit命令时，脚本将立即退出且不会对脚本的其余内容进行处理</p><p>  可以使用可选的整数参数（0到255之间，表示退出代码）来执行exit命令。退出代码进程完成后返回的代码。退出代码值0表示没有错误。所有其他非零值都表示存在错误的退出代码</p><p>  尽可以使用不同的非零值来区分遇到的不同类型错误。此退出代码传回到父进程，后这将它存储在？变量中，并可通过$?进行访问。</p><pre class=" language-language-bash"><code class="language-language-bash">[root@servera /]# vim hello.sh#!/bin/bashecho "hello world"exit 1[root@servera /]# echo $?</code></pre><h3 id="1-3-3-使用运算符执行测试"><a href="#1-3-3-使用运算符执行测试" class="headerlink" title="1.3.3 使用运算符执行测试"></a>1.3.3 <strong>使用运算符执行测试</strong></h3><pre class=" language-language-bash"><code class="language-language-bash"># test与[]:test 0 -ne 1    36  echo $?   37  test 0 -ge 0    38  echo $?   39  test 0 -ge 1    40  echo $?   41  test 8 -gt 4   42  echo $?   43  [ 0 -ge 0 ]   44  echo $?-eq 等于则为真-ne 不等于则为真-gt 大于则为真-lt 小于则为真-ge 大于等于则为真-le 小于等于则为真字符串判断= ==  != [ 字符 == 字符 ][ 字符 != 字符 ]单目，双目-e 文件和文件夹-f 普通文件-d 目录-c 设备文件</code></pre><h3 id="1-3-4-exit、if、elif、else"><a href="#1-3-4-exit、if、elif、else" class="headerlink" title="1.3.4 exit、if、elif、else"></a>1.3.4 <strong>exit、if、elif、else</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">if [ 条件 ]  then       声明fiif [ xx ];then     commandfi 一、vim if.sh#!/bin/bashif [ 0 -ge 0 ];then        echo okfi二、vim test.sh#!/bin/bashif [ -e /file1 ];then        echo one        exit 10fi三、#!/bin/bashif [ -e /file1 ];then        echo one        exit 10else        echo two        exit 20fi四、#!/bin/bashif [ -e /file1 ];then        echo one        exit 10elif [ -e /opt/file1 ];then        echo two        exit 20else        echo three        exit 30fi</code></pre><h3 id="1-3-5-位置变量"><a href="#1-3-5-位置变量" class="headerlink" title="1.3.5 位置变量"></a>1.3.5 <strong>位置变量</strong></h3><pre class=" language-language-bash"><code class="language-language-bash"># $0、$1、$2..$9、$#:vim ping.sh#!/bin/bashping -c $2 172.25.254.$1echo '$0: ' $0echo '$1: ' $1echo '$2: ' $2echo '$3: ' $3echo '$#: ' $#[root@servera ~]# chmod +x ping.sh[root@servera ~]# ./ping.sh 254 5PING 172.25.254.254 (172.25.254.254) 56(84) bytes of data.64 bytes from 172.25.254.254: icmp_seq=1 ttl=63 time=3.02 ms64 bytes from 172.25.254.254: icmp_seq=2 ttl=63 time=0.976 ms64 bytes from 172.25.254.254: icmp_seq=3 ttl=63 time=1.03 ms64 bytes from 172.25.254.254: icmp_seq=4 ttl=63 time=1.09 ms64 bytes from 172.25.254.254: icmp_seq=5 ttl=63 time=2.16 ms--- 172.25.254.254 ping statistics ---5 packets transmitted, 5 received, 0% packet loss, time 12msrtt min/avg/max/mdev = 0.976/1.654/3.015/0.808 ms$0:  ./ping.sh       脚本名$1:  254             执行脚本时赋予脚本的第一个值$2:  5               执行脚本时赋予脚本的第二个值$3: $#:  2               一共赋予多少个值补充:$@                    具体赋予了什么值$？                    看上一条命令的返回值0为正常执行，非0是非正常执行$$                    查看子进程进程号创建一个添加用户的脚本在system1上创建一个脚本，名为/root/makeusers，此脚本能实现为系统system1创建本地用户，并且这些用户的用户名来自一个包含列表的文件。用户满足下列要求：（1） 此脚本要求提供一个参数，此参数就是包含用户名列表的文件（2） 如果没有提供参数，此脚本应该给出下面的提示信息 Usage: /root/makeusers userfile然后退出并返回相应的值（3） 如果提供一个不存在的文件名，此脚本应该给出下面的提示信息 Input file not found然后退出并返回相应的值（4） 创建的用户登录shell为/bin/false（5） 此脚本不需要为用户设置密码[root@servera ~]# cd /root/[root@servera ~]# cat /root/userfiletestuser1testuser2testuser3[root@servera ~]# vim /root/makeusers#!/bin/bashif [ $# -lt 1 ];then        echo "Usage: $0 userfile"        exit 1elif [ ! -f $1 ];then        echo "Input file not found"        exit 1else        for i in `cat $1`;do                /usr/sbin/useradd -s /bin/false $i        donefi[root@servera ~]# ./root/makeusers /root/userlist</code></pre><h2 id="1-4-cut"><a href="#1-4-cut" class="headerlink" title="1.4 cut"></a><strong>1.4 cut</strong></h2><pre class=" language-language-bash"><code class="language-language-bash">grep root /etc/passwd   #重要 grep将文本中包含关键字的行打印出来，默认是从上到下的查询顺序。查文件内容用的grep root /etc/passwd | cut  -d :  -f 1,3-5      #截取文本中的列 -d 指定分隔符号 -f 指定列     grep root /etc/passwd | cut -c 1,3-5           #-c 指定字符        grep ^root /etc/passwdgrep nologin$ /etc/passwdcat -n /etc/passwd                                   grep -n ^# /etc/selinux/config   grep ^$ /etc/selinux/config  | wc -lgrep -n ^$ /etc/selinux/config   // 过滤空行  grep -v ^$ /etc/selinux/config   // 过滤非空行 grep -vn ^# /etc/selinux/config  // 过滤非#开头的行cat /etc/selinux/config | grep -v ^# | grep -v ^$[root@foundation0 /]# grep ng /usr/share/xml/iso-codes/iso_639_3.xml > /1.txt[root@foundation0 /]# [root@foundation0 /]# [root@foundation0 /]# grep ^$ /1.txt[root@foundation0 /]# grep ^$ /1.txt | wc -l额外：# grep -e root -e 0 /etc/passwd       grep -e可以在一个文件内单独匹配多个参数root:x:0:0:root:/root:/bin/bashsync:x:5:0:sync:/sbin:/bin/syncshutdown:x:6:0:shutdown:/sbin:/sbin/shutdown# grep -E 'root|0' /etc/passwd[root@foundation0 ~]# grep 'kiosk|root' /etc/passwd[root@foundation0 ~]# egrep 'kiosk|root' /etc/passwdroot:x:0:0:root:/root:/bin/bashoperator:x:11:0:operator:/root:/sbin/nologinkiosk:x:1000:1000::/home/kiosk:/bin/bash[root@foundation0 ~]# grep  -E 'kiosk|root' /etc/passwdroot:x:0:0:root:/root:/bin/bashoperator:x:11:0:operator:/root:/sbin/nologinkiosk:x:1000:1000::/home/kiosk:/bin/bashgrep -A  2 root #查看root关键字后两行grep -B         #前x行grep -C         #前后x行grep -A 2 daemon   /etc/passwdhead -5 /etc/passwdhead -5 /etc/passwd > /opt/passwd.tstlscat passwd.tst grep -A 2 daemon grep -A 2 daemon passwd.tst grep -B  2 daemon passwd.tst grep -C  2 daemon passwd.tst // 正则表达式:[root@foundation0 /]# cat testfile catcotcutcutcutdogdogconcatenatedogmacategoryeducatedboondogglevindicationchilidogaacatcaaaaaaaat匹配行首和行尾[root@foundation0 /]# grep ^cat testfile catcategory [root@foundation0 /]# grep cat$ testfile cataacat[root@foundation0 /]# grep ^cat$ testfile cat向正则表达式中添加通配符和倍数1、.匹配换行符以外的任何“单”个字符[root@servera opt]# grep c.t testfile 2、选择[]内的一个字符。搜索结果应为c开头、中间a或o或u、结尾t[root@servera opt]# grep c[aou]t testfile     cat cot cut3、倍数* 匹配前面的子表达式零次或多次[root@servera opt]# grep c*t testfile  4、倍数通常与通配符一起使用，如.*  这将匹配任何以包含c和t中间有0个或多个任意字符的行[root@servera opt]# grep c.*t testfile </code></pre><h1 id="2-Linux计划任务"><a href="#2-Linux计划任务" class="headerlink" title="2 Linux计划任务"></a><strong>2 Linux计划任务</strong></h1><h2 id="2-1-at"><a href="#2-1-at" class="headerlink" title="2.1 at"></a><strong>2.1 at</strong></h2><pre class=" language-language-bash"><code class="language-language-bash">[root@servera /]# rpm -q atat-3.1.20-11.el8.x86_64[root@servera /]# systemctl status atd.service [root@servera /]# rpm -qc at/etc/at.deny/etc/pam.d/atd/etc/sysconfig/atd语法：at 选项 参数at 时间  #设置一个任务atq 查询atrm 删除任务创建13:49分时候执行touch指令[root@servera /]# at 13:49warning: commands will be executed using /bin/shat> touch /at.txtat> <EOT>          ctrl+d退出3分钟后执行echo `date` >> /home/student/myjob.txt | at now +3min明天17:20点执行echoat 17:20 tomorrowat> echo hello三天后下午5:10分执行/bin/lsat 5:20pm+3daysat> /bin/ls使用时间，和月/日/年的方式指定任务at 17:20 5/20/2022在7月的31日上午10点at 10am Jul 31查看[root@servera /]# atq作业编号  执行日期和时间             队列a           运行作业所有者7        Sun Mar  8 13:51:00 2020 a              root[root@servera /]# at -l查看任务内容[root@servera /]# at -c 7删除[root@servera /]# at -d 9[root@servera /]# atrm 8systemctl status atdman atat 17:30man atat - 1at -c 1atqatrm 1atqat 17:20atqat 17:30 08/19/2022at 17:30 2022-7-24man atat now +3minat now +3hourat now +3daysman atat 4pm +3daysat 16:02 +3daysman atat teatimeman athistoryecho 123 > /root/backup | at 17:20atqat -c 11atq监控任务[root@servera ~]# watch atq      ctrl+c 退出监控模式一次性计划任务重启后，任务未执行依然会保存，直至删除或执行完毕后消失。黑白名单/etc/at.deny  哪个用户在黑名单里，哪个用户不能使用at，该文件默认存在/etc/at.allow 在白名单内的用户可以使用at，白名单以外的人不能使用，白名单和黑名单同时存在时优先于黑名单，该文件默认不存在，如使用需自己创建。</code></pre><h2 id="2-2-crontab"><a href="#2-2-crontab" class="headerlink" title="2.2 crontab"></a><strong>2.2 crontab</strong></h2><pre class=" language-language-bash"><code class="language-language-bash">[root@servera /]# systemctl status crond.service  #重要[root@servera /]# systemctl  enable crond[root@servera /]# systemctl is-enabled crond[root@servera /]# systemctl enable --now crond[root@servera ~]# rpm -q crontabpackage crontab is not installed[root@servera ~]# rpm -qa | grep croncronie-anacron-1.5.7-8.el9.x86_64cronie-1.5.7-8.el9.x86_64crontabs-1.11-27.20190603git.el9_0.noarch[root@servera ~]# rpm -qc crontabs/etc/crontab/etc/sysconfig/run-parts[root@servera ~]# vim /etc/crontab[root@servera ~]# crontab 选项 -e  编辑计划任务    crontab -e-u  指定用户          crontab -u student -e-r  删除所有任务       crontab -r              #删除某个任务时利用-e选项进入编辑模式手动删除即可。-l  列出                crontab -lcron时间表示方法:前五个字段使用相同的语法规则规则          说明*             表示“无关紧要”，始终x-y           表示范围,x到y(含)x,y           表示列表，也可以包含范围，如5,10-13,15*/x           表示x的时间间隔*       *       *       *       *       command分       时     日      月       周       任务内容0-59    0-23   1-31    1-12    0-71.每年2月2日上午9点执行echo  hello0       9       2       2       *       /usr/bin/echo hello  #which echo可以寻找命令绝对路径2.每天3到6点 第2分 执行一个脚本/root/1.sh2   3-6  *  *   * /bin/sh /root/1.sh3.每两个小时的第2分钟，执行一个脚本/root/1.sh2   */2   * *   *    /bin/sh /root/1.sh4.每年７月的第１天和第５天，两点２分，执行一个脚本/root/1.sh2   2   1,5  7  *    /bin/sh /root/1.sh5.配置cron任务，每隔2分钟运行logger “Ex200 in progress”，以harry用户身份运行[root@servera /]# id harry [root@servera /]# crontab -u harry -e[root@servera /]# crontab -u harry -l  (也可以su - harry切换到任务用户，运行crontab -l)*/2     *   *   *   *    /usr/bin/logger “Ex200 in progress” 删除某条可以crontab -e 进去编辑删除用户的所有任务 crontab -r    黑名单：vim /etc/cron.deny  限制用户使用crond服务白名单：mandbman -k cronman 1 crontabecho harry >> /etc/cron.allow白名单启用后，就不用黑名单了，谁在白名单里谁能用该功能   测试：su - harry,crontab -e    #可以使用exitsu - tom,crontab -e     #不可使用// 练习:1、每年2月2日上午9点执行echo hello任务   0    9   2   2  *  /usr/bin/echo hello2、七月每周5的,9点至下午5点，每5分钟执行echo hi   */5  9-17  * 7   5  /usr/bin/echo hello3、执行一个任务,该任务每隔2分钟运行以下命令/usr/bin/logger "hello"，给harry设定这个任务   */2 *    *   *   *  /usr/bin/logger "hello"4、使用root身份为用户tom设置一个计划任务，每天的下午2点43分执行/home/tom/tom.sh脚本   crontab -u tom -e   43  14  *  *  *  /bin/bash /home/tom/tom.sh5、每天的，1点，6点，9点整，将/var/log/messages文件进行归档，要求使用gzip工具，归档文件保存在/tmp/当前时间.tar.gz   0  1,6,9  *  *   *  tar -zcvf /tmp/$(date +%Y-%m-%d).tar.gz /var/log/messages</code></pre><h2 id="2-3-管理临时文件"><a href="#2-3-管理临时文件" class="headerlink" title="2.3 管理临时文件"></a><strong>2.3 管理临时文件</strong></h2><pre class=" language-language-bash"><code class="language-language-bash">rhel6 tmpwatchsystemd-tmpfiles1 手动清理临时文件[root@servera /]# systemctl status systemd-tmpfiles-setup   查看服务状态[root@servera /]# rpm -qf /usr/lib/tmpfiles.d/tmp.conf systemd-239-13.el8.x86_64cp /usr/lib/tmpfiles.d/tmp.conf /etc/tmpfiles.d/cd /etc/tmpfiles.d/vim tmp.confq /tmp 1777 root root 5dsystemd-tmpfiles --clean /etc/tmpfiles.d/tmp.conf 2 清理临时文件小实验创建一个存放临时文件的目录，并且设置相应权限/run/momentary 0700 root root[root@servera /]# vim /etc/tmpfiles.d/momentary.confd /run/momentary 0700 root root 30s创建存放临时文件目录[root@servera /]# systemd-tmpfiles --create /etc/tmpfiles.d/momentary.conf [root@servera /]# ll /run/momentary/ -ddrwx------. 2 root root 40 Mar  8 15:08 /run/momentary/在目录中创建一个文件叫做mom.txt，此文件模拟临时文件[root@servera /]# touch /run/momentary/mom.txt[root@servera /]# sleep 30[root@servera /]# ll /run/momentary/mom.txt -rw-r--r--. 1 root root 0 Mar  8 15:08 /run/momentary/mom.txt输入清除临时文件命令，清除所有的临时文件[root@servera /]# systemd-tmpfiles --clean /etc/tmpfiles.d/momentary.conf [root@servera /]# ll /run/momentary/mom.txt ls: cannot access '/run/momentary/mom.txt': No such file or directory</code></pre><h1 id="3-系统性能调优"><a href="#3-系统性能调优" class="headerlink" title="3 系统性能调优"></a><strong>3 系统性能调优</strong></h1><h2 id="3-1-tuned"><a href="#3-1-tuned" class="headerlink" title="3.1 tuned"></a><strong>3.1 tuned</strong></h2><h3 id="3-1-1-查看状态"><a href="#3-1-1-查看状态" class="headerlink" title="3.1.1 查看状态"></a>3.1.1 <strong>查看状态</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">[root@servera tmp]# yum install -y tuned[root@servera tmp]# systemctl enable --now tuned[root@servera tmp]# systemctl status tuned</code></pre><h3 id="3-1-2-tuned-adm管理指令"><a href="#3-1-2-tuned-adm管理指令" class="headerlink" title="3.1.2 tuned-adm管理指令"></a>3.1.2 <strong>tuned-adm管理指令</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">[root@servera tmp]# tuned-adm list  #列出优化方案[root@servera tmp]# tuned-adm recommend   #系统推荐的优化方案[root@servera tmp]# tuned-adm profile virtual-guest #修改优化方案为virtual-guest[root@servera tmp]# tuned-adm off #关闭优化，默认不关闭，考试时不要关闭</code></pre><h3 id="3-1-3-配置文件存储路径"><a href="#3-1-3-配置文件存储路径" class="headerlink" title="3.1.3 配置文件存储路径"></a>3.1.3 <strong>配置文件存储路径</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">每个优化方案对应要给配置文件，其中描述了修改的内核参数路径：/usr/lib/tuned/</code></pre><h2 id="3-2-使用cockpit修改调优的方式"><a href="#3-2-使用cockpit修改调优的方式" class="headerlink" title="3.2 使用cockpit修改调优的方式"></a><strong>3.2 使用cockpit修改调优的方式</strong></h2><pre class=" language-language-bash"><code class="language-language-bash">【servera】systemctl start cockpit【foundation】打开浏览器输入：https://servera:9090--点击右侧高级选项---添加访问---账号密码：root redhat ----左边Overview---找到configure--找到调优</code></pre><h2 id="3-3-调节nice值"><a href="#3-3-调节nice值" class="headerlink" title="3.3 调节nice值"></a><strong>3.3 调节nice值</strong></h2><pre class=" language-language-bash"><code class="language-language-bash">进程有默认优先级，但是优先级默认不能更改，但是可以通过修改nice值来影响进程优先级。nice值+old优先级=new优先级Nice +  80   = 新优先级Nice值调节范围：    root：修改范围-20~19    调节优先级的工作由root来执行    user:   修改范围0~19        调节后无法降级    优先级：        数值越大优先度越低        数值越小优先级越高nice 直接给一个新的指令设置优先级renice 给一个现有的进程调节优先</code></pre><h3 id="3-3-1-nice值管理"><a href="#3-3-1-nice值管理" class="headerlink" title="3.3.1 nice值管理"></a>3.3.1 <strong>nice值管理</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">语法：nice 选项  command选项：-n ： -n 后面添加优先级 例：nice -n 10 vim 1.txt 语法：renice 选项 进程号-n：  -n 后面添加优先级 例：renice -n 10 pid</code></pre><h2 id="3-4-练习"><a href="#3-4-练习" class="headerlink" title="3.4 练习"></a><strong>3.4 练习</strong></h2><pre class=" language-language-bash"><code class="language-language-bash">[root@clear ~]# cd /opt/[root@clear opt]# lsdir1  file1[root@clear opt]# rm -rf *[root@clear opt]# vim test.txt  &   #生成一个进程，&放后台[1] 59090[root@clear opt]# ps -lF S   UID     PID    PPID  C PRI  NI ADDR SZ WCHAN  TTY          TIME CMD4 S     0    1139    1138  0  80   0 - 59210 -      pts/2    00:00:03 bash0 T     0   59090    1139  1  80   0 - 60817 -      pts/2    00:00:00 vim  #出现了0 R     0   59091    1139  0  80   0 - 63799 -      pts/2    00:00:00 ps[root@clear opt]# nice -n 10 vim 1.txt &  #创建新进程 并且添加nice值为正10[2] 59097[root@clear opt]# ps -lF S   UID     PID    PPID  C PRI  NI ADDR SZ WCHAN  TTY          TIME CMD4 S     0    1139    1138  0  80   0 - 59243 -      pts/2    00:00:03 bash0 T     0   59090    1139  0  80   0 - 60817 -      pts/2    00:00:00 vim0 T     0   59097    1139  2  90  10 - 60817 -      pts/2    00:00:00 vim  #在这里0 R     0   59098    1139  0  80   0 - 63799 -      pts/2    00:00:00 ps[2]+  Stopped                 nice -n 10 vim 1.txt[root@clear opt]# renice -n -5 59090         #修改现有进程，nice值为负5，指定进程号59090 (process ID) old priority 0, new priority -5[root@clear opt]# ps -lF S   UID     PID    PPID  C PRI  NI ADDR SZ WCHAN  TTY          TIME CMD4 S     0    1139    1138  0  80   0 - 59243 -      pts/2    00:00:03 bash0 T     0   59090    1139  0  75  -5 - 60817 -      pts/2    00:00:00 vim   #已经改变了0 T     0   59097    1139  0  90  10 - 60817 -      pts/2    00:00:00 vim0 R     0   59100    1139  0  80   0 - 63799 -      pts/2    00:00:00 ps[root@clear opt]# </code></pre><h1 id="4-管理SELinux"><a href="#4-管理SELinux" class="headerlink" title="4 管理SELinux"></a><strong>4 管理SELinux</strong></h1><h2 id="4-1-介绍selinux"><a href="#4-1-介绍selinux" class="headerlink" title="4.1 介绍selinux"></a><strong>4.1 介绍selinux</strong></h2><h3 id="4-1-1-selinux简介"><a href="#4-1-1-selinux简介" class="headerlink" title="4.1.1 selinux简介"></a>4.1.1 <strong>selinux简介</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">SELinux全称是Security Enhanced Linux (安全强化 Linux),是MAC (Mandatory Access Control，强制访问控制系统)的一个实现，在于明确的指明某个进程可以访问哪些资源(文件、网络端口等)强制访问控制系统的用途在于增强系统抵御0-Day攻击(利用尚未公开的漏洞实现的攻击行为)的能力它不是网络防火墙或FACL的替代品，在用途上也不重复。在目前的大多数发行版中，已经默认在内核集成了SELinux</code></pre><h3 id="4-1-2-selinux实现原理"><a href="#4-1-2-selinux实现原理" class="headerlink" title="4.1.2 selinux实现原理"></a>4.1.2 <strong>selinux实现原理</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">    普通权限和selinux权限对比：    传统的Linux使用用户、文件权限的概念来限制资源的访问，通过对比进程的发起用户和文件权限以此来保证系统资源的安全，这是一种自由访问控制方式（DAC）    SELinux是Linux下的一种安全强化机制，为进程和文件加入了除权限之外更多的限制来增强访问条件，这种方式为强制访问控制(MAC)    进程和文件都有相应的标签，称为上下文，只有进程上下文和文件上下文对应上，该进程才可以访问文件    何为对应？系统中大量的进程和文件上下文已经被定义，如http服务进程上下文为httpd_t域，/var/www/html/目录上下文为httpd_sys_content_t，后者归属于前者的匹配域内，即可匹配      分类                  源               目的--------------------- ---------------- ----------------------------  传统文件系统权限DAC   用户             文件系统权限  SELinux权限MAC        用户进程上下文   文件（或目录端口等）上下文</code></pre><h3 id="4-1-3-selinux的限制范围"><a href="#4-1-3-selinux的限制范围" class="headerlink" title="4.1.3 selinux的限制范围"></a>4.1.3 <strong>selinux的限制范围</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">SElinux具有多种上下文类型，常见种类:     安全上下文(限制文件的访问)：该种类上下文存在于内存和文件中，进程访问文件inode时读取到上下文类型进行对比   布尔值(限制软件功能的访问)：该种类型上下文主要控制某些进程是否可以访问服务常用功能中出现的文件   安全端口(限制服务的访问)：selinux会限制服务启用的非标准端口号 ID                                     SELinux---- ------------ --------------------- --------------------------------------------- Filesystem   chmod, chown, setfacl semanage fcontext ... restorecon ... chcon                                          ... touch /.autorelabel Service      vim /etc/\*.conf      setsebool -P ... Firewall     firewall-cmd ...      semanage port ... SELinux      vim          /etc/selinux/config             </code></pre><h3 id="4-1-4-查看上下文"><a href="#4-1-4-查看上下文" class="headerlink" title="4.1.4 查看上下文"></a>4.1.4 <strong>查看上下文</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">[root@servera ~]# dnf install -y httpd[root@servera ~]# systemctl enable --now httpd进程：              ps auxZ            ps -eZ[root@servera ~]# ps auxZ | grep httpdsystem_u:system_r:httpd_t:s0    root      1971  0.0  1.2 273800 10496 ?        Ss   04:58   0:00 /usr/sbin/httpd -DFOREGROUND文件：ls -Z[root@servera ~]# ll -dZ /var/www/html/system_u:object_r:httpd_sys_content_t:s0 /var/www/html/只要进程和文件的安全上下文匹配，该进程就可以访问该文件资源</code></pre><h3 id="4-1-5-security-context介绍"><a href="#4-1-5-security-context介绍" class="headerlink" title="4.1.5 security context介绍"></a>4.1.5 <strong>security context介绍</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">content一词是我们常说的上下文，安全上下文有5个字段，以：冒号分割，unconfined_u   :object_r:   httpd_sys_content_t:      s0           [类别]   身份 user -u    角色roles -r  类型 type  -t                             灵敏度（级别）     类别     1) 身份字段（user)   用于标识该数据被哪个身份所拥有，相当于权限中的用户身份。这个字段并没有特别的作用，知道就好。常见的身份类型有以下 3 种：- root：表示安全上下文的身份是 root。- system_u：表示系统用户身份，其中“_u”代表 user。- user_u：表示与一般用户账号相关的身份，其中“_u”代表 user。- 以使用 seinfo 命令来进行查询2) 角色（role）主要用来表示此数据是进程还是文件或目录。这个字段在实际使用中也不需要修改，所以了解就好。常见的角色有以下两种：- object_r：代表该数据是文件或目录，这里的“_r”代表 role。- system_r：代表该数据是进程，这里的“_r”代表 role。3) 类型（type）   类型字段是安全上下文中最重要的字段，进程是否可以访问文件，主要就是看进程的安全上下文类型字段是否和文件的安全上下文类型字段相匹配，如果匹配则可以访问。#（掌握重点）注意，类型字段在文件或目录的安全上下文中被称作类型（type），但是在进程的安全上下文中被称作域（domain）。也就是说，在主体（Subject）的安全上下文中，这个字段被称为域；在目标（Object）的安全上下文中，这个字段被称为类型。域和类型需要匹配（进程的类型要和文件的类型相匹配），才能正确访问。context查询工具seinfo、sesearch    seinfo -u    # 查询所有的user字段的种类    seinfo -r    # 查询所有的role字段的种类    seinfo -t    # 查询所有的type字段的种类 sesearch -A 可以查询什么类型进程可以读取什么type类型的文件    sesearch -A -s 进程type    # 查询type类型的进程能够读取的文件type       sesearch -A -b 规则（规则的boolean值，所以为-b选项，理解为bool规则）    [root@foundation0 ~]# sesearch -A -s httpd_t | grep '^allow httpd_t httpd_sys_content_t'4) 灵敏度   灵敏度一般是用 s0、s1、s2 来命名的，数字代表灵敏度的分级。数值越大，代表灵敏度越高。5) 类别   类别字段不是必须有的，所以我们使用 ls 和 ps 命令查询的时候并没有看到类别字段。通过seinfo -u -x查看-serverasystemctl stop firewalldsetenforce 1yum install -y httpdsystemctl enable --now httpdps auxZ | grep httpd     #-Z 大写Z就表示上下文，发现http_t字段就是httpd服务进程上下文'类型'字段cd /var/www/htmlll -dZ /var/www/html    #发现上下文是httpd开头echo test >  /var/www/html/index.html    #创建测试页面ll -Z  /var/www/html/index.html #发现所有文件类型字段上下文，都是httpd开头,看上下文的第三段 类型字段-foundation0 打开浏览器，网址位置输入 172.25.250.10/index.html   #访问servera的网页发现可以访问到网页内容，证明上下文一致，不被限制，可以访问-serverachcon -t default_t /var/www/html/index.html   #更改了file3的上下文ll -Z  #发现index.html上下文类型字段变成default_t-foundation0 打开浏览器，网址位置输入 172.25.250.10/index.html   #访问servera的网页发现不可以访问到网页内容，证明上下文不一致，被限制，不可访问-serverall -dZ /var/www/html/  #查看到httpd相关上下文chcon -t httpd_sys_content_t /var/www/html/index.html #更改上下文改为httpd_sys_content_t-foundation0 打开浏览器，网址位置输入 172.25.250.10/index.html   #访问servera的网页发现可以访问到网页内容，证明上下文一致，不被限制，可以访问</code></pre><h2 id="4-2-更改SElinux强制模式"><a href="#4-2-更改SElinux强制模式" class="headerlink" title="4.2 更改SElinux强制模式"></a><strong>4.2 更改SElinux强制模式</strong></h2><h3 id="4-2-1-临时开启或关闭selinux"><a href="#4-2-1-临时开启或关闭selinux" class="headerlink" title="4.2.1 临时开启或关闭selinux"></a>4.2.1 <strong>临时开启或关闭selinux</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">#临时修改意思是重启失效[root@clear /]# getenforce Enforcing[root@clear /]# setenforce usage:  setenforce [ Enforcing | Permissive | 1 | 0 ]    # 强制 1|宽容 0[root@clear /]# setenforce 0[root@clear /]# getenforce Permissive[root@clear /]# setenforce Permissive[root@clear /]# getenforce Permissive[root@clear /]# setenforce 1[root@clear /]# getenforce Enforcing</code></pre><h3 id="4-2-2-永久开启或关闭selinux"><a href="#4-2-2-永久开启或关闭selinux" class="headerlink" title="4.2.2 永久开启或关闭selinux"></a>4.2.2 <strong>永久开启或关闭selinux</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">-RHEL<=9[root@servera ~]# vim /etc/selinux/config#     enforcing - SELinux security policy is enforced.#     permissive - SELinux prints warnings instead of enforcing.#     disabled - No SELinux policy is loaded.SELINUX=enforcing修改后，重启操作系统生效</code></pre><h3 id="4-2-3-继承特性"><a href="#4-2-3-继承特性" class="headerlink" title="4.2.3 继承特性"></a>4.2.3 <strong>继承特性</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">继承：1、在父目录下创建文件会继承selinux上下文touch2、cp时不继承，即cp时不保留原来的父目录上下文关系   创建了文件并且移动(mv)会保留原来的父目录上下文关系   cp -a(rp)复制时会保留之前的上下文关系【servera】 [root@servera /]# cd /var/www/html/[root@servera html]# ll -dZ .drwxr-xr-x. 2 root root system_u:object_r:httpd_sys_content_t:s0 23 May 21 09:13 .[root@servera html]# touch haha.txt[root@servera html]# ll -Z haha.txt -rw-r--r--. 1 root root unconfined_u:object_r:httpd_sys_content_t:s0 0 May 21 10:06 haha.txt[root@servera ~]# cd /tmp/[root@servera tmp]# touch file{1..3}[root@servera tmp]# ls -Z /tmp/file*unconfined_u:object_r:user_tmp_t:s0 /tmp/file1 unconfined_u:object_r:user_tmp_t:s0 /tmp/file2 unconfined_u:object_r:user_tmp_t:s0 /tmp/file3[root@servera tmp]# cp /tmp/file1 /var/www/html/[root@servera tmp]# cp -a /tmp/file2 /var/www/html/[root@servera tmp]# mv /tmp/file3 /var/www/html/[root@servera tmp]# cd /var/www/html/[root@servera html]# ls -Z *unconfined_u:object_r:httpd_sys_content_t:s0 file1           unconfined_u:object_r:user_tmp_t:s0 file3         unconfined_u:object_r:user_tmp_t:s0 file2[root@servera html]# touch /var/www/html/file0[root@servera html]# ll -Z /var/www/html/file0-rw-r--r--. 1 root root unconfined_u:object_r:httpd_sys_content_t:s0 0 Apr 10 05:08 /var/www/html/file0</code></pre><h2 id="4-3-selinux文件上下文规则"><a href="#4-3-selinux文件上下文规则" class="headerlink" title="4.3 selinux文件上下文规则"></a><strong>4.3 selinux文件上下文规则</strong></h2><pre class=" language-language-bash"><code class="language-language-bash">方法1：永久设置，但不记录至数据库      chcon 设置上下文关系方法2：永久设置，记录至数据库      semanage fcontext  添加、修改、查看、删除默认上下文      restorecon 恢复默认上下文 </code></pre><h3 id="4-3-1-chcon"><a href="#4-3-1-chcon" class="headerlink" title="4.3.1 chcon"></a>4.3.1 <strong>chcon</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">chcon 选项 上下文类型  文件[root@servera html]# ll -Z total 0-rw-r--r--. 1 root root unconfined_u:object_r:httpd_sys_content_t:s0 0 Dec 11 05:36 file1-rw-r--r--. 1 root root unconfined_u:object_r:httpd_sys_content_t:s0 0 Dec 11 05:38 file2-rw-r--r--. 1 root root unconfined_u:object_r:user_tmp_t:s0          0 Dec 11 05:37 file3-rw-r--r--. 1 root root unconfined_u:object_r:user_tmp_t:s0          0 Dec 11 05:37 file4[root@servera html]# man chcon[root@servera html]# chcon -t httpd_sys_content_t file3[root@servera html]# ll -Z total 0-rw-r--r--. 1 root root unconfined_u:object_r:httpd_sys_content_t:s0 0 Dec 11 05:36 file1-rw-r--r--. 1 root root unconfined_u:object_r:httpd_sys_content_t:s0 0 Dec 11 05:38 file2-rw-r--r--. 1 root root unconfined_u:object_r:httpd_sys_content_t:s0 0 Dec 11 05:37 file3-rw-r--r--. 1 root root unconfined_u:object_r:usexr_tmp_t:s0         0 Dec 11 05:37 file4</code></pre><h3 id="4-3-2-semanage-fcontext"><a href="#4-3-2-semanage-fcontext" class="headerlink" title="4.3.2 semanage fcontext"></a>4.3.2 <strong>semanage fcontext</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">帮助中查看示例：man semanageman semanage fcontext选项：semanage fcontext -a  添加   添加至数据库-d  删除-l  查看-t  指定上下文-m  修改修改流程：1、查看selinux上下文类型数据库是否有记录？有就恢复I(restorecon)，没有就添加(semanage fcontext -a)2、man semanage fcontext添加文件标签类型至数据库. 添加后，文件并不会更改标签类型3、使用restorecon命令同步和数据库一致【servera】-l[root@clear /]# man semanage fcontext | grep \#root@servera ~]# yum provides sesearchLast metadata expiration check: 2:54:21 ago on Sat Mar  1 00:44:02 2025.setools-console-4.4.3-1.el9.x86_64 : Policy analysis command-line tools for SELinuxRepo        : rhel-9.3-for-x86_64-baseos-rpmsMatched from:Filename    : /usr/bin/sesearch[root@clear /]# semanage  fcontext -l | grep /var/www  看第一行即可[root@clear /]# semanage  fcontext -l | grep /var/www/html/file3/var/www/html/file3                                all files          system_u:object_r:default_t:s0 [root@clear /]# semanage fcontext -a -t httpd_sys_content_t /var/www/html/file3 #数据库没有上下文记录，用-a添加，如已存在则用-m修改数据库中错误的上下文[root@clear /]# semanage  fcontext -l | grep /var/www/html/file3/var/www/html/file1                                all files          system_u:object_r:httpd_sys_content_t:s0 restorecon  恢复文件上下文和数据库一致-v  显示修改标签内容-R  递归[root@clear /]# restorecon -R -v /var/www/html/file3Relabeled /var/www/html/file3 from system_u:object_r:default_t:s0 to system_u:object_r:httpd_sys_content_t:s0[root@clear /]# ll -Z /var/www/html/file3-chcon chcont -t httpd_sys_content_t /var/www/html/index.htmlman semanage fcontext -l | grep \#-semanage fcontextman semanage fcontext -l | grep \#    semanage fcontext -a -t httpd_sys_content_t /var/www/html/index.html semanage fcontext -m -t httpd_sys_content_t /var/www/html/index.htmlsemanage fcontext -d -t httpd_sys_content_t /var/www/html/index.htmlsemanage fcontext -l  /var/www/html/index.htmlrestorecon -R -v /var/www/html/index.html课上练习：1.servera上安装httpd软件2.在/var/www/html目录创建3个文件file0、file1、file2、对应内容test0、test1、test23.修改file0上下文为default_t4.开启httpd服务。关闭防火墙 systemctl stop firewalld5.在f0上用浏览器访问三个网页文件，测试发现，file0访问不到内容，而file1、file2可以6.回到servera上修改file0上下文为httpd_sys_content_t7.再测试</code></pre><h2 id="4-4-管理布尔值"><a href="#4-4-管理布尔值" class="headerlink" title="4.4 管理布尔值"></a>4.4 管理布尔值</h2><h3 id="4-4-1-管理布尔值"><a href="#4-4-1-管理布尔值" class="headerlink" title="4.4.1 管理布尔值"></a>4.4.1 <strong>管理布尔值</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">布尔值主要对应的是应用的功能的开启或关闭getsebool       列出布尔值状态  usersetsebool       设置布尔值开启或关闭on 开，off 关-P              更改布尔值永久生效 setsebool -psemanage boolean -l 查看布尔值是否永久[root@servera /]# yum install -y selinux-policy-doc[root@servera /]# mandb[root@servera /]# man -k '_selinux' | grep httpd[root@servera /]# man 8 httpd_selinux[root@servera /]# man 8 httpd_selinux |  grep -B 1 homedir[root@servera /]# getsebool -a  [root@servera /]# getsebool -a |  grep httpd | grep homedir修改布尔值状态[root@servera /]# setsebool httpd_enable_homedirs on[root@servera /]# semanage boolean -l  | grep httpd_enable_homehttpd_enable_homedirs          (off  ,  off)  Allow httpd to enable homedirs[root@servera /]# setsebool -P httpd_enable_homedirs on  永久生效[root@servera /]# semanage boolean -l  | grep httpd_enable_homehttpd_enable_homedirs          (on   ,   on)  Allow httpd to enable homedirs[root@servera /]# setsebool -P httpd_enable_homedirs off</code></pre><h3 id="4-4-2-使用布尔值调整"><a href="#4-4-2-使用布尔值调整" class="headerlink" title="4.4.2 使用布尔值调整"></a>4.4.2 <strong>使用布尔值调整</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">1.关闭selinux正常使用  apache发布页面托管在用户主页上的web内容功能1.关闭selinux[root@clear /]# setenforce 0;systemctl stop firewalld   2.编辑配置文件[root@clear /]# vim /etc/httpd/conf.d/userdir.conf #UserDir disabled   #注释该行UserDir public_html  #解除该行注释，启用该功能3.切换student用户，制作发布目录和网页[root@clear /]# su - student[student@clear ~]$ mkdir public_html  #创建发布目录[student@clear ~]$ echo  test_web_page > public_html/index.html #制作网页[student@clear ~]$ logout  #退出[root@clear /]# chmod 711 /home/student/  #root用户身份，修改用户家目录权限为711，目的是为了让其他人有权限访问子目录及文件[root@clear /]# systemctl restart httpd4.在foundation上做访问测试firefox  http://172.25.250.10/~student/index.htmltest_web_page5.开启selinux再次访问【172.25.250.10】[root@clear /]# setenforce 1【foundation】firefox  http://172.25.250.10/~student/index.htmlForbiddenYou don't have permission to access /~student/index.html on this server.6.开启对应布尔值，允许该功能[root@clear /]# yum install -y selinux-policy-doc[root@clear /]# mandb[root@clear /]# man -k 'http'[root@clear /]# man 8 httpd_selinux    #文档里搜索homedirs，复制该命令，开启该功能[root@clear /]# setsebool -P httpd_enable_homedirs 1[root@clear /]# getsebool[root@clear /]# getsebool -a[root@clear /]# getsebool -a | grep http | grep homedir  #第一种查询方式root@clear /]# semanage boolean -l | grep homedirs   #第二种查询方式，查布尔值数据库httpd_enable_homedirs          (on   ,   on)  Allow httpd to enable homedirs                              （功能打开，永久生效）7.在foundation上做访问测试firefox  http://172.25.250.10/~student/index.htmltest_web_page</code></pre><h2 id="4-5-安全端口"><a href="#4-5-安全端口" class="headerlink" title="4.5 安全端口"></a><strong>4.5 安全端口</strong></h2><pre class=" language-language-bash"><code class="language-language-bash">实验目标：当apache服务发布端口从80修改为82时，保证服务可以启动并开机自启动。【servera】[root@servera html]# systemctl stop firewalld[root@servera html]# yum install -y httpd[root@servera html]# setenforce 1[root@servera html]# systemctl enable --now httpd   #服务正常启动【f0】curl http://servera/file1 #正常可以访问【servera】[root@servera html]# rpm -qc httpd   #倒数第四行[root@servera html]# vim /etc/httpd/conf/httpd.conf  Listen 82      #47行 练习时可以从80改为82[root@servera html]# systemctl restart httpd      #服务起不来[root@servera html]# cat /var/log/messages  #看日志文件最后的部分*[root@servera html]# man semanage port | grep \#       # semanage port -l       # semanage port -a -t http_port_t -p tcp 81       # semanage port -a -t ssh_port_t -p tcp 8991[root@servera html]# semanage port -l | grep http_port_t   http_port_t                    tcp      80, 81, 443, 488, 8008, 8009, 8443, 9000*[root@servera html]# semanage port -a -t http_port_t -p tcp 82  #添加安全端口*[root@servera html]# semanage port -l | grep http_port_t   #并查看是否有82http_port_t                    tcp      82, 80, 81, 443, 488, 8008, 8009, 8443, 9000pegasus_http_port_t            tcp      5988[root@servera html]# echo haha > /var/www/html/index.html  #手动制作一个测试页[root@servera html]# systemctl restart httpd  #可以启动服务[root@servera html]# systemctl enable httpd #开机自启动[root@servera html]# netstat -ntlp | grep 82[root@servera html]# localhost:82/index.html  #本机测试82端口访问index.html网页文件【f0】# curl http://servera:82/index.html  #再次访问</code></pre><h2 id="4-6-SElinux日志"><a href="#4-6-SElinux日志" class="headerlink" title="4.6 SElinux日志"></a><strong>4.6 SElinux日志</strong></h2><p>  SELinux 会使用被称为 AVC（Access VectorCache，访问矢量缓存）的缓存，如果访问被拒绝（也被称为 AVC拒绝），则会在一个日志文件中记录下拒绝消息</p><p>  这些被拒绝的消息可以帮助诊断和解决常规的SELinux策略违规行为，至于这些拒绝消息到底被记录在什么位置，则取决于 auditd 和<br>rsyslogd 守护进程的状态： 若auditd守护进程正在运行，则拒绝消息将被记录与 /var/log/audit/audit.log 中</p><p>  若 auditd 守护进程没有运行，但 rsyslogd守护进程正在运行，则拒绝消息会记录到 /var/log/messages中</p><pre class=" language-language-bash"><code class="language-language-bash">-a：分析指定的日志文件sealert -a /var/log/audit/audit.log  回显比较慢多等一会</code></pre><h1 id="5-管理基本存储"><a href="#5-管理基本存储" class="headerlink" title="5 管理基本存储"></a><strong>5 管理基本存储</strong></h1><h2 id="5-1-添加分区"><a href="#5-1-添加分区" class="headerlink" title="5.1 添加分区"></a><strong>5.1 添加分区</strong></h2><h3 id="5-1-1-分区方案-MBR-GPT"><a href="#5-1-1-分区方案-MBR-GPT" class="headerlink" title="5.1.1 分区方案-MBR&amp;GPT"></a>5.1.1 <strong>分区方案-MBR&amp;GPT</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">MBR分区方案:MBR叫做主引导记录，存在于磁盘的0柱面0磁道0扇区中，是磁盘的第一个扇区内，大小为512字节，446字节初始化程序加载器，64字节分区表，2字节校验码，每个分区16字节，所以最多4个分区，最大磁盘空间支持2T。主分区和扩展分区编号用1-4，逻辑分区编号5以上GPT分区方案:GPT是GUID Partition Table，全局唯一标识磁盘分区表。它由UEFI启动硬盘，这样就有了UEFI取代传动BIOS，而GPT则取代传统的MBR，windows支持最多128个GPT分区MBR分区方案分区表=64字节1个分区=16字节4x16=64 最多只能记录4个分区 主分区4个分区不够用？比如5个以上？1.主分区最多4个，占分区编号1-4，可以格式化(可使用存放数据)2.扩展分区最多可以有1个，牺牲一个主分区来做扩展分区，它不能格式化（不能使用，不能存放数据），它的作用是装载逻辑分区用的，也就是用扩展分区的空间再划分多个逻辑分区3.逻辑分区-由扩展分区的空间划分而来的，约可以分15个左右。可以格式化（可以使用，可以存放数据），逻辑分区必定从5号开始分区方案:4P、3P+1E  </code></pre><h3 id="5-1-2-分区工具-fdisk-parted"><a href="#5-1-2-分区工具-fdisk-parted" class="headerlink" title="5.1.2 分区工具:fdisk&amp;parted"></a>5.1.2 分区工具:fdisk&amp;parted</h3><pre class=" language-language-bash"><code class="language-language-bash">使用新磁盘流程规划：1.分区（可选）fdisk   parted2.格式化     mkfs3.挂载       mount4.使用      fdisk是一个分区工具，既可以查看磁盘状况，也可以对磁盘进行分区:语法：fdisk  选项  设备名选项：-l 查看所有磁盘状态例：fdisk  -l            #查所有磁盘信息fdisk  -l /dev/vdb   #查某一个磁盘信息</code></pre><h3 id="5-1-3-分区方案练习"><a href="#5-1-3-分区方案练习" class="headerlink" title="5.1.3 分区方案练习"></a><strong>5.1.3 分区方案练习</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">1 MBR分区方案：5G磁盘，每个分区1G3P+1E ， 1E（L5、L6）[root@clear /]# fdisk -l[root@clear /]# fdisk -l /dev/vdb[root@clear /]# fdisk /dev/vdbn   #创建分区p   #选择p主  或  e扩展1   #分区编号回车，不通过扇区范围分配        +1G:设置一个1G大小分区   p:查看分区状态    d:删除    w:保存退出-删除分区Command (m for help): dPartition number (1-6, default 6): 6Partition 6 has been deleted.#partprobe    磁盘分区正常结束后，此命令可以正常执行，不返回任何信息，主要做刷新分表信息通知内核[root@clear /]# fdisk -l /dev/vdb[root@servera ~]# lsblkNAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTSvda    252:0    0   10G  0 disk ├─vda1 252:1    0    1M  0 part ├─vda2 252:2    0  200M  0 part /boot/efi├─vda3 252:3    0  600M  0 part /boot└─vda4 252:4    0  9.2G  0 part /vdb    252:16   0    5G  0 disk ├─vdb1 252:17   0    1G  0 part ├─vdb2 252:18   0    1G  0 part ├─vdb3 252:19   0    1G  0 part ├─vdb4 252:20   0    1K  0 part ├─vdb5 252:21   0    1G  0 part └─vdb6 252:22   0 1021M  0 part vdc    252:32   0    5G  0 disk vdd    252:48   0    5G  0 disk 2 GPT分区方案Command (m for help): gCreated a new GPT disklabel (GUID: 1BA96F11-6DA0-204D-82D6-0CD15E42851E).The old dos signature will be removed by a write command.Command (m for help): nPartition number (1-128, default 1):  回车First sector (2048-10485726, default 2048): 回车 Last sector, +sectors or +size{K,M,G,T,P} (2048-10485726, default 10485726): +1GCreated a new partition 1 of type 'Linux filesystem' and of size 1 GiB.Command (m for help): nPartition number (2-128, default 2): First sector (2099200-10485726, default 2099200): Last sector, +sectors or +size{K,M,G,T,P} (2099200-10485726, default 10485726): +2GCreated a new partition 2 of type 'Linux filesystem' and of size 2 GiB.Command (m for help): l   #列出分区标识类型Command (m for help): t   #改变分区标识类型Partition number (1,2, default 2): 2Partition type (type L to list all types): 19Changed type of partition 'Linux filesystem' to 'Linux swap'.Command (m for help): pDisk /dev/vdb: 5 GiB, 5368709120 bytes, 10485760 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisklabel type: gptDisk identifier: 1BA96F11-6DA0-204D-82D6-0CD15E42851EDevice       Start     End Sectors Size Type/dev/vdb1     2048 2099199 2097152   1G Linux filesystem/dev/vdb2  2099200 6293503 4194304   2G Linux swapCommand (m for help): wThe partition table has been altered.Calling ioctl() to re-read partition table.Syncing disks.# partprobe  同步数据至内核</code></pre><h3 id="5-1-4-parted使用MBR分区方案"><a href="#5-1-4-parted使用MBR分区方案" class="headerlink" title="5.1.4 parted使用MBR分区方案"></a>5.1.4 parted使用MBR分区方案</h3><pre class=" language-language-bash"><code class="language-language-bash">1.mbr方式定义分区方案分区分3个区 主、扩展 、逻辑。再用非交互式创建第二个逻辑[root@servera /]# parted /dev/vdc     #直接指定设备，而不是分区(parted) mklabel        #按回车键  定义分区方案                                                    New disk label type? msdos     #两一下tab键，填写                                             Number  Start  End  Size  Type  File system  Flags(parted) mkpart #分区                                                          Partition type?  primary/extended? p  #主/扩展/逻辑                                    File system type?  [ext2]? ext4   #无用，不生效Start? 2048s#第一个分区，一定从1M或2048s开始                                                          End? 1000MB #分1G分区，1000M、1G、（10G磁盘，可以写10%，完全使用就是100%）                                                              (parted) p          #查看                                                      Number  Start   End     Size   Type     File system  Flags 1      1049kB  1000MB  999MB  primary  ext4         lba(parted) quit        #退出                                                    Information: You may need to update /etc/fstab.[root@servera ~]#udevadm  settle (更新通知内核，建议敲上，不是必要)非交互式方式命令：[root@servera /]# parted /dev/vdc mkpart p ext4 1000MB 2000MB</code></pre><h3 id="5-1-5-parted使用GPT方案"><a href="#5-1-5-parted使用GPT方案" class="headerlink" title="5.1.5 parted使用GPT方案"></a>5.1.5 <strong>parted使用GPT方案</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">[root@clear /]# parted  /dev/vdc  #使用了上一个实验的同样的分区，重复使用了vdc(parted) mklabel                                                          New disk label type? gpt  #再更改分区方案时会抹掉之前的分区数据Warning: The existing disk label on /dev/vdc will be destroyed and all data on this disk will be lost. Doyou want to continue?Yes/No? yes    #yes                                                            (parted) p                                                                 BPartition Table: gpt  #此处显示gpt分区方案(parted) mkpart                                                           Partition name?  []? part1   #分区名字                                               File system type?  [ext2]?     #直接回车                                           Start? 1M                                                                 End? 10%                                                                  (parted) p                                                                Number  Start   End     Size    File system  Name   Flags 1      1049kB  1074MB  1073MB  ext2         part1        #注意Number和Name(parted) mkpartPartition name?  []? part2                                                File system type?  [ext2]?                                                Start? 10%                                                                End? 20%(parted) pNumber  Start   End     Size    File system  Name   Flags 1      1049kB  1074MB  1073MB  ext2         part1 2      1074MB  2147MB  1074MB  ext2         part2   #第二个分区完成(parted) rm                                                               Partition number? 2               #选择第二个分区的Number                                      (parted) p                                                                Number  Start   End     Size    File system  Name   Flags 1      1049kB  1074MB  1073MB  ext2         part1(parted) q                                                                #非交互式方式重新分第二个分区[root@clear /]# parted /dev/vdc mkpart  part2 ext2 10% 20%                [root@clear /]# parted /dev/vdc pNumber  Start   End     Size    File system  Name   Flags 1      1049kB  1074MB  1073MB               part1 2      1074MB  2147MB  1074MB               part2   #成功分配lsblk lsblk /dev/vdcblkid </code></pre><h2 id="5-2-文件系统"><a href="#5-2-文件系统" class="headerlink" title="5.2 文件系统"></a><strong>5.2 文件系统</strong></h2><pre class=" language-language-bash"><code class="language-language-bash">1.分区后，会给分区定义文件系统类型windos: fat32 ntfs exfat linux : exfat 有ext2 ext3 ext4 xfs vfat MacOS : exfat 2.为什么定义文件系统？给磁盘定义一种存储数据的方法，这样块存储设备才可以记录文件数据。3.每个分区都可以定义一个独立的文件系统，定义的方法就是格式化。设备有了文件系统后才可以存储数据。4.操作系统里分区很多，每个分区可能会有相同或不同的文件系统类型，彼此独立5.VFS  虚拟文件系统：作用，将用户发送的指令给任何文件系统做翻译，对于用户来说，我不必学习不同文件系统的操作方法，而是使用常用shell管理指令，就可以通过VFS传递给不同的文件系统了。</code></pre><h3 id="5-2-1-格式化"><a href="#5-2-1-格式化" class="headerlink" title="5.2.1 格式化"></a>5.2.1 <strong>格式化</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">语法：mkfs  选项  文件系统类型  设备名mkfs  -t    ext4      /dev/vdb1选项：-t： 指定文件系统  -t ext4例：[root@servera /]# mkfs -t ext4 /dev/vdc1    例2：使用.点代替-t[root@servera /]# mkfs.ext4 /dev/vdc2</code></pre><h3 id="5-2-2-lsblk"><a href="#5-2-2-lsblk" class="headerlink" title="5.2.2 lsblk"></a><strong>5.2.2 lsblk</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">[root@servera /]# lsblk --fs /dev/vdc   #-f  --fsNAME   FSTYPE LABEL UUID                                 MOUNTPOINTvdc                                                      ├─vdc1 ext4         af656cc6-80e3-4b05-abcf-a162907c2f0a └─vdc2 xfs          64237913-4937-48ff-8afa-28c6fc05124d [root@servera /]# parted /dev/vdc pModel: Virtio Block Device (virtblk)Disk /dev/vdc: 5369MBSector size (logical/physical): 512B/512BPartition Table: msdosDisk Flags: Number  Start   End     Size   Type     File system  Flags 1      1049kB  1000MB  999MB  primary  ext4 2      1000MB  2000MB  999MB  primary  xfs 查看文件系统lsblk  --fs /dev/vdcblkid 超级管理员可用 也可查文件系统类型[root@servera ~]# lsblk -f /dev/vdb1NAME FSTYPE FSVER LABEL UUID                                 FSAVAIL FSUSE% MOUNTPOINTSvdb1 xfs                e36c91a4-83a0-4dba-a015-3f62bdc32b60                [root@servera ~]# blkid /dev/vdb1/dev/vdb1: UUID="e36c91a4-83a0-4dba-a015-3f62bdc32b60" TYPE="xfs" PARTUUID="bd4097dc-01"</code></pre><h2 id="5-3-挂载与永久挂载"><a href="#5-3-挂载与永久挂载" class="headerlink" title="5.3 挂载与永久挂载"></a><strong>5.3 挂载与永久挂载</strong></h2><h3 id="5-3-1-mount"><a href="#5-3-1-mount" class="headerlink" title="5.3.1 mount"></a>5.3.1 <strong>mount</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">mount挂载也称为手动挂载，或临时挂载，重启失效语法：mount 文件系统 挂载点      #源设备需要格式化后，成为文件系统才可挂载   #挂载点需要是空目录例1：mount /dev/vdb1 /mnt/disk_vdb1选项：-t 指定文件系统类型（默认自动识别） mount  -t ext4 /dev/vdb1    /mnt/disk_vdb1-o 指定挂载权限卸载--》再指定权限  mount  -o ro /dev/vdb1    /mnt/disk_vdb1例2：remount 重新挂载 （不卸载的基础上重新挂载）mount -o remount,ro /dev/vdc2卸载：umount 文件系统/挂载点例：umount /dev/vdb1  #或者 umount /mnt/disk_vdb1  #卸载时要退出/mnt/disk_vdb1目录1.临时挂载 [root@clear dev]# mkdir /mnt/disk1   #创建挂载点[root@clear dev]# mount /dev/vdc1 /mnt/disk1   #挂载[root@clear dev]# df -ThFilesystem     Type      Size  Used Avail Use% Mounted on/dev/vdc1      ext4      991M  2.6M  922M   1% /mnt/disk1[root@clear dev]# cd /mnt/disk1  #进入目录  [root@clear disk1]# touch haha   #使用[root@clear disk1]# lshaha  lost+found[root@clear disk1]# cd /卸载[root@clear /]# umount /dev/vdc1[root@clear /]# df -Th  #查看发现已经没有/dev/vdc1的挂载信息，就算成功了 。2.使用UUID方式挂载[root@clear /]# lsblk -f #也可以查看UUID[root@clear /]# blkid[root@clear /]# blkid /dev/vdc1/dev/vdc1: UUID="9bdeba87-5ad0-4c52-b577-0234115df2e1" TYPE="ext4" PARTLABEL="part1" PARTUUID="28f6e868-cd04-434c-9fd3-618f17382797"[root@clear /]# mount UUID="9bdeba87-5ad0-4c52-b577-0234115df2e1" /mnt/disk1 #鼠标左键选定后按滑轮中间。[root@clear /]# df -Th/dev/vdc1      ext4      991M  2.6M  922M   1% /mnt/disk1mount方式挂载，重启失效[root@clear /]# df -Th[root@clear /]# reboot  #重启后再查看挂载</code></pre><h3 id="5-3-2-etc-fstab"><a href="#5-3-2-etc-fstab" class="headerlink" title="5.3.2 /etc/fstab"></a>5.3.2 <strong>/etc/fstab</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">mount临时挂载:mount /dev/vdb1 /mnt/disk1mount -t ext4 -o rw /dev/vdb1 /mnt/disk1    //指定参数以只读方式挂载2.开机自动挂载   永久[root@clear /]# df -h/dev/vdc1       991M  2.6M  922M   1% /mnt/disk1[root@clear /]# umount /dev/vdc1[root@clear /]# df -h[root@clear /]# vim /etc/fstab /dev/vdc1       /mnt/disk1      ext4    defaults    0     0设备ID或设备名称    挂载点    文件系统类型   选项（权限，认证设定，其他）   内核日志检测机制0不检测，1、2检测，1比2优先级高  磁盘检测机制0不检测、1、2检测，1比2优先级高[root@clear /]# mount -a #挂载/etc/fstab中所有未挂载的设备[root@clear /]# df -Th/dev/vdc1      ext4      991M  2.6M  922M   1% /mnt/disk1#reboot   #模拟考试环境，没做完selinux安全端口别重启，会起不来`注意`如果/etc/fstab中配置错误导致不能启动系统，重启时会自动进入紧急模式.解决方案流程：1 此时输入管理员root密码2 编辑挂载权限 #mount -o remount,rw / 3 vi /etc/fstab更改正内容或将其用  #井号注释挂载内容后，4 reboot即可</code></pre><h2 id="5-4-管理交换分区"><a href="#5-4-管理交换分区" class="headerlink" title="5.4 管理交换分区"></a><strong>5.4 管理交换分区</strong></h2><h3 id="5-4-1-创建交换分区swap"><a href="#5-4-1-创建交换分区swap" class="headerlink" title="5.4.1 创建交换分区swap"></a><strong>5.4.1 创建交换分区swap</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">创建swap 流程：1. 分区---1G[root@clear /]# parted  /dev/vdc mkpart part3 ext2 20% 30% Information: You may need to update /etc/fstab.[root@clear /]# parted  /dev/vdc pNumber  Start   End     Size    File system  Name   Flags 1      1049kB  1074MB  1073MB  ext4         part1 2      1074MB  2147MB  1074MB  xfs          part2 3      2147MB  3221MB  1074MB               part32. 查询系统中swap空间，使用free命令[root@servera ~]# free -m               total        used        free      shared  buff/cache   availableMem:            1763         371        1398          13         144        1391Swap:              0           0           0[root@servera ~]# free -h               total        used        free      shared  buff/cache   availableMem:           1.7Gi       371Mi       1.4Gi        13Mi       144Mi       1.4GiSwap:             0B          0B          0B3. 格式化为swap[root@servera ~]# mkswap /dev/vdb2Setting up swapspace version 1, size = 1024 MiB (1073737728 bytes)no label, UUID=2cc08ea9-26ea-4e28-9ff5-070c84366f914. 给系统加载swap空间     4.1 临时加载与卸载，重启失效 [root@servera ~]# swapon /dev/vdb2[root@servera ~]# free -m               total        used        free      shared  buff/cache   availableMem:            1763         372        1398          13         144        1391Swap:           1023           0        1023[root@servera ~]# swapoff /dev/vdb2[root@servera ~]# free -m               total        used        free      shared  buff/cache   availableMem:            1763         372        1396          13         148        1391Swap:              0           0           0     4.2 写入/etc/fstab文件永久生效[root@servera ~]# vim /etc/fstab/dev/vdb2       swap            swap    defaults  0   0[root@servera ~]# swapon -a    #swap空间用swapon -a挂载[root@servera ~]# free -m               total        used        free      shared  buff/cache   availableMem:            1763         377        1390          13         149        1385Swap:           1023           0        1023</code></pre><h3 id="5-4-2-使用本地存储创建swap"><a href="#5-4-2-使用本地存储创建swap" class="headerlink" title="5.4.2 使用本地存储创建swap"></a><strong>5.4.2 使用本地存储创建swap</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">swap-file# df -h# dd if=/dev/zero of=/pagefile.sys bs=512M count=1# mkswap /pagefile.sys # chmod 0600 /pagefile.sys # vim /etc/fstab .../pagefile.sys swap swap defaults 0 0 # swapon -a# free -h</code></pre><h1 id="6-逻辑卷管理LVM"><a href="#6-逻辑卷管理LVM" class="headerlink" title="6 逻辑卷管理LVM"></a><strong>6 逻辑卷管理LVM</strong></h1><h2 id="6-1-创建和扩展逻辑卷"><a href="#6-1-创建和扩展逻辑卷" class="headerlink" title="6.1 创建和扩展逻辑卷"></a><strong>6.1 创建和扩展逻辑卷</strong></h2><h3 id="6-1-1-逻辑卷管理概述"><a href="#6-1-1-逻辑卷管理概述" class="headerlink" title="6.1.1 逻辑卷管理概述"></a><strong>6.1.1 逻辑卷管理概述</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">逻辑卷(LVM):基于内核的一种逻辑卷管理器，LVM适合于管理大存储设备，并允许用户动态调整文件系统的大小物理卷(PV)：LVM的最底层概念，是LVM的逻辑存储块，物理卷与磁盘分区是逻辑的对应关系卷组(VG)：LVM逻辑概念上的磁盘设备，通过将单个或多个物理卷组合后生成卷组。卷组的大小取决于物理卷的容量以及个数物理长度(PE)：物理长度是将物理卷组合为卷组后，所划分的最小存储单位，即逻辑意义上磁盘的最小存储单元。LVM默认PE大小为4MB逻辑卷(LV):LVM逻辑意义上的分区，可以指定从卷组中提取多少容量来创建逻辑卷，最后对逻辑卷格式化并挂载使用</code></pre><h3 id="6-1-2-构建LVM存储"><a href="#6-1-2-构建LVM存储" class="headerlink" title="6.1.2 构建LVM存储"></a><strong>6.1.2 构建LVM存储</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">1.分区或者添加物理硬盘               fdisk,parted (mbr,gpt)2.pv让物理磁盘或分区变成lvm可用的卷   pvcreate 3.创建vg同时指定pe块大小             vgcreate -s 4.在vg中划分lv空间                   lvcreate -L | -l  -n vgname5.格式化lv空间6.挂载或者永久挂载PV语法：pvcreate  /dev/vdb1  /dev/vdb   #分区名称或磁盘名VG语法：vgcreate -s 16M vgname pvname   #-s不写默认4M，扩大的话可以是2的次方，比如4、8、16、32...，vgname是vg名称自定义，pvname就是创建pv时的物理分区名，就是pv名称LV语法：lvcreate -L 容量 -n lvname vgname #指定容量可以使用-L 容量 或 -l 块数1.分区     至少分3个分区，模拟物理磁盘，作为pv的底层物理块设备[root@clear ~]# fdisk -l /dev/vdbDevice     Boot   Start      End  Sectors Size Id Type/dev/vdb1          2048  2099199  2097152   1G 83 Linux/dev/vdb2       2099200  4196351  2097152   1G 83 Linux/dev/vdb3       4196352  6293503  2097152   1G 83 Linux/dev/vdb4       6293504 20971519 14678016   7G  5 Extended/dev/vdb5       6295552  8392703  2097152   1G 83 Linux2.PV阶段[root@clear ~]# man pvcreate ,搜索/EXAMPLES[root@servera ~]# pvcreate /dev/vdb{1,3,5}  Physical volume "/dev/vdb1" successfully created.  Physical volume "/dev/vdb3" successfully created.  Physical volume "/dev/vdb5" successfully created.[root@clear ~]# pvs 或者 pvscan 或者 pvdisplay进行查询[root@servera ~]# pvscan  PV /dev/vdb1                      lvm2 [1.00 GiB]  PV /dev/vdb3                      lvm2 [1.00 GiB]  PV /dev/vdb5                      lvm2 [1.00 GiB]  Total: 3 [3.00 GiB] / in use: 0 [0   ] / in no VG: 3 [3.00 GiB]3.VG阶段[root@clear ~]# man vgcreate ,搜索/myvg[root@clear ~]# man vgcreate | grep myvg[root@clear ~]# vgcreate -s 16M vg100 /dev/vdb{1..3}    # -s指定物理扩展块16M一个Physical volume "/dev/vdb2" successfully created.  Volume group "vg100" successfully created[root@clear ~]# vgs         #主要查看下vg的大小，拥有的pv和lv数量VG    #PV #LV #SN Attr   VSize VFree  vg100   3   0   0 wz--n- 2.95g 2.95g[root@clear ~]# vgdisplay   #vg名，容量，块大小，块的使用量--- Volume group ---  VG Name               vg100  System ID               Format                lvm2  Metadata Areas        3  Metadata Sequence No  1  VG Access             read/write  VG Status             resizable  MAX LV                0  Cur LV                0  Open LV               0  Max PV                0  Cur PV                3  Act PV                3  VG Size               2.95 GiB  PE Size               16.00 MiB  Total PE              189  Alloc PE / Size       0 / 0     Free  PE / Size       189 / 2.95 GiB  VG UUID               mA8syS-SLSn-VO3X-VReN-Awik-2eVW-Geqqv2pv vg  pe 65535 固定 16M  x 65535 = 270G  2^2  4.LV阶段[root@clear ~]# man lvcreate ,搜索/64m[root@clear ~]# man lvcreate | grep 64mlvcreate -L 64m -n mylv vg00 /dev/sda:0-7 /dev/sdb:0-7[root@clear ~]# lvcreate -L 1G -n lv100 vg100　　　　//(-L:指定具体容量、-n:指定逻辑卷名称)Logical volume "lv100" created.[root@clear ~]# lvsLV    VG    Attr       LSize Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert  lv100 vg100 -wi-a----- 1.00g [root@clear ~]# lvdisplay --- Logical volume ---  LV Path                /dev/vg100/lv100  LV Name                lv100  VG Name                vg100  LV UUID                zxJzck-SgUJ-1kBV-5rfo-aG2I-OHZ9-5KOLPt  LV Write Access        read/write  LV Creation host, time servera.lab.example.com, 2025-03-02 00:14:49 -0500  LV Status              available  # open                 0  LV Size                1.00 GiB  Current LE             64  Segments               2  Allocation             inherit  Read ahead sectors     auto  - currently set to     8192  Block device           253:05.格式化[root@servera ~]# mkfs.xfs /dev/vg100/lv100meta-data=/dev/vg100/lv100       isize=512    agcount=4, agsize=65536 blks         =                       sectsz=512   attr=2, projid32bit=1         =                       crc=1        finobt=1, sparse=1, rmapbt=0         =                       reflink=1    bigtime=1 inobtcount=1 nrext64=0data     =                       bsize=4096   blocks=262144, imaxpct=25         =                       sunit=0      swidth=0 blksnaming   =version 2              bsize=4096   ascii-ci=0, ftype=1log      =internal log           bsize=4096   blocks=16384, version=2         =                       sectsz=512   sunit=0 blks, lazy-count=1realtime =none                   extsz=4096   blocks=0, rtextents=0Discarding blocks...Done.              [root@servera ~]# lsblk -f /dev/vg100/lv100NAME        FSTYPE FSVER LABEL UUID                                 FSAVAIL FSUSE% MOUNTPOINTSvg100-lv100 xfs                e665f339-9faf-4fc9-8cbd-d29468bed8126.创建挂载点与临时挂载# mkdir /mnt/lvm1# mount /dev/vg100/lv100 /mnt/lvm1# df -h# cd /mnt/lvm/7.永久挂载[root@clear ~]# cd /[root@clear /]# echo "/dev/vg100/lv100 /mnt/lvm1 xfs defaults 0 0" >> /etc/fstab    // ">>"表示追加[root@clear /]# mount -a[root@servera ~]# df -Th/dev/mapper/vg100-lv100 xfs       960M   39M  922M   5% /mnt/lvm1[root@servera ~]# ll /dev/mapper/vg100-lv100 /dev/vg100/lv100lrwxrwxrwx. 1 root root 7 Mar  2 00:24 /dev/mapper/vg100-lv100 -> ../dm-0lrwxrwxrwx. 1 root root 7 Mar  2 00:24 /dev/vg100/lv100 -> ../dm-08.reboot重启验证9.删除逻辑卷思路：  创建顺序---分区--lv（pv-vg-lv）--格式化---挂载  卸载顺序---卸载--删lv--删vg--删pv--删分区  vgremove vg100</code></pre><h3 id="6-1-3-扩展逻辑卷"><a href="#6-1-3-扩展逻辑卷" class="headerlink" title="6.1.3 扩展逻辑卷"></a><strong>6.1.3 扩展逻辑卷</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">扩展流程：1、扩展lv大小增加容量2、重新定义文件系统大小1 扩展语法：lvextend 【-L| -l】【size|PE】 lv_name选项：-L：指定容量   直接指定最终大小 -L 1500M ，或者在原有基础上增加多少容量 -L2-l：指定块数   -l 60     ， -l +30[root@servera ~]# lvextend -L 1500M /dev/vg100/lv100  Rounding size to boundary between physical extents: <1.47 GiB.  Size of logical volume vg100/lv100 changed from 1.00 GiB (64 extents) to <1.47 GiB (94 extents).  Logical volume vg100/lv100 successfully resized.[root@servera ~]# lvdisplay   --- Logical volume ---  LV Path                /dev/vg100/lv100  LV Name                lv100  VG Name                vg100  LV UUID                zxJzck-SgUJ-1kBV-5rfo-aG2I-OHZ9-5KOLPt  LV Write Access        read/write  LV Creation host, time servera.lab.example.com, 2025-03-02 00:14:49 -0500  LV Status              available  # open                 1  LV Size                <1.47 GiB  Current LE             94  Segments               2  Allocation             inherit  Read ahead sectors     auto  - currently set to     8192  Block device           253:0$ lvextend -l 60 /dev/vg100/lv1002 重新定义文件系统大小ext 文件系统 ”resize2fs  设备名/挂载点“   resize2fs /dev/vg100/lv100xfs 文件系统 “xfs_growfs 设备名/挂载点”   xfs_growfs /dev/vg100/lv100 或 xfs_growfs 挂载点    例：如果是xfs文件系统使用：[root@servera /]# xfs_growfs /mnt/lvm (挂载点)[root@servera ~]# df -Th/dev/mapper/vg100-lv100 xfs       1.5G   43M  1.4G   3% /mnt/lvm1如果是ext4文件系统使用：[root@servera /]# resize2fs /dev/myvg/mylv （lv设备名）创建的lv名称为myly，属于myvg卷组，lv需要30个pe，每个pe16M，需要开机自动挂载到/mnt/mylvdir. 并且使用xfs文件系统</code></pre><h3 id="6-1-4-缩小逻辑卷"><a href="#6-1-4-缩小逻辑卷" class="headerlink" title="6.1.4 缩小逻辑卷"></a><strong>6.1.4 缩小逻辑卷</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">格式化:[root@servera ~]# mkfs.ext4 /dev/vg200/lv200mke2fs 1.46.5 (30-Dec-2021)Discarding device blocks: done                            Creating filesystem with 385024 4k blocks and 96384 inodesFilesystem UUID: acc0ec9f-90af-4373-8daa-c9525954aeefSuperblock backups stored on blocks:     32768, 98304, 163840, 229376, 294912Allocating group tables: done                            Writing inode tables: done                            Creating journal (8192 blocks): doneWriting superblocks and filesystem accounting information: done永久挂载:[root@servera ~]# mkdir /mnt/lvm2[root@servera ~]# echo "/dev/vg200/lv200 /mnt/lvm2 ext4 defaults 0 0" >> /etc/fstab[root@servera ~]# mount -amount: (hint) your fstab has been modified, but systemd still uses       the old version; use 'systemctl daemon-reload' to reload.[root@servera ~]# systemctl daemon-reload[root@servera ~]# mount -a[root@servera ~]# df -ThFilesystem              Type      Size  Used Avail Use% Mounted on/dev/mapper/vg100-lv100 xfs       1.5G   43M  1.4G   3% /mnt/lvm1/dev/mapper/vg200-lv200 ext4      1.5G   24K  1.4G   1% /mnt/lvm2ext文件系统可以缩小，xfs不支持:流程：1. 卸载[root@servera ~]# umount /mnt/lvm22. resize2fs 定义缩小后的大小[root@servera ~]# resize2fs /dev/vg200/lv200 1Gresize2fs 1.46.5 (30-Dec-2021)Please run 'e2fsck -f /dev/vg200/lv200' first.3. 磁盘检测[root@servera ~]# e2fsck -f /dev/vg200/lv200e2fsck 1.46.5 (30-Dec-2021)Pass 1: Checking inodes, blocks, and sizesPass 2: Checking directory structurePass 3: Checking directory connectivityPass 4: Checking reference countsPass 5: Checking group summary information/dev/vg200/lv200: 11/96384 files (0.0% non-contiguous), 15380/385024 blocks4. 重新执行resize2fs命令[root@servera ~]# resize2fs /dev/vg200/lv200 1Gresize2fs 1.46.5 (30-Dec-2021)Resizing the filesystem on /dev/vg200/lv200 to 262144 (4k) blocks.The filesystem on /dev/vg200/lv200 is now 262144 (4k) blocks long.5.重新挂载并查看[root@servera ~]# mount -a[root@servera ~]# df -ThFilesystem              Type      Size  Used Avail Use% Mounted on/dev/mapper/vg100-lv100 xfs       1.5G   43M  1.4G   3% /mnt/lvm1/dev/mapper/vg200-lv200 ext4      973M   24K  906M   1% /mnt/lvm25. lvresize -L 1G 逻辑卷名[root@servera ~]# lvresize -L 1G /dev/vg200/lv200[root@servera ~]# lvdisplay  --- Logical volume ---  LV Path                /dev/vg200/lv200  LV Name                lv200  VG Name                vg200  LV UUID                0jTstG-VDnH-8IAu-ixXm-blym-tenp-d6t4Jt  LV Write Access        read/write  LV Creation host, time servera.lab.example.com, 2025-03-02 00:49:11 -0500  LV Status              available  # open                 1  LV Size                1.00 GiB  Current LE             64  Segments               2  Allocation             inherit  Read ahead sectors     auto  - currently set to     8192  Block device           253:1</code></pre><h2 id="6-2-管理分层存储"><a href="#6-2-管理分层存储" class="headerlink" title="6.2 管理分层存储"></a><strong>6.2 管理分层存储</strong></h2><h3 id="6-2-1-stratis"><a href="#6-2-1-stratis" class="headerlink" title="6.2.1 stratis"></a><strong>6.2.1 stratis</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">1.1 安装$ yum install -y stratis-cli stratisd$ systemctl enable --now stratisd```1.2 部署存储池1.为磁盘分区(可选用磁盘或分区)，模拟块设备（磁盘）         [root@servera ~]# stratis pool create pool1 /dev/vdb    #创建池名为pool1[root@servera ~]# stratis pool list    #列出池信息包括大小[root@servera ~]# stratis blockdev list  #列出池有哪些物理块设备组成[root@servera ~]# stratis pool add-data pool1 /dev/vdc #添加额外存储[root@servera ~]# stratis pool list[root@servera ~]# stratis blockdev list ool Name   Device Node   Physical Size   Tierpool1       /dev/vdb              5 GiB   Datapool1       /dev/vdc              5 GiB   Data1.3 创建文件系统[root@servera ~]# man stratis   #搜/example[root@servera ~]# stratis filesystem create pool1 fs1   #在pool1中创建文件系统fs1[root@servera ~]# stratis filesystem list  #列出文件系统信息Pool Name   Name   Used      Created             Device                   UUID                                pool1       fs1    546 MiB   Sep 16 2023 21:30   /dev/stratis/pool1/fs1   0e40b338-6178-4bee-87b3-6e13b8be5ad0 6d1ed6e714a6428eb374549b4fdd8d2b  [root@servera ~]# mkdir /mnt/stratisdisk   #创建挂载点如何查看uuid[root@servera ~]# lsblk --output=UUID  /dev/stratis/pool1/fs1[root@servera ~]# mount /dev/stratis/pool1/fs1 /mnt/stratisdisk/   #临时挂载```1.4 备份-创建测试文件[root@servera ~]# touch /mnt/stratisdisk/haha.txt-备份[root@servera ~]# stratis filesystem snapshot pool1 fs1 fs1.bak[root@servera ~]# rm -f /mnt/stratisdisk/haha.txt [root@servera ~]# umount /mnt/stratisdisk [root@servera ~]# mount /dev/stratis/pool1/fs1.bak /mnt/stratisdisk[root@servera ~]# ls /mnt/stratisdiskhaha.txt1.5 开机自动挂载```bashvim /etc/fstab/dev/stratis/pool1/fs1.bak /mnt/stratisdisk xfs _netdev 0 0 #_netdev 延迟挂载，先连接网络再挂载文件系统mount -a[root@clear ~]# systemctl start stratis[root@clear ~]# stratis pool create mypool /dev/vdb1[root@clear ~]# stratis pool add-cache mypool /dev/vdb2[root@clear ~]# stratis blockdev list mypool Pool Name  Device Node  Physical Size   Tiermypool     /dev/vdb1            1 GiB   Datamypool     /dev/vdb2            1 GiB  Cache</code></pre><h3 id="6-2-2-VDO"><a href="#6-2-2-VDO" class="headerlink" title="6.2.2 VDO"></a><strong>6.2.2 VDO</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">## 2 VDO### 1.1安装```bash该实验需要在普通环境上做，恢复init快照，默认是294，要切换至rh134课程切换方法：【foundation】[kiosk@foundation0 ~]$ rht-clearcourse 0[kiosk@foundation0 ~]$ rht-setcourse rh134[kiosk@foundation0 ~]$ cat /etc/rht | grep RHT_COURSE   RHT_COURSE=rh134        #必须保证课程是rh134才可以[kiosk@foundation0 ~]$ for i in classroom bastion workstation servera;do rht-vmctl start $i;done  #开这4台虚拟机，打开时稍等3分钟左右，让其保证都开启，然后ping一下测试连通性[kiosk@foundation0 ~]$ for i in classroom bastion workstation servera;do ping -c 4  $i;done  结果都是以下结果即可，应出现icmp_seq=1 ttl=64 time=1.13 ms字样：PING bastion.lab.example.com (172.25.250.254) 56(84) bytes of data.64 bytes from bastion.lab.example.com (172.25.250.254): icmp_seq=1 ttl=64 time=1.13 ms64 bytes from bastion.lab.example.com (172.25.250.254): icmp_seq=2 ttl=64 time=0.180 ms64 bytes from bastion.lab.example.com (172.25.250.254): icmp_seq=3 ttl=64 time=0.234 ms64 bytes from bastion.lab.example.com (172.25.250.254): icmp_seq=4 ttl=64 time=0.265 m【foundation】ssh student@workstation【workstation】lab advstorage-vdo start   #运行脚本，运行前，保证servera已打开ssh student@servera【servera】[root@servera ~]# sudo -i[root@servera ~]# yum search vdo[root@servera ~]# yum install -y vdo.x86_64 kmod-kvdo.x86_64[root@servera ~]# systemctl enable --now vdo```### 1.2 部署vdo```bash[root@servera ~]# man vdo   #/EXAMPLE*[root@servera ~]# vdo create --name=vdo1 --device=/dev/vdd --vdoLogicalSize=50G[root@servera ~]# vdo list[root@servera ~]# vdo status --name=vdo1[root@servera ~]# vdo status --name=vdo1 | grep Dedu[root@servera ~]# vdo status --name=vdo1 | grep Comp```### 1.3 格式化及临时挂载测试```bash格式化*[root@servera ~]#  mkfs.xfs -K /dev/mapper/vdo1      #-K让命令可以快速返回，效果类似快速格式化 ，如果已有文件系统 可以使用 -f强制执行 挂载*[root@servera ~]# mkdir /mnt/vdo1[root@servera ~]# mount /dev/mapper/vdo1 /mnt/vdo1[root@servera ~]# df -Th[root@servera ~]# vdostats --human-readable[root@servera ~]# cp /root/install.img /mnt/vdo1/install.img.1[root@servera ~]# vdostats --human-readable[root@servera ~]# vdostats --human-readable[root@servera ~]# cp /root/install.img /mnt/vdo1/install.img.2[root@servera ~]# vdostats --human-readable vdostats --human-readablels /mnt/vdo1/lab advstorage-vdo finish```### 1.4 开机自动挂载```bash开机自动挂载方法：教材推荐*[root@servera ~]# man vdo- | grep x-systemd/dev/mapper/vdo1 /mnt/vdo1 xfs defaults,x-systemd.requires=vdo.service 0 0mount -a方法二：/dev/mapper/vdo1 /mnt/vdo1 xfs defaults,_netdev 0 0</code></pre><h1 id="7-访问网络存储"><a href="#7-访问网络存储" class="headerlink" title="7 访问网络存储"></a><strong>7 访问网络存储</strong></h1><h2 id="7-1-NFS挂载网络附加存储"><a href="#7-1-NFS挂载网络附加存储" class="headerlink" title="7.1 NFS挂载网络附加存储"></a><strong>7.1 NFS挂载网络附加存储</strong></h2><h3 id="7-1-1-查看NFS共享"><a href="#7-1-1-查看NFS共享" class="headerlink" title="7.1.1 查看NFS共享"></a><strong>7.1.1 查看NFS共享</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">普通环境[root@servera ~]# showmount -e 172.25.254.250  #后面IP地址是NFS服务器的地址，环境默认已经部署好Export list for 172.25.254.250:     #来自250的共享/content 172.25.0.0/255.255.0.0     #服务器共享的目录</code></pre><h3 id="7-1-2-客户端挂载-mount"><a href="#7-1-2-客户端挂载-mount" class="headerlink" title="7.1.2 客户端挂载 mount"></a><strong>7.1.2 客户端挂载 mount</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">语法：mount -t nfs  ip/域名:共享目录  本地挂载点练习：[root@servera ~]# mkdir /mnt/nfs1#mount -t nfs -o ro 172.25.254.250:/content  /mnt/nfs1  #-t nfs指定文件系统为nfs，-o ro指定挂载权限为只读，这两个选项是可选的。[root@servera ~]# mount 172.25.254.250:/content  /mnt/nfs1[root@servera ~]# df -ThFilesystem              Type      Size  Used Avail Use% Mounted on172.25.254.250:/content nfs4      244G  102G  142G  42% /mnt/nfs1</code></pre><h3 id="7-1-3-开机自动挂载-etc-fstab"><a href="#7-1-3-开机自动挂载-etc-fstab" class="headerlink" title="7.1.3 开机自动挂载 /etc/fstab"></a><strong>7.1.3 开机自动挂载 /etc/fstab</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">[root@servera ~]# umount /mnt/nfs1[root@servera ~]# vim /etc/fstab172.25.254.250:/content /mnt/nfs1 nfs defaults 0 0[root@servera ~]# mount -a[root@servera ~]# df -ThFilesystem              Type      Size  Used Avail Use% Mounted on172.25.254.250:/content nfs4      244G  102G  142G  42% /mnt/nfs1[root@servera ~]# reboot  (重启后使用df -Th查看挂载状态)模拟考试环境没做selinux题，先别重启，起不来</code></pre><h2 id="7-2-自动挂载网络附加存储autofs"><a href="#7-2-自动挂载网络附加存储autofs" class="headerlink" title="7.2 自动挂载网络附加存储autofs"></a><strong>7.2 自动挂载网络附加存储autofs</strong></h2><h3 id="7-2-1-自动挂载示例"><a href="#7-2-1-自动挂载示例" class="headerlink" title="7.2.1 自动挂载示例"></a><strong>7.2.1 自动挂载示例</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">servera上做该练习，挂载f0，172.25.254.250上的/content到servera上的/mnt/nfs10，读写权限-mountmkdir /mnt/nfs10mount 172.25.254.250:/content /mnt/nfs10-fstabmkdir /mnt/nfs10vim  /etc/fstab172.25.254.250:/content /mnt/nfs10  nfs4  defaults 0 0-autofs1.[root@clear home]# yum search autofs  [root@clear home]# yum install -y autofs2.[root@servera ~]# rpm -qc autofs  /etc/auto.master   # 主配置文件  /etc/auto.misc     # 映射文件  /etc/auto.net  /etc/auto.smb  /etc/autofs.conf  /etc/autofs_ldap_auth.conf  /etc/sysconfig/autofs  /usr/lib/systemd/system/autofs.service3.[root@servera ~]# vim /etc/auto.master   基础挂载点     映射文件   /data         /etc/auto.misc         # /data是基础挂载点，表示挂载是从这里开始的，系统自动创建/data4.[root@servera ~]# vim /etc/auto.misc   映射挂载点         文件系统类型 权限          共享目录   nfs10             -fstype=nfs,rw         172.25.250.250:/content   # auto.misc是映射文件，内容为映射挂载点、挂载权限、共享目录路径等5.[root@servera ~]# systemctl restart autofs   # 重启让以上配置生效6.验证[root@servera ~]# ls /data/nfs10   # ls是使用挂载点目录boot  courses  ebook  ks  manifests  rhel7.0  rhel9.0  rhel9.3  rhtops  slides  ucf[root@servera ~]# df -h | tail -1172.25.254.250:/content  244G  102G  142G  42% /data/nfs10  # 才会出现挂载项注明:autofs共享服务只有在访问时才会看到挂载信息</code></pre><h3 id="7-2-2-autofs-直接映射"><a href="#7-2-2-autofs-直接映射" class="headerlink" title="7.2.2 autofs 直接映射"></a><strong>7.2.2 autofs 直接映射</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">[root@clear /]# umount /mnt/nfs101.主配置文件[root@clear /]# vim /etc/auto.master.d/nfs.autofs  #nfs.autofs 名称规则和上个实验一样/- /etc/auto.nfs     #所有直接映射条目使用/-作为基础目录2.映射文件[root@clear /]# vim /etc/auto.nfs   #固定文件名/mnt/nfs10  -rw 172.25.254.250:/content3.重启服务[root@clear /]# systemctl restart autofs4.测试[root@clear /]# ll /mnt/nfs1   #cd或ll方式都可以访问共享目录内容，即可挂载[root@servera /]# df -hFilesystem               Size  Used Avail Use% Mounted on172.25.254.250:/content  491G   66G  426G  14% /mnt/nfs1  </code></pre><h3 id="7-2-3-autofs-间接映射"><a href="#7-2-3-autofs-间接映射" class="headerlink" title="7.2.3 autofs 间接映射"></a><strong>7.2.3 autofs 间接映射</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">1.主配置文件[root@clear /]# vim /etc/auto.master.d/nfs.autofs /mnt /etc/auto.nfs2.映射文件[root@clear /]# vim /etc/auto.nfs *   -rw  172.25.254.250:/&   #如果共享导出了多个子目录可以用&代替子目录的名称，而星*号会自动匹配共享的目录名称*   -rw  172.25.254.250:/&  /content /public  /share      3.重启服务[root@clear /]# systemctl restart autofs4.测试[root@clear /]# cd /mnt/content;ls[root@clear remoteuser1]# df -h  #应该能看到挂载信息</code></pre><h1 id="8-启动流程"><a href="#8-启动流程" class="headerlink" title="8 启动流程"></a><strong>8 启动流程</strong></h1><h2 id="8-1-选择启动目标"><a href="#8-1-选择启动目标" class="headerlink" title="8.1 选择启动目标"></a><strong>8.1 选择启动目标</strong></h2><h3 id="8-1-2-Linux-9启动过程"><a href="#8-1-2-Linux-9启动过程" class="headerlink" title="8.1.2 Linux 9启动过程"></a><strong>8.1.2 Linux 9启动过程</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">1、计算机接通电源。系统固件（现代UEFI或更旧的BIOS）运行开机自检（POST），并开始初始化部分硬件    使用系统BIOS或UEFI配置屏幕(早期按F2可进入设置)2、系统固件会搜索可启动设备，可能是在UEFI启动固件中配置的，也可能按照BIOS中配置的顺序搜索所有磁盘上的主引导记录（MBR）   使用系统BIOS或UEFI配置屏幕（早期按F2可进入设置）3、系统固件会从磁盘读取启动加载器，然后将系统控制权交给启动加载器。红帽企业版Linux8中，启动加载器为GRand Unified Bootloader version2（GRUB2）   使用grub2-install命令进行配置，它将安装GRUB2作为磁盘上的启动加载器。4、GRUB2将从/boot/grub2/grub.cfg文件加载配置并显示一个菜单，从中可以选择要启动的内核。   使用/etc/grub.d/目录、/etc/default/grub文件和grub2-mkconfig命令进行配置，以生成/boot/grub2/grub.cfg文件。5、选择内核超时到期后，启动加载器从磁盘中加载内核和initramfs，并将他们放入内存中。initramfs是一个存档，其中包含启动时所有必要硬件的内核模块、初始化脚本等等。在redhat8中，initramfs包含自身可用的整个系统。     使用/etc/dracut.conf.d/目录、dracut命令和lsinitrd命令进行配置，以检查initramfs文件。6、启动加载器将控制权交给内核，从而传递启动加载器的内核命令行中指定的任何选项，以及initramfs在内存中的位置7、对于内核可在initramfs中找到驱动程序的所有硬件，内核会初始化这些硬件，然后作为PID1从initramfs执行/sbin/init。在redhat8中/sbin/init是一个指向systemd的链接。8、initramfs中的systemd进程会执行initrd.target目标的所有单元。这包括将磁盘上的root文件系统挂载于/sysroot目录。    使用/etc/fstab进行配置9、内核将root文件系统从initramfs切换回/sysroot中的root文件系统。随后，systemd会使磁盘中安装的systemd副本来重新执行。10、systemd会查找从内核命令行传递或系统中配置的默认目标，然后启动或停止单元，以符合该目标的配置，从而自动解决单元之间依赖关系。本质上，systemd进程是一组系统应激活以达到所需状态的单元。这些进程通常启动一个基于文本的登录或图形登录屏幕     可使用/etc/systemd/system/default.target和/etc/systemd/system/进行配置。</code></pre><h3 id="8-1-3-重启和关机"><a href="#8-1-3-重启和关机" class="headerlink" title="8.1.3 重启和关机"></a>8.1.3 <strong>重启和关机</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">-RHEL9<=关机：systemctl poweroff    init 0                重启：systemctl reboot     init 6reboot</code></pre><h3 id="8-1-4-选择SYSTEND-TERGET"><a href="#8-1-4-选择SYSTEND-TERGET" class="headerlink" title="8.1.4 选择SYSTEND TERGET"></a><strong>8.1.4 选择SYSTEND TERGET</strong></h3><p>  下表列出了systemd启动达到的systemd单元:</p><table><thead><tr><th>目标</th><th>用途</th></tr></thead><tbody><tr><td>graphical.target</td><td>多用户、图形、文本登录</td></tr><tr><td>multi-user.target</td><td>多用户、文本登录</td></tr><tr><td>rescue.target</td><td>救援</td></tr><tr><td>emergency.target</td><td>紧急，进入initramfs环境，root只读形式挂载于/上</td></tr></tbody></table><pre class=" language-language-bash"><code class="language-language-bash">systemctl list-units --type=target --allsystemctl list-unit-files --state=enabledsystemctl list-dependencies graphical.target | grep target</code></pre><h3 id="8-1-5-运行时选择target"><a href="#8-1-5-运行时选择target" class="headerlink" title="8.1.5 运行时选择target"></a><strong>8.1.5 运行时选择target</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">切换图形或字符[root@workstation ~]# systemctl isolate multi-user.target  或   init 3 [root@workstation ~]# systemctl isolate graphical.target   或   init 5  [root@workstation ~]# grep AllowIsolate /usr/lib/systemd/system/multi-user.targetAllowIsolate=yes    单元文件中包含AllowIsolate=yes才可以进行切换</code></pre><h3 id="8-1-6-设置默认target"><a href="#8-1-6-设置默认target" class="headerlink" title="8.1.6 设置默认target"></a><strong>8.1.6 设置默认target</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">设置默认的启动目标[root@servera ~]# systemctl get-default [root@servera ~]# syetemctl set-default  multi-user.target[root@servera ~]# ll /etc/systemd/system/default.target</code></pre><h3 id="8-1-7-启动时选择其他目标"><a href="#8-1-7-启动时选择其他目标" class="headerlink" title="8.1.7 启动时选择其他目标"></a><strong>8.1.7 启动时选择其他目标</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">【f0】grub 账号：rootgrub 密码： Asimovreboot选择内核的位置按elinux.....<按键end或者ctrl+e> systemd.unit=emergency.target  #multi-user.target 或graphical.target ctrl+x 如果进入了紧急模式，需要输入root密码mount -o remount,rw /vim /etc/fstabexit 或 reboot</code></pre><h2 id="8-2-重置root密码"><a href="#8-2-重置root密码" class="headerlink" title="8.2 重置root密码"></a><strong>8.2 重置root密码</strong></h2><pre class=" language-language-bash"><code class="language-language-bash">切换模拟考试环境，serverb-serverb#打开serverb的视图模式，-Activites-所有应用-Virtaul Machine Manager-双击serverb-点击左上角三个小方块-ctrl+alt+del1.重新启动系统。$ reboot（Send key 选择ctrl+alt+del）2.按任意键(Enter除外)中断启动加载器倒计时。$ 按方向键 ↓ 下3.将光标移到要引导的救援内核条目 (名称中带有rescue一词的条目)。$ 光标停留第二个内核rescue位置4.按e编辑选定的条目。$ e5.将光标移到内核命令行 (以inux开头的行)。$ linux... 按ctrl+e移动光标至最后6.附加rd.break。利用该选项，就在系统从initramfs 向实际系统移交控制权前，系统将会中断。$ rd.break console=tty07.按ctrl+x使用这些更改来启动。$ ctrl+x8.提示时，按Enter执行维护。$ 救援模式下回车9.给根目录设置rw权限$ mount -o remount,rw /sysroot/10.进入根目录$ chroot /sysroot/      #cd / ,ls -a /11.修改密码$ echo redhat | passwd --stdin root12.添加/.autorelabel文件，刷新selinux标记$ touch /.autorelabel   #[root@servera ~]# systemctl status selinux-autorelabel13.退出当前shell，会自动重启$ exit$ exit</code></pre><h2 id="8-3-诊断和修复文件系统"><a href="#8-3-诊断和修复文件系统" class="headerlink" title="8.3 诊断和修复文件系统"></a>8.3 诊断和修复文件系统</h2><pre class=" language-language-bash"><code class="language-language-bash">当/etc/fstab中挂载信息写错可能会导致系统起不来，会自动进入紧急模式下表为常见错误： 问题                          结果----------------------------- --------------------------------------------------------------- 文件系统损坏                  systemd尝试修复，无法修复进入紧急(emergency)模式 /etc/fstab                    systemd等待一定时间，等设备变得可用。如不可用，则进入紧急模式 引用的设备/UUID不存在          /etc/fstab 挂载点不存在       直接进入紧急模式 /etc/fstab挂载点错误          直接进入紧急模</code></pre><h2 id="8-4-进入紧急模式"><a href="#8-4-进入紧急模式" class="headerlink" title="8.4 进入紧急模式"></a>8.4 进入紧急模式</h2><pre class=" language-language-bash"><code class="language-language-bash">版本建议：编辑/etc/fstab后使用systemd daemon-reload加载。否则systemd可能会继续使用用旧版本。解决方法：#当进入紧急模式后Give root password for maintenance(or pressControl-D to continue): redhat     #输入root密码后按回车进入系统1 输入root密码2 mount -o remount,rw /                     #RHEL9中/根目录权限是可写的，所以无需敲该指令3 vim /etc/fstab                            #可将错误字段需改，或在挂载行前，直接添加#井号注释掉该行。然后reboot重启或者将之前编写的挂载项注释掉，让系统先正常启动，然后再修改调试。</code></pre><h1 id="9-firewalld"><a href="#9-firewalld" class="headerlink" title="9 firewalld"></a>9 firewalld</h1><pre class=" language-language-bash"><code class="language-language-bash">firewalld、iptables   策略限制MAC、IP、PORT、APPselinux                  上下文、布尔值，端口软件权限                  读写执行等文件系统                  rwx，隐藏权限，acl</code></pre><hr><h2 id="9-1-防火墙架构概念"><a href="#9-1-防火墙架构概念" class="headerlink" title="9.1 防火墙架构概念"></a><strong>9.1 防火墙架构概念</strong></h2><pre class=" language-language-bash"><code class="language-language-bash">1 现代的计算机环境不仅需要流畅的网络连通，更需要具备安全性的网络，所以我们除了及时更新系统补丁以外事件，可以针对自己的计算机环境设置接收哪些数据和不接收哪些数据。我们可以使用软件来实现这一目的，这种软件就叫做防火墙。防火墙这种软件会制定一些规则，我们也叫做策略，管理数据包的通过。 2 firewalld优点  iptables在于可使用zone、service简化配置任务，易于管理。而且属于动态管理（修改规则后不必重启整个防火墙服务）。3.zone区域firewalld预先提供了多个区域，不同区域拥有不同设置好的规则，类似不同的管理方案。系统默认区域为public。所有区域默认在系统中会同时开启但是 如何判断我们的数据包在哪个区域中实现了数据限制，通过以下三种方法来判断：- source，源地址- interface，接收请求的网卡（ 一个网卡，只能绑定一个区域。多个网卡，可以绑定同一区域）- firewalld.conf中配置的默认zone三个优先级按次序降低。匹配后不再向下匹配。</code></pre><h2 id="9-1-nftables增强了netfilter"><a href="#9-1-nftables增强了netfilter" class="headerlink" title="9.1 nftables增强了netfilter"></a><strong>9.1 nftables增强了netfilter</strong></h2><p>  nftables—&gt;替代—&gt;netfilter</p><pre class=" language-language-bash"><code class="language-language-bash"># firewalld简介rhel7之前---iptables（静态）rhel7之后---firewalld（动态）# 预定义区域[root@foundation0 ~]# firewall-cmd --get-zonesblock dmz drop external home internal libvirt public trusted work# 预定义服务[root@foundation0 ~]# firewall-cmd --get-service</code></pre><h2 id="9-3-配置防火墙"><a href="#9-3-配置防火墙" class="headerlink" title="9.3 配置防火墙"></a><strong>9.3 配置防火墙</strong></h2><table><thead><tr><th>管理方法</th><th>解释</th></tr></thead><tbody><tr><td>/etc/firewalld</td><td>直接修改配置文件</td></tr><tr><td>Web控制台图形界面</td><td>通过cockpit</td></tr><tr><td>firewalld-cmd命令行</td><td>shell命令行直接执行</td></tr><tr><td>firewall-config</td><td>图形</td></tr></tbody></table><h3 id="9-3-1-Web控制台配置防火墙"><a href="#9-3-1-Web控制台配置防火墙" class="headerlink" title="9.3.1 Web控制台配置防火墙"></a><strong>9.3.1 Web控制台配置防火墙</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">【servera】[root@servera ~]# systemctl start cockpit  #开启cockpit功能[root@servera ~]# netstat -ntlp            #查看是否开启了9090端口[root@servera ~]# firewall-cmd --list-all  #查看防火墙策略services: cockpit dhcpv6-client http ssh   #策略中包含了cockpit，表示允许访问cockpit【f0】firefox https://172.25.250.10:9090         #可以访问【servera】[root@servera ~]# firewall-cmd --permanent --remove-service=cockpitsuccess[root@servera ~]# firewall-cmd --reloadsuccess[root@servera ~]# firewall-cmd --list-all【f0】firefox https://172.25.250.10:9090         #不可以访问【servera】[root@servera ~]# firewall-cmd --permanent --add-service=cockpit  #添加cockpit服务，客户端再次访问即可success[root@servera ~]# firewall-cmd --reloadsuccess[root@servera ~]# firewall-cmd --list-all</code></pre><h3 id="9-3-2-命令行配置防火墙"><a href="#9-3-2-命令行配置防火墙" class="headerlink" title="9.3.2 命令行配置防火墙"></a><strong>9.3.2 命令行配置防火墙</strong></h3><table><thead><tr><th>防火墙命令</th><th>解释</th></tr></thead><tbody><tr><td>–get-default-zone</td><td>查看默认区域</td></tr><tr><td>–set-default-zone=public</td><td>设置默认区域为public，永久设置</td></tr><tr><td>–get-zones</td><td>列出所有可用区域</td></tr><tr><td>–get-active-zones</td><td>列出当前正在使用所有区域</td></tr><tr><td>–add-source=CIDR [–zone=ZONE]</td><td>将IP或网络到指定区域，如果未提供–zone=选项，则使用默认区域</td></tr><tr><td>–remove-source=CIDR</td><td>删除IP或网络…..，如果未提供–zone=选项，…则删除默认区域</td></tr><tr><td>[–zone=ZONE]</td><td></td></tr><tr><td>–add-interface=</td><td>在某个区域中添加端口</td></tr><tr><td>–change-interface=</td><td>改变端口至某个区域</td></tr><tr><td>–list-all [–zone=ZONE]</td><td>查看区域所有策略</td></tr><tr><td>–add-service= [–zone=ZONE]</td><td>允许一个服务</td></tr><tr><td>–add-port= [–zone=ZONE]</td><td>允许一个端口</td></tr><tr><td>–remove-service= [–zone=ZONE]</td><td>移除一个服务</td></tr><tr><td>–remove-port= [–zone=ZONE]</td><td>移除一个端口</td></tr><tr><td>–permanent</td><td>永久生效</td></tr><tr><td>–reload</td><td>立即加载</td></tr></tbody></table><h3 id="9-3-3-配置防火墙练习"><a href="#9-3-3-配置防火墙练习" class="headerlink" title="9.3.3 配置防火墙练习"></a><strong>9.3.3 配置防火墙练习</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">1、管理防火墙服务状态systemctl status firewalld systemctl start firewalld systemctl stop firewalld systemctl restart firewalld systemctl enable --now firewalld 2、查看与设置默认区域man firewall-cmd #/Exfirewall-cmd --get-servicefirewall-cmd --get-zonesfirewall-cmd --get-default-zone firewall-cmd --set-default-zone=home     设置默认区域，了解就可以，不是必须要设置firewall-cmd --list-allman 5 firewalld.zones3.配置防火墙（考）允许服务[root@servera ~]# firewall-cmd --list-all  #查看区域所有配置[root@servera ~]# firewall-cmd --permanent --add-service=http #允许http服务永久生效，要结合reload[root@servera ~]# firewall-cmd --reload[root@servera ~]# firewall-cmd --list-all移除服务[root@servera ~]# firewall-cmd --permanent --remove-service=http[root@servera ~]# firewall-cmd --reload[root@servera ~]# firewall-cmd --list-all允许端口[root@servera ~]# firewall-cmd --permanent --add-port=8000/tcp[root@servera ~]# firewall-cmd --reload[root@servera ~]# firewall-cmd --list-all移除端口[root@servera ~]# firewall-cmd --permanent --remove-port=8000/tcp[root@servera ~]# firewall-cmd --reload[root@servera ~]# firewall-cmd --list-all允许源地址到某个区域（了解）firewall-cmd --add-source=172.25.250.100 --zone=trusted --permanentfirewall-cmd --reload  firewall-cmd --add-interface=enp2s0 --zone=trusted --permanentfirewall-cmd --reload</code></pre><h3 id="9-3-4-典型举例"><a href="#9-3-4-典型举例" class="headerlink" title="9.3.4 典型举例"></a><strong>9.3.4 典型举例</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">允许apache服务foundation-----访问-----servera的web服务思路【servera】$ firewall-cmd --permanent --remove-service=http  $ firewall-cmd --reload  #立即生效$ firewall-cmd --list-all$ yum install -y httpd$ echo test_page > /var/www/html/index.html$ systemctl enable --now httpd$ curl localhost     访问成功后，证明本地可以正常访问test_page【foundation】$ curl http://servera  发现不能访问【servera】systemctl enable --now firewalldsystemctl status firewalldfirewall-cmd --permanent --add-service=http    #--permanent 永久生效，必须添加firewall-cmd --reload  #立即生效firewall-cmd --list-all【foundation】curl http://servera  发现可以访问练习：允许ftp服务servera端：yum install -y vsftpd    #安装vsftpd软件systemctl enable --now vsftpdvim /etc/vsftpd/vsftpd.conf   #进入配置文件 anonymou_enable=NO  改为YES    #开启匿名访问systemctl restart vsftpdyum install -y ftp     #安装ftp可客户端$ ftp localhost     #访问本机ftp服务器Trying ::1...Connected to localhost (::1).220 (vsFTPd 3.0.3)Name (localhost:root): ftp          #ftp表示匿名用户登录331 Please specify the password.Password: 直接回车f0充当client端测试：yum install -y ftpftp localhost   发现不能登录，需要在server端允许ftp服务。</code></pre><h2 id="9-4-SElinux安全端口"><a href="#9-4-SElinux安全端口" class="headerlink" title="9.4 SElinux安全端口"></a><strong>9.4 SElinux安全端口</strong></h2><pre class=" language-language-bash"><code class="language-language-bash">【servera】[root@servera ~]# setenforce 1[root@servera ~]# vim /etc/httpd/conf/httpd.conf Listen 80 改成了Listen 82[root@servera ~]# systemctl restart httpd   重启不了，因为selinux[root@servera ~]# man semanage port    #/EX[root@servera ~]# semanage port -a -t http_port_t -p tcp 82  #数据库没有标签内容则-a，有则-m[root@servera ~]# semanage port -l | grep http重启web服务[root@servera ~]# systemctl restart httpd[root@servera ~]# systemctl enable --now httpd[root@servera ~]# firewall-cmd --permanent --add-port=82/tcp   #本地访问无须配置，远端主机访问需要配置[root@servera ~]# firewall-cmd --reload[root@servera ~]# firewall-cmd --list-all测试[serverb curl http://servea:82] 富规则参考[root@servera ~]# man 5 firewalld.richlanguage</code></pre><h1 id="10-kickstart"><a href="#10-kickstart" class="headerlink" title="10 kickstart"></a><strong>10 kickstart</strong></h1><pre class=" language-language-bash"><code class="language-language-bash">  安装方式    简介----------- --------------------------------  DVD 光盘    物理系统光盘  ISO镜像     光盘制作成为的镜像.iso文件  QCOW2镜像   云环境或虚拟环境中部署为虚拟机</code></pre><h2 id="10-1-KICKSTART自动安装系统"><a href="#10-1-KICKSTART自动安装系统" class="headerlink" title="10.1 KICKSTART自动安装系统"></a>10.1 KICKSTART自动安装系统</h2><pre class=" language-language-bash"><code class="language-language-bash">P293 Kickstart练习[kiosk@foundation0 ~]$ ssh workstation[student@workstation ~]$ lab start installing kickstart....[student@workstation ~]$ ssh servera[student@workstation ~]$ sudo -i redhat1.后面按照教材要求进行配置[root@servera ks-config]# vim /var/www/html/ks-config/kickstart.cfgbootloader --append="console=ttyS0 console=ttyS0,115200n8 no_timer_check net.ifnames=0  crashkernel=auto" --location=mbr --timeout=1 --boot-drive=vdagraphicalkeyboard --vckeymap=uslang en_US.UTF-8repo --name="BaseOS" --baseurl="http://classroom.example.com/content/rhel9.0/x86_64/dvd/BaseOS/"repo --name="Appstream" --baseurl="http://classroom.example.com/content/rhel9.0/x86_64/dvd/AppStream"url --url="http://classroom.example.com/content/rhel9.0/x86_64/dvd/"rootpw --plaintext redhatauthselect select sssdselinux --enforcingservices --disabled="kdump,rhsmcertd" --enabled="sshd,rngd,chronyd"timezone America/New_York --utcignoredisk --only-use=vdaautopart%pre --erroronfail echo "Kickstarted on $(date)" >> /etc/issue%end%post --erroronfailecho -n "Setting default runlevel to multiuser text mode"rm -f /etc/systemd/system/default.targetln -s /lib/systemd/system/multi-user.target /etc/systemd/system/default.targetecho .echo "Removing linux-firmware package."dnf -C -y remove linux-firmwareecho "virtual-guest" > /etc/tuned/active_profilecat > /etc/hosts << EOF127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4::1         localhost localhost.localdomain localhost6 localhost6.localdomain6EOF%end%packages@core chronydracut-config-genericdracut-norescuefirewalldgrub2kernelrsynctar httpd-plymouth%end2.重启httpd服务，并开机自启动。3.关闭防火墙，selinux。</code></pre><h3 id="10-1-1-dhcp设置"><a href="#10-1-1-dhcp设置" class="headerlink" title="10.1.1 dhcp设置"></a><strong>10.1.1 dhcp设置</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">【root@servera】[root@servera ~]# systemctl stop firewalld;setenforce 0一、dhcp1 安装[root@servera ~]# yum install -y dhcp-server2 建立配置文件[root@servera ~]# cp /usr/share/doc/dhcp-server/dhcpd.conf.example /etc/dhcp/dhcpd.confcp: overwrite '/etc/dhcp/dhcpd.conf'? y[root@servera ~]# vim /etc/dhcp/dhcpd.conf   #man 5 dhcpd.conf   /next-server3 配置服务[root@servera ~]# vim /etc/dhcp/dhcpd.confallow bootp;allow booting;subnet 172.25.250.0 netmask 255.255.255.0 {  range 172.25.250.100 172.25.250.200;  option routers 172.25.250.254;  default-lease-time 600;  max-lease-time 7200;  filename "/pxelinux.0";  next-server 172.25.250.10;}4 启动并测试[root@servera ~]# systemctl enable --now dhcpd5 测试dhcp功能：设置serverb开机启动为网卡启动，当做客户端，测试能够获取ip即可</code></pre><h3 id="10-1-2-tftp-and-syslinux"><a href="#10-1-2-tftp-and-syslinux" class="headerlink" title="10.1.2 tftp and syslinux"></a><strong>10.1.2 tftp and syslinux</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">1、安装tftp服务[root@servera ~]# yum install -y tftp-server tftp[root@servera ~]# rpm -ql tftp-server2、安装syslinux-tftpboot该软件后提供了/tftpboot目录其中包含了一些引导文件、内核文件及pxelinux.0文件等，建立pxelinux.cfg目录，准备存放default文件。[root@servera ~]# yum install -y syslinux-tftpboot.noarch[root@servera ~]# rpm -ql syslinux-tftpboot[root@servera ~]# mkdir /tftpboot/pxelinux.cfg/3、将254.250上的光盘镜像相关文件挂载至本机[root@servera ~]# mkdir /content[root@servera ~]# mount 172.25.254.250:/content /content/[root@servera ~]# df -h[root@serveran ~]# cp /content/rhel9.0/x86_64/dvd/images/pxeboot/{initrd.img,vmlinuz} /tftpboot/[root@servera ~]# cp /content/rhel9.0/x86_64/dvd/isolinux/boot.msg /tftpboot/[root@servera ~]# cp /content/rhel9.0/x86_64/dvd/isolinux/isolinux.cfg /tftpboot/pxelinux.cfg/default[root@servera ~]# vim /tftpboot/pxelinux.cfg/default default vesamenu.c32 timeout 60  可以改为60，就是6秒display boot.msglabel linux  menu label ^Install Red Hat Enterprise Linux 9.0.0  menu default  kernel vmlinuz  append initrd=initrd.img inst.stage2=ftp://172.25.250.10/dvd  inst.ks=http://172.25.250.10/ks-config/kickstart.cfg quiet4、修改tftp发布目录，并启动服务及测试[root@servera ~]# vim /usr/lib/systemd/system/tftp.service [Service]ExecStart=/usr/sbin/in.tftpd -s /tftpboot  (将-s /var/lib/tftpboot，更成-s /tftpboot)[root@servera ~]# systemctl enable --now tftp测试：登录servera，yum install -y tftp ,tftp 172.25.250.10,get ls.c32 quit</code></pre><h3 id="101-3-ftp"><a href="#101-3-ftp" class="headerlink" title="101.3 ftp"></a><strong>101.3 ftp</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">1、安装[root@servera ~]# yum install -y vsftpd.x86_64 ftp[root@servera ~]# rpm -qc vsftpd2、配置服务[root@servera ~]# vim /etc/vsftpd/vsftpd.conf anonymous_enable=YES[root@servera ~]# mkdir /var/ftp/dvd[root@servera ~]# mount /content/rhel9.0/x86_64/isos/rhel-baseos-9.0-x86_64-dvd.iso /var/ftp/dvd/3、启动及测试df -h[root@servera ~]# systemctl enable --now vsftpd4 从serverb上测试一下tftp功能是否正常（可选）【serverb】cleint以网卡方式启动--安装1、指定ftp路径172.25.250.9/dvd 2 最小化 3 设置lvm分区进度条走完-重启，添加硬盘启动 ， 从本地硬盘启动。</code></pre><h3 id="10-1-4-保证所有服务测试正常"><a href="#10-1-4-保证所有服务测试正常" class="headerlink" title="10.1.4 保证所有服务测试正常"></a><strong>10.1.4 保证所有服务测试正常</strong></h3><pre class=" language-language-bash"><code class="language-language-bash">1.dhcpd   分配IP，指导访问tftp2.tftp    分配启动所需文件及pxelinux安装程序3.vsftpd  共享光盘镜像4.httpd   共享ks文件其实vsftpd和httpd可以二选一，例如只用httpd服务共享光盘镜像、ks文件。</code></pre><h2 id="10-2-cockpit安装虚拟机"><a href="#10-2-cockpit安装虚拟机" class="headerlink" title="10.2 cockpit安装虚拟机"></a><strong>10.2 cockpit安装虚拟机</strong></h2><pre class=" language-language-bash"><code class="language-language-bash">[root@servera ~]# yum install -y cockpit-machines以服务的形式启动http，一旦启动就会长期运行，在内存中产生相应的进程systemct start httpd容器以进程的方式运行http，一旦运行完毕容器就会自动关闭，自动退出，结束运行。当再想运行http的时候需要新开启一个容器rhel8查看一个文件，容器容器：1个应用  -- 好管理    apache   php   mysql +linux= lamp -- 支持php网站容器：多个应用 -- 不好管理   （apache   php   mysql）</code></pre>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux进阶 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux的基本使用</title>
      <link href="/2022/05/28/linux/linux-de-ji-ben-shi-yong/"/>
      <url>/2022/05/28/linux/linux-de-ji-ben-shi-yong/</url>
      
        <content type="html"><![CDATA[<h1 id="1-访问命令行"><a href="#1-访问命令行" class="headerlink" title="1 访问命令行"></a>1 访问命令行</h1><h2 id="1-1-登录Linux系统"><a href="#1-1-登录Linux系统" class="headerlink" title="1.1 登录Linux系统"></a>1.1 登录Linux系统</h2><pre class=" language-language-bash"><code class="language-language-bash">图形化：系统菜单-注销-或切换用户字符界面：Ctrl+alt+F2-F6   在本机上切换用户：su - root退出登录：ctrl+d、exit、logout)网络登录：ssh ip、ssh 主机名[kiosk@foundation0 ~]$ ssh serverassh 用户名@ip/主机名[kiosk@foundation0 ~]$ ssh student@servera</code></pre><h2 id="1-2-终端切换"><a href="#1-2-终端切换" class="headerlink" title="1.2 终端切换"></a>1.2 终端切换</h2><pre class=" language-language-bash"><code class="language-language-bash">CLI   Ctrl+alt+Fx   xin （2，6）GUI   Ctrl+alt+F1  </code></pre><h2 id="1-3-Shell简介"><a href="#1-3-Shell简介" class="headerlink" title="1.3 Shell简介"></a>1.3 Shell简介</h2><p>  是一个解释器，可以帮助用户将指令信息传递内核</p><p>  红帽企业Linux中为用户提供的默认shell是bash，bash是与UNIX类似的系统上使用的其中一个最成功的shell改进版本</p><h2 id="1-4-基本组成"><a href="#1-4-基本组成" class="headerlink" title="1.4 基本组成"></a>1.4 基本组成</h2><pre class=" language-language-bash"><code class="language-language-bash">[kiosk@foundation0 ~]$                    #$普通用户[kiosk@foundation0 ~]$ su - root          #切换用户：su - 用户名Password:                                 #输入用户登录密码Last login: Sat Feb 22 15:11:13 CST 2020 on tty3[root@foundation0 ~]#                    #超级用户ctrl+d or exit                           退出登录</code></pre><p>注明：</p><p>  1.bash shell在概念上与微软的cmd相似，但bash具有更加复杂的脚本语言</p><p>  2.与win系统powershell类似、mac的管理终端使用工具也是使用的bash shell</p><h2 id="1-5-GNOME-Shell"><a href="#1-5-GNOME-Shell" class="headerlink" title="1.5 GNOME Shell"></a>1.5 GNOME Shell</h2><pre class=" language-language-bash"><code class="language-language-bash">ALT+F2  输入 gnome-terminal    # 启动终端win+l  # 锁定#  关闭                 重启  init 0               init 6  poweroff             reboot  systemctl poweroff   systemctl reboot  shutdown -h 20：00   shutdown -r 0ctrl+alt 上\|下 箭头   # 工作区切换</code></pre><h2 id="1-6-Shell的特性"><a href="#1-6-Shell的特性" class="headerlink" title="1.6 Shell的特性"></a>1.6 Shell的特性</h2><h3 id="1-6-1-linux命令语法"><a href="#1-6-1-linux命令语法" class="headerlink" title="1.6.1 linux命令语法"></a>1.6.1 linux命令语法</h3><p>  完成具体功能的命令、扩展该命令功能的选项、命令要操作的对象</p><p>  cmd 【-option】 【arg1】 【arg2】</p><pre class=" language-language-bash"><code class="language-language-bash">简单的命令示例：whoamidatetouch file1；mkdir dir1完成某些工作的指令扩展命令功能的选项参数lsls -a    ls -a    ~/.bashrcls -a  -l  ~/.bashrcls -al  ~/.bashrc</code></pre><h3 id="1-6-2-命令的基础分类"><a href="#1-6-2-命令的基础分类" class="headerlink" title="1.6.2 命令的基础分类"></a>1.6.2 命令的基础分类</h3><pre class=" language-language-bash"><code class="language-language-bash"># 回显式命令date +%Y%m%ddate +%Y-%m-%d# 交互式命令passwd# tab补全按一下是补全按两下列出可用命令tab键  输入单词或命令前面几个首字母后，保证唯一可补全，不唯一可列出能选择的命令# 历史命令-historyenv--能容纳1000条[root@servera ~]# env | grep SIZEHISTSIZE=1000[root@servera ~]# history -w [root@servera ~]# vim ~/.bash_history     记录历史命令文件，vim是一个文本工具，可以打开后面的文件，进入后:q退出[root@servera ~]# history -c   清除[root@servera ~]# history history的其他方法：！！！23    历史命令的编号！h      命令首字母当前历史命令支持的最大条数[root@foundation0 /]# grep ^HISTSIZE /etc/profileHISTSIZE=1000历史命令存放文件路径[root@foundation0 /]# set | grep HISTFILEHISTFILE=/root/.bash_historyvim /etc/profileexport HISTFILE=/root/.newfilesource /etc/profilehistory -wcat /root/.newfilectrl+R 搜索历史命令</code></pre><h2 id="1-7-命令行快捷键"><a href="#1-7-命令行快捷键" class="headerlink" title="1.7 命令行快捷键"></a>1.7 命令行快捷键</h2><table><thead><tr><th align="left">快捷键</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">ctrl + shift + t</td><td align="left">当前画面添加一个标签</td></tr><tr><td align="left">ctrl + shift + n</td><td align="left">打开一个新的标签</td></tr><tr><td align="left">alt + 1，alt + 2</td><td align="left">切换标签</td></tr><tr><td align="left">ctrl + shift + =，ctrl + -</td><td align="left">扩大与缩小终端字体</td></tr><tr><td align="left">ctrl + shift + w</td><td align="left">关闭标签</td></tr></tbody></table><h2 id="1-8-Shell常用快捷键"><a href="#1-8-Shell常用快捷键" class="headerlink" title="1.8 Shell常用快捷键"></a>1.8 Shell常用快捷键</h2><table><thead><tr><th align="left">快捷键</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">ctrl + a</td><td align="left">光标跳至行首</td></tr><tr><td align="left">ctrl + e</td><td align="left">光标跳至行尾</td></tr><tr><td align="left">ctrl + u</td><td align="left">从光标所在位置清空至行首</td></tr><tr><td align="left">ctrl + k</td><td align="left">从光标所在位置清空至行末</td></tr><tr><td align="left">ctrl + 左箭头</td><td align="left">光标向左跳一个单词</td></tr><tr><td align="left">ctrl + 右箭头</td><td align="left">光标向右跳一个单词</td></tr><tr><td align="left">ctrl + w</td><td align="left">回删一个单词</td></tr><tr><td align="left">alt + d</td><td align="left">删除光标后一个单词</td></tr><tr><td align="left">esc + . 或 alt + .</td><td align="left">调用之前使用过的路径，alt+.一直点可以向上翻阅路径</td></tr></tbody></table><h1 id="2-从命令行管理文件"><a href="#2-从命令行管理文件" class="headerlink" title="2 从命令行管理文件"></a>2 从命令行管理文件</h1><h2 id="2-1-系统目录结构"><a href="#2-1-系统目录结构" class="headerlink" title="2.1 系统目录结构"></a>2.1 系统目录结构</h2><p>  根(/)目录下每个目录的作用:</p><table><thead><tr><th align="left">目录名</th><th align="left">作用</th></tr></thead><tbody><tr><td align="left">bin</td><td align="left">用户可执行目录(命令root和普通)</td></tr><tr><td align="left">sbin</td><td align="left">系统可执行目录(命令root)</td></tr><tr><td align="left">lib</td><td align="left">库文件目录(32位)</td></tr><tr><td align="left">lib64</td><td align="left">库文件目录(64位)</td></tr><tr><td align="left">dev</td><td align="left">设备文件目录dev</td></tr><tr><td align="left">usr</td><td align="left">应用程序目录</td></tr><tr><td align="left">var</td><td align="left">服务器数据目录(数据日志)</td></tr><tr><td align="left">src</td><td align="left">服务器数据目录</td></tr><tr><td align="left">etc</td><td align="left">配置文件目录</td></tr><tr><td align="left">tmp</td><td align="left">临时文件目录</td></tr><tr><td align="left">boot</td><td align="left">服务器启动目录(内核和启动文件)</td></tr><tr><td align="left">media</td><td align="left">媒介目录(u盘、cdrom)</td></tr><tr><td align="left">mnt</td><td align="left">其他挂载点</td></tr><tr><td align="left">opt</td><td align="left">第三方应用程序目录</td></tr><tr><td align="left">proc</td><td align="left">伪文件系统(内核参数、进程信息、硬件信息)</td></tr><tr><td align="left">sys</td><td align="left">伪文件系统(配置文件目录、内核参数、进程信息、硬件信息)</td></tr><tr><td align="left">run</td><td align="left">进程锁目录</td></tr><tr><td align="left">root</td><td align="left">root管理员家目录</td></tr><tr><td align="left">home</td><td align="left">普通用户家目录</td></tr></tbody></table><h2 id="2-2-文件类型"><a href="#2-2-文件类型" class="headerlink" title="2.2 文件类型"></a>2.2 文件类型</h2><table><thead><tr><th align="left">文件类型</th><th align="left">说明</th><th align="left">全称</th></tr></thead><tbody><tr><td align="left">-</td><td align="left">普通文件</td><td align="left">file</td></tr><tr><td align="left">d</td><td align="left">目录文件</td><td align="left">directory</td></tr><tr><td align="left">c</td><td align="left">字符设备文件</td><td align="left">character</td></tr><tr><td align="left">b</td><td align="left">块设备文件</td><td align="left">block</td></tr><tr><td align="left">s</td><td align="left">套接字文件</td><td align="left">socket</td></tr><tr><td align="left">p</td><td align="left">管道文件</td><td align="left">pipe</td></tr><tr><td align="left">l</td><td align="left">符号链接文件(软链接)</td><td align="left">symbolic</td></tr></tbody></table><h2 id="2-3-文件名定位文件"><a href="#2-3-文件名定位文件" class="headerlink" title="2.3 文件名定位文件"></a>2.3 文件名定位文件</h2><pre class=" language-language-bash"><code class="language-language-bash">[root@foundation0 home]# cd /[root@foundation0 /]# cd /etc/</code></pre><h2 id="2-4-路径"><a href="#2-4-路径" class="headerlink" title="2.4 路径"></a>2.4 路径</h2><pre class=" language-language-bash"><code class="language-language-bash"># 路径的表示:1.绝对路径(通常以/开头)  例如：根开头    cd /etc/sysconfig2.相对路径:  非根开头 cd  ..  # 导航路径# pwd[root@foundation0 yum.repos.d]# pwd/etc/yum.repos.d# cdcd -   返回之前的目录cd or cd ~  家目录cd .    当前目录cd ..    上一级目录# lslsls -a ls -a /home ls -a -l ls -al[root@foundation0 ~]# ls -a .viminfo.viminfo[root@foundation0 ~]# ls -a -l .viminfo-rw-------. 1 root root 2545 Mar 13 13:12 .viminfo[root@foundation0 ~]# ls -al .viminfo-rw-------. 1 root root 2545 Mar 13 13:12 .viminfo[root@foundation0 /]# ls -l -d /homedrwxr-xr-x. 4 root root 30 Mar 13 11:38 /home</code></pre><h2 id="2-5-查看文件内容"><a href="#2-5-查看文件内容" class="headerlink" title="2.5 查看文件内容"></a>2.5 查看文件内容</h2><pre class=" language-language-bash"><code class="language-language-bash">cat    cat /etc/passwd             # 将文件内容打印到屏幕上tail   tail /var/log/message       # 默认查看文件后10行。-F （追踪）指定文件不存在时再创建相同名称文件       tail -n 5 或 tail -5 /var/log/message   head   head /var/log/message       # 默认查看文件头10行       head -5 /var/log/message                less   less /var/log/message           more   more /var/log/message         vim    vim /etc/passwd             # 文本编辑器</code></pre><h2 id="2-6-命令行管理文件-目录"><a href="#2-6-命令行管理文件-目录" class="headerlink" title="2.6 命令行管理文件/目录"></a>2.6 命令行管理文件/目录</h2><h3 id="2-6-1-管理文件-目录的命令"><a href="#2-6-1-管理文件-目录的命令" class="headerlink" title="2.6.1 管理文件/目录的命令"></a>2.6.1 管理文件/目录的命令</h3><pre class=" language-language-bash"><code class="language-language-bash"> 创建   touch   mkdir -p 改名   mv      mv 移动   mv      mv 拷贝   cp      cp -r 删除   rm      rm -rtouch、mkdir、rm、cp、mv</code></pre><h3 id="2-6-2-touch命令-管理文件"><a href="#2-6-2-touch命令-管理文件" class="headerlink" title="2.6.2 touch命令(管理文件)"></a>2.6.2 touch命令(管理文件)</h3><pre class=" language-language-bash"><code class="language-language-bash">[root@servera opt]# man touch[root@servera opt]# touch /file4 /tmp/file5[root@servera opt]# ls /file4;ls /tmp/file5/file4/tmp/file5[root@servera opt]# touch file{10..20}</code></pre><h3 id="2-6-3-mkdir命令-管理目录"><a href="#2-6-3-mkdir命令-管理目录" class="headerlink" title="2.6.3 mkdir命令(管理目录)"></a>2.6.3 mkdir命令(管理目录)</h3><pre class=" language-language-bash"><code class="language-language-bash">mkdir选项： -p：递归创建     -v：显示过程[root@servera opt]# lsdir1[root@servera opt]# mkdir dir2 /dir3[root@servera opt]# lsdir1  dir2[root@servera opt]# mkdir dir3/dir4mkdir: cannot create directory ‘dir3/dir4’: No such file or directory[root@servera opt]# mkdir -pv dir3/dir4mkdir: created directory 'dir3'mkdir: created directory 'dir3/dir4'[root@servera opt]# ls -R dir3  # -R递归查看，可以查看多级目录内容dir3:dir4dir3/dir4:[root@servera opt]# ll -R dir3/dir4dir3/dir4:total 0[root@servera opt]# ll  dir3total 0drwxr-xr-x. 2 root root 6 Mar 13 22:23 dir4[root@servera opt]# ll  dir3/dir4/total 0[root@servera opt]# ll  dir3/dir4/ -ddrwxr-xr-x. 2 root root 6 Mar 13 22:23 dir3/dir4/</code></pre><h3 id="2-6-4-rm命令-删除"><a href="#2-6-4-rm命令-删除" class="headerlink" title="2.6.4 rm命令(删除)"></a>2.6.4 rm命令(删除)</h3><pre class=" language-language-bash"><code class="language-language-bash">[root@servera opt]# man rm[root@servera opt]# lsdir1  dir2  dir3  file1  file2  file3[root@servera opt]# rm file1rm: remove regular empty file 'file1'? y    # 询问是否删除y删除n不删除[root@servera opt]# rm file2rm: remove regular empty file 'file2'? n[root@servera opt]# rm -f file2             强制删除不询问[root@servera opt]# lsdir1  dir2  dir3  file3[root@servera opt]# rm -f file*         *代表一个或多个字符[root@servera opt]# lsdir1  dir2  dir3[root@servera opt]# rm dir1             rm: cannot remove 'dir1': Is a directory[root@servera opt]# rm -r dir1          删除目录需要-r表示递归rm: remove directory 'dir1'? y[root@servera opt]# rm -rf dir2[root@servera opt]# lsdir3</code></pre><h3 id="2-6-5-copy命令-复制"><a href="#2-6-5-copy命令-复制" class="headerlink" title="2.6.5 copy命令(复制)"></a>2.6.5 copy命令(复制)</h3><pre class=" language-language-bash"><code class="language-language-bash">[root@servera opt]# lsdir1  dir2  file1  file2  file3[root@servera opt]# cp file1 /tmp/[root@servera opt]# ls /tmp/file1/tmp/file1[root@servera opt]# cp file1 /tmp/file10[root@servera opt]# ls /tmp/file10/tmp/file10[root@servera opt]# cp /etc/man_db.conf .[root@servera opt]# lsdir1  dir2  file1  file2  file3  man_db.conf</code></pre><h3 id="2-6-6-mv命令-移动文件-目录"><a href="#2-6-6-mv命令-移动文件-目录" class="headerlink" title="2.6.6 mv命令(移动文件/目录)"></a>2.6.6 mv命令(移动文件/目录)</h3><pre class=" language-language-bash"><code class="language-language-bash">[root@servera opt]# mv file1 /[root@servera opt]# lsdir1  dir2  file2  file3  man_db.conf[root@servera opt]# mv file2 /file20[root@servera opt]# lsdir1  dir2  file3  man_db.conf[root@servera opt]# mv file3 file30[root@servera opt]# lsdir1  dir2  file30  man_db.conf[root@servera opt]# mv dir1 /[root@servera opt]# lsdir2  file30  man_db.conf[root@servera opt]# mv dir2 dir20[root@servera opt]# lsdir20  file30  man_db.conf</code></pre><h2 id="2-7-通配符规则"><a href="#2-7-通配符规则" class="headerlink" title="2.7 通配符规则"></a>2.7 通配符规则</h2><table><thead><tr><th align="left">通配符</th><th align="left">规则</th></tr></thead><tbody><tr><td align="left">*</td><td align="left">匹配0个或多个任意字符</td></tr><tr><td align="left">？</td><td align="left">匹配1个任意字符</td></tr><tr><td align="left">[ ]</td><td align="left">匹配中括号内一个字符</td></tr><tr><td align="left">[ - ]</td><td align="left">匹配中括号内连续范围的一个字符</td></tr><tr><td align="left">[ ^ ]</td><td align="left">取反，匹配非中括号内的字符，表示一定有一个字符，但不是中括号内出现的。【^ab】</td></tr><tr><td align="left">{a,b}或{a..c}</td><td align="left">匹配括号中的字符或连续的字符</td></tr></tbody></table><h1 id="3-在线获取帮助"><a href="#3-在线获取帮助" class="headerlink" title="3 在线获取帮助"></a>3 在线获取帮助</h1><h2 id="3-1-MAN手册说明"><a href="#3-1-MAN手册说明" class="headerlink" title="3.1 MAN手册说明"></a>3.1 MAN手册说明</h2><table><thead><tr><th align="left">命令</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">man 1</td><td align="left">用户命令</td></tr><tr><td align="left">man 2</td><td align="left">系统调用</td></tr><tr><td align="left">man 3</td><td align="left">库调用</td></tr><tr><td align="left">man 4</td><td align="left">特殊文件</td></tr><tr><td align="left">man 5</td><td align="left">配置文件</td></tr><tr><td align="left">man 6</td><td align="left">游戏</td></tr><tr><td align="left">man 7</td><td align="left">杂项</td></tr><tr><td align="left">man 8</td><td align="left">系统命令</td></tr></tbody></table><h2 id="3-2-获取帮助的方法"><a href="#3-2-获取帮助的方法" class="headerlink" title="3.2 获取帮助的方法"></a>3.2 获取帮助的方法</h2><pre class=" language-language-bash"><code class="language-language-bash"># man命令mandbman passwdman -k passwd man 5 passwdman setfacl | grep -B 1 lisa# --helpsetfacl --help | grep \\-asetfacl --help | grep -w \\-a  # pinfopinfo   回车  upinfo  ls# rpm包中提供帮助rpm -qa | grep httpdrpm -ql 软件包名称rpm -qc</code></pre><h1 id="4-创建、查看、编辑文本"><a href="#4-创建、查看、编辑文本" class="headerlink" title="4 创建、查看、编辑文本"></a>4 创建、查看、编辑文本</h1><h2 id="4-1-VIM的模式分类"><a href="#4-1-VIM的模式分类" class="headerlink" title="4.1 VIM的模式分类"></a>4.1 VIM的模式分类</h2><table><thead><tr><th align="left">模式</th><th align="left">功能</th></tr></thead><tbody><tr><td align="left">命令模式</td><td align="left">光标移动、复制、删除</td></tr><tr><td align="left">输入模式</td><td align="left">输入文本内容</td></tr><tr><td align="left">末行模式</td><td align="left">保存退出、设置环境</td></tr></tbody></table><h2 id="4-2-VIM的模式说明"><a href="#4-2-VIM的模式说明" class="headerlink" title="4.2 VIM的模式说明"></a>4.2 VIM的模式说明</h2><h3 id="4-2-1-命令模式"><a href="#4-2-1-命令模式" class="headerlink" title="4.2.1 命令模式"></a>4.2.1 命令模式</h3><table><thead><tr><th align="left">命令</th><th align="left">解释</th></tr></thead><tbody><tr><td align="left">h j k l</td><td align="left">左下上右</td></tr><tr><td align="left">方向键</td><td align="left">上下左右</td></tr><tr><td align="left">1G、nG</td><td align="left">n代表一个数字，去第1行或n行</td></tr><tr><td align="left">gg</td><td align="left">将光标定位到文章的顶端</td></tr><tr><td align="left">G</td><td align="left">将光标定位到文章的底端（$定位光标到行尾，0和^定位光标到行首）</td></tr><tr><td align="left">x，X</td><td align="left">向后删除一个字符、向前删除一个字符</td></tr><tr><td align="left">dd，ndd</td><td align="left">删除1行，n是一个数字，n行 例如：dgg、dG、d$、d0 D</td></tr><tr><td align="left">yy，nyy</td><td align="left">复制1行，复制n行</td></tr><tr><td align="left">p，P</td><td align="left">粘贴到下一行，粘贴到上一行</td></tr><tr><td align="left">u</td><td align="left">撤销</td></tr><tr><td align="left">ZZ</td><td align="left">保存退出</td></tr></tbody></table><h3 id="4-2-2-插入模式"><a href="#4-2-2-插入模式" class="headerlink" title="4.2.2 插入模式"></a>4.2.2 插入模式</h3><pre class=" language-language-bash"><code class="language-language-bash">a   字符后进入插入模式i   当前字符位置进入插入模式o   在下一行新创建一行进入插入模式A   在行尾进入插入模式I   在行首进入插入模式O   在上一行新创建一行进入插入模式s   删除光标位置字符并进入插入模式S   删除光标所在行并进入插入模式</code></pre><h3 id="4-2-3-末行模式"><a href="#4-2-3-末行模式" class="headerlink" title="4.2.3 末行模式"></a>4.2.3 末行模式</h3><table><thead><tr><th align="left">命令</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">w</td><td align="left">保存</td></tr><tr><td align="left">q</td><td align="left">退出</td></tr><tr><td align="left">wq</td><td align="left">退出并保存</td></tr><tr><td align="left">q!</td><td align="left">强制退出</td></tr><tr><td align="left">x</td><td align="left">保存退出</td></tr><tr><td align="left">set nu</td><td align="left">设置行号</td></tr><tr><td align="left">set nonu</td><td align="left">取消行号</td></tr><tr><td align="left">：w /newfile</td><td align="left">另存为其他文件 例子：”:w /man.txt”</td></tr><tr><td align="left">：r /newfile</td><td align="left">读取/newfile到本文件中 例子： “:r /etc/passwd”</td></tr><tr><td align="left">：！ command</td><td align="left">vim编辑过程中，查询linux “:! ls /“</td></tr><tr><td align="left">: e！</td><td align="left">重新读取文件</td></tr></tbody></table><h3 id="4-2-4-其他模式"><a href="#4-2-4-其他模式" class="headerlink" title="4.2.4 其他模式"></a>4.2.4 其他模式</h3><pre class=" language-language-bash"><code class="language-language-bash">v、V或Ctrl+V    # 可视模式R              # 替换模式/word，？word  # /向下查找，？向上查找n，N          # 定位到下一个匹配字符，定位到上一个匹配字符# 视图模式# 视图模式修改方法：ctrl+v ， jjj，I，  写入#号，esc</code></pre><h2 id="4-3-VIM的缩进与保存"><a href="#4-3-VIM的缩进与保存" class="headerlink" title="4.3 VIM的缩进与保存"></a>4.3 VIM的缩进与保存</h2><pre class=" language-language-bash"><code class="language-language-bash">：set all         # 查看末行模式的帮助：set autoindent  # 保存上下缩进：set tabstop=2   # 调整tab键缩进：set nu          # 设置行号[root@foundation0 ~]# vim ~/.vimrc    仅对当前用户生效set nuset tabstop=2[root@foundation0 ~]# vim /etc/vimrc  全局设置，每个用户使用vim工具都有行号set nu</code></pre><h2 id="4-4-VIM的替换"><a href="#4-4-VIM的替换" class="headerlink" title="4.4 VIM的替换"></a>4.4 VIM的替换</h2><pre class=" language-language-bash"><code class="language-language-bash">:s///   @@@  AAA  ; ;;:s/old/new/:s/old/new/g:#,#s/old/new/g     #井号代表一个数字比如：1,5s/old/new/g:%s/old/new/g:#,$s/old/new/g    #井号代表数字，比如1，$s ，$代表末行，该命令为1行至末行# 修改某一段ip地址: %s/192.168.1/172.25.250/g# 取消文本中某个字段：:%s/10.10.10.10//g</code></pre><h2 id="4-5-关于重定向"><a href="#4-5-关于重定向" class="headerlink" title="4.5 关于重定向"></a>4.5 关于重定向</h2><pre class=" language-language-bash"><code class="language-language-bash">1=stand，2=error，&=1+2echo $SHELLecho 123456 > file1grep root /etc/passwd > /opt/a.txtgrep apache /etc/passwd > /opt/a.txtgrep -n ^$ /etc/resolv.confgrep na /etc/resolv.conf   > /root/lines.txttc/resolv.conf   > /root/lines.txt                 </code></pre><h1 id="5-管理本地用户和组"><a href="#5-管理本地用户和组" class="headerlink" title="5 管理本地用户和组"></a>5 管理本地用户和组</h1><h2 id="5-1-USER-用户"><a href="#5-1-USER-用户" class="headerlink" title="5.1 USER-用户"></a>5.1 USER-用户</h2><p>  基本概念：用户用于访问计算机资源</p><pre class=" language-language-bash"><code class="language-language-bash">0          超级用户 1000以下   系统用户1000以上   普通用户 组与用户ID对应(自然创建)</code></pre><h3 id="5-1-1-useradd-添加用户"><a href="#5-1-1-useradd-添加用户" class="headerlink" title="5.1.1 useradd-添加用户"></a>5.1.1 useradd-添加用户</h3><pre class=" language-language-bash"><code class="language-language-bash">语法:useradd 选项 选项参数 用户名option：-u：指定用户uid-g：指定主要群组-G：指定附加群组-s：指定shell环境 /bin/bash /sbin/nolgoin /bin/false-c：指定描述-d：指定用户家目录(通常不更改，如果设置，需要是未存在的目录)例：useradd user1   创建user1passwd user1    为user1设置密码id user1        查询用户信息</code></pre><h3 id="5-1-2-用户配置文件"><a href="#5-1-2-用户配置文件" class="headerlink" title="5.1.2 用户配置文件"></a>5.1.2 用户配置文件</h3><pre class=" language-language-bash"><code class="language-language-bash"># 用户配置文件路径:/etc/passwd[kiosk@foundation0 ~]$ vim /etc/passwdroot:x:0:0:root:/root:/bin/bash#用户名：密码占位符：UID：GID：描述：家目录：shell环境# 练习1：   [root@servera /]# useradd -u 2000 user1[root@servera /]# id user1[root@servera /]# groupadd group1[root@servera /]# tail -1 /etc/group[root@servera /]# useradd -g group1 user2[root@servera /]# tail -1 /etc/passwd[root@servera /]# useradd -G wheel user3[root@servera /]# useradd -c student -d /user4dir -s /sbin/nologin user4[root@servera /]# tail -1 /etc/passwd[root@servera /]# su - user1[user1@servera /]# ctrl+d[root@servera /]# su - user1[root@servera /]# su - user2  需要密码[root@servera /]# ctrl+d  退出用户[root@servera /]# passwd user2  超级用户设置密码123456123456[root@servera /]# su - user1[root@servera /]# su - user2  输入密码[root@servera /]# useradd -G root,tom user5   #将user5同时加入到组root和tom组中# 练习2：tom10，uid 3000 ，gid devops，shell环境为/bin/false,描述 student，家目录/tom10dir,附加组 root。useradd -u 3000 -g devops -s /bin/false -c student -d /tom10dir -G root  tom10</code></pre><h3 id="5-1-3-usermod-修改用户"><a href="#5-1-3-usermod-修改用户" class="headerlink" title="5.1.3 usermod-修改用户"></a>5.1.3 usermod-修改用户</h3><pre class=" language-language-bash"><code class="language-language-bash">语法：usermod 选项 选项参数 用户名option：-u：指定用户uid-g：指定主要群组-G：指定附加群组-s：指定shell环境 /bin/bash  /sbin/nolgoin /bin/false-c：指定描述-d：指定用户家目录（通常不更改，且如设置需要是未存在的目录）-a：额外指定附加组# 练习1:[root@servera /]# usermod -u 3000 user1[root@servera /]# usermod -g group1 user1[root@servera /]# usermod -G root user1[root@servera /]# usermod -s /bin/false user1    #shell环境为/bin/false的用户和系统无任何交互[root@servera /]# su - user1[root@servera /]# usermod -c heihei user1# 练习2：tom11的附加组，root。想额外添加一个附加组为devops[root@servera opt]# usermod -a -G root tom11[root@servera opt]# usermod -G root,devops tom11</code></pre><h3 id="5-1-4-userdel-删除用户"><a href="#5-1-4-userdel-删除用户" class="headerlink" title="5.1.4 userdel-删除用户"></a>5.1.4 userdel-删除用户</h3><pre class=" language-language-bash"><code class="language-language-bash">语法：userdel 选项 选项参数  用户名option：-r：删除用户同时删除邮箱和家目录[root@servera /]# userdel -r user5</code></pre><h2 id="5-2-PASSWORD-密码"><a href="#5-2-PASSWORD-密码" class="headerlink" title="5.2 PASSWORD-密码"></a>5.2 PASSWORD-密码</h2><h3 id="5-2-1-设置密码"><a href="#5-2-1-设置密码" class="headerlink" title="5.2.1 设置密码"></a>5.2.1 设置密码</h3><pre class=" language-language-bash"><code class="language-language-bash">语法:passwd 用户名# 方法1：[root@foundation0 /]# echo 123456 | passwd --stdin zhangsan  非交互式Changing password for user zhangsan.passwd: all authentication tokens updated successfully.# 方法2：[root@foundation0 /]# passwd zhangsan  交互式</code></pre><h3 id="5-2-2-密码配置文件"><a href="#5-2-2-密码配置文件" class="headerlink" title="5.2.2 密码配置文件"></a>5.2.2 密码配置文件</h3><pre class=" language-language-bash"><code class="language-language-bash">路径:/etc/shadowuser2:$6$9R47OYVVaxga34EJ$Y3pGf5EnHpn6vfiBk5ZU1U89d7UiySOsnAs/fkFMuPRyhCZAvv0a6UXRVLGXqRUKwP34Sg0W/CYb1VQp7H08L0:20015:0:99999:7:::说明:第一列: 用户名第二列: 密码(有密码状态,无密码状态,!!帐号锁定,* 该帐号永久不能登陆系统)第三列: 密码的最后一次修改时间（从1970年1月1日至今的天数）18834=今天第四列: 密码的最小时间(和第三列比较，密码修改相隔时间，或理解为密码自最后一次修改后多少天内不能再重复修改)第五列: 密码的最大时间(密码有效期) 99999表示永久不过期(和第3列比，相当于自最后一次修改多久后必须变更密码，否则过期)第六列: 密码过期前警告时间（和第5列比，在过n天你的密码就过期了，需要重设密码。）第七列: 密码过期后帐号（宽限时间，第五列密码的最大时间到期后，还可以使用系统的宽限时间，该期间中可以继续使用系统，但是再次登入系统时强制修改密码，否则无法进入）第八列: 帐号有效期（账号失效后，无论密码是否过期都不能使用。）第九列: 保留列</code></pre><h2 id="5-3-GROUP-用户组"><a href="#5-3-GROUP-用户组" class="headerlink" title="5.3 GROUP-用户组"></a>5.3 GROUP-用户组</h2><h3 id="5-3-1-groupadd"><a href="#5-3-1-groupadd" class="headerlink" title="5.3.1 groupadd"></a>5.3.1 groupadd</h3><pre class=" language-language-bash"><code class="language-language-bash">语法：groupadd 选项 选项参数 组名-g：指定组ID[root@servera /]# groupadd group10[root@servera /]# groupadd -g 3000 group10</code></pre><h3 id="5-3-2-groupmod"><a href="#5-3-2-groupmod" class="headerlink" title="5.3.2 groupmod"></a>5.3.2 groupmod</h3><pre class=" language-language-bash"><code class="language-language-bash">语法：groupmod 选项 选项参数 组名-n：更改组名 groupmod -n 新组名 旧组名[root@servera /]# groupmod -n group100 group10</code></pre><h3 id="5-3-3-groupdel"><a href="#5-3-3-groupdel" class="headerlink" title="5.3.3 groupdel"></a>5.3.3 groupdel</h3><pre class=" language-language-bash"><code class="language-language-bash"># 删除组信息groupdel groupname[root@foundation0 ~]# groupdel haha1</code></pre><h3 id="5-3-4-gpasswd"><a href="#5-3-4-gpasswd" class="headerlink" title="5.3.4 gpasswd"></a>5.3.4 gpasswd</h3><p>  加入群组与清除群组成员</p><pre class=" language-language-bash"><code class="language-language-bash">gpasswd-a：添加用户到群组-d：从组中清除用户[root@foundation0 ~]# useradd -G upup user5  添加用户时指定附加组（次要群组）[root@foundation0 ~]# usermod -G upup user1  修改用户时指定附加组（次要群组） [root@foundation0 ~]# gpasswd -a user2 rootAdding user user2 to group root[root@foundation0 ~]# gpasswd -d user2 rootRemoving user user2 from group root</code></pre><h3 id="5-3-5-用户组配置文件"><a href="#5-3-5-用户组配置文件" class="headerlink" title="5.3.5 用户组配置文件"></a>5.3.5 用户组配置文件</h3><pre class=" language-language-bash"><code class="language-language-bash">路径:/etc/group[root@localhost ~]# vim /etc/groupupup:x:2006:第一段: 组名第二段: 组密码占位符号第三段: gid第四段: 用户列表</code></pre><h1 id="6-控制对文件的访问"><a href="#6-控制对文件的访问" class="headerlink" title="6 控制对文件的访问"></a>6 控制对文件的访问</h1><h2 id="6-1-系统安全的技术点对比"><a href="#6-1-系统安全的技术点对比" class="headerlink" title="6.1 系统安全的技术点对比"></a><strong>6.1 系统安全的技术点对比</strong></h2><pre class=" language-language-bash"><code class="language-language-bash">#Linux操作系统涉及的安全部分:           防火墙                              semanage port ，selinux                            semanage ...软件app                             semanage boolean文件系统权限 特殊权限 facl 隐藏权限    semanage fcontext</code></pre><h2 id="6-2-文件权限说明"><a href="#6-2-文件权限说明" class="headerlink" title="6.2 文件权限说明"></a>6.2 文件权限说明</h2><table><thead><tr><th align="left">权限表示</th><th align="left">权限解释</th></tr></thead><tbody><tr><td align="left">r</td><td align="left">read(读)</td></tr><tr><td align="left">w</td><td align="left">write(写)</td></tr><tr><td align="left">x</td><td align="left">execute(执行)</td></tr></tbody></table><h2 id="6-3-权限表示"><a href="#6-3-权限表示" class="headerlink" title="6.3 权限表示"></a>6.3 权限表示</h2><pre class=" language-language-bash"><code class="language-language-bash"># ls -l test-rw-r--r--. 1 stu1 class1 35 May 21 14:09 testrw-r--r--   #中间9位是权限，逻辑分三组，所有者 所属组 其他人权限stu1   所有者class1 所属组</code></pre><h2 id="6-4-系统权限的作用"><a href="#6-4-系统权限的作用" class="headerlink" title="6.4 系统权限的作用"></a>6.4 系统权限的作用</h2><table><thead><tr><th align="left">权限</th><th align="left">对文件的影响</th><th align="left">对目录的影响</th></tr></thead><tbody><tr><td align="left">r</td><td align="left">cat</td><td align="left">ls</td></tr><tr><td align="left">w</td><td align="left">vim</td><td align="left">touch，rm，mkdir</td></tr><tr><td align="left">x</td><td align="left">./script</td><td align="left">cd</td></tr></tbody></table><h2 id="6-5-符号修改文件权限"><a href="#6-5-符号修改文件权限" class="headerlink" title="6.5 符号修改文件权限"></a>6.5 符号修改文件权限</h2><table><thead><tr><th align="left">对象</th><th align="left">设置方式</th><th align="left">权限</th></tr></thead><tbody><tr><td align="left">u(user)</td><td align="left">+ (添加)</td><td align="left">r</td></tr><tr><td align="left">g(group)</td><td align="left">-(减去)</td><td align="left">w</td></tr><tr><td align="left">o(other)</td><td align="left">= (设置）</td><td align="left">x</td></tr><tr><td align="left">a(all)</td><td align="left"></td><td align="left">s(SUID、SGID)、t(Sbit)</td></tr></tbody></table><h2 id="6-6-数字方式修改文件权限"><a href="#6-6-数字方式修改文件权限" class="headerlink" title="6.6 数字方式修改文件权限"></a>6.6 <strong>数字方式修改文件权限</strong></h2><table><thead><tr><th align="left">rwx</th><th align="left">8进制表示</th><th align="left">数字表示</th></tr></thead><tbody><tr><td align="left">r–</td><td align="left">100</td><td align="left">4</td></tr><tr><td align="left">-w-</td><td align="left">010</td><td align="left">2</td></tr><tr><td align="left">–x</td><td align="left">001</td><td align="left">1</td></tr></tbody></table><h2 id="6-7-文件权限设置-chmod"><a href="#6-7-文件权限设置-chmod" class="headerlink" title="6.7 文件权限设置-chmod"></a>6.7 文件权限设置-chmod</h2><pre class=" language-language-bash"><code class="language-language-bash">#语法：chmod 权限 文件名u g o a   + - =   r w x s t[root@node1 opt]# ll test -rw-r--r--. 1 root root 0 Nov 24 04:55 test[root@node1 opt]# chmod u+x test [root@node1 opt]# ll test -rwxr--r--. 1 root root 0 Nov 24 04:55 test</code></pre><h2 id="6-8-文件属主和属组-chown"><a href="#6-8-文件属主和属组-chown" class="headerlink" title="6.8 文件属主和属组-chown"></a>6.8 文件属主和属组-chown</h2><pre class=" language-language-bash"><code class="language-language-bash">#语法：chown  所有者:所属组 文件名 chown  该命令可以作用于文件、目录，修改时保证所有者的用户及组都是存在的。例:chown user2:user2 newfile# 练习:[root@node1 opt]# ll test-rwxr--r--. 1 root root 0 Nov 24 04:55 test[root@node1 opt]# id studentuid=1000(student) gid=1000(student) groups=1000(student),10(wheel)[root@node1 opt]# useradd harry[root@node1 opt]# chown student test;ll test-rwxr--r--. 1 student root 0 Nov 24 04:55 test[root@node1 opt]# chown :harry test;ll test-rwxr--r--. 1 student harry 0 Nov 24 04:55 test[root@node1 opt]# useradd sally[root@node1 opt]# chown sally:sally test;ll test-rwxr--r--. 1 sally sally 0 Nov 24 04:55 test# -R参数[root@node1 opt]# ll -d dir1drwxrwxr-x. 2 root root 19 Nov 24 05:15 dir1[root@node1 opt]# chown -R sally:sally dir1[root@node1 opt]# ll -d dir1drwxrwxr-x. 2 sally sally 19 Nov 24 05:15 dir1</code></pre><h2 id="6-9-文件默认权限-umask"><a href="#6-9-文件默认权限-umask" class="headerlink" title="6.9 文件默认权限-umask"></a>6.9 文件默认权限-umask</h2><pre class=" language-language-bash"><code class="language-language-bash">#系统默认定义权限对于文件是666、对于目录是777#查看umask值[root@servera /]# umask0022#修改方法umask[root@servera /]# umask 0002修改完后，可以去文件和目录查看权限，看是否和之前不一样，看完改回来#永久生效[root@servera /]# echo 'umask 0002' >> ~/.bash_profile#将后面文件中的值加载到当前shell中。系统登录会读取~/.bash_profile文件自动加载[root@servera /]# source ~/.bash_profile  #source </code></pre><h2 id="6-10-umask的计算"><a href="#6-10-umask的计算" class="headerlink" title="6.10 umask的计算"></a>6.10 umask的计算</h2><pre class=" language-language-bash"><code class="language-language-bash">#示例1：文件默认权限666umask后三位022快捷方法：变成权限后相减rw-rw-rw-  =  666  文件系统默认权限----w--w-  =  022  umask值------------------------------rw-r--r--  =  644  创建文件时的默认权限目录默认权限777rwxrwxrwx  =  777  目录系统默认权限----w--w-  =  022  umask值------------------------------rwxr-xr-x  =  755  创建目录时的默认权限故系统中应设置为:0022#示例2:文件权限是r-- --- ---， 400   文件夹是dr-x --- ---  500umask?目录rwxrwxrwx =  777r-x------ =  500--------------------w-rwxrwx =  277文件rw-rw-rw-  =  666-w-rwxrwx  =  umask  ------------------r-------   =  400参考umask计算方法：https://www.cnblogs.com/wyllearning/p/16482006.html如果减法时目录和文件权限不一致时，以目录的为准计算umask值</code></pre><h2 id="6-10-特殊权限"><a href="#6-10-特殊权限" class="headerlink" title="6.10 特殊权限"></a>6.10 特殊权限</h2><p>  文件系统权限可以完成一些基本权限功能设置，但有些特殊要求是达不到的，可能需要特殊权限来完成</p><p>  Linux系统中特殊权限有三个：SUID 4 、SGID 2 、SBIT 1</p><h3 id="6-10-1-SUID-4"><a href="#6-10-1-SUID-4" class="headerlink" title="6.10.1 SUID 4"></a>6.10.1 SUID 4</h3><pre class=" language-language-bash"><code class="language-language-bash"># 通常设置在二进制可执行文件（命令）上，并具有执行权限的情况下# 作用：设置了该权限的命令，被其他用户执行时，会临时获取文件所有者权限[student@clear ~]$ cat /etc/shadow   #普通用户无法查看/etc/shadow[student@clear ~]$ su - root         #切换root身份[root@clear ~]# chmod u+s /usr/bin/cat   #数字修改方式：chmod 4755 /usr/bin/cart[root@clear ~]# ll /usr/bin/cat-rwsr-xr-x. 1 root root 34512 Aug 13  2018 /usr/bin/cat[student@clear ~]$ su - studnet[student@clear ~]$ cat /etc/shadow #能够看见内容，临时获取拥有者权限#数字修改法：chmod 4755 /usr/bin/cat# check：创建两个不同用户登录操作系统，进入dirt目录分别创建文件，尝试互相删除对方文件，结果应不能互相删除文件# 大S和小s区别，  1.执行权限位大S是，没有x  2.执行权限位小s是该位，有x</code></pre><h3 id="6-10-2-SGID-2"><a href="#6-10-2-SGID-2" class="headerlink" title="6.10.2 SGID 2"></a>6.10.2 SGID 2</h3><pre class=" language-language-bash"><code class="language-language-bash">#该权限通常设置在`目录`上，设置了该权限的目录，在该目录中创建`子文件及目录`时会`继承`父目录所属组[root@clear opt]# chmod g+s dir1[root@clear opt]# ll -d dir1drwxr-sr-x. 2 student student 22 Nov 19 04:51 dir1[root@clear opt]# touch dir1/root1.txt[root@clear opt]# ll dir1/root1.txt-rw-r--r--. 1 root student 0 Nov 19 04:52 dir1/root1.txt#数字修改法： chmod 2755 dir1</code></pre><h3 id="6-10-3-SBIT-1"><a href="#6-10-3-SBIT-1" class="headerlink" title="6.10.3 SBIT 1"></a>6.10.3 SBIT 1</h3><pre class=" language-language-bash"><code class="language-language-bash">#该权限通常设置在目录上，设置了该权限的目录，其他用户在该目录中只能删除所有者是自己的文件[root@clear opt]# chmod 1777 /opt/share/[root@clear opt]# ll -d /opt/share/drwxrwxrwt. 2 root root 6 Nov 19 04:56 /opt/share/[root@clear opt]# su - studentLast login: Sat Nov 19 04:55:24 EST 2022 on pts/0[student@clear ~]$ touch /opt/share/student.txt.haha[student@clear ~]$ logout[root@clear opt]# su - tomLast login: Sat Nov 19 04:55:38 EST 2022 on pts/0[tom@clear ~]$ rm -f /opt/share/student.txt.haharm: cannot remove '/opt/share/student.txt.haha': Operation not permitted</code></pre><h1 id="7-进程监控及管理"><a href="#7-进程监控及管理" class="headerlink" title="7 进程监控及管理"></a>7 进程监控及管理</h1><pre class=" language-language-bash"><code class="language-language-bash">yum install -y psmiscpstree -p# 程序被开启会产生一个或多个进程，他们都有对应父进程与子进程，每个进程都有进程号PID# systemd 1 不能被杀死，除非重启，关机</code></pre><h2 id="7-1-查看进程"><a href="#7-1-查看进程" class="headerlink" title="7.1 查看进程"></a>7.1 查看进程</h2><pre class=" language-language-bash"><code class="language-language-bash"># ps以静态的方式查看系统进程ps -lps  aux  ps aux | grep http[root@servera ~]# ps -l# 查看httpd进程ps aux |grep httpd# top以同态的形式查看进程top</code></pre><h2 id="7-2-终止进程"><a href="#7-2-终止进程" class="headerlink" title="7.2 终止进程"></a>7.2 终止进程</h2><h3 id="7-2-1-kill命令"><a href="#7-2-1-kill命令" class="headerlink" title="7.2.1 kill命令"></a>7.2.1 kill命令</h3><pre class=" language-language-bash"><code class="language-language-bash">#语法 kill -s 信号名称 或-n 信号编号#Options:-s sig  SIG is a signal name-n sig  SIG is a signal numberkill -s SIGKILL httpdkill -n 9 httpd   # 或 kill -9 httpd[root@node1 /]# kill -l 1) SIGHUP   2) SIGINT   3) SIGQUIT  4) SIGILL   5) SIGTRAP 6) SIGABRT  7) SIGBUS   8) SIGFPE   9) SIGKILL 10) SIGUSR1[root@node1 /]# vim 1 &[1] 1372[root@node1 /]# ps -l[root@node1 /]# kill -n 9 1372[root@node1 /]# ps -lF S   UID     PID    PPID  C PRI  NI ADDR SZ WCHAN  TTY          TIME CMD0 S     0    1313    1312  0  80   0 - 59084 -      pts/1    00:00:00 bash0 R     0    1374    1313  0  80   0 - 63799 -      pts/1    00:00:00 ps[1]+  Killed                  vim 1</code></pre><h3 id="7-2-2-killall命令"><a href="#7-2-2-killall命令" class="headerlink" title="7.2.2 killall命令"></a>7.2.2 killall命令</h3><pre class=" language-language-bash"><code class="language-language-bash">#语法：killall 守护进程名称#yum install -y httpdsystemctl start httpdps aux | grep httpdkillall httpdyum provides killallyum install -y psmisc-23.1-3.el8.x86_64killall httpdps aux | grep httpd</code></pre><h2 id="7-3-作业控制jobs"><a href="#7-3-作业控制jobs" class="headerlink" title="7.3 作业控制jobs"></a>7.3 作业控制jobs</h2><pre class=" language-language-bash"><code class="language-language-bash">[root@servera ~]# dd if=/dev/zero of=./bigfile bs=1M count=1000ctrl + z [root@servera ~]# jobs[1]+  Stopped                 dd if=/dev/zero of=./bigfile bs=1M count=1000[root@servera ~]# bg ％1[1]+ dd if=/dev/zero of=./bigfile bs=1M count=1000 &[root@servera ~]# jobs[1]+  Running                 dd if=/dev/zero of=./bigfile bs=1M count=1000 &[root@servera ~]# fg %1[root@servera ~]# kill -9 %2[2]-  Stopped                 vim file2[root@servera ~]# jobs[2]-  Killed                  vim file2[3]+  Stopped                 nice -n -10 vim file4</code></pre><h2 id="7-4-进程优先级调整"><a href="#7-4-进程优先级调整" class="headerlink" title="7.4 进程优先级调整"></a>7.4 进程优先级调整</h2><pre class=" language-language-bash"><code class="language-language-bash">#nice值#超级用户root 可以修改nice值范围 -20~19#普通用户user 可以修改nice值范围  0-191.进程优先级数字越小，优先级越高2.优先级不能直接改，可以通过nice值来影响优先级3.旧优先级 + nice值 = 新优先级  80       -10   = 70#两种方法：1.产生新进程时，设置nice值  nice  -n -5  vim file2 &2.修改现有进程nice值  renice -n  10  PID# ps -l 查看需要更改的进程号  renice -n 10 28183</code></pre><h1 id="8-控制服务与守护进程"><a href="#8-控制服务与守护进程" class="headerlink" title="8 控制服务与守护进程"></a>8 控制服务与守护进程</h1><h2 id="8-1-服务状态关键字段"><a href="#8-1-服务状态关键字段" class="headerlink" title="8.1 服务状态关键字段"></a>8.1 服务状态关键字段</h2><table><thead><tr><th align="left">字段</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">Loaded</td><td align="left">服务单元是否加载到内存</td></tr><tr><td align="left">Active</td><td align="left">服务单元是否在运行，运行了多久</td></tr><tr><td align="left">Main PID</td><td align="left">服务的主进程ID，包括命令名称</td></tr><tr><td align="left">Status</td><td align="left">有关该服务的其他信息</td></tr></tbody></table><h2 id="8-2-systemctl管理服务"><a href="#8-2-systemctl管理服务" class="headerlink" title="8.2 systemctl管理服务"></a>8.2 systemctl管理服务</h2><pre class=" language-language-bash"><code class="language-language-bash">systemctl -t help# 列入.service扩展名，代表服务，如web服务systemctl list-units --type service  列出当前服务器加载的服务单元systemctl  status  httpd.service     查看某个服务    [root@servera system]# systemctl status httpd# 查看服务是否启动[root@servera system]# systemctl  is-active httpdactive# 查看服务是否开机启动[root@servera system]# systemctl enable httpd[root@servera system]# systemctl is-enabled httpdenabled[root@servera system]# systemctl disable httpdRemoved /etc/systemd/system/multi-user.target.wants/httpd.service.[root@servera system]# systemctl is-enabled httpddisabled# 常见特征：1、安装   yum install -y httpd2、启动   systemctl  start  httpd.service （单元文件）/usr/lib/systemd/system/3、查进程 ps aux | grep httpd , 每个服务有自己的守护进程/usr/sbin/httpd4、查端口 netstat -ntlp ，找到80端口，对应Listen监听状态 对应httpd服务# vim /etc/service  该文件记录了系统服务的端口和协议的对应关系</code></pre><h2 id="8-3-服务状态分类"><a href="#8-3-服务状态分类" class="headerlink" title="8.3 服务状态分类"></a>8.3 服务状态分类</h2><table><thead><tr><th align="left">关键字</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">loaded</td><td align="left">单元配置文件已处理</td></tr><tr><td align="left">active（running）</td><td align="left">正在通过一个或多个持续进程与运行</td></tr><tr><td align="left">active（exited）</td><td align="left">已成功完成一次性配置</td></tr><tr><td align="left">active（waiting）</td><td align="left">运行中，但正在等待事件</td></tr><tr><td align="left">inactive</td><td align="left">不在运行</td></tr><tr><td align="left">enabled</td><td align="left">在系统引导时启动</td></tr><tr><td align="left">disabled</td><td align="left">未设为在系统引导时启动</td></tr><tr><td align="left">static</td><td align="left">无法启动，但可以由某一启动的单元自动启动</td></tr></tbody></table><h2 id="8-4-管理系统服务"><a href="#8-4-管理系统服务" class="headerlink" title="8.4 管理系统服务"></a>8.4 管理系统服务</h2><p>  语法：systemctl 管理命令 unitname</p><table><thead><tr><th align="left">管理命令</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">status</td><td align="left">查看状态</td></tr><tr><td align="left">start</td><td align="left">开启</td></tr><tr><td align="left">stop</td><td align="left">关闭</td></tr><tr><td align="left">restart</td><td align="left">重启</td></tr><tr><td align="left">reload</td><td align="left">加载配置文件</td></tr><tr><td align="left">enable</td><td align="left">开机启动</td></tr><tr><td align="left">disable</td><td align="left">关闭开机启动</td></tr><tr><td align="left">is-active</td><td align="left">查看服务状态是否启动</td></tr><tr><td align="left">is-enabled</td><td align="left">查看服务是否开机自启动</td></tr><tr><td align="left">list-dependencies 【unitname】</td><td align="left">查看单元依赖</td></tr><tr><td align="left">mask</td><td align="left">禁止服务，无法启动或开机启动</td></tr><tr><td align="left">unmask</td><td align="left">解除码</td></tr></tbody></table><h1 id="9-OPENSSH服务"><a href="#9-OPENSSH服务" class="headerlink" title="9 OPENSSH服务"></a>9 OPENSSH服务</h1><h2 id="9-1-ssh常用功能"><a href="#9-1-ssh常用功能" class="headerlink" title="9.1 ssh常用功能"></a>9.1 ssh常用功能</h2><pre class=" language-language-bash"><code class="language-language-bash">[root@servera ~]# vim /etc/hosts     系统是否做了dns,ip和域名及主机名的映射[root@servera ~]# ssh root@172.25.250.11[root@serverb /]# scp root@172.25.250.10:/opt/newfile  .root@172.25.250.10's password: newfile                                                  100%    0     0.0KB/s   00:00 [root@servera opt]# ssh root@172.25.250.11 'yum install -y httpd'ssh root@172.25.250.11 'yum install -y httpd'</code></pre><h2 id="9-2-ssh免密登录"><a href="#9-2-ssh免密登录" class="headerlink" title="9.2 ssh免密登录"></a>9.2 ssh免密登录</h2><pre class=" language-language-bash"><code class="language-language-bash">[root@servera ssh]# ssh-keygen  后面三个回车[root@servera ssh]# ssh-copy-id  root@serverb[root@serverb /]# cd /root/.ssh/[root@serverb .ssh]# lsauthorized_keys  known_hosts[root@servera ssh]# ssh root@serverb# a免密远程b，如果想b远程a免密，需要相同的配置</code></pre><h2 id="9-3-ssh服务控制"><a href="#9-3-ssh服务控制" class="headerlink" title="9.3 ssh服务控制"></a>9.3 ssh服务控制</h2><pre class=" language-language-bash"><code class="language-language-bash"># 拒绝root登录[root@serverb ~]# vim /etc/ssh/sshd_configPermitRootLogin no[root@serverb ~]# systemctl reload sshd（或restart）</code></pre><h2 id="9-4-sudo命令"><a href="#9-4-sudo命令" class="headerlink" title="9.4 sudo命令"></a>9.4 sudo命令</h2><pre class=" language-language-bash"><code class="language-language-bash"># 将用户设置为特权用户[student@servera ~]$ yum remove -y httpdError: This command has to be run under the root user.[root@servera /]# vim /etc/sudoers    或者 visudo## Allow root to run any commands anywhere root    ALL=(ALL)       ALLstudent ALL=(ALL)       ALL[student@servera ~]$ sudo yum remove -y httpd[sudo] password for student: student# 将账号添加到特权用户组中，培训环境默认特权用户组是wheel组，在/etc/sudoers文件中用%wheel来表示usermod -G wheel tom# 设置特权组中用户切换时不需要密码%admin  ALL=(ALL)       NOPASSWD: ALL# 添加一个特权组admin，而且组内有一个成员是harry。最终harry账号应当为特权账号[root@serverb ~]# groupadd admin[root@serverb ~]# visudo[root@serverb ~]# useradd -G admin harry[root@serverb ~]# su - harry[harry@serverb ~]$ sudo -i[sudo] password for harry: </code></pre><h1 id="10-日志分析与存储"><a href="#10-日志分析与存储" class="headerlink" title="10 日志分析与存储"></a>10 日志分析与存储</h1><h2 id="10-1-系统中的日志文件"><a href="#10-1-系统中的日志文件" class="headerlink" title="10.1 系统中的日志文件"></a>10.1 系统中的日志文件</h2><table><thead><tr><th align="left">日志文件</th><th align="left">存储的消息类型</th></tr></thead><tbody><tr><td align="left">/var/log/messages</td><td align="left">大多数系统日志消息处存放处</td></tr><tr><td align="left">/var/log/secure</td><td align="left">与安全性和身份验证时间相关的syslog消息</td></tr><tr><td align="left">/var/log/maillog</td><td align="left">与邮件服务器相关的syslog消息</td></tr><tr><td align="left">/var/log/cron</td><td align="left">与计划任务执行相关的syslog消息</td></tr><tr><td align="left">/var/log/boot.log</td><td align="left">与系统启动相关的消息</td></tr></tbody></table><h3 id="10-1-1-rsyslog服务管理日志"><a href="#10-1-1-rsyslog服务管理日志" class="headerlink" title="10.1.1 rsyslog服务管理日志"></a>10.1.1 rsyslog服务管理日志</h3><pre class=" language-language-bash"><code class="language-language-bash">[root@haha log]# yum provides /etc/rsyslog.conf  #查看文件是哪个软件包提供的[root@clear log]# rpm -qc rsyslog-8.1911.0-3.el8.x86_64 /etc/logrotate.d/syslog/etc/rsyslog.conf       #一般服务文件以.conf结尾，改文件是日志服务的配置文件/etc/sysconfig/rsyslog[root@clear log]# vim /etc/rsyslog.conf</code></pre><h3 id="10-1-2-记录日志的规则"><a href="#10-1-2-记录日志的规则" class="headerlink" title="10.1.2 记录日志的规则"></a>10.1.2 记录日志的规则</h3><pre class=" language-language-bash"><code class="language-language-bash">#日志文件配置格式: mail.info  /var/log/vsftpd.log  #.点代表包含后面级别及以上级别AAAA.BBBB CCCCAAAA 产生日志的设备（类别）    #如何产生的日志BBBB 日志的级别              #日志有不同安全级别，类似轻重缓急的严重程度，发出警告CCCC 保存日志的位置          #在系统中保存日志文件的路径</code></pre><h3 id="10-1-3-rsyslog配置文件类别"><a href="#10-1-3-rsyslog配置文件类别" class="headerlink" title="10.1.3 rsyslog配置文件类别"></a>10.1.3 rsyslog配置文件类别</h3><table><thead><tr><th align="left">类别</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">Kern</td><td align="left">内核</td></tr><tr><td align="left">authpriv</td><td align="left">授权和安全</td></tr><tr><td align="left">cron</td><td align="left">计划任务</td></tr><tr><td align="left">mail</td><td align="left">邮件</td></tr><tr><td align="left">daemon</td><td align="left">系统守护进程</td></tr><tr><td align="left">user</td><td align="left">普通用户级别的</td></tr><tr><td align="left">syslog</td><td align="left">由rsyslog生成的信息</td></tr><tr><td align="left">loca10~loca17</td><td align="left">自定义本地策略</td></tr><tr><td align="left">*</td><td align="left">所有类别</td></tr></tbody></table><h3 id="10-1-4-日志级别"><a href="#10-1-4-日志级别" class="headerlink" title="10.1.4 日志级别"></a>10.1.4 日志级别</h3><table><thead><tr><th align="left">等级</th><th align="left">解释</th></tr></thead><tbody><tr><td align="left">EMERG（紧急）</td><td align="left">会导致主机系统不可用的情况</td></tr><tr><td align="left">ALERT（警告）</td><td align="left">必须马上采取措施解决的问题</td></tr><tr><td align="left">CRIT（严重）</td><td align="left">比较严重的情况</td></tr><tr><td align="left">ERR（错误）</td><td align="left">运行出现错误</td></tr><tr><td align="left">WARNING（提醒）</td><td align="left">可能会影响系统功能的事件</td></tr><tr><td align="left">NOTICE（注意）</td><td align="left">不会影响系统但值得注意</td></tr><tr><td align="left">INFO（信息）</td><td align="left">一般信息</td></tr><tr><td align="left">DEBUG（调试）</td><td align="left">程序或系统调试信息等</td></tr><tr><td align="left">*</td><td align="left">所有等级</td></tr><tr><td align="left">none</td><td align="left">不记录日志</td></tr></tbody></table><pre class=" language-language-bash"><code class="language-language-bash">*.info;mail.none;authpriv.none;cron.none                /var/log/messages*.info    # *代表所有级别    .点代表后面的等级及以上等级，也就是info以上的等级全记录；分号是不同设备等级的分隔符号-/var/log/maillog   # - 代表先记录缓存，再记录硬盘，减轻硬盘i/o读写压力</code></pre><h3 id="10-1-5-logger发送测试日志"><a href="#10-1-5-logger发送测试日志" class="headerlink" title="10.1.5 logger发送测试日志"></a>10.1.5 logger发送测试日志</h3><pre class=" language-language-bash"><code class="language-language-bash">1 查看rsyslog服务是否开启 (默认系统已开启)[root@servera ~]# systemctl status rsyslog2 编辑rsyslog配置文件[root@servera ~]# vim /etc/rsyslog.conf# Save boot messages also to boot.loglocal7.*                                                /var/log/boot.log..*.debug                                                 /var/log/messages.debug3 重启rsyslog日志服务让配置生效[root@servera ~]# systemctl restart rsyslog4 开另一个窗口 ctrl+shift+t[root@servera ~]# tail -n 0 -f /var/log/messages.debug   5 使用logger命令生成一个user类别，debug级别的日志内容为“Debug test messages”  #（考点）[root@servera ~]# logger -p user.debug "Debug test messages"    6 在第4步的窗口中查看新生成日志信息[root@servera ~]# tail -n 0 -f /var/log/messages.debugJun 18 14:45:31 servera root[29174]: messages haha</code></pre><h2 id="10-2-journalctl"><a href="#10-2-journalctl" class="headerlink" title="10.2 journalctl"></a>10.2 journalctl</h2><pre class=" language-language-bash"><code class="language-language-bash"># 传统的日志服务是rsyslog# 新的日志服务是systemd-journal，它也是一个日志管理服务，可以收集来自内核、系统早期启动阶段的日志，以及系统进程在启动和运行中的一些标准输出与错误输出# systemd-journal一旦重启既消失，因为保存在了/run/log/journal/*/*.journal结尾，该文件是一个二进制日志文件，需要用journalctl命令查看journalctl      #查看系统日志journalctl -n   #通过q或ctrl接触观看  ，此命令显示方式类似与tail -njournalctl -n 5 journalctl -p err  日志等级journalctl -f journalctl -p err journalctl -p info  （deubg、info、notice、warning、err、crit、alert、emerg）journalctl --since "2020-02-28 22:53:35" --until "2020-02-28 22:53:40"</code></pre><h3 id="10-2-1-journalctl常用字段"><a href="#10-2-1-journalctl常用字段" class="headerlink" title="10.2.1 journalctl常用字段"></a>10.2.1 journalctl常用字段</h3><table><thead><tr><th align="left">常用字段</th><th align="left">含义</th></tr></thead><tbody><tr><td align="left">_COMM</td><td align="left">命令名称</td></tr><tr><td align="left">_EXE</td><td align="left">进程的可执行文件的路径</td></tr><tr><td align="left">_PID</td><td align="left">进程的PID</td></tr><tr><td align="left">_UID</td><td align="left">UID</td></tr><tr><td align="left">_SYSTEM_UNIT</td><td align="left">启动该进程的systemd单元</td></tr></tbody></table><pre class=" language-language-bash"><code class="language-language-bash">journalctl -o verbose journalctl _HOSTNAME=localhostjournalctl _HOSTNAME=localhost _PID=1</code></pre><h3 id="102-2-保存journal服务文件"><a href="#102-2-保存journal服务文件" class="headerlink" title="102.2 保存journal服务文件"></a>102.2 保存journal服务文件</h3><pre class=" language-language-bash"><code class="language-language-bash">mandbman -k journalman 5 journald.conf  ， Storage=[root@clear journal]# ll -d /run/log/journal[root@clear journal]# cp -a /run/log/journal/ /var/log/journal[root@clear journal]# ll -d /var/log/journaldrwxr-sr-x. 4 root systemd-journal 86 Nov 19 04:30 /var/log/journal[root@clear journal]# systemctl restart systemd-journald[root@clear journal]# ll /var/log/journal/3a2b4da8dabb4729935c193e58ad052d/  #字符串目录名字每个人的可能不一样。不要复制我的笔记。total 8192-rw-r-----. 1 root root 8388608 Nov 19 04:30 system.journal[root@clear journal]# journalctl</code></pre><h2 id="10-3-准确的系统时间"><a href="#10-3-准确的系统时间" class="headerlink" title="10.3 准确的系统时间"></a>10.3 准确的系统时间</h2><pre class=" language-language-bash"><code class="language-language-bash"># RHEL6 ntp服务# RHEL8 chrony服务# 还是使用同样的协议标准ntp（network time protocol）UTC：通用协调时   （UTC时间0点是北京时间8点,因为中国、新加坡、马来西亚、菲律宾等国的时间与UTC的时差均为+8,也就是UTC+8,所以当UTC时间0点,北京时间即为0+8=8点）GMT：格林威治标准时间CST：中国标准时间 (China Standard Time）    （中国大陆、中国香港、中国澳门、中国台湾、蒙古国、新加坡、马来西亚、菲律宾、西澳大利亚州的时间与UTC的时差均为＋8，也就是UTC+8）RTC：(Real-Time Clock)也称为硬件时间：RTC是芯片内置的硬件时钟，只要芯片不断电，即使操作系统关机的时候，RTC时钟也是正常在      走的，所以当操作系统关机重启后，可通过读取RTC时间来更新系统时间    （可通过hwclock命令来获取具体的时间       -r 查看硬件时间      -s 硬件时间设置到系统      -w 系统设置到硬件）</code></pre><h3 id="10-3-1-timedatectl命令"><a href="#10-3-1-timedatectl命令" class="headerlink" title="10.3.1 timedatectl命令"></a>10.3.1 timedatectl命令</h3><pre class=" language-language-bash"><code class="language-language-bash">[root@servera log]# timedatectl                Local time: Sat 2020-02-29 08:51:49 CST           Universal time: Sat 2020-02-29 00:51:49 UTC                 RTC time: Sat 2020-02-29 08:11:07                Time zone: Asia/Shanghai (CST, +0800)System clock synchronized: yes              NTP service: active          RTC in local TZ: no          [root@servera log]# timedatectl list-timezones     [root@servera log]# timedatectl set-timezone Asia/Hong_Kong [root@servera log]# timedatectl                Local time: Sat 2020-02-29 08:55:48 HKT           Universal time: Sat 2020-02-29 00:55:48 UTC                 RTC time: Sat 2020-02-29 08:15:06                Time zone: Asia/Hong_Kong (HKT, +0800)System clock synchronized: yes              NTP service: active          RTC in local TZ: no# 修改时间方法timedatectl set-time "2020-02-30 10:00:00"Failed to set time: NTP unit is activetimedatectl set-ntp false timedatectl set-time "2020-02-30 10:00:00"timedatectl set-ntp true </code></pre><h3 id="10-3-2-chrony命令"><a href="#10-3-2-chrony命令" class="headerlink" title="10.3.2 chrony命令"></a>10.3.2 chrony命令</h3><pre class=" language-language-bash"><code class="language-language-bash">server===server选项格式===server host  [ key n ] [ version n ] [ prefer ] [ mode n ] [ minpoll n ] [ maxpoll n ] [ iburst ]其中host是上层NTP服务器的IP地址或域名，随后所跟的参数解释如下所示：◆ key： 表示所有发往服务器的报文包含有秘钥加密的认证信息，n是32位的整数，表示秘钥号。◆ version： 表示发往上层服务器的报文使用的版本号，n默认是3，可以是1或者2。◆ prefer： 如果有多个server选项，具有该参数的服务器有限使用。◆ mode： 指定数据报文mode字段的值。◆ minpoll： 指定与查询该服务器的最小时间间隔为2的n次方秒，n默认为6，范围为4-14。◆ maxpoll：  指定与查询该服务器的最大时间间隔为2的n次方秒，n默认为10，范围为4-14。◆ iburst： 当初始同步请求时，采用突发方式接连发送8个报文，时间间隔为2秒。[root@servera ~]# systemctl enable --now chronyd    #--now启动服务 enable 开机自动[root@servera ~]# systemctl status chronyd[root@servera ~]# vim /etc/chrony.conf   #大概第7行 server 后面添加服务器'地址'或'域名'。server classroom.exmaple.com iburst[root@servera ~]# systemctl  restart chronyd.service[root@servera ~]# chronyc sources -v</code></pre><h1 id="11-RHEL网络管理"><a href="#11-RHEL网络管理" class="headerlink" title="11 RHEL网络管理"></a>11 RHEL网络管理</h1><h2 id="11-1-IPv4地址"><a href="#11-1-IPv4地址" class="headerlink" title="11.1 IPv4地址"></a>11.1 IPv4地址</h2><pre class=" language-language-bash"><code class="language-language-bash">IP/(NETMASK\|PREFIX)   172.25.0.9/255.255.0.0 \| 172.25.0.9/16--- ---------------------- --------------------------------------------GATEWAY                172.25.x.xDNS                    正向解析 \# host servera， 反向解析 \# host私有地址：A　１－１２７B　１２８－１９１C　１９２－２２３IP地址分类默认对应的子网掩码掩码：Ａ：２５５．０．０．０         11111111.00000000.00000000.00000000     /8Ｂ：２５５．２５５．０．０      11111111.11111111.00000000.00000000     /16Ｃ：２５５．２５５．２５５．０  11111111.11111111.11111111.00000000     /24</code></pre><h3 id="11-1-1-IP与掩码二进制与运算"><a href="#11-1-1-IP与掩码二进制与运算" class="headerlink" title="11.1.1 IP与掩码二进制与运算"></a>11.1.1 IP与掩码二进制与运算</h3><pre class=" language-language-bash"><code class="language-language-bash">网络地址   172.25.0.0       主机位全0---------- ---------------- -----------广播地址   172.25.255.255   主机位全1</code></pre><h3 id="11-1-2-查看ipv4与ipv6"><a href="#11-1-2-查看ipv4与ipv6" class="headerlink" title="11.1.2 查看ipv4与ipv6"></a>11.1.2 查看ipv4与ipv6</h3><pre class=" language-language-bash"><code class="language-language-bash"># 查看ip地址方法1：[root@servera ~]#ifconfig [root@servera ~]#ifconfig  eth0# 查看ip地址方法2：[root@servera ~]# ip addr show eth0[root@servera ~]# ip a  s eth0[root@servera ~]# ip -s link show enp1s0 </code></pre><h3 id="11-1-3-端口与服务"><a href="#11-1-3-端口与服务" class="headerlink" title="11.1.3 端口与服务"></a>11.1.3 端口与服务</h3><pre class=" language-language-bash"><code class="language-language-bash"># 查看服务端口是否被占用lsof -i:80 或 netstat-n：显示接口和端口编号-t：tcp信息-u：udp信息-l：监听状态信息-a：显示所有信息-p：显示协议名称而不是端口netstat -ntlp | grep 80# 参考ss和netstat区别：https://blog.csdn.net/qq_37863891/article/details/107283415# 标准服务端口 /etc/services</code></pre><h2 id="11-2-网络管理工具"><a href="#11-2-网络管理工具" class="headerlink" title="11.2 网络管理工具"></a>11.2 网络管理工具</h2><h3 id="11-2-1-nmcli的概念"><a href="#11-2-1-nmcli的概念" class="headerlink" title="11.2.1 nmcli的概念"></a>11.2.1 nmcli的概念</h3><pre class=" language-language-bash"><code class="language-language-bash">1.使用nmcli管理网络服务NetworkManager2.nmcli工具的功能：查看网络设备、创建网络连接、修改网络配置3.nmcli的特点及概念：  nmcli工具可以对网卡或网卡配置文件操作  device ---- 网卡设备  connection --- 连接  指的就是网卡配置文件  一个device可以拥有多个connection，同一时间只能启用一个connection，且一个connection只能属于一个device4.举例：  device-----eth0  connection1  ----  dhcp    自动获取IP    connection2  ----  static  静态IP  </code></pre><h3 id="11-2-2-nmcli管理网络"><a href="#11-2-2-nmcli管理网络" class="headerlink" title="11.2.2 nmcli管理网络"></a>11.2.2 nmcli管理网络</h3><pre class=" language-language-bash"><code class="language-language-bash">mandbman -k nmclinmcli (1) nmcli-examples (7)man nmcli | grep -A 2 'nmcli connection add'-basic[root@servera ~]# nmcli connection show [root@servera ~]# nmcli connection show --active [root@servera ~]# nmcli device status -add---添加   dhcp方式: #创建一个名为default的手动链接，绑定至eth0网卡[root@servera ~]# nmcli connection add  con-name 'default' type ethernet ifname eth0  autoconnect yes    [root@servera ~]# nmcli con show    static方式：#创建一个名为static的静态链接，绑定至eth1网卡[root@servera ~]# nmcli connection add con-name static type ethernet ifname eth0 autoconnect yes ipv4.addresses 192.168.0.1/24 ipv4.gateway 192.168.0.254 ipv4.dns 8.8.8.8 ipv4.method manual  [root@servera ~]# nmcli connection showNAME                UUID                                  TYPE      DEVICE Wired connection 1  1f5ad5ae-e926-3f54-9805-33174e63af47  ethernet  eth0   static              980f6712-86b7-4d92-bc84-62e677ccabfc  ethernet  eth1     #此处dhcp                82c4a93f-1ca2-432b-94da-59a6c4f5aaca  ethernet  --     Wired connection 2  e801f880-78a6-3344-857f-588f7495bb26  ethernet  --     [root@servera /]# nmcli connection up static   启动static网卡[root@servera /]# ip a s eth1 | grep -w inet-modify---修改#将链接static网络信息更改： IP：192.168.0.2  mask：/24  gw：192.168.0.200 dns：114.114.114.114[root@servera ~]# nmcli connection modify static ipv4.addresses 192.168.0.2/24 ipv4.gateway 192.168.0.200 ipv4.dns 114.114.114.114 autoconnect yes ipv4.method manual[root@servera ~]# nmcli connection up  static[root@servera ~]# ip a s eth0    inet 192.168.0.2/24 brd 192.168.0.255 scope global noprefixroute eth1   [root@servera ~]# route -nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface0.0.0.0         172.25.250.254  0.0.0.0         UG    100    0        0 eth00.0.0.0         192.168.0.200   0.0.0.0         UG    101    0        0 eth1[root@servera ~]# cat /etc/resolv.conf # Generated by NetworkManagersearch lab.example.com example.comnameserver 172.25.250.254nameserver 114.114.114.114 [root@serverb ~]# nmcli connection delete static  #删除一个链接Connection 'static' (b85e6a57-b8f7-421f-8d15-9ff5e27cbb85) successfully deleted.-up_down---启动与关闭网卡[root@servera /]# nmcli connection down static   关闭static网卡-off---关闭网络服务[root@servera /]# nmcli networking off       关闭网络服务，慎重使</code></pre><h3 id="11-2-3-图形化管理工具nmtui"><a href="#11-2-3-图形化管理工具nmtui" class="headerlink" title="11.2.3 图形化管理工具nmtui"></a>11.2.3 图形化管理工具nmtui</h3><pre class=" language-language-bash"><code class="language-language-bash">nmtui-edit图形化管理配置通过点击设置--network--网卡设置，ipv4address  netmask  dns  gatewaynmtui-edit[root@servera /]# nmcli connection up static</code></pre><h3 id="11-2-4-网卡配置文件"><a href="#11-2-4-网卡配置文件" class="headerlink" title="11.2.4 网卡配置文件"></a>11.2.4 网卡配置文件</h3><pre class=" language-language-bash"><code class="language-language-bash">-RHEL8 版本# grep -r IPADDR /usr/share/ #找到下面手册的指令vim /usr/share/doc/initscripts/sysconfig.txt 帮助手册修改配置文件方式修改IP[root@servera ~]# vim /etc/sysconfig/network-scripts/ifcfg-Wired_connection_1BOOTPROTO=none          #获取IP的方式  static--静态 none--不设置 dhcp--自动获取 ，手动配IP选前两个中任意一个ONBOOT=yes              #开机自动连接IPADDR=172.25.250.100   #ip地址PREFIX=24               #子网掩码  PREFIX=24(等效于255.255.255.0)，mask=255.255.255.0 netmask=255.255.255.0GATEWAY=172.25.250.254  #网关DNS1=xxxx               #dns，dns可以有三个 DNS1= DNS2= DNS3=加载网卡配置文件方法一：[root@serverb network-scripts]# nmcli connection reload ifcfg-Wired_connection_1 或 nmcli connection reload[root@serverb network-scripts]# nmcli connection up staticsystemctl restart NetworkManager-RHEL9版本 网卡配置文件位置[root@node1 system-connections]# vim /etc/NetworkManager/system-connections/System\ eth0.nmconnection</code></pre><h2 id="11-3-更改网络信息"><a href="#11-3-更改网络信息" class="headerlink" title="11.3 更改网络信息"></a>11.3 更改网络信息</h2><h3 id="11-3-1-主机名"><a href="#11-3-1-主机名" class="headerlink" title="11.3.1 主机名"></a>11.3.1 主机名</h3><pre class=" language-language-bash"><code class="language-language-bash">[root@servera ~]# hostnameservera.lab.example.com[root@servera ~]# hostnmae  www.example.com 临时[root@servera ~]# vim /etc/hostname  永久（重启系统:reboot、init 6)[root@servera ~]# hostnamectl set-hostname hostname　永久</code></pre><h3 id="11-3-2-网关-gateway"><a href="#11-3-2-网关-gateway" class="headerlink" title="11.3.2 网关(gateway)"></a>11.3.2 网关(gateway)</h3><pre class=" language-language-bash"><code class="language-language-bash"># 使用nmclinmcli con add con-name xxx ipv4.gateway xxx.xxx.xxx.xxx  配置网关nmcli con mod xxx ipv4.gateway xxx.xxx.xxx.xxx           修改网关以上两种改完之后，需要nmcli con up xxx# 修改配置文件vim /etc/sysconfig/network-scripts/ifcfg-xxxxGATEWAY=xxx.xxx.xxx.xxx  修改完后要nmcli con reload ，再nmcli con up xxxx</code></pre><h3 id="11-3-3-查看路由及网关"><a href="#11-3-3-查看路由及网关" class="headerlink" title="11.3.3 查看路由及网关"></a>11.3.3 查看路由及网关</h3><pre class=" language-language-bash"><code class="language-language-bash">[root@servera ~]# ip route default via 172.25.250.254 dev enp1s0 proto static metric 100 172.25.250.0/24 dev enp1s0 proto kernel scope link src 172.25.250.10 metric 100[root@servera ~]# route -nKernel IP routing tableDestination     Gateway         Genmask         Flags Metric Ref    Use Iface0.0.0.0         172.25.250.254  0.0.0.0         UG    100    0        0 enp1s0172.25.250.0    0.0.0.0         255.255.255.0   U     100    0        0 enp1s0[root@servera ~]# nmcli connection show Wired\ connection\ 1 | grep ipv4.gaipv4.gateway:                           172.25.250.254[root@servera ~]# netstat -nrKernel IP routing tableDestination     Gateway         Genmask         Flags   MSS Window  irtt Iface0.0.0.0         172.25.250.254  0.0.0.0         UG        0 0          0 enp1s0172.25.250.0    0.0.0.0         255.255.255.0   U         0 0          0 enp1s0</code></pre><h3 id="11-3-4-指定DNS"><a href="#11-3-4-指定DNS" class="headerlink" title="11.3.4 指定DNS"></a>11.3.4 指定DNS</h3><pre class=" language-language-bash"><code class="language-language-bash">vim /etc/resolv.conf   #该文件指定dns和域名的/etc/sysconfig/network-scripts/ifcfg-xxx中的DNS字段会同步到/etc/resolv.conf，后者优先。nameserver 172.25.250.254# 测DNS域名解析是否正常[root@servera ~]# host classroom.example.com classroom.example.com has address 172.25.254.254[root@servera ~]# nslookup classroom.example.comServer:     172.25.250.254Address:    172.25.250.254#53Name:   classroom.example.comAddress: 172.25.254.254[root@servera ~]# dig classroom.example.com</code></pre><h1 id="12-归档与系统间复制文件"><a href="#12-归档与系统间复制文件" class="headerlink" title="12 归档与系统间复制文件"></a>12 归档与系统间复制文件</h1><h2 id="12-1-归档及压缩"><a href="#12-1-归档及压缩" class="headerlink" title="12.1 归档及压缩"></a>12.1 归档及压缩</h2><pre class=" language-language-bash"><code class="language-language-bash"># 语法：tar 选项  归档文件名    源文件 源文件2 源文件N-c  创建-t  查看-f  指定文件名-v  显示详细信息-x  解包-C  指定解包路径man tartar -cvf /root/etc.tar /etc/</code></pre><h3 id="12-1-1-文件及目录打包、解包"><a href="#12-1-1-文件及目录打包、解包" class="headerlink" title="12.1.1 文件及目录打包、解包"></a>12.1.1 文件及目录打包、解包</h3><pre class=" language-language-bash"><code class="language-language-bash"># 文件打包归档[root@servera opt]#etc.tar  file1  file2  file3[root@servera opt]# tar -cvf file.tar file1 file2 file3[root@servera opt]# lsetc.tar  file1  file2  file3  file.tar# 文件解包[root@servera opt]# tar -xvf file.tar -C /tmp/[root@servera opt]# ls /tmp/file1  rclocal.logfile2  rht-bastionfile3  rht-defaultNIC1   rht-vm-hostsNIC2   systemd-private-ef2feb022cd2465c9dd920878a1d962b-chronyd.service-kRKFp0# 目录打包归档[root@servera opt]# tar -cvf etc.tar /etc[root@servera opt]# lsetc.tar  file1  file2  file3  file.tar# 目录解包[root@servera opt]# tar -xvf etc.tar </code></pre><h3 id="12-1-2-文件压缩"><a href="#12-1-2-文件压缩" class="headerlink" title="12.1.2 文件压缩"></a>12.1.2 文件压缩</h3><pre class=" language-language-bash"><code class="language-language-bash"># 只压缩文件[root@servera opt]# gzip file1[root@servera opt]# file file1.gz file1.gz: gzip compressed data, was "file1", last modified: Sun Mar  1 05:54:06 2020, from Unix, original size 0[root@servera opt]# bzip2 file2[root@servera opt]# file file2.bz2 file2.bz2: bzip2 compressed data, block size = 900k[root@servera opt]# xz file.tar [root@servera opt]# lsetc.tar  file1.gz  file2.bz2  file3  file.tar.xz</code></pre><h3 id="12-1-3-tar打包并压缩"><a href="#12-1-3-tar打包并压缩" class="headerlink" title="12.1.3 tar打包并压缩"></a>12.1.3 tar打包并压缩</h3><pre class=" language-language-bash"><code class="language-language-bash"># tar的压缩选项  man tar | grep gzip-z  gzip    -j  bzip2    -J  xz# 打包并压缩 tar -zcvf /root/etc.tar.gz /etc/ file etc.tar.gz  tar -jcvf /opt.tar.bz2 /opt/ tar -Jcvf /root/etc.tar.gz /etc/# 解压缩并指定路径tar -zxvf etc.tar.gz -C /opt/tar xf etc.tar.gz -C /opt/</code></pre><h2 id="12-2-远程传输"><a href="#12-2-远程传输" class="headerlink" title="12.2 远程传输"></a>12.2 远程传输</h2><h3 id="12-2-1-远程文件传输"><a href="#12-2-1-远程文件传输" class="headerlink" title="12.2.1 远程文件传输"></a>12.2.1 远程文件传输</h3><pre class=" language-language-bash"><code class="language-language-bash"># scp实现远程文件传输scp servra.txt root@bastion:/opt/scp root@bastion:/opt/bastion.txt .# sftp实现远程文件传输ID    app   roles---- ------- ----------------1     ftp    client2     sftp   ssh SubService3     vsftp  service[root@servera opt]# touch put.txt[root@servera opt]# sftp instructor@classroom.example.cominstructor@classroom.example.com's password: Connected to instructor@classroom.example.com.sftp> cd /tmp/sftp> put /opt/put.txt Uploading /opt/put.txt to /tmp/put.txt/opt/put.txt                                    100%    0     0.0KB/s   00:00    sftp> ls</code></pre><h3 id="12-2-2-同步文件内容"><a href="#12-2-2-同步文件内容" class="headerlink" title="12.2.2 同步文件内容"></a>12.2.2 同步文件内容</h3><pre class=" language-language-bash"><code class="language-language-bash"># rsync  -v  显示详细信息     -a  相当于存档模式  # 本地同步[root@servera tmp]# rsync -av /var/log/* /tmp# 远程同步[root@servera tmp]# rsync -av /var/log/* serverb:/tmp# 将serverb上的/var/log/同步到，servera当前目录下[root@servera tmp]# rsync -av serverb:/var/log/  .</code></pre><h1 id="13-安装和升级软件包"><a href="#13-安装和升级软件包" class="headerlink" title="13 安装和升级软件包"></a>13 安装和升级软件包</h1><h2 id="13-1-RPM包管理"><a href="#13-1-RPM包管理" class="headerlink" title="13.1 RPM包管理"></a>13.1 RPM包管理</h2><h3 id="13-1-1-rpm包语法"><a href="#13-1-1-rpm包语法" class="headerlink" title="13.1.1 rpm包语法"></a>13.1.1 rpm包语法</h3><pre class=" language-language-bash"><code class="language-language-bash">#软件的获取方式： 1、互联网(下载光盘镜像.iso)、直接使用网络yum源 2、光盘#rpm包语法:rpm 选项 包名-i  安装-v  显示过程-h  以易读方式显示进度条-e  卸载rpm -ivh xxx.rpm#示例:1. 在f0中进入软件包的存储位置[root@foundation0 /]# cd /content/rhel8.0/x86_64/dvd/AppStream/Packages/[root@foundation0 Packages]# pwd/content/rhel8.0/x86_64/dvd/AppStream/Packages2.安装软件[root@foundation0 Packages]# rpm -ivh lftp-4.8.4-1.el8.x86_64.rpm</code></pre><h3 id="13-1-2-rpm包查询命令"><a href="#13-1-2-rpm包查询命令" class="headerlink" title="13.1.2 rpm包查询命令"></a>13.1.2 rpm包查询命令</h3><pre class=" language-language-bash"><code class="language-language-bash">#语法:rpm -q 软件包名称-q: query      查询，和其他参数配合-l：list       列出软件包安装后给系统带来的所有文件-a：all        查看所有已安装的软件包-c: configure  查看软件包提供的配置文件rpm -qa | grep telnetrpm -qc openssh-server-8.0p1-4.el8_1.x86_64#卸载RPM包[root@node1 /]# rpm -q telnettelnet-0.17-73.el8.x86_64[root@node1 /]# rpm -e telnet-0.17-73.el8.x86_64[root@node1 /]# rpm -q telnetpackage telnet is not installed</code></pre><h2 id="13-2-YUM工具"><a href="#13-2-YUM工具" class="headerlink" title="13.2 YUM工具"></a>13.2 YUM工具</h2><h3 id="13-2-1-管理yum源文件"><a href="#13-2-1-管理yum源文件" class="headerlink" title="13.2.1 管理yum源文件"></a>13.2.1 管理yum源文件</h3><pre class=" language-language-bash"><code class="language-language-bash"># yum源软件配置方式:[root@servera /]# cd /etc/yum.repos.d/[root@servera yum.repos.d]# mkdir old[root@servera yum.repos.d]# mv * old     #将系统默认的yum源文件移动到old中，可以在该文件中查看原来的yum源路径[root@servera yum.repos.d]# man 5 yum.conf[root@servera yum.repos.d]# vim rhel.repo[AppStream]      #id名称自定义name=AppStream   #描述自定义，和id不必一样baseurl=http://content.example.com/rhel8.4/x86_64/dvd/AppStream   #file:///中://是url格式，第三个/是根目录gpgcheck=0   #gpgchek=1 要进行公钥验证，需要再添加选项gpgkey=http://content.example.com/rhel8.4/x86_64/dvd/RPM-GPG-KEY-redhat-releaseenabled=1[BaseOS]name=BaseOSbaseurl=http://content.example.com/rhel8.4/x86_64/dvd/BaseOSgpgcheck=0enabled=1[root@servera yum.repos.d]# yum clean all           #清除缓存，避免沿用之前缓存的软件[root@servera yum.repos.d]# yum makecache           #和当前yum源建立缓存关联[root@servera yum.repos.d]# yum repolist all        #查看当前yum源状态[root@servera yum.repos.d]# yum install -y telnet   #测试安装软件telnet[root@servera yum.repos.d]# rpm -q telnet           #使用rpm方式查询测试</code></pre><h3 id="13-2-2-yum源命令配置"><a href="#13-2-2-yum源命令配置" class="headerlink" title="13.2.2 yum源命令配置"></a>13.2.2 yum源命令配置</h3><pre class=" language-language-bash"><code class="language-language-bash">1 找到提供yum-config-manager命令的软件包名称[kiosk@foundation0 ~]$ yum provides yum-config-manager2 安装yum-utils软件 #打开浏览器输入yum源仓库地址，找到yum-utils的软件包，并且通过rpm命令安装网络上的yum-utils软件包，来提通yum-config-manager命令[root@servera ]# rpm -ivh http://content.example.com/rhel8.4/x86_64/dvd/BaseOS/Packages/yum-utils-4.0.18-4.el8.noarch.rpm3  通过yum-config-manager命令部署yum源[root@servera ]# yum-config-manager --help[root@servera ]# yum-config-manager --add-repo=http://content.example.com/rhel8.4/x86_64/dvd/AppStream[root@servera ]# yum-config-manager --add-repo=http://content.example.com/rhel8.4/x86_64/dvd/BaseOS4 命令制作的yum源中没有gpgcheck选项，如何配置？可以通过以下方法：   1、此处可以在/etc/yum.repos.d/xx.repo文件里添加 gpgcheck=0   2、rpm --import ‘公钥地址’   导入公钥` [root@servera yum.repos.d]# rpm --import http://content.example.com/rhel8.4/x86_64/dvd/RPM-GPG- KEY-redhat-release  5.开启或关闭[root@servera /]# yum-config-manager --disable rhel-8.0-for-x86_64-appstream-rpms（yum池ID）[root@servera /]# yum repolist all[root@servera /]# yum-config-manager --enable rhel-8.0-for-x86_64-appstream-rpms[root@servera /]# yum repolist all</code></pre><h3 id="13-2-3-YUM常见的命令"><a href="#13-2-3-YUM常见的命令" class="headerlink" title="13.2.3 YUM常见的命令"></a>13.2.3 YUM常见的命令</h3><pre class=" language-language-bash"><code class="language-language-bash">yum list http*yum search httpdyum info httpd-manual[root@servera /]# yum provides /var/www/html# yum update# yum install 包名      yum remove 包名[root@servera /]# yum install  -y autofs[root@servera /]# yum remove -y autofs[root@servera /]# yum history# yum clean all      yum repolist     yum repolist all# yum group list     yum groupinfo 'Server with GUI'# yum groupinstall -y 'Server with GUI'# startx 切图形</code></pre><h2 id="13-3-第三方YUM源"><a href="#13-3-第三方YUM源" class="headerlink" title="13.3 第三方YUM源"></a>13.3 第三方YUM源</h2><pre class=" language-language-bash"><code class="language-language-bash">1.虚拟机联网  虚拟机设置里面NAT选择已连接   nmcli connection up ens192  2.百度搜索（阿里源、华为源...），将.repo文件下载到系统curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-vault-8.5.2111.repo3.验证cd /etc/yum.repos.d/;lsyum repolist allyum install -y vsftpd</code></pre><h1 id="14-访问Linux文件系统"><a href="#14-访问Linux文件系统" class="headerlink" title="14 访问Linux文件系统"></a>14 访问Linux文件系统</h1><h2 id="14-1-存储管理"><a href="#14-1-存储管理" class="headerlink" title="14.1 存储管理"></a>14.1 存储管理</h2><h3 id="14-1-1-文件系统、存储和块设备"><a href="#14-1-1-文件系统、存储和块设备" class="headerlink" title="14.1.1 文件系统、存储和块设备"></a>14.1.1 文件系统、存储和块设备</h3><table><thead><tr><th align="left">块设备</th><th align="left">含义</th></tr></thead><tbody><tr><td align="left">/dev/sda、/dev/sdb</td><td align="left">STAT/SAS（新SCSI技术）/USB 附加存储</td></tr><tr><td align="left">/dev/vda、/dev/vdb</td><td align="left">virtio-blk 超虚拟化存储（部分虚拟机）</td></tr><tr><td align="left">/dev/nvme0，/dev/nvme1</td><td align="left">附加存储 （SSD）</td></tr><tr><td align="left">/dev/mmcblk0、/dev/mmcblk1</td><td align="left">SD卡</td></tr></tbody></table><h3 id="14-1-2-磁盘分区"><a href="#14-1-2-磁盘分区" class="headerlink" title="14.1.2 磁盘分区"></a>14.1.2 磁盘分区</h3><pre class=" language-language-bash"><code class="language-language-bash"># 分区--格式化--挂载--使用# mount命令挂载是临时的，意味着重启系统后将取消挂载。需要手动重新挂载# 永久挂载需要将挂载项记入/etc/fstab中1 分区，gpt方案 ，分2个区，每个1G[root@servera ~]# fdisk /dev/vdbCommand (m for help): m   d   delete a partition    #删除分区   n   add a new partition   #创建分区   p   print the partition table  #打印分区表   w   write table to disk and exit   #保存并退出  Create a new label   g   create a new empty GPT partition table  #指定分区方案gpt   o   create a new empty DOS partition table  #指定分区方位mbrCommand (m for help): g   #指定分区方案gptCreated a new GPT disklabel (GUID: D29B3E19-BA51-1042-BFE6-0FD975D1B7DB).Command (m for help): nPartition number (1-128, default 1): #回车First sector (2048-10485726, default 2048):  #回车Last sector, +sectors or +size{K,M,G,T,P} (2048-10485726, default 10485726): +1G  #指定分区大小1GCreated a new partition 1 of type 'Linux filesystem' and of size 1 GiB.Command (m for help): pDisklabel type: gpt  #查看分区方案Device     Start     End Sectors Size Type  #分区表/dev/vdb1   2048 2099199 2097152   1G Linux filesystem  #/dev/vdb 分区为1GCommand (m for help): n   #创建第二个分区Partition number (2-128, default 2): First sector (2099200-10485726, default 2099200): Last sector, +sectors or +size{K,M,G,T,P} (2099200-10485726, default 10485726): +1GCommand (m for help): pDevice       Start     End Sectors Size Type/dev/vdb1     2048 2099199 2097152   1G Linux filesystem/dev/vdb2  2099200 4196351 2097152   1G Linux filesystemCommand (m for help): w  #保存退出[root@servera ~]# fdisk -l /dev/vdb  #查看/dev/vdb分区表Device       Start     End Sectors Size Type/dev/vdb1     2048 2099199 2097152   1G Linux filesystem/dev/vdb2  2099200 4196351 2097152   1G Linux filesystem[root@servera ~]# lsblk /dev/vdb   #lsblk查看块设备NAME   MAJ:MIN RM SIZE RO TYPE MOUNTPOINTvdb    252:16   0   5G  0 disk ├─vdb1 252:17   0   1G  0 part └─vdb2 252:18   0   1G  0 part 2 格式化，将两个分区分别格式化为ext4和xfs文件系统  # mkfs 选项 设备名     -t 指定文件系统类型mkfs -t ext4 /dev/vdb1     mkfs.ext4 /dev/vdb1    [root@servera /]# mkfs -t ext4 /dev/vdb1   #mkfs格式化 ext4是文件系统类型 /dev/vdb1是要格式化的磁盘分区[root@servera /]# echo $?     $?是看上一条命令返回值，0为正确，非0为错误0[root@servera /]# mkfs.xfs /dev/vdb2[root@servera /]# echo $?0[root@servera ~]# lsblk -f[root@servera ~]# lsblk -f /dev/vdb  #查看文件系统类型，NAME   FSTYPE LABEL UUID                                 MOUNTPOINTvdb                                                      ├─vdb1 ext4         ecb332da-5bf4-4b86-b92e-d9da25f22a07 └─vdb2 xfs          b538bf38-2b33-4d53-a785-372627587c52 3 挂载  创建挂载点  mkdir /mnt/disk1  文件系统：格式化后的设备或分区   挂载点：linux中的空目录挂载：mount  文件系统  挂载点    mount  /dev/vdb1  /mnt/disk1卸载：umount 文件系统/挂载点     umount /dev/vdb1 or umount /mnt/disk1#挂载[root@servera ~]# lsblk -f /dev/vdbNAME   FSTYPE LABEL UUID                                 MOUNTPOINTvdb                                                      ├─vdb1 ext4         ecb332da-5bf4-4b86-b92e-d9da25f22a07 └─vdb2 xfs          b538bf38-2b33-4d53-a785-372627587c52 [root@servera ~]# mkdir /mnt/{disk1,disk2}  # 创建挂载点[root@servera ~]# ls /mntdisk1  disk2[root@servera ~]# mount /dev/vdb1 /mnt/disk1  #将/dev/vdb1 挂载到/mnt/disk1目录上[root@servera ~]# df [root@servera ~]# df -Th  #-T 显示文件系统，-h以易读单位显示Filesystem     Type      Size  Used Avail Use% Mounted on/dev/vdb1      ext4      976M  2.6M  907M   1% /mnt/disk1/dev/vdb2      xfs      1014M   40M  975M   4% /mnt/disk2[root@servera ~]# tree /mnt//mnt/├── disk1│   ├── haha.txt│   └── lost+found└── disk2    └── heihei.txt 卸载   [root@servera ~]# cd /mnt/disk2[root@servera disk2]# umount /dev/vdb2      #使用时不能卸载umount: /mnt/disk2: target is busy.[root@servera disk2]# cd /    #需要退出挂载点[root@servera /]# umount /dev/vdb2   #卸载[root@servera /]# df -h | tail -2tmpfs           183M     0  183M   0% /run/user/0/dev/vdb1       976M  2.6M  907M   1% /mnt/disk1</code></pre><h3 id="14-1-3-检查文件系统"><a href="#14-1-3-检查文件系统" class="headerlink" title="14.1.3 检查文件系统"></a>14.1.3 检查文件系统</h3><pre class=" language-language-bash"><code class="language-language-bash"># df查看系统挂载状态-T 查看文件系统类型-h 以易读方式列出容量单位du查看文件大小[root@servera /]# du /etc/[root@servera /]# du -h /etc/[root@servera /]# du -sh  /etc/24M /etc/[root@servera /]# du /etc/man_db.conf 8   /etc/man_db.conf[root@servera /]# du /etc/man_db.conf  -h  #占用了的块大小，linux默认一个块4k8.0K    /etc/man_db.conf[root@servera /]# ll /etc/man_db.conf -rw-r--r--. 1 root root 5165 Nov  7  2018 /etc/man_db.conf</code></pre><h2 id="14-2-文件查找"><a href="#14-2-文件查找" class="headerlink" title="14.2 文件查找"></a>14.2 文件查找</h2><pre class=" language-language-bash"><code class="language-language-bash"># locateupdatedb      #收集所有文件元数据locate passwdlocate -i imagelocate -n 5  image   #显示前5行# findfind  查找范围  查找条件   动作(可选)find /  -name  passwd-name： 以文件名的形式查找-size： 根据文件大小 -size 1k ：大小为1k的文件，+1k大于1k的文件，-1k小于1k的文件-user /  -uid： 文件所有者   -user studnet  ：student是用户名，查找student拥有的文件-group / -gid-perm： 权限查找     -perm 700 ：搜索权限为700的文件-type： 按文件类型   -type f ： f表示文件，d表示目录-exec： 选项后接Linux指令，操作查找到的文件  command {} ; find /etc -name sshd_configfind / -user student | xargs ls -lfind / -perm 700 -type d -user student | xargs ls -ldfind /etc -type f -size +3k  -and -size -10k  find / -perm -4000 | xargs ls -ld将系统中student用户的文件复制到/root/studentdir目录中，并且保留权限[root@servera ~]# find / -user student -exec cp -a {} /root/studentdir/ \;将系统中student用户的文件列表保存到/root/studentdir文件中find / -user student > /root/studentdir</code></pre><h2 id="14-3-ln-软链接与硬链接"><a href="#14-3-ln-软链接与硬链接" class="headerlink" title="14.3 ln 软链接与硬链接"></a>14.3 ln 软链接与硬链接</h2><pre class=" language-language-bash"><code class="language-language-bash"># 软链接(符号链接)：使用范围广，方便访问源文件# 文件链接创建方式：ln -s 源文件   链接文件ln -s dir1 linkdir1#硬链接：节省系统空间    ln 源文件  链接文件ln /opt/sou_file.txt /opt/link_file.txt# 取消链接[root@servera opt]# unlink /opt/link_file.txt</code></pre><h2 id="14-4-软链接和硬链接区别"><a href="#14-4-软链接和硬链接区别" class="headerlink" title="14.4 软链接和硬链接区别"></a>14.4 软链接和硬链接区别</h2><pre class=" language-language-bash"><code class="language-language-bash">1.命令相同 参数不同2.硬链接的权限和源文件完全一致、软链接的链接文件权限永远是777，和源文件权限不同3.硬链接可以删除，移动源文件、软链接不可以删除，移动源文件4.软链接inode和源文件不同、硬链接的inode的源文件相同5.软链接可以对目录及文件生效、硬链接只可以对文件操作6.软链接可以跨文件系统、硬链接不可以跨文件系统</code></pre>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux的基本使用 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux命令</title>
      <link href="/2022/04/28/linux/linux-ming-ling/"/>
      <url>/2022/04/28/linux/linux-ming-ling/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux命令 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
