<!DOCTYPE HTML>
<html lang="zh-CN">
    

    

<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Docker容器&amp;Kubernetes, Linux技术博客">
    <meta name="description" content="">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport"
        content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style"
        content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Docker容器&amp;Kubernetes | Linux技术博客</title>
    <link rel="icon" type="image/png"
        href="/favicon.png">

    <link rel="stylesheet" type="text/css"
        href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css"
        href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css"
        href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css"
        href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css"
        href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css"
        href="/css/matery.css">
    <link rel="stylesheet" type="text/css"
        href="/css/my.css">
    <link rel="stylesheet" type="text/css"
        href="/css/loading.css">

    <script
        src="/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 7.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="Linux技术博客" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>


    
    <style>
    body{
       background-image: url(/medias/background.jpg);
       background-repeat:no-repeat;
       background-size:cover;
       background-attachment:fixed;
    }
</style>

    
    <body>
        <div class="stars-con">
            <div id="stars"></div>
            <div id="stars2"></div>
            <div id="stars3"></div>
        </div>
        <svg aria-hidden="true"
            style="position: absolute; overflow: hidden; width: 0; height: 0">
            <symbol id="icon-sun" viewBox="0 0 1024 1024">
                <path
                    d="M960 512l-128 128v192h-192l-128 128-128-128H192v-192l-128-128 128-128V192h192l128-128 128 128h192v192z"
                    fill="#FFD878" p-id="8420"></path>
                <path d="M736 512a224 224 0 1 0-448 0 224 224 0 1 0 448 0z"
                    fill="#FFE4A9" p-id="8421"></path>
                <path
                    d="M512 109.248L626.752 224H800v173.248L914.752 512 800 626.752V800h-173.248L512 914.752 397.248 800H224v-173.248L109.248 512 224 397.248V224h173.248L512 109.248M512 64l-128 128H192v192l-128 128 128 128v192h192l128 128 128-128h192v-192l128-128-128-128V192h-192l-128-128z"
                    fill="#4D5152" p-id="8422"></path>
                <path
                    d="M512 320c105.888 0 192 86.112 192 192s-86.112 192-192 192-192-86.112-192-192 86.112-192 192-192m0-32a224 224 0 1 0 0 448 224 224 0 0 0 0-448z"
                    fill="#4D5152" p-id="8423"></path>
            </symbol>
            <symbol id="icon-moon" viewBox="0 0 1024 1024">
                <path
                    d="M611.370667 167.082667a445.013333 445.013333 0 0 1-38.4 161.834666 477.824 477.824 0 0 1-244.736 244.394667 445.141333 445.141333 0 0 1-161.109334 38.058667 85.077333 85.077333 0 0 0-65.066666 135.722666A462.08 462.08 0 1 0 747.093333 102.058667a85.077333 85.077333 0 0 0-135.722666 65.024z"
                    fill="#FFB531" p-id="11345"></path>
                <path
                    d="M329.728 274.133333l35.157333-35.157333a21.333333 21.333333 0 1 0-30.165333-30.165333l-35.157333 35.157333-35.114667-35.157333a21.333333 21.333333 0 0 0-30.165333 30.165333l35.114666 35.157333-35.114666 35.157334a21.333333 21.333333 0 1 0 30.165333 30.165333l35.114667-35.157333 35.157333 35.157333a21.333333 21.333333 0 1 0 30.165333-30.165333z"
                    fill="#030835" p-id="11346"></path>
            </symbol>
        </svg>
        <a onclick="switchNightMode()" class="icon-V hidden" title="切换主题">
            <svg width="48" height="48" viewBox="0 0 1024 1024">
                <use id="modeicon" xlink:href="#icon-moon"></use>
            </svg>
        </a>
        <script>
      function checkNightMode() {
        '1' === localStorage.getItem('isDark') ? ($('body').addClass('DarkMode'), $('#changeMode-top').removeClass('fa-moon').addClass('fa-sun'), $('#modeicon').attr('xlink:href', '#icon-sun')) : '0' === localStorage.getItem('isDark') ? $('#modeicon').attr('xlink:href', '#icon-moon') : new Date().getHours() >= 20 || new Date().getHours() < 7 ? ($('body').addClass('DarkMode'), $('#changeMode-top').removeClass('fa-moon').addClass('fa-sun'), $('#modeicon').attr('xlink:href', '#icon-sun')) : matchMedia('(prefers-color-scheme: dark)').matches ? ($('body').addClass('DarkMode'), $('#changeMode-top').removeClass('fa-moon').addClass('fa-sun'), $('#modeicon').attr('xlink:href', '#icon-sun')) : $('#modeicon').attr('xlink:href', '#icon-moon')
      }
      function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
          setTimeout(function () {
            $('body').hasClass('DarkMode') ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#changeMode-top').removeClass('fa-sun').addClass('fa-moon'), $('#modeicon').attr('xlink:href', '#icon-moon')) : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#changeMode-top').removeClass('fa-moon').addClass('fa-sun'), $('#modeicon').attr('xlink:href', '#icon-sun')),
              setTimeout(function () {
                $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                  $(this).remove()
                })
              }, 2e3)
          })
      }
      function switchNightModeTop() {
        $('body').hasClass('DarkMode') ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#changeMode-top').removeClass('fa-sun').addClass('fa-moon'), $('#modeicon').attr('xlink:href', '#icon-moon')) : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#changeMode-top').removeClass('fa-moon').addClass('fa-sun'), $('#modeicon').attr('xlink:href', '#icon-sun'))
      }
    </script>

        <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Linux技术博客</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Linux技术博客</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/luovip/tecBlog.github.io" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/luovip/tecBlog.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

        



<div class="bg-cover pd-header post-cover" style="background-image: url('/img/docker&k8s.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Docker容器&amp;Kubernetes</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet"
    href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
        background-color: rgb(255, 255, 255,0.7);
        border-radius: 10px;
        box-shadow: 0 10px 35px 2px rgba(0, 0, 0, .15), 0 5px 15px rgba(0, 0, 0, .07), 0 2px 5px -5px rgba(0, 0, 0, .1) !important;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }
    #toc-content .toc-link:hover {
        color: #f40;
        font-weight: 700;
        text-decoration: underline;
    }
    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #f40;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Docker%E5%AE%B9%E5%99%A8-Kubernetes/">
                                <span class="chip bg-color">Docker容器&amp;Kubernetes</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/Kubernetes/" class="post-category">
                                Kubernetes
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-05-28
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-06-05
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    30.1k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    141 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="1-微服务"><a href="#1-微服务" class="headerlink" title="1 微服务"></a>1 微服务</h1><p>  把一个庞大的应用拆成几个小的独立的服务，再把独立的服务串起来的一种架构设计:内聚更强，更加敏捷</p>
<p><img src="/images/%E5%BE%AE%E6%9C%8D%E5%8A%A1.png"></p>
<h2 id="1-1-应用架构的发展"><a href="#1-1-应用架构的发展" class="headerlink" title="1.1 应用架构的发展"></a>1.1 应用架构的发展</h2><p><img src="/images/%E5%BA%94%E7%94%A8%E6%9E%B6%E6%9E%84%E7%9A%84%E5%8F%91%E5%B1%95.png"></p>
<h2 id="1-2-传统单体架构vs微服务软件架构"><a href="#1-2-传统单体架构vs微服务软件架构" class="headerlink" title="1.2 传统单体架构vs微服务软件架构"></a>1.2 传统单体架构vs微服务软件架构</h2><p>  不同于微服务，传统的项目会包含很多功能，是一个大而全的“超级”工程</p>
<p>  例如：以普通架构方式实现的电商平台包含：登录、权限、会员、商品库存、订单、收藏、关注、购物车等功能的多个单一项目。随着项目业务越来越复杂、开发人员越来越多，相应开发、编译、部署、技术扩展、水平扩展都会受到限制</p>
<p><img src="/images/%E4%BC%A0%E7%BB%9F%E5%8D%95%E4%BD%93%E6%9E%B6%E6%9E%84vs%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84.png"></p>
<h2 id="1-3-基于微服务的系统架构"><a href="#1-3-基于微服务的系统架构" class="headerlink" title="1.3 基于微服务的系统架构"></a>1.3 基于微服务的系统架构</h2><p><img src="/images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84.png"></p>
<p>  核心思路是拆分</p>
<p>  单体项目的问题，通过把项目拆分成一个个小项目就可以解决</p>
<h2 id="1-4-微服务的特征"><a href="#1-4-微服务的特征" class="headerlink" title="1.4 微服务的特征"></a>1.4 微服务的特征</h2><p><img src="/images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%9A%84%E7%89%B9%E5%BE%81.png"></p>
<h2 id="1-5-单体架构"><a href="#1-5-单体架构" class="headerlink" title="1.5 单体架构"></a>1.5 单体架构</h2><p>  紧耦合面临的问题：故障影响范围大、变更成本高、无法支持大规模计算</p>
<p><img src="/images/%E5%8D%95%E4%BD%93%E6%9E%B6%E6%9E%84.png"></p>
<p>  如果需要加入模块C，需要更改模块A、B的代码，需要各个系统人员协调处理</p>
<h2 id="1-6-解耦架构"><a href="#1-6-解耦架构" class="headerlink" title="1.6 解耦架构"></a>1.6 解耦架构</h2><p><img src="/images/%E8%A7%A3%E8%80%A6%E6%9E%B6%E6%9E%84.png"></p>
<p>  解耦架构的优势：</p>
<p>  1.模块化，缩小故障范围</p>
<p>  2.降低变更成本，插入新模块不影响其他模块</p>
<p>  3.开发人员协作更简单</p>
<p>  4.易于扩展</p>
<h2 id="1-7-消息队列"><a href="#1-7-消息队列" class="headerlink" title="1.7 消息队列"></a>1.7 消息队列</h2><h3 id="1-7-1-传统架构"><a href="#1-7-1-传统架构" class="headerlink" title="1.7.1 传统架构"></a>1.7.1 传统架构</h3><p><img src="/images/%E4%BC%A0%E7%BB%9F%E6%9E%B6%E6%9E%84.png"></p>
<h3 id="1-7-2-消息队列架构"><a href="#1-7-2-消息队列架构" class="headerlink" title="1.7.2 消息队列架构"></a>1.7.2 消息队列架构</h3><p><img src="/images/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E6%9E%B6%E6%9E%84.png"></p>
<h2 id="1-8-微服务面临的挑战"><a href="#1-8-微服务面临的挑战" class="headerlink" title="1.8 微服务面临的挑战"></a>1.8 微服务面临的挑战</h2><table>
<thead>
<tr>
<th></th>
<th>单体架构</th>
<th>微服务架构</th>
</tr>
</thead>
<tbody><tr>
<td>迭代速度</td>
<td>较慢</td>
<td>快</td>
</tr>
<tr>
<td>部署频率</td>
<td>不经常部署</td>
<td>经常发布</td>
</tr>
<tr>
<td>系统性能</td>
<td>吞吐量小</td>
<td>吞吐量大</td>
</tr>
<tr>
<td>系统扩展性</td>
<td>扩展性差</td>
<td>扩展性好</td>
</tr>
<tr>
<td>技术栈多样性</td>
<td>单一、封闭</td>
<td>多样、开放</td>
</tr>
<tr>
<td>运维</td>
<td>简单</td>
<td>运维复杂</td>
</tr>
<tr>
<td>部署难度</td>
<td>容易部署</td>
<td>较难部署</td>
</tr>
<tr>
<td>架构复杂度</td>
<td>较小</td>
<td>复杂度高</td>
</tr>
<tr>
<td>查错</td>
<td>简单</td>
<td>定位问题较难</td>
</tr>
<tr>
<td>管理成本</td>
<td>主要在于开发成本</td>
<td>服务治理、运维</td>
</tr>
</tbody></table>
<h2 id="1-9-虚拟机与容器的比较"><a href="#1-9-虚拟机与容器的比较" class="headerlink" title="1.9 虚拟机与容器的比较"></a>1.9 虚拟机与容器的比较</h2><p><img src="/images/%E8%99%9A%E6%8B%9F%E6%9C%BAvs%E5%AE%B9%E5%99%A8.png"></p>
<table>
<thead>
<tr>
<th>对比模块</th>
<th>虚拟机</th>
<th>容器</th>
</tr>
</thead>
<tbody><tr>
<td>占用空间</td>
<td>非常大，GB级别</td>
<td>小，MB/KB级别</td>
</tr>
<tr>
<td>启用速度</td>
<td>慢，分钟级</td>
<td>快，秒级</td>
</tr>
<tr>
<td>运行形态</td>
<td>运行于Hypervisor</td>
<td>直接运行在宿主机内核上</td>
</tr>
<tr>
<td>并发性</td>
<td>一台宿主机上十几个，最多几 十个</td>
<td>上百个，甚至数百个</td>
</tr>
<tr>
<td>性能</td>
<td>低于宿主机</td>
<td>接近于宿主机本地进程</td>
</tr>
<tr>
<td>资源利用率</td>
<td>低</td>
<td>高</td>
</tr>
</tbody></table>
<h1 id="2-容器的基本使用"><a href="#2-容器的基本使用" class="headerlink" title="2 容器的基本使用"></a>2 容器的基本使用</h1><h2 id="2-1-容器介绍"><a href="#2-1-容器介绍" class="headerlink" title="2.1 容器介绍"></a>2.1 容器介绍</h2><p>  容器是一个可以在共享的操作系统上将应用程序以指定格式打包并运行在一个与操作系统相关联的环境中的方法</p>
<p>  和虚拟机相比，容器并不会打包整个操作系统，而只是打包应用程序所必须的库和设置，这将使得容器具备高效率、轻量化、系统隔离性，以上特性将会确保无论在何处部署，容器每次运行都会完全一致</p>
<p>  容器工具：Rkt、Containerd、Docker、Podman</p>
<h2 id="2-2-部署Docker"><a href="#2-2-部署Docker" class="headerlink" title="2.2 部署Docker"></a>2.2 部署Docker</h2><p>  从南京大学开源镜像站在Ubuntu上安装docker</p>
<p><img src="/images/docker%E5%AE%89%E8%A3%85.png"></p>
<h3 id="2-2-1-安装依赖"><a href="#2-2-1-安装依赖" class="headerlink" title="2.2.1 安装依赖"></a>2.2.1 安装依赖</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 检测系统是否安装了docker</span>
root@k8s-master:~<span class="token comment"># for pkg in docker.io docker-doc docker-compose podman-docker containerd runc; do sudo apt-get remove $pkg; done</span>

<span class="token comment"># 安装依赖</span>
root@k8s-master:~<span class="token comment"># sudo apt-get update</span>
root@k8s-master:~<span class="token comment"># sudo apt-get install ca-certificates curl gnupg</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="2-2-2-安装GPG公钥"><a href="#2-2-2-安装GPG公钥" class="headerlink" title="2.2.2 安装GPG公钥"></a>2.2.2 安装GPG公钥</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># sudo install -m 0755 -d /etc/apt/keyrings</span>
root@k8s-master:~<span class="token comment"># curl -fsSL https://mirror.nju.edu.cn/docker-ce/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg</span>

root@k8s-master:~<span class="token comment"># sudo chmod a+r /etc/apt/keyrings/docker.gpg</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="2-2-3-添加Docker仓库"><a href="#2-2-3-添加Docker仓库" class="headerlink" title="2.2.3 添加Docker仓库"></a>2.2.3 添加Docker仓库</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># echo \</span>
  <span class="token string">"deb [arch=<span class="token variable"><span class="token variable">$(</span>dpkg --print-architecture<span class="token variable">)</span></span> signed-by=/etc/apt/keyrings/docker.gpg] https://mirror.nju.edu.cn/docker-ce/linux/ubuntu \
  "</span><span class="token variable"><span class="token variable">$(</span><span class="token builtin class-name">.</span> /etc/os-release <span class="token operator">&amp;&amp;</span> <span class="token builtin class-name">echo</span> <span class="token string">"<span class="token variable">$VERSION_CODENAME</span>"</span><span class="token variable">)</span></span><span class="token string">" stable"</span> <span class="token operator">|</span> <span class="token punctuation">\</span>
  <span class="token function">sudo</span> <span class="token function">tee</span> /etc/apt/sources.list.d/docker.list <span class="token operator">&gt;</span> /dev/null<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="2-2-4-安装Docker"><a href="#2-2-4-安装Docker" class="headerlink" title="2.2.4 安装Docker"></a>2.2.4 安装Docker</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># sudo apt-get update</span>
root@k8s-master:~<span class="token comment"># sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin</span>

<span class="token comment"># 拉取失败，因此在中国需要加速器</span>
root@k8s-master:~<span class="token comment"># sudo docker run hello-world</span>
Unable to <span class="token function">find</span> image <span class="token string">'hello-world:latest'</span> locally
docker: Error response from daemon: Get <span class="token string">"https://registry-1.docker.io/v2/"</span><span class="token builtin class-name">:</span> context deadline exceeded <span class="token punctuation">(</span>Client.Timeout exceeded <span class="token keyword">while</span> awaiting headers<span class="token punctuation">)</span>

Run <span class="token string">'docker run --help'</span> <span class="token keyword">for</span> <span class="token function">more</span> information<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="2-2-5-Docker镜像加速器"><a href="#2-2-5-Docker镜像加速器" class="headerlink" title="2.2.5 Docker镜像加速器"></a>2.2.5 Docker镜像加速器</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># mkdir -p /etc/docker</span>
root@k8s-master:~<span class="token comment"># cd /etc/docker</span>
root@k8s-master:/etc/docker<span class="token comment"># vim daemon.json</span>
<span class="token punctuation">{</span>
  <span class="token string">"registry-mirrors"</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span>
        <span class="token string">"https://docker.mirrors.ustc.edu.cn"</span>,
        <span class="token string">"https://mirror.baidubce.com"</span>,
        <span class="token string">"https://docker.m.daocloud.io"</span>,
        <span class="token string">"https://mirror.ccs.tencentyun.com"</span>,
        <span class="token string">"https://docker.nju.edu.cn"</span>,
        <span class="token string">"https://docker.mirrors.sjtug.sjtu.edu.cn"</span>,
        <span class="token string">"https://mirror.gcr.io"</span>,
        <span class="token string">"https://docker.registry.cyou"</span>,
        <span class="token string">"https://docker-cf.registry.cyou"</span>,
        <span class="token string">"https://dockercf.jsdelivr.fyi"</span>,
        <span class="token string">"https://docker.jsdelivr.fyi"</span>,
        <span class="token string">"https://dockertest.jsdelivr.fyi"</span>,
        <span class="token string">"https://mirror.aliyuncs.com"</span>,
        <span class="token string">"https://dockerproxy.com"</span>
  <span class="token punctuation">]</span>,
  <span class="token string">"exec-opts"</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token string">"native.cgroupdriver=systemd"</span><span class="token punctuation">]</span>
<span class="token punctuation">}</span>
root@k8s-master:~<span class="token comment"># systemctl daemon-reload</span>
root@k8s-master:~<span class="token comment"># systemctl restart docker</span>

root@k8s-master:~<span class="token comment"># sudo docker pull hello-world</span>
Using default tag: latest
latest: Pulling from library/hello-world
Digest: sha256:c41088499908a59aae84b0a49c70e86f4731e588a737f1637e73c8c09d995654
Status: Image is up to <span class="token function">date</span> <span class="token keyword">for</span> hello-world:latest
docker.io/library/hello-world:latest

root@k8s-master:~<span class="token comment"># docker images</span>
REPOSITORY    TAG       IMAGE ID       CREATED        SIZE
hello-world   latest    74cc54e27dc4   <span class="token number">3</span> months ago   <span class="token number">10</span>.1kB<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="2-2-6-重启Docker服务"><a href="#2-2-6-重启Docker服务" class="headerlink" title="2.2.6 重启Docker服务"></a>2.2.6 重启Docker服务</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># systemctl restart docker</span>
root@k8s-master:~<span class="token comment"># docker info</span>
Client: Docker Engine - Community
 Version:    <span class="token number">28.1</span>.1
 Context:    default
 Debug Mode: <span class="token boolean">false</span>
 Plugins:
  buildx: Docker Buildx <span class="token punctuation">(</span>Docker Inc.<span class="token punctuation">)</span>
    Version:  v0.23.0
    Path:     /usr/libexec/docker/cli-plugins/docker-buildx
  compose: Docker Compose <span class="token punctuation">(</span>Docker Inc.<span class="token punctuation">)</span>
    Version:  v2.35.1
    Path:     /usr/libexec/docker/cli-plugins/docker-compose

Server:
 Containers: <span class="token number">2</span>
  Running: <span class="token number">1</span>
  Paused: <span class="token number">0</span>
  Stopped: <span class="token number">1</span>
 Images: <span class="token number">2</span>
 Server Version: <span class="token number">28.1</span>.1
 Storage Driver: overlay2
  Backing Filesystem: extfs
  Supports d_type: <span class="token boolean">true</span>
  Using metacopy: <span class="token boolean">false</span>
  Native Overlay Diff: <span class="token boolean">true</span>
  userxattr: <span class="token boolean">false</span>
 Logging Driver: json-file
 Cgroup Driver: systemd
 Cgroup Version: <span class="token number">2</span>
 Plugins:
  Volume: <span class="token builtin class-name">local</span>
  Network: bridge <span class="token function">host</span> ipvlan macvlan null overlay
  Log: awslogs fluentd gcplogs gelf journald json-file <span class="token builtin class-name">local</span> splunk syslog
 Swarm: inactive
 Runtimes: io.containerd.runc.v2 runc
 Default Runtime: runc
 Init Binary: docker-init
 containerd version: 05044ec0a9a75232cad458027ca83437aae3f4da
 runc version: v1.2.5-0-g59923ef
 init version: de40ad0
 Security Options:
  apparmor
  seccomp
   Profile: <span class="token builtin class-name">builtin</span>
  cgroupns
 Kernel Version: <span class="token number">6.8</span>.0-53-generic
 Operating System: Ubuntu <span class="token number">24.04</span>.2 LTS
 OSType: linux
 Architecture: x86_64
 CPUs: <span class="token number">2</span>
 Total Memory: <span class="token number">3</span>.777GiB
 Name: k8s-master
 ID: 6c5b4dc6-423d-47e6-a687-e75062cf4fd9
 Docker Root Dir: /var/lib/docker
 Debug Mode: <span class="token boolean">false</span>
 Experimental: <span class="token boolean">false</span>
 Insecure Registries:
  ::1/128
  <span class="token number">127.0</span>.0.0/8
 Registry Mirrors:
  https://docker.mirrors.ustc.edu.cn/
  https://mirror.baidubce.com/
  https://docker.m.daocloud.io/
  https://mirror.ccs.tencentyun.com/
  https://docker.nju.edu.cn/
  https://docker.mirrors.sjtug.sjtu.edu.cn/
  https://mirror.gcr.io/
  https://docker.registry.cyou/
  https://docker-cf.registry.cyou/
  https://dockercf.jsdelivr.fyi/
  https://docker.jsdelivr.fyi/
  https://dockertest.jsdelivr.fyi/
  https://mirror.aliyuncs.com/
  https://dockerproxy.com/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="2-3-操作容器"><a href="#2-3-操作容器" class="headerlink" title="2.3 操作容器"></a>2.3 操作容器</h2><h3 id="2-3-1-创建持续运行的容器"><a href="#2-3-1-创建持续运行的容器" class="headerlink" title="2.3.1 创建持续运行的容器"></a>2.3.1 创建持续运行的容器</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># docker run -d --name nginxtest nginx</span>
root@k8s-master:~<span class="token comment"># docker ps</span>
CONTAINER ID   IMAGE     COMMAND                  CREATED              STATUS              PORTS     NAMES
b68184fd3b9b   nginx     <span class="token string">"/docker-entrypoint.…"</span>   About a minute ago   Up About a minute   <span class="token number">80</span>/tcp  nginxtest

root@k8s-master:~<span class="token comment"># docker ps -a</span>
CONTAINER ID   IMAGE    COMMAND                  CREATED              STATUS               PORTS     NAMES
b68184fd3b9b   nginx    <span class="token string">"/docker-entrypoint.…"</span>   About a minute ago   Up About a minute     <span class="token number">80</span>/tcp  nginxtest
8ea8394296ac   hello-world   <span class="token string">"/hello"</span>            <span class="token number">22</span> minutes ago    Exited <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token number">22</span> minutes ago   goofy_brattain<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="2-3-2-进入容器"><a href="#2-3-2-进入容器" class="headerlink" title="2.3.2 进入容器"></a>2.3.2 进入容器</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># docker exec -it nginxtest /bin/bash</span>
root@b68184fd3b9b:/<span class="token comment"># cat /etc/nginx/nginx.conf</span>
root@b68184fd3b9b:/<span class="token comment"># exit</span>
<span class="token builtin class-name">exit</span>
root@k8s-master:~<span class="token comment">#</span>

<span class="token comment"># @后的主机名在exec后发生了变化，这就是进入容器内的标志</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="2-3-3-删除容器"><a href="#2-3-3-删除容器" class="headerlink" title="2.3.3 删除容器"></a>2.3.3 删除容器</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># docker ps</span>
CONTAINER ID   IMAGE      COMMAND                  CREATED         STATUS        PORTS       NAMES
260028d6b4a2   httpd:v1   <span class="token string">"httpd-foreground"</span>       <span class="token number">5</span> seconds ago   Up <span class="token number">4</span> seconds   <span class="token number">0.0</span>.0.0:4000-<span class="token operator">&gt;</span><span class="token number">80</span>/tcp, <span class="token punctuation">[</span>::<span class="token punctuation">]</span>:4000-<span class="token operator">&gt;</span><span class="token number">80</span>/tcp   luoyudockerfile
b68184fd3b9b   nginx      <span class="token string">"/docker-entrypoint.…"</span>   <span class="token number">12</span> hours ago    Up <span class="token number">12</span> hours    <span class="token number">80</span>/tcp    nginxtest

root@k8s-master:~<span class="token comment"># docker rm -f nginxtest luoyudockerfile</span>
nginxtest
luoyudockerfile
root@k8s-master:~<span class="token comment"># docker ps</span>
CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="2-4-构建-使用镜像"><a href="#2-4-构建-使用镜像" class="headerlink" title="2.4 构建&amp;使用镜像"></a>2.4 构建&amp;使用镜像</h2><h3 id="2-4-1-镜像概述"><a href="#2-4-1-镜像概述" class="headerlink" title="2.4.1 镜像概述"></a>2.4.1 镜像概述</h3><p>  镜像是一个用于创建容器的只读模板，通常来讲，包含一些额外的自定义，比如说，可以构建一个基于centos的镜像，在镜像构建时，直接包含一些应用程序，比如Apache或者其他程序，构建完成后，可以直接基于这个镜像启动容器，快速获得期望的业务</p>
<p>  镜像可以来自公共的仓库，也可通过Dockerfile等定义文件来构建，并且把自己的镜像推送到仓库中，以备在任何地方任何时间下载使用</p>
<h3 id="2-4-2-公共镜像仓库"><a href="#2-4-2-公共镜像仓库" class="headerlink" title="2.4.2 公共镜像仓库"></a>2.4.2 公共镜像仓库</h3><p>  Docker公共镜像仓库：<a target="_blank" rel="noopener" href="https://hub.docker.com/">https://hub.docker.com</a></p>
<p>  Docker Hub是一个基于云端的registry服务，这个服务允许我们连接仓库代码、建立镜像、 推送镜像等功能，提供了一个集中式的容器资源管理平台，包含了各式各样的官方镜像，例如Apache、Centos以及各种企业级应用镜像，还以星级和评分来确保镜像的可靠性和适用性</p>
<p><img src="/images/%E5%85%AC%E5%85%B1%E9%95%9C%E5%83%8F%E5%BA%93.png"></p>
<p>  打开<a target="_blank" rel="noopener" href="https://hub.docker.com,注册一个docker/">https://hub.docker.com，注册一个Docker</a> ID，登陆后浏览各项功能</p>
<h3 id="2-4-3-镜像分层技术"><a href="#2-4-3-镜像分层技术" class="headerlink" title="2.4.3 镜像分层技术"></a>2.4.3 镜像分层技术</h3><p><img src="/images/%E9%95%9C%E5%83%8F%E5%88%86%E5%B1%82.png"></p>
<h3 id="2-4-4-构建镜像的方法"><a href="#2-4-4-构建镜像的方法" class="headerlink" title="2.4.4 构建镜像的方法"></a>2.4.4 构建镜像的方法</h3><p>  1.docker commit</p>
<p>  使用容器中发生更改的部分生成一个新的镜像，通常的使用场景为，基于普通镜像启动了容器，在容器内部署了所需的业务后，把当前的状态重新生成镜像，以便以当前状态快速部署业务所用</p>
<p>  2.Dockerfile 创建镜像</p>
<p>  从零开始构建自己所需的镜像，在创建镜像之初把所需的各种设置和所需要的各种应用程序包含进去，生成的镜像可直接用于业务部署</p>
<p>  3.Dockerfile高频指令集</p>
<p><img src="/images/dockerfile%E6%8C%87%E4%BB%A4.png"></p>
<h3 id="2-4-5-Dockerfile-image"><a href="#2-4-5-Dockerfile-image" class="headerlink" title="2.4.5 Dockerfile image"></a>2.4.5 Dockerfile image</h3><p>  在设计Dockerfile时应考虑以下事项：</p>
<p>  1.容器应该是暂时的</p>
<p>  2.避免安装不必要的软件包</p>
<p>  3.每个容器只应该有一个用途</p>
<p>  4.避免容器有过多的层</p>
<p>  5.多行排序</p>
<p>  6.建立缓存</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 创建dockerfile文件</span>
root@k8s-master:~<span class="token comment"># cat &gt; dockerfile &lt;&lt;EOF</span>
FROM httpd
MAINTAINER luovipyu@163.com
RUN <span class="token builtin class-name">echo</span> hello luoyu dockerfile container <span class="token operator">&gt;</span> /usr/local/apache2/htdocs/index.html
EXPOSE <span class="token number">80</span>
WORKDIR /usr/local/apache2/htdocs/
EOF

<span class="token comment"># 开始构建镜像</span>
root@k8s-master:~<span class="token comment"># docker build -t httpd:v1 -f dockerfile .</span>

<span class="token comment"># 查看docker镜像</span>
root@k8s-master:~<span class="token comment"># docker images</span>
REPOSITORY    TAG       IMAGE ID       CREATED          SIZE
httpd         v1        d6d24a446dd4   <span class="token number">25</span> seconds ago   148MB
nginx         latest    a830707172e8   <span class="token number">3</span> weeks ago      192MB
hello-world   latest    74cc54e27dc4   <span class="token number">3</span> months ago     <span class="token number">10</span>.1kB

注明：如果文件名是Dockerfile时可不指定
<span class="token function">docker</span> build <span class="token parameter variable">-t</span> web:v1 <span class="token builtin class-name">.</span>

<span class="token comment"># 如果用的是containerd，dockerfile方式构建容器镜像的命令就是下面这样的</span>
nerdctl build  <span class="token parameter variable">-t</span> httpd:v1 <span class="token parameter variable">-f</span> dockerfile <span class="token builtin class-name">.</span>
nerdctl images<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="2-4-6-使用Dockerfile镜像"><a href="#2-4-6-使用Dockerfile镜像" class="headerlink" title="2.4.6 使用Dockerfile镜像"></a>2.4.6 使用Dockerfile镜像</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 用httpd:v1的镜像在本机4000端口上提供一个名为luoyudockerfile的容器</span>
root@k8s-master:~<span class="token comment"># docker run -d -p 4000:80 --name luoyudockerfile httpd:v1</span>
260028d6b4a2b11cd2cfca9ab6ae9d406cc8fa9afd33131db03c880cc235e68f

root@k8s-master:~<span class="token comment"># docker ps</span>
CONTAINER ID   IMAGE      COMMAND                  CREATED         STATUS        PORTS       NAMES
260028d6b4a2   httpd:v1   <span class="token string">"httpd-foreground"</span>       <span class="token number">5</span> seconds ago   Up <span class="token number">4</span> seconds   <span class="token number">0.0</span>.0.0:4000-<span class="token operator">&gt;</span><span class="token number">80</span>/tcp, <span class="token punctuation">[</span>::<span class="token punctuation">]</span>:4000-<span class="token operator">&gt;</span><span class="token number">80</span>/tcp   luoyudockerfile
b68184fd3b9b   nginx      <span class="token string">"/docker-entrypoint.…"</span>   <span class="token number">12</span> hours ago    Up <span class="token number">12</span> hours    <span class="token number">80</span>/tcp    nginxtest

root@k8s-master:~<span class="token comment"># curl http://127.0.0.1:4000</span>
hello luoyu dockerfile container

<span class="token comment"># 如果用的是containerd，dockerfile方式构建容器镜像的使用命令就是下面这样的</span>
nerdctl run <span class="token parameter variable">-d</span> <span class="token parameter variable">-p</span> <span class="token number">4000</span>:80 <span class="token parameter variable">--name</span> luoyudockerfile httpd:v1
nerdctl <span class="token function">ps</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="2-4-7-关于镜像命名"><a href="#2-4-7-关于镜像命名" class="headerlink" title="2.4.7 关于镜像命名"></a>2.4.7 关于镜像命名</h3><p>  1.镜像命名格式：REPOSITORY+TAG，使用版本号作为命名</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># docker images</span>
REPOSITORY    TAG       IMAGE ID       CREATED        SIZE
httpd         v1        d6d24a446dd4   <span class="token number">11</span> hours ago   148MB
nginx         latest    a830707172e8   <span class="token number">3</span> weeks ago    192MB
hello-world   latest    74cc54e27dc4   <span class="token number">3</span> months ago   <span class="token number">10</span>.1kB<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>  2.关于latest tag的说明</p>
<p>  如果在建立镜像时没有指定Tag，会使用默认值latest，所以，当看到一个镜像的Tag处显示latest的时候，并不一定意味着此版本是最新版，而只意味着在建立镜像的时候，没有指定Tag</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># docker build -t web .</span>
root@k8s-master:~<span class="token comment"># docker images</span>
REPOSITORY    TAG       IMAGE ID       CREATED        SIZE
httpd         v1        d6d24a446dd4   <span class="token number">11</span> hours ago   148MB
web           latest    d6d24a446dd4   <span class="token number">11</span> hours ago   148MB
nginx         latest    a830707172e8   <span class="token number">3</span> weeks ago    192MB
hello-world   latest    74cc54e27dc4   <span class="token number">3</span> months ago   <span class="token number">10</span>.1kB<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="2-4-8-删除镜像"><a href="#2-4-8-删除镜像" class="headerlink" title="2.4.8 删除镜像"></a>2.4.8 删除镜像</h3><p>  删除一个特定的镜像，需要知道该镜像的ID或者标签(repository:tag)。或者，如果只记得镜像的部分ID，可以使用这个ID来删除镜像</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># docker images</span>
REPOSITORY    TAG       IMAGE ID       CREATED        SIZE
httpd         v1        d6d24a446dd4   <span class="token number">11</span> hours ago   148MB
web           latest    d6d24a446dd4   <span class="token number">11</span> hours ago   148MB
nginx         latest    a830707172e8   <span class="token number">3</span> weeks ago    192MB
hello-world   latest    74cc54e27dc4   <span class="token number">3</span> months ago   <span class="token number">10</span>.1kB
root@k8s-master:~<span class="token comment"># docker rmi web:latest</span>
Untagged: web:latest
root@k8s-master:~<span class="token comment"># docker rmi 74cc54e27dc4</span>
Error response from daemon: conflict: unable to delete 74cc54e27dc4 <span class="token punctuation">(</span>must be forced<span class="token punctuation">)</span> - image is being used by stopped container 8ea8394296ac
root@k8s-master:~<span class="token comment"># docker ps -a</span>
CONTAINER ID   IMAGE         COMMAND    CREATED        STATUS                    PORTS     NAMES
8ea8394296ac   hello-world   <span class="token string">"/hello"</span>   <span class="token number">13</span> hours ago   Exited <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token number">13</span> hours ago             goofy_brattain

root@k8s-master:~<span class="token comment"># docker rm 8ea8394296ac</span>

root@k8s-master:~<span class="token comment"># docker rmi 74cc54e27dc4</span>

root@k8s-master:~<span class="token comment"># docker images</span>
<span class="token punctuation">\</span>REPOSITORY   TAG       IMAGE ID       CREATED        SIZE
httpd        v1        d6d24a446dd4   <span class="token number">11</span> hours ago   148MB
nginx        latest    a830707172e8   <span class="token number">3</span> weeks ago    192MB<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="2-4-9-私有镜像仓库"><a href="#2-4-9-私有镜像仓库" class="headerlink" title="2.4.9 私有镜像仓库"></a>2.4.9 私有镜像仓库</h3><p>  构建私有镜像存储考虑：</p>
<p>  1.交付时效，例如，下载并运行镜像，需要消耗带宽和时间</p>
<p>  2.机房是否允许接入外网</p>
<p>  3.镜像私密，不允许将数据放到外网</p>
<p>  4.内网速率更高</p>
<p>  什么是Registry？</p>
<p>  1.Registry是一个无状态、高度可扩展的服务，可以存储和分发镜像</p>
<p>  2.Registry是一个基于Apache License许可的开源服务</p>
<p>  为什么使用Registry？</p>
<p>  1.严格控制映像存储位置</p>
<p>  2.拥有完全属于自己的镜像分发渠道</p>
<p>  3.将镜像存储和分布紧密集成到内部开发工作流程中</p>
<p>  部署Registry步骤如下：如果选用Harbor，请参考Gitee文档</p>
<p>  1.下载Docker官方最新版的Registry镜像</p>
<p>  2.启动Registry容器</p>
<p>  3.下载测试镜像</p>
<p>  4.将测试镜像上传至自己的私有仓库</p>
<p>  5.验证从自有仓库下载并启动容器</p>
<h1 id="3-部署Harbor私有仓库"><a href="#3-部署Harbor私有仓库" class="headerlink" title="3 部署Harbor私有仓库"></a>3 部署Harbor私有仓库</h1><p>  在现代软件开发中，容器化应用已经成为主流，而容器镜像仓库则是确保容器镜像安全、管理和分发的重要工具。Harbor作为一款开源的企业级容器镜像仓库管理工具，不仅支持多种认证方式，还提供镜像复制、漏洞扫描和用户访问控制等功能，为企业提供了一个安全、高效的镜像管理方案</p>
<table>
<thead>
<tr>
<th>主机名</th>
<th>角色</th>
<th>IP</th>
<th>VMware网络类型</th>
<th>用户名</th>
<th>密码</th>
<th>系统</th>
</tr>
</thead>
<tbody><tr>
<td>harbor</td>
<td>Harbor主机</td>
<td>192.168.8.52</td>
<td>NAT</td>
<td>root</td>
<td>harbor</td>
<td>RHEL-9.5</td>
</tr>
</tbody></table>
<h2 id="3-1-RedHat9镜像源配置"><a href="#3-1-RedHat9镜像源配置" class="headerlink" title="3.1 RedHat9镜像源配置"></a>3.1 RedHat9镜像源配置</h2><h3 id="3-1-1-国内镜像源"><a href="#3-1-1-国内镜像源" class="headerlink" title="3.1.1 国内镜像源"></a>3.1.1 国内镜像源</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># cd /etc/yum.repos.d</span>
<span class="token punctuation">[</span>root@harbor yum.repos.d<span class="token punctuation">]</span><span class="token comment"># ll</span>
-rw-r--r--. <span class="token number">1</span> root root <span class="token number">358</span> May <span class="token number">14</span> <span class="token number">11</span>:25 redhat.repo

<span class="token punctuation">[</span>root@harbor yum.repos.d<span class="token punctuation">]</span><span class="token comment"># vim aliyun_yum.repo</span>
<span class="token punctuation">[</span>ali_baseos<span class="token punctuation">]</span>
<span class="token assign-left variable">name</span><span class="token operator">=</span>ali_baseos
<span class="token assign-left variable">baseurl</span><span class="token operator">=</span>https://mirrors.aliyun.com/centos-stream/9-stream/BaseOS/x86_64/os/
<span class="token assign-left variable">gpgcheck</span><span class="token operator">=</span><span class="token number">0</span>

<span class="token punctuation">[</span>ali_appstream<span class="token punctuation">]</span>
<span class="token assign-left variable">name</span><span class="token operator">=</span>ali_appstream
<span class="token assign-left variable">baseurl</span><span class="token operator">=</span>https://mirrors.aliyun.com/centos-stream/9-stream/AppStream/x86_64/os/
<span class="token assign-left variable">gpgcheck</span><span class="token operator">=</span><span class="token number">0</span>

<span class="token punctuation">[</span>root@harbor yum.repos.d<span class="token punctuation">]</span><span class="token comment"># yum makecache</span>

<span class="token comment"># 根据需要选择是否更新yum源</span>
<span class="token punctuation">[</span>root@harbor yum.repos.d<span class="token punctuation">]</span><span class="token comment"># yum -y update</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="3-1-2-本地yum源配置"><a href="#3-1-2-本地yum源配置" class="headerlink" title="3.1.2 本地yum源配置"></a>3.1.2 本地yum源配置</h3><p>  配置本地yum源可以创建一个本地的软件包存储库，以便更快地安装、更新和管理软件包</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 创建文件夹并将光盘挂载到新建的文件中</span>
<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># mkdir -p /GuaZai/Iso</span>
<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># mount /dev/sr0 /GuaZai/Iso</span>
mount: /GuaZai/Iso: WARNING: <span class="token builtin class-name">source</span> write-protected, mounted read-only.

<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># cd /GuaZai/Iso</span>
<span class="token punctuation">[</span>root@harbor Iso<span class="token punctuation">]</span><span class="token comment"># ls</span>
AppStream  BaseOS  EFI  EULA  extra_files.json  GPL  images  isolinux  media.repo  RPM-GPG-KEY-redhat-beta  RPM-GPG-KEY-redhat-release

<span class="token comment">#配置yum文件</span>
<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># vim /etc/yum.repos.d/rhel9.repo</span>
<span class="token punctuation">[</span>BaseOS<span class="token punctuation">]</span>
<span class="token assign-left variable">name</span><span class="token operator">=</span>rhel9-BaseOS
<span class="token assign-left variable">baseurl</span><span class="token operator">=</span>file:///GuaZai/Iso/BaseOS
<span class="token assign-left variable">gpgcheck</span><span class="token operator">=</span><span class="token number">0</span>
<span class="token punctuation">[</span>Appstream<span class="token punctuation">]</span>
<span class="token assign-left variable">name</span><span class="token operator">=</span>rhel9-Appstream
<span class="token assign-left variable">baseurl</span><span class="token operator">=</span>file:///GuaZai/Iso/AppStream
<span class="token assign-left variable">gpgcheck</span><span class="token operator">=</span><span class="token number">0</span>

<span class="token comment"># 查看仓库序列</span>
<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># yum repolist</span>

<span class="token comment"># 生成yum缓存</span>
<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># yum makecache</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="3-2-主机名和IP地址映射"><a href="#3-2-主机名和IP地址映射" class="headerlink" title="3.2 主机名和IP地址映射"></a>3.2 主机名和IP地址映射</h2><p>  配置Harbor主机的主机名和IP地址映射，映射文件“/etc/hosts”加入如下内容</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># vim /etc/hosts</span>
<span class="token number">192.168</span>.8.52 registry.luovip.cn<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<h2 id="3-3-部署Docker-CE"><a href="#3-3-部署Docker-CE" class="headerlink" title="3.3 部署Docker CE"></a>3.3 部署Docker CE</h2><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 检测系统是否安装了docker并卸载旧版本的容器</span>
<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># sudo dnf remove docker \</span>
                  docker-client <span class="token punctuation">\</span>
                  docker-client-latest <span class="token punctuation">\</span>
                  docker-common <span class="token punctuation">\</span>
                  docker-latest <span class="token punctuation">\</span>
                  docker-latest-logrotate <span class="token punctuation">\</span>
                  docker-logrotate <span class="token punctuation">\</span>
                  docker-engine <span class="token punctuation">\</span>
                  <span class="token function">podman</span> <span class="token punctuation">\</span>
                  runc
<span class="token comment"># 安装依赖</span>
<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># sudo yum install -y yum-utils</span>
<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># sudo dnf -y install dnf-plugins-core</span>
<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># sudo dnf config-manager --add-repo https://download.docker.com/linux/rhel/docker-ce.repo</span>

<span class="token comment"># 安装docker</span>
<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># sudo sed -i 's+https://download.docker.com+https://mirror.nju.edu.cn/docker-ce+' /etc/yum.repos.d/docker-ce.repo</span>
<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># sudo yum install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin</span>

<span class="token comment"># 查看docker状态</span>
<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># sudo systemctl enable --now docker</span>
Created symlink /etc/systemd/system/multi-user.target.wants/docker.service → /usr/lib/systemd/system/docker.service.
<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># sudo systemctl status docker</span>
<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># docker info                         </span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="3-4-Docker镜像加速器"><a href="#3-4-Docker镜像加速器" class="headerlink" title="3.4 Docker镜像加速器"></a>3.4 Docker镜像加速器</h2><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># mkdir -p /etc/docker</span>
<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># cd /etc/docker</span>
<span class="token punctuation">[</span>root@harbor docker<span class="token punctuation">]</span><span class="token comment"># vim /etc/docker/daemon.json</span>
<span class="token punctuation">{</span>
  <span class="token string">"registry-mirrors"</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span>
        <span class="token string">"https://docker.mirrors.ustc.edu.cn"</span>,
        <span class="token string">"https://mirror.baidubce.com"</span>,
        <span class="token string">"https://docker.m.daocloud.io"</span>,
        <span class="token string">"https://mirror.ccs.tencentyun.com"</span>,
        <span class="token string">"https://docker.nju.edu.cn"</span>,
        <span class="token string">"https://docker.mirrors.sjtug.sjtu.edu.cn"</span>,
        <span class="token string">"https://mirror.gcr.io"</span>,
        <span class="token string">"https://docker.registry.cyou"</span>,
        <span class="token string">"https://docker-cf.registry.cyou"</span>,
        <span class="token string">"https://dockercf.jsdelivr.fyi"</span>,
        <span class="token string">"https://docker.jsdelivr.fyi"</span>,
        <span class="token string">"https://dockertest.jsdelivr.fyi"</span>,
        <span class="token string">"https://mirror.aliyuncs.com"</span>,
        <span class="token string">"https://dockerproxy.com"</span>
  <span class="token punctuation">]</span>,
  <span class="token string">"data-root"</span><span class="token builtin class-name">:</span> <span class="token string">"/data/docker"</span>   <span class="token comment"># 自定义Docker的镜像存储路径</span>
<span class="token punctuation">}</span>

<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># mkdir -p /data/docker</span>
<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># cp -a /var/lib/docker/* /data/docker/</span>

<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># systemctl daemon-reload</span>
<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># systemctl restart docker</span>
<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># docker info</span>


<span class="token comment"># 测试</span>
<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># docker pull nginx</span>
<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># docker images</span>
REPOSITORY   TAG       IMAGE ID       CREATED       SIZE
nginx        latest    a830707172e8   <span class="token number">3</span> weeks ago   192MB<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="3-5-Compose支持"><a href="#3-5-Compose支持" class="headerlink" title="3.5 Compose支持"></a>3.5 Compose支持</h2><p>  添加Compose支持，并启动Docker服务</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 下载docker-compose并放在/usr/local/bin下</span>
<span class="token function">curl</span> <span class="token parameter variable">-L</span> <span class="token string">"https://github.com/docker/compose/releases/download/v2.36.0/docker-compose-linux-x86_64"</span> <span class="token parameter variable">-o</span> /usr/local/bin/docker-compose

<span class="token function">chmod</span> +x /usr/local/bin/docker-compose
systemctl daemon-reload
systemctl restart <span class="token function">docker</span>
<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># docker-compose version</span>
Docker Compose version v2.36.0

<span class="token comment"># 注明：github可能会访问不了，故先从github下载到本地，再上传到服务器</span>
https://github.com/docker/compose/releases<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="3-6-下载Harbor"><a href="#3-6-下载Harbor" class="headerlink" title="3.6 下载Harbor"></a>3.6 下载Harbor</h2><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># wget https://github.com/goharbor/harbor/releases/download/v2.13.0/harbor-offline-installer-v2.13.0.tgz</span>

<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># tar xf harbor-offline-installer-v2.13.0.tgz -C /usr/local/bin</span>

<span class="token comment"># 使用docker load命令将解压后的tar文件加载为Docker镜像</span>
<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># cd /usr/local/bin</span>
<span class="token punctuation">[</span>root@harbor bin<span class="token punctuation">]</span><span class="token comment"># ll</span>
total <span class="token number">72004</span>
-rwxr-xr-x. <span class="token number">1</span> root root <span class="token number">73731911</span> May <span class="token number">14</span> <span class="token number">14</span>:25 <span class="token function">docker-compose</span>
drwxr-xr-x. <span class="token number">2</span> root root      <span class="token number">123</span> May <span class="token number">14</span> <span class="token number">16</span>:33 harbor
<span class="token punctuation">[</span>root@harbor bin<span class="token punctuation">]</span><span class="token comment"># cd harbor</span>
<span class="token punctuation">[</span>root@harbor harbor<span class="token punctuation">]</span><span class="token comment"># docker load -i harbor.v2.13.0.tar.gz</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="3-7-修改harbor-yml文件"><a href="#3-7-修改harbor-yml文件" class="headerlink" title="3.7 修改harbor.yml文件"></a>3.7 修改harbor.yml文件</h2><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">mv</span> harbor.yml.tmpl harbor.yml

<span class="token comment"># 备份harbor.yml文件</span>
<span class="token function">cp</span> harbor.yml harbor.yml.bak

<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># vim /usr/local/bin/harbor/harbor.yml</span>
<span class="token number">1</span>.修改hostname为192.168.8.52
<span class="token number">2</span>.修改http的端口为82
<span class="token number">3</span>.修改harbor_admin_password为admin
<span class="token comment"># 如果不启用https就注释掉12行-20行</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="3-8-安装Harbor"><a href="#3-8-安装Harbor" class="headerlink" title="3.8 安装Harbor"></a>3.8 安装Harbor</h2><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 加载配置并安装</span>
<span class="token punctuation">[</span>root@harbor harbor<span class="token punctuation">]</span><span class="token comment"># ./prepare</span>
<span class="token punctuation">[</span>root@harbor harbor<span class="token punctuation">]</span><span class="token comment"># ./install.sh</span>
<span class="token punctuation">..</span>.
<span class="token punctuation">[</span>Step <span class="token number">5</span><span class="token punctuation">]</span>: starting Harbor <span class="token punctuation">..</span>.
<span class="token punctuation">[</span>+<span class="token punctuation">]</span> Running <span class="token number">10</span>/10
 ✔ Network harbor_harbor        Created    <span class="token number">0</span>.0s                                                    
 ✔ Container harbor-log         Started    <span class="token number">0</span>.3s                                                      
 ✔ Container registryctl        Started    <span class="token number">0</span>.8s                                                    
 ✔ Container harbor-db          Started    <span class="token number">1</span>.2s                                                     
 ✔ Container redis              Started    <span class="token number">1</span>.2s                                                 
 ✔ Container harbor-portal      Started    <span class="token number">1</span>.2s                                                          
 ✔ Container registry           Started    <span class="token number">1</span>.3s                                                 
 ✔ Container harbor-core        Started    <span class="token number">1</span>.4s                                              
 ✔ Container harbor-jobservice  Started    <span class="token number">2</span>.0s                                               
 ✔ Container nginx              Started    <span class="token number">2</span>.0s                                           
✔ ----Harbor has been installed and started successfully.----<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="3-9-重启Harbor"><a href="#3-9-重启Harbor" class="headerlink" title="3.9 重启Harbor"></a>3.9 重启Harbor</h2><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@harbor harbor<span class="token punctuation">]</span><span class="token comment"># docker-compose down</span>
<span class="token punctuation">[</span>root@harbor harbor<span class="token punctuation">]</span><span class="token comment"># ./prepare</span>
<span class="token punctuation">[</span>root@harbor harbor<span class="token punctuation">]</span><span class="token comment"># docker-compose up -d</span>

<span class="token comment"># 浏览器访问Harbor   http://192.168.8.52:82  用户名/密码:admin/admin</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="3-10-生成服务文件"><a href="#3-10-生成服务文件" class="headerlink" title="3.10 生成服务文件"></a>3.10 生成服务文件</h2><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">cat</span> <span class="token operator">&gt;</span> /etc/systemd/system/harbor.service <span class="token operator">&lt;&lt;</span><span class="token string">EOF
[Unit]
Description=Harbor
After=docker.service systemd-networkd.service systemd-resolved.service
Requires=docker.service
Documentation=http://github.com/vmware/harbor
[Service]
Type=simple
Restart=on-failure
RestartSec=5
ExecStart=/usr/local/bin/docker-compose -f /usr/local/bin/harbor/docker-compose.yml up
ExecStop=/usr/local/bin/docker-compose -f /usr/local/bin/harbor/docker-compose.yml down
[Install]
WantedBy=multi-user.target
EOF</span>

<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># systemctl daemon-reload</span>
<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># systemctl enable harbor --now</span>
<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># systemctl stop harbor</span>
<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># systemctl status harbor</span>
<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># systemctl start harbor</span>
<span class="token punctuation">[</span>root@harbor ~<span class="token punctuation">]</span><span class="token comment"># systemctl restart harbor</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="3-11-推送镜像到Harbor"><a href="#3-11-推送镜像到Harbor" class="headerlink" title="3.11 推送镜像到Harbor"></a>3.11 推送镜像到Harbor</h2><p>  将registry.luovip.cn以及其对应的IP添加到/etc/hosts，然后将上述实验中的httpd:v1镜像，改名为带上IP:PORT形式，上传的镜像到本地仓库</p>
<p>  1.添加域名解析</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># vim /etc/hosts</span>
<span class="token number">192.168</span>.8.52 registry.luovip.cn<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>  2.编辑文件“/usr/lib/systemd/system/docker.service”，输入以下内容。其中，my.harbor.com是Harbor主机的主机名</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># vim /usr/lib/systemd/system/docker.service</span>
<span class="token assign-left variable">ExecStart</span><span class="token operator">=</span>/usr/bin/dockerd --insecure-registry registry.luovip.cn<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>  3.编辑“/etc/docker/daemon.json”文件，在该文件中指定私有镜像仓库地址</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># vim /etc/docker/daemon.json</span>
<span class="token string">"insecure-registries"</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span>
        <span class="token string">"192.168.8.52:82"</span>
  <span class="token punctuation">]</span>
<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># systemctl daemon-reload</span>
<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># systemctl restart docker.service</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>  4.推送的命令</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># Docker推送命令:</span>
<span class="token number">1</span>.在项目中标记镜像:
<span class="token function">docker</span> tag SOURCE_IMAGE<span class="token punctuation">[</span>:TAG<span class="token punctuation">]</span> <span class="token number">192.168</span>.8.52:82/library/REPOSITORY<span class="token punctuation">[</span>:TAG<span class="token punctuation">]</span>
<span class="token number">2</span>.推送镜像到当前项目：
<span class="token function">docker</span> push <span class="token number">192.168</span>.8.52:82/library/REPOSITORY<span class="token punctuation">[</span>:TAG<span class="token punctuation">]</span>

Podman推送命令：
<span class="token number">1</span>.推送镜像到当前项目：
<span class="token function">podman</span> push IMAGE_ID <span class="token number">192.168</span>.8.52:82/library/REPOSITORY<span class="token punctuation">[</span>:TAG<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>  5.推送镜像</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker images</span>
REPOSITORY   TAG       IMAGE ID       CREATED        SIZE
tomcat       latest    c6c6349a7df2   <span class="token number">47</span> hours ago   468MB
nginx        latest    a830707172e8   <span class="token number">4</span> weeks ago    192MB

<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker login 192.168.8.52:82</span>

<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker tag c6c6349a7df2 192.168.8.52:82/library/tomcat:v2</span>
<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docekr images</span>
-bash: docekr: <span class="token builtin class-name">command</span> not found
<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker images</span>
REPOSITORY                       TAG       IMAGE ID       CREATED        SIZE
<span class="token number">192.168</span>.8.52:82/library/tomcat   v2        c6c6349a7df2   <span class="token number">47</span> hours ago   468MB
tomcat                           latest    c6c6349a7df2   <span class="token number">47</span> hours ago   468MB
nginx                            latest    a830707172e8   <span class="token number">4</span> weeks ago    192MB

<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker push 192.168.8.52:82/library/tomcat:v2</span>

<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker pull 192.168.8.52:82/library/tomcat:v2</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h1 id="4-管理容器的资源"><a href="#4-管理容器的资源" class="headerlink" title="4 管理容器的资源"></a>4 管理容器的资源</h1><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 创建容器并观察内存量</span>
<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker run -d --name=httpd_server httpd</span>
<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker run -d --name=httpd_tomcat tomcat</span>

<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker ps -a</span>
CONTAINER ID   IMAGE     COMMAND              CREATED         STATUS         PORTS      NAMES
796227a2aac7   tomcat    <span class="token string">"catalina.sh run"</span>    <span class="token number">2</span> minutes ago   Up <span class="token number">2</span> minutes   <span class="token number">8080</span>/tcp   httpd_tomcat
b025ca41d951   httpd     <span class="token string">"httpd-foreground"</span>   <span class="token number">3</span> minutes ago   Up <span class="token number">3</span> minutes   <span class="token number">80</span>/tcp     httpd_server

<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker exec -it httpd_server grep MemTotal /proc/meminfo</span>
MemTotal:        <span class="token number">3974748</span> kB
<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker exec -it httpd_tomcat grep MemTotal /proc/meminfo</span>
MemTotal:        <span class="token number">3974748</span> kB<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="4-1-容器的内存配额"><a href="#4-1-容器的内存配额" class="headerlink" title="4.1 容器的内存配额"></a>4.1 容器的内存配额</h2><p>  根据以上得出结论，每个容器的内存量，全部等于物理宿主机的内存总量，这意味这更好的性能，但同时也意味着一旦业务需求上升，将有可能发生资源争用，这通常在运维规划时，应当极力避免</p>
<p>  容器可使用的内存：物理内存和交换空间(Swap)</p>
<p>  Docker默认没有设置内存限制。可以通过相关选项限制设置：</p>
<p>  1.-m(–memory)：设置容器可用的最大内存，该值最低为4MB</p>
<p>  2.–memory-swap：允许容器置入磁盘交换空间中的内存大小</p>
<h3 id="4-1-1-用户内存限制"><a href="#4-1-1-用户内存限制" class="headerlink" title="4.1.1 用户内存限制"></a>4.1.1 用户内存限制</h3><p>  Docker提供4种方式设置容器的用户内存使用:</p>
<p>  1.对容器内存使用无限制（两个选项都不使用）</p>
<p>  2.设置内存限制并取消<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E4%BA%A4%E6%8D%A2%E7%A9%BA%E9%97%B4&amp;spm=1001.2101.3001.7020">交换空间</a>内存限制</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment">#使用300内存和尽可能多的交换空间</span>
<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker run -it -m 300M --memory-swap -1 ubuntu /bin/bash</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>  3.只设置内存限制</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"> <span class="token comment"># 300MB的内存和300MB的交换空间</span>
 <span class="token comment"># 默认情况下虚拟内存总量将设置为内存大小的两倍，因此容器能使用300M的交换空间</span>
<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker run -it -m 300M ubuntu /bin/bash</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>  4.同时设置内存和交换空间</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 300MB的内存和700MB的交换空间</span>
<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker run -it -m 300M --memory-swap 700m ubuntu /bin/bash</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<h3 id="4-1-2-内核内存限制"><a href="#4-1-2-内核内存限制" class="headerlink" title="4.1.2 内核内存限制"></a>4.1.2 内核内存限制</h3><p>  内核内存不能交换到磁盘中，无法使用交换空间，消耗过多可能导致其阻塞系统服务</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 在500MB的内存中，可以使用最高50MB的内核内存</span>
<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker run -it -m 500M --kernel-memory 50M ubuntu /bin/bash</span>

<span class="token comment"># 只可以使用50MB的内核内存</span>
<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker run -it --kernel-memory 50M ubuntu /bin/bash</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="4-1-3-内存预留实现软限制"><a href="#4-1-3-内存预留实现软限制" class="headerlink" title="4.1.3 内存预留实现软限制"></a>4.1.3 内存预留实现软限制</h3><p>  使用–memory-reservation选项设置内存预留，它是一种内存软限制，允许更多的内存共享。设置后，Docker将检测内存争用或内存不足，并强制容器将其内存消耗限制为预留值</p>
<p>  内存预留值应当始终低于硬限制，作为一个软限制功能，内存预留并不能保证不会超过限制</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 限制内存为500MB，内存预留值(软限制)为200MB。</span>
<span class="token comment"># 当容器消耗内存大于200MB、小于500MB时，下一次系统内存回收将尝试将容器内存缩减到200MB以下</span>
<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker run -it -m 500M --memory-reservation 200M ubuntu /bin/bash</span>
<span class="token function">docker</span> run –it –m 500M --memory-reservation 200M ubuntu /bin/bash

<span class="token comment"># 设置内存软限制为1GB</span>
<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker run -it —-memory-reservation 1G ubuntu /bin/bash</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="4-2-容器的CPU配额"><a href="#4-2-容器的CPU配额" class="headerlink" title="4.2 容器的CPU配额"></a>4.2 容器的CPU配额</h2><p>  默认情况下，所有容器都可以使用相同的CPU资源，并且没有任何限制，这和内存问题一样，一旦CPU需求业务上升，同样会引起CPU资源的争用，但是和内存指定绝对量的不同，CPU是通过指定相对权重值来进行的配额</p>
<p>  使用–cpu-shares参数对CPU来进行配额分配，默认情况下，这个值为1024</p>
<p>  当前容器中的业务空闲时，其他的容器有权利使用其空闲的CPU周期，这将确保业务的性能</p>
<p>  CPU限额的分配，只有在物理机资源不足的时候才会生效，并且是根据不同的优先级进行的，当其他容器空闲时，忙碌的容器可以获得全部可用的CPU资源</p>
<h3 id="4-2-1-CPU份额限制"><a href="#4-2-1-CPU份额限制" class="headerlink" title="4.2.1 CPU份额限制"></a>4.2.1 CPU份额限制</h3><p>  -c(–cpu-shares)选项将CPU份额权重设置为指定的值</p>
<p>  默认值为1024，如果设置为0，系统将忽略该值并使用默认值1024</p>
<h3 id="4-2-2-CPU周期限制"><a href="#4-2-2-CPU周期限制" class="headerlink" title="4.2.2 CPU周期限制"></a>4.2.2 CPU周期限制</h3><p>  –cpu-period选项(以μs为单位)设置CPU周期以限制容器CPU资源的使用</p>
<p>  默认的CFS(完全公平调度器)周期为100ms(100000μs)</p>
<p>  通常将–cpu-period与–cpu-quota这两个选项配合使用：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 如果只有1个CPU，则容器可以每50ms(50000μs)获得50%(25000/50000)的CPU运行时间</span>
<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker run -it --cpu-period=50000 --cpu-quota=25000 ubuntu /bin/bash</span>

<span class="token comment"># 可用--cpus选项指定容器的可用CPU资源来达到同样的目的</span>
<span class="token comment"># --cpus选项值是一个浮点数，默认值为0.000，表示不受限制</span>
<span class="token comment"># 上述可改为</span>
<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker run -it --cpus=0.5 ubuntu /bin/bash</span>

<span class="token comment"># --cpu-period和--cpu-quota选项都是以1个CPU为基准</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="4-2-3-CPU放置限制"><a href="#4-2-3-CPU放置限制" class="headerlink" title="4.2.3 CPU放置限制"></a>4.2.3 CPU放置限制</h3><p>  –cpuset-cpus选项限制容器进程在指定的CPU上执行</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 容器中的进程可以在cpu1和cpu3上执行</span>
<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker run -it --cpuset-cpus="1,3" ubuntu:14.04 /bin/bash</span>

<span class="token comment"># 容器中的进程可以在cpu0、cpu1和cpu 2上执行</span>
<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker run -it --cpuset-cpus="0-2" ubuntu:14.04 /bin/bash</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="4-2-4-CPU配额限制"><a href="#4-2-4-CPU配额限制" class="headerlink" title="4.2.4 CPU配额限制"></a>4.2.4 CPU配额限制</h3><p>  –cpu-quota选项限制容器的CPU配额，默认值为0表示容器占用100%的CPU资源个CPU</p>
<p>  CFS用于处理进程执行的资源分配，是由内核使用的默认Linux调度程序。将此值设置50000意味着限制容器至多使用CPU资源的50%，对于多个CPU而言，调整–cpu-quota选项必要的</p>
<h2 id="4-3-容器的I-O配额"><a href="#4-3-容器的I-O配额" class="headerlink" title="4.3 容器的I/O配额"></a>4.3 容器的I/O配额</h2><p>  默认情况下，所有容器都可以使用相同的I/O资源(500权重)，并且没有任何限制，这和内存、 CPU问题一样，一旦I/O需求业务上升，硬盘读写会变得非常迟缓，所以为了更好的提供服务，也应该对容器使用硬盘方面进行调整</p>
<p>  块I/O带宽(Block I/O Bandwidth，Blkio)是另一种可以限制容器使用的资源</p>
<p>  块I/O指磁盘的写，Docker可通过设置权重限制每秒字节数(B/s)和每秒I/O次数(IO/s)的方式控制容器读写盘的带宽</p>
<h3 id="4-3-1-设置块I-O权重"><a href="#4-3-1-设置块I-O权重" class="headerlink" title="4.3.1 设置块I/O权重"></a>4.3.1 设置块I/O权重</h3><p>  –blkio-weight选项更改比例(原默认为500)，设置相对于所有其他正在运行的容器的块I/O带宽权重</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 创建两个有不同块I/O带宽权重的容器</span>
<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker run -it --name c1 --blkio-weight 300 ubuntu /bin/bash</span>

<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker run -it --name c2 --blkio-weight 600 ubuntu /bin/bash</span>

在以下案例中，权重为600的容器将比300的在I/O能力方面多出两倍:

<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker run -d --name 300io --blkio-weight 300 httpd</span>

<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker run -d --name 600io --blkio-weight 600 httpd</span>

命令测试I/O性能:
<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># time dd if=/dev/zero of=test.out bs=1M count=1024</span>
<span class="token number">1024</span>+0 records <span class="token keyword">in</span>
<span class="token number">1024</span>+0 records out
<span class="token number">1073741824</span> bytes <span class="token punctuation">(</span><span class="token number">1.1</span> GB, <span class="token number">1.0</span> GiB<span class="token punctuation">)</span> copied, <span class="token number">4.05265</span> s, <span class="token number">265</span> MB/s

real    0m4.055s
user    0m0.000s
sys     0m4.036s

注：此设定在I/O争用时，才会体现<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="4-3-2-限制设备读写速率"><a href="#4-3-2-限制设备读写速率" class="headerlink" title="4.3.2 限制设备读写速率"></a>4.3.2 限制设备读写速率</h3><p>  Docker根据两类指标限制容器的设备读写速率：一类是每秒字节数，另一类是每秒I/O次数</p>
<p>  1.限制每秒字节数</p>
<p>  –device-read-bps选项限制指定设备的读取速率，即每秒读取的字节数</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 创建一个容器，并限制对/dev/mapper/rhel-swap设备的读取速率为每秒1MB</span>
<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker run -it --device-read-bps /dev/mapper/rhel-swap:1mb ubuntu</span>
<span class="token function">docker</span> run <span class="token parameter variable">-it</span> --device-read-bps /dev/sda:1mb ubuntu

<span class="token comment"># 类似地，可使用--device-write-bps选项限制指定设备的写入速率。格式： &lt;设备&gt;:&lt;速率值&gt;[单位]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>  2.限制每秒I/O次数</p>
<p>  –device-read-iops和–device-write-iops选项制指定设备的读取和写入速率，用每秒I/O次数表示</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 创建一个容器，限制它对/dev/mapper/rhel-swap设备的读取速率为每秒1000次</span>
<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker run -it --device-read-iops /dev/mapper/rhel-swap:1000 ubuntu</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<h2 id="4-4-容器底层技术实现"><a href="#4-4-容器底层技术实现" class="headerlink" title="4.4 容器底层技术实现"></a>4.4 容器底层技术实现</h2><p>  对容器使用的内存、CPU和块I/O带宽资源的限制具体是由控制组(Cgroup)的相应子系统来实现的</p>
<p>  1.memory子系统设置控制组中的住务所使用的内存限制</p>
<p>  2.cpu子系统通过调度程序提供对CPU的控制组任务的访问</p>
<p>  3.blkio子系统为块设备(如磁盘、固态硬盘、USB等)设置输入和输出限制</p>
<p>  在docker run命令中使用–cpu-shares、–memory、–device-read-bps等选项实际上就是在配置控制组，相关的配置文件保存在/sys/fs/cgroup目录中</p>
<h3 id="4-4-1-资源限制的底层实现"><a href="#4-4-1-资源限制的底层实现" class="headerlink" title="4.4.1 资源限制的底层实现"></a>4.4.1 资源限制的底层实现</h3><p>  Linux通过cgroup来分配进程使用的CPU、memory、I/O资源的配额，可以通过/sys/fs/cgroup/下面的设定来查看容器的配额部分</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 启动一个容器，设置内存限额为300MB，CPU权重为512</span>
<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker run --rm -d -p 8080:80 -m 300M --cpu-shares=512 httpd</span>
1dc9a3907b6b82521addd810d52d2514c6ab5fed1e274f03a90e5a1454d16a49

<span class="token comment"># 动态更改容器的资源限制</span>
<span class="token comment"># docker update命令可以动态地更新容器配置，其语法：docker update [选项] 容器 [容器...]</span>
<span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker update -m 500M --cpu-shares=10245 1dc9a3907b6b82521addd810d52d2514c6ab5fed1e274f03a90e5a1454d16a49</span>
1dc9a3907b6b82521addd810d52d2514c6ab5fed1e274f03a90e5a1454d16a49<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="4-4-2-容器的隔离底层实现"><a href="#4-4-2-容器的隔离底层实现" class="headerlink" title="4.4.2 容器的隔离底层实现"></a>4.4.2 容器的隔离底层实现</h3><p>  每个容器貌似都有自己独立的根目录以及/etc、/var等目录，而且貌似都有自己的独立网卡，但事实上物理宿主机只有一个网卡，那么容器之间是怎么实现的“独立性”的呢？</p>
<p>  Linux使用namespace技术来实现了容器间的资源隔离，namespace管理着宿主机中的全局唯一资源，并且可以让每个容器都会认为自己拥有且只有自己在使用资源，namespace一共有6种，分别为：mount、UTS、IPC、PID、Network、User</p>
<h3 id="4-4-3-namespace"><a href="#4-4-3-namespace" class="headerlink" title="4.4.3 namespace"></a>4.4.3 namespace</h3><p>  Mount namespace让容器看上去拥有整个文件系统，容器有自己的根目录</p>
<p>  UTS namespace可以让容器有自己的主机名，默认情况下，容器的主机名是它本身的短ID，可通过-h或者–hostname设置主机名</p>
<p>  IPC namespace可以让容器拥有自己的共享内存和信号量来实现进程间通信</p>
<p>  PID namespace让容器拥有自己的进程树，可以在容器中执行ps命令查看</p>
<p>  Network namespace可以让容器拥有自己独立的网卡、IP、路由等资源</p>
<p>  User namespace 让容器能够管理自己的用户，而不是和宿主机公用/etc/passwd</p>
<h1 id="5-容器原生网络与存储"><a href="#5-容器原生网络与存储" class="headerlink" title="5 容器原生网络与存储"></a>5 容器原生网络与存储</h1><h2 id="5-1-容器原生网络"><a href="#5-1-容器原生网络" class="headerlink" title="5.1 容器原生网络"></a>5.1 容器原生网络</h2><p>  docker原生提供了以下几种网络，如果对原生网络不满意，还可以创建自定义网络<br>  原生网络分为：none、bridge、host，这些网络在docker安装的时候会自动创建，可以通过以下命令来查看</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>root@docker ~<span class="token punctuation">]</span><span class="token comment"># docker network ls</span>
NETWORK ID     NAME      DRIVER    SCOPE
f85881372579   bridge    bridge    <span class="token builtin class-name">local</span>
668aba04b5b0   <span class="token function">host</span>      <span class="token function">host</span>      <span class="token builtin class-name">local</span>
3fa8ef65ab94   none      null      <span class="token builtin class-name">local</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>  如果容器使用的是none网络，那么此容器将不具备常规理解上的网卡，只具备lo网络，如果要使用这个网络，在创建容器时，指定–network=none即可</p>
<p>  None网络是比较封闭的网络，对一些安全要求比较高并且不需要联网的场景，可以用none网络，比如手机上接收的验证码、随机数生成等场景，就可以放在none网络中以避免被窃取</p>
<p>  Host网络是一个共享宿主机网络栈的一个容器共享网络，可以通过–network=host在创建容器 的时候指定host网络，处于host网络模式的容器，网络配置和宿主机是完全一样的，也就是说，在容器中可以看到宿主机的所有网卡，并且主机名也是宿主机的，这最大的好处就是性能很高，传输速率特别好，但是宿主机上已经使用的端口，容器就不可以使用</p>
<h2 id="5-2-容器和层"><a href="#5-2-容器和层" class="headerlink" title="5.2 容器和层"></a>5.2 容器和层</h2><p>  容器和镜像最大的不同在于最顶上的可写层，所有在容器中的数据写入和修改都会直接存储到这个可写层中，这就意味着，当容器被删除时，可写层中的数据就丢失了，虽然每个容器都有自己不同的可写层，但是容器底层的镜像却是可以同时共享的</p>
<p><img src="/images/%E5%AE%B9%E5%99%A8%E5%92%8C%E5%B1%82.png"></p>
<h2 id="5-3-主流存储驱动"><a href="#5-3-主流存储驱动" class="headerlink" title="5.3 主流存储驱动"></a>5.3 主流存储驱动</h2><p>  在容器设计和使用的时候，在容器的可写层中写入的数据是非常少的，但在运维中大部分数据是必须要具备持久化保存的能力，所以在容器中引入了多种的存储驱动来解决上面说的可写层数据的易失性</p>
<p>  目前主流受支持的存储驱动有：</p>
<p><img src="/images/%E5%AD%98%E5%82%A8%E9%A9%B1%E5%8A%A8.png"></p>
<h2 id="5-4-Copy-on-write策略"><a href="#5-4-Copy-on-write策略" class="headerlink" title="5.4 Copy-on-write策略"></a>5.4 Copy-on-write策略</h2><p><img src="/images/Copy-on-write.png"></p>
<h2 id="5-5-容器数据管理"><a href="#5-5-容器数据管理" class="headerlink" title="5.5 容器数据管理"></a>5.5 容器数据管理</h2><p>  容器中持久化数据一般采用两种存储方式：</p>
<p>   1.volume</p>
<p>   2.bind mount</p>
<p><img src="/images/%E6%8C%81%E4%B9%85%E5%8C%96%E6%95%B0%E6%8D%AE.png"></p>
<h1 id="6-Kubernetes"><a href="#6-Kubernetes" class="headerlink" title="6 Kubernetes"></a>6 Kubernetes</h1><h2 id="6-1-K8S的概念"><a href="#6-1-K8S的概念" class="headerlink" title="6.1 K8S的概念"></a>6.1 K8S的概念</h2><p>  Kubernetes是一个可移植的、可扩展的开源平台，用于管理容器化的工作负载和服务，可促进声明式配置和自动化</p>
<p>  Kubernetes拥有一个庞大且快速增长的生态系统。Kubernetes 的服务、支持和工具广泛可用</p>
<p><img src="/images/k8s.png"></p>
<h2 id="6-2-K8S的特点"><a href="#6-2-K8S的特点" class="headerlink" title="6.2 K8S的特点"></a>6.2 K8S的特点</h2><p>  Kubernetes具有以下几个特点：</p>
<p>   1.可移植: 支持公有云、私有云、混合云、多重云（multi-cloud）</p>
<p>   2.可扩展: 模块化、插件化、可挂载、可组合</p>
<p>   3.自动化: 自动部署、自动重启、自动复制、自动伸缩/扩展</p>
<h2 id="6-3-K8S的作用"><a href="#6-3-K8S的作用" class="headerlink" title="6.3 K8S的作用"></a>6.3 K8S的作用</h2><p>  Kubernetes的主要职责是容器编排(Container Orchestration)，即在一组服务器上启动、 监控、回收容器，在满足排程的同时，保证容器可以健康的运行</p>
<p><img src="/images/k8s%E7%9A%84%E4%BD%9C%E7%94%A8.png"></p>
<h2 id="6-4-K8S的整体架构"><a href="#6-4-K8S的整体架构" class="headerlink" title="6.4 K8S的整体架构"></a>6.4 K8S的整体架构</h2><p><img src="/images/k8s%E7%9A%84%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84.png"></p>
<h3 id="6-4-1-Master节点"><a href="#6-4-1-Master节点" class="headerlink" title="6.4.1 Master节点"></a>6.4.1 Master节点</h3><p>1.kube-apiserver</p>
<p>  API服务器是Kubernetes控制面的前端</p>
<p>  Kubernetes API服务器的主要实现是kube-apiserver</p>
<p>  kube-apiserver设计上考虑了水平伸缩，可通过部署多个实例进行伸缩。 可以运行kube-apiserver的多个实例，并在这些实例之间平衡流</p>
<p>2.etcd</p>
<p>  etcd是兼具一致性和高可用性的键值数据库，可以作为保存Kubernetes所有集群数据的后台数据库</p>
<p>3.cloud-controller-manager</p>
<p>  cloud-controller-manager仅运行特定于云平台的控制回路</p>
<p>  如果在自己的环境中运行Kubernetes，或者在本地计算机中运行学习环境， 所部署的环境中不需要云控制器管理器</p>
<p>4.kube-scheduler</p>
<p>  控制平面组件，负责监视新创建的、未指定运行节点（node）的 Pods，选择节点让 Pod 在上面运行</p>
<p>5.kube-controller-manager</p>
<p>  这些控制器包括:</p>
<p>  节点控制器（Node Controller）: 负责在节点出现故障时进行通知和响应</p>
<p>  任务控制器（Job controller）: 监测代表一次性任务的Job对象，然后创建Pods来运行这些任务直至完成</p>
<p>  端点控制器（Endpoints Controller）: 填充端点(Endpoints)对象(即加入 Service 与 Pod)</p>
<p>  服务帐户和令牌控制器（Service Account &amp; Token Controllers）: 为新的命名空间创建默认帐户和API访问令牌</p>
<h3 id="6-4-2-Node节点"><a href="#6-4-2-Node节点" class="headerlink" title="6.4.2 Node节点"></a>6.4.2 Node节点</h3><p>1.kubelet</p>
<p>  一个在集群中每个节点（node）上运行的代理，保证容器（containers）都运行在Pod中</p>
<p>2.kube-proxy</p>
<p>  kube-proxy是集群中每个节点上运行的网络代理， 实现Kubernetes服务(Service)概念的一部分</p>
<p>  kube-proxy 维护节点上的网络规则。这些网络规则允许从集群内部或外部的网络会话与Pod进行网络通信</p>
<p>  如果操作系统提供了数据包过滤层并可用的话，kube-proxy会通过它来实现网络规则。否则， kube-proxy仅转发流量本身</p>
<p>3.容器运行时（Container Runtime）</p>
<p>  Kubernetes支持多个容器运行环境: Docker、 containerd、CRI-O以及任何实现Kubernetes CRI (容器运行环境接口)</p>
<h3 id="6-4-3-插件-Addons"><a href="#6-4-3-插件-Addons" class="headerlink" title="6.4.3 插件(Addons)"></a>6.4.3 插件(Addons)</h3><p>  插件使用Kubernetes资源（DaemonSet、 Deployment等）实现集群功能。 因为这些插件提供集群级别的功能，插件中命名空间域的资源属于kube-system命名空间</p>
<p>  1.Core-dns：为整个集群提供DNS服务</p>
<p>  2.Ingress Controller：为service提供外网访问入口</p>
<p>  3.Dashboard: 提供图形化管理界面</p>
<p>  4.Flannel/ Calico ：为kubernetes提供方便的网络规划服务</p>
<h1 id="7-Kubernetes集群部署"><a href="#7-Kubernetes集群部署" class="headerlink" title="7 Kubernetes集群部署"></a>7 Kubernetes集群部署</h1><h2 id="7-1-Kubernetes的安装流程"><a href="#7-1-Kubernetes的安装流程" class="headerlink" title="7.1 Kubernetes的安装流程"></a>7.1 Kubernetes的安装流程</h2><h3 id="7-1-1-先决条件"><a href="#7-1-1-先决条件" class="headerlink" title="7.1.1 先决条件"></a>7.1.1 先决条件</h3><p>  1.最小配置：2G内存2核CPU</p>
<p>  2.集群中的所有机器的网络彼此均能相互连接(公网和内网都可以)</p>
<p>  3.节点之中不可以有重复的主机名、MAC 地址或product_uuid</p>
<p>  4.禁用交换分区</p>
<p>  5.开启机器上的某些端口</p>
<h3 id="7-1-2-安装runtime"><a href="#7-1-2-安装runtime" class="headerlink" title="7.1.2 安装runtime"></a>7.1.2 安装runtime</h3><p>  默认情况下，Kubernetes使用容器运行时接口（Container Runtime Interface，CRI） 与所选择的容器运行时交互</p>
<p>  如果不指定运行时，则kubeadm会自动尝试检测到系统上已经安装的运行时， 方法是扫描一组众所周知的Unix域套接字，docker启用shim来对接K8S</p>
<p>  运行时的域套接字：<br>  Docker unix:///var/run/cri-dockerd.sock</p>
<p>  containerd /run/containerd/containerd.sock</p>
<p>  CRI-O /var/run/crio/crio.sock</p>
<h3 id="7-1-3-安装kubeadm、kubelet和kubectl"><a href="#7-1-3-安装kubeadm、kubelet和kubectl" class="headerlink" title="7.1.3 安装kubeadm、kubelet和kubectl"></a>7.1.3 安装kubeadm、kubelet和kubectl</h3><p>  需要在每台机器上安装以下软件包：</p>
<p>  kubeadm：用来初始化集群的指令</p>
<p>  kubelet：在集群中的每个节点上用来启动Pod和容器等</p>
<p>  kubectl：用来与集群通信的命令行工具</p>
<p>  确保它们与通过kubeadm安装的控制平面的版本相匹配。 不然可能会导致一些预料之外的错误和问题。 然而，控制平面与kubelet间的相差一个次要版本不一致是支持的，但kubelet的版本不可以超过API服务器的版本。 例如，1.7.0 版本的kubelet可以完全兼容1.8.0版本的API 服务器，反之则不可以</p>
<h3 id="7-1-4-检查所需端口"><a href="#7-1-4-检查所需端口" class="headerlink" title="7.1.4 检查所需端口"></a>7.1.4 检查所需端口</h3><p>1.控制平面</p>
<table>
<thead>
<tr>
<th align="left">协议</th>
<th align="left">方向</th>
<th align="left">端口范围</th>
<th align="left">作用</th>
<th align="left">使用者</th>
</tr>
</thead>
<tbody><tr>
<td align="left">TCP</td>
<td align="left">入站</td>
<td align="left">6443</td>
<td align="left">Kubernetes API服务器</td>
<td align="left">所有组件</td>
</tr>
<tr>
<td align="left">TCP</td>
<td align="left">入站</td>
<td align="left">2379-2380</td>
<td align="left">etcd服务器客户端API</td>
<td align="left">kube-apiserver,etcd</td>
</tr>
<tr>
<td align="left">TCP</td>
<td align="left">入站</td>
<td align="left">10250</td>
<td align="left">Kubelet API</td>
<td align="left">kubelet自身、控制平面组件</td>
</tr>
<tr>
<td align="left">TCP</td>
<td align="left">入站</td>
<td align="left">10251</td>
<td align="left">kube-scheduler</td>
<td align="left">kube-scheduler自身</td>
</tr>
<tr>
<td align="left">TCP</td>
<td align="left">入站</td>
<td align="left">10252</td>
<td align="left">kube-controller-manager</td>
<td align="left">kube-controller-manager自身</td>
</tr>
</tbody></table>
<p>2.工作节点</p>
<table>
<thead>
<tr>
<th align="left">协议</th>
<th align="left">方向</th>
<th align="left">端口范围</th>
<th align="left">作用</th>
<th align="left">使用者</th>
</tr>
</thead>
<tbody><tr>
<td align="left">TCP</td>
<td align="left">入站</td>
<td align="left">10250</td>
<td align="left">Kubelet API</td>
<td align="left">kubelet自身、控制平面组件</td>
</tr>
<tr>
<td align="left">TCP</td>
<td align="left">入站</td>
<td align="left">30000-32767</td>
<td align="left">NodePort服务</td>
<td align="left">所有组件</td>
</tr>
</tbody></table>
<h3 id="7-1-5-Iptables桥接流量"><a href="#7-1-5-Iptables桥接流量" class="headerlink" title="7.1.5 Iptables桥接流量"></a>7.1.5 Iptables桥接流量</h3><p>  为了让Linux节点上的iptables能够正确地查看桥接流量，需要确保sysctl配置中将net.bridge.bridge-nf-call-iptables设置为1</p>
<p><img src="/images/iptables.png"></p>
<h3 id="7-1-6-环境准备"><a href="#7-1-6-环境准备" class="headerlink" title="7.1.6 环境准备"></a>7.1.6 环境准备</h3><p>  本K8S集群使用3台机器(ubuntu)进行部署，各节点信息如下表：</p>
<p>  注明：使用的容器为Docker</p>
<table>
<thead>
<tr>
<th align="left">主机名</th>
<th align="left">角色</th>
<th align="left">IP</th>
<th align="left">VMware网络类型</th>
<th align="left">用户名</th>
<th align="left">密码</th>
<th align="left">互联网连接</th>
</tr>
</thead>
<tbody><tr>
<td align="left">k8s-master</td>
<td align="left">控制平面</td>
<td align="left">192.168.8.3</td>
<td align="left">NAT</td>
<td align="left">vagrant root</td>
<td align="left">vagrant vargrant</td>
<td align="left">是</td>
</tr>
<tr>
<td align="left">k8s-worker1</td>
<td align="left">数据平面</td>
<td align="left">192.168.8.4</td>
<td align="left">NAT</td>
<td align="left">vagrant root</td>
<td align="left">vagrant vargrant</td>
<td align="left">是</td>
</tr>
<tr>
<td align="left">k8s-worker2</td>
<td align="left">数据平面</td>
<td align="left">192.168.8.5</td>
<td align="left">NAT</td>
<td align="left">vagrant root</td>
<td align="left">vagrant vargrant</td>
<td align="left">是</td>
</tr>
</tbody></table>
<p>准备DNS解析：</p>
<p>  这一步需要在所有机器上完成</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 这一步需要在所有机器上完成</span>
<span class="token function">cat</span> <span class="token operator">&gt;&gt;</span> /etc/hosts <span class="token operator">&lt;&lt;</span><span class="token string">EOF
192.168.8.3 k8s-master
192.168.8.4 k8s-worker1
192.168.8.5 k8s-worker2
192.168.30.133 registry.xiaohui.cn
EOF</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="7-2-Docker-CE-部署"><a href="#7-2-Docker-CE-部署" class="headerlink" title="7.2 Docker CE 部署"></a>7.2 Docker CE 部署</h2><h3 id="7-2-1-添加Docker仓库"><a href="#7-2-1-添加Docker仓库" class="headerlink" title="7.2.1 添加Docker仓库"></a>7.2.1 添加Docker仓库</h3><p>  这一步要在所有机器上完成：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 安装依赖</span>
<span class="token function">sudo</span> <span class="token function">apt-get</span> update
<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> <span class="token parameter variable">-y</span> ca-certificates <span class="token function">curl</span> gnupg lsb-release

<span class="token comment"># 添加公钥到系统</span>
<span class="token function">sudo</span> <span class="token function">mkdir</span> <span class="token parameter variable">-p</span> /etc/apt/keyrings
<span class="token function">curl</span> <span class="token parameter variable">-fsSL</span> https://mirrors.nju.edu.cn/docker-ce/linux/ubuntu/gpg <span class="token operator">|</span> <span class="token function">sudo</span> gpg <span class="token parameter variable">--dearmor</span> <span class="token parameter variable">-o</span> /etc/apt/keyrings/docker.gpg

<span class="token comment"># 添加仓库到系统</span>
<span class="token builtin class-name">echo</span> <span class="token string">"deb [arch=<span class="token variable"><span class="token variable">$(</span>dpkg --print-architecture<span class="token variable">)</span></span> signed-by=/etc/apt/keyrings/docker.gpg] https://mirrors.nju.edu.cn/docker-ce/linux/ubuntu <span class="token variable"><span class="token variable">$(</span>lsb_release <span class="token parameter variable">-cs</span><span class="token variable">)</span></span> stable"</span> <span class="token operator">|</span> <span class="token function">sudo</span> <span class="token function">tee</span> /etc/apt/sources.list.d/docker.list <span class="token operator">&gt;</span> /dev/null

<span class="token comment"># 判断仓库是否已做好</span>
<span class="token function">sudo</span> <span class="token function">apt-get</span> update<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="7-2-2-安装Docker-CE"><a href="#7-2-2-安装Docker-CE" class="headerlink" title="7.2.2 安装Docker CE"></a>7.2.2 安装Docker CE</h3><p>  这一步要在所有机器上完成：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> <span class="token parameter variable">-y</span> docker-ce docker-ce-cli containerd.io docker-compose-plugin
<span class="token comment"># 部署完Docker CE之后，还需要cri-docker shim才可以和Kubernetes集成</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<h3 id="7-2-3-CRI-Docker部署"><a href="#7-2-3-CRI-Docker部署" class="headerlink" title="7.2.3 CRI-Docker部署"></a>7.2.3 CRI-Docker部署</h3><p>  这一步要在所有机器上完成：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 下载cri-docker</span>
<span class="token function">wget</span> http://hub.gitmirror.com/https://github.com/Mirantis/cri-dockerd/releases/download/v0.3.17/cri-dockerd_0.3.17.3-0.ubuntu-jammy_amd64.deb

<span class="token comment"># 安装cri-docker</span>
dpkg <span class="token parameter variable">-i</span> cri-dockerd_0.3.17.3-0.ubuntu-jammy_amd64.deb<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="7-2-4-Docker镜像加速器"><a href="#7-2-4-Docker镜像加速器" class="headerlink" title="7.2.4 Docker镜像加速器"></a>7.2.4 Docker镜像加速器</h3><p>  这一步要在所有机器上完成：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">vim</span> /etc/docker/daemon.json
<span class="token punctuation">{</span>
  <span class="token string">"registry-mirrors"</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span>
        <span class="token string">"https://docker.mirrors.ustc.edu.cn"</span>,
        <span class="token string">"https://mirror.baidubce.com"</span>,
        <span class="token string">"https://docker.m.daocloud.io"</span>,
        <span class="token string">"https://mirror.ccs.tencentyun.com"</span>,
        <span class="token string">"https://docker.nju.edu.cn"</span>,
        <span class="token string">"https://docker.mirrors.sjtug.sjtu.edu.cn"</span>,
        <span class="token string">"https://mirror.gcr.io"</span>,
        <span class="token string">"https://docker.registry.cyou"</span>,
        <span class="token string">"https://docker-cf.registry.cyou"</span>,
        <span class="token string">"https://dockercf.jsdelivr.fyi"</span>,
        <span class="token string">"https://docker.jsdelivr.fyi"</span>,
        <span class="token string">"https://dockertest.jsdelivr.fyi"</span>,
        <span class="token string">"https://mirror.aliyuncs.com"</span>,
        <span class="token string">"https://dockerproxy.com"</span>
  <span class="token punctuation">]</span>,
  <span class="token string">"exec-opts"</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token string">"native.cgroupdriver=systemd"</span><span class="token punctuation">]</span>
<span class="token punctuation">}</span>
systemctl daemon-reload
systemctl restart <span class="token function">docker</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="7-2-5-将镜像指引到国内"><a href="#7-2-5-将镜像指引到国内" class="headerlink" title="7.2.5 将镜像指引到国内"></a>7.2.5 将镜像指引到国内</h3><p>  这一步要在所有机器上完成：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">cp</span> /lib/systemd/system/cri-docker.service /etc/systemd/system/cri-docker.service

<span class="token function">sed</span> <span class="token parameter variable">-i</span> <span class="token string">'s/ExecStart=.*/ExecStart=\/usr\/bin\/cri-dockerd --container-runtime-endpoint fd:\/\/ --network-plugin=cni --pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com\/google_containers\/pause:3.10/'</span> /etc/systemd/system/cri-docker.service

systemctl daemon-reload
systemctl restart cri-docker.service
systemctl <span class="token builtin class-name">enable</span> cri-docker.service<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="7-3-Kubernetes部署"><a href="#7-3-Kubernetes部署" class="headerlink" title="7.3 Kubernetes部署"></a>7.3 Kubernetes部署</h2><h3 id="7-3-1-关闭swap分区"><a href="#7-3-1-关闭swap分区" class="headerlink" title="7.3.1 关闭swap分区"></a>7.3.1 关闭swap分区</h3><p>  这一步要在所有机器上完成：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 实时关闭</span>
swapoff <span class="token parameter variable">-a</span>
<span class="token comment"># 永久关闭</span>
<span class="token function">sed</span> <span class="token parameter variable">-i</span> <span class="token string">'s/.*swap.*/#&amp;/'</span> /etc/fstab<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="7-3-2-允许iptables检查桥接流量"><a href="#7-3-2-允许iptables检查桥接流量" class="headerlink" title="7.3.2 允许iptables检查桥接流量"></a>7.3.2 允许iptables检查桥接流量</h3><p>  这一步要在所有机器上完成：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">cat</span> <span class="token operator">&lt;&lt;</span><span class="token string">EOF<span class="token bash punctuation"> <span class="token operator">|</span> <span class="token function">sudo</span> <span class="token function">tee</span> /etc/modules-load.d/k8s.conf</span>
br_netfilter
EOF</span>
modprobe br_netfilter
<span class="token function">cat</span> <span class="token operator">&lt;&lt;</span><span class="token string">EOF<span class="token bash punctuation"> <span class="token operator">|</span> <span class="token function">sudo</span> <span class="token function">tee</span> /etc/sysctl.d/k8s.conf</span>
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
EOF</span>

<span class="token function">sudo</span> <span class="token function">sysctl</span> <span class="token parameter variable">--system</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="7-3-3-安装kubeadm"><a href="#7-3-3-安装kubeadm" class="headerlink" title="7.3.3 安装kubeadm"></a>7.3.3 安装kubeadm</h3><p>  这一步要在所有机器上完成：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 安装依赖</span>
<span class="token function">apt-get</span> update <span class="token operator">&amp;&amp;</span> <span class="token function">apt-get</span> <span class="token function">install</span> <span class="token parameter variable">-y</span> apt-transport-https <span class="token function">curl</span>

<span class="token comment"># 安装K8S软件包仓库-阿里云</span>
<span class="token function">cat</span> <span class="token operator">&gt;</span> /etc/apt/sources.list.d/k8s.list <span class="token operator">&lt;&lt;</span><span class="token string">EOF
deb https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.32/deb /
EOF</span>

<span class="token comment"># 安装软件包仓库的公钥</span>
<span class="token function">curl</span> <span class="token parameter variable">-fsSL</span> https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.32/deb/Release.key <span class="token operator">|</span> apt-key <span class="token function">add</span> -

<span class="token comment"># 更新软件包的仓库索引</span>
<span class="token function">apt-get</span> update

<span class="token comment"># 开始安装</span>
<span class="token function">apt-get</span> <span class="token function">install</span> <span class="token parameter variable">-y</span> kubelet kubeadm kubectl

<span class="token comment"># 操作系统所有软件包升级时将忽略kubelet、kubeadm、kubectl</span>
apt-mark hold kubelet kubeadm kubectl<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="7-3-4-添加命令自动补齐"><a href="#7-3-4-添加命令自动补齐" class="headerlink" title="7.3.4 添加命令自动补齐"></a>7.3.4 添加命令自动补齐</h3><p>  这一步要在所有机器上完成：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">kubectl completion <span class="token function">bash</span> <span class="token operator">&gt;</span> /etc/bash_completion.d/kubectl
kubeadm completion <span class="token function">bash</span> <span class="token operator">&gt;</span> /etc/bash_completion.d/kubeadm
<span class="token builtin class-name">source</span> /etc/bash_completion.d/kubectl
<span class="token builtin class-name">source</span> /etc/bash_completion.d/kubeadm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="7-3-5-集成CRI-Docker"><a href="#7-3-5-集成CRI-Docker" class="headerlink" title="7.3.5 集成CRI-Docker"></a>7.3.5 集成CRI-Docker</h3><p>  这一步要在所有机器上完成：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">crictl config <span class="token parameter variable">--set</span> runtime-endpoint unix:///run/cri-dockerd.sock
crictl images<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<h3 id="7-3-6-集群部署"><a href="#7-3-6-集群部署" class="headerlink" title="7.3.6 集群部署"></a>7.3.6 集群部署</h3><p>  kubeadm.yaml中name字段必须在网络中可被解析，也可以将解析记录添加到集群中所有机器的/etc/hosts中</p>
<p>  初始化集群部署的操作只能在k8s-master上执行</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 初始化配置</span>
kubeadm config print init-defaults <span class="token operator">&gt;</span> kubeadm.yaml
<span class="token function">sed</span> <span class="token parameter variable">-i</span> <span class="token string">'s/.*advert.*/  advertiseAddress: 192.168.8.3/g'</span> kubeadm.yaml
<span class="token function">sed</span> <span class="token parameter variable">-i</span> <span class="token string">'s/.*name.*/  name: k8s-master/g'</span> kubeadm.yaml
<span class="token function">sed</span> <span class="token parameter variable">-i</span> <span class="token string">'s|imageRepo.*|imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers|g'</span> kubeadm.yaml
<span class="token function">sed</span> <span class="token parameter variable">-i</span> <span class="token string">"/^<span class="token entity" title="\\">\\</span>s*networking:/a<span class="token entity" title="\\">\\</span>  podSubnet: 172.16.0.0/16"</span> kubeadm.yaml

<span class="token comment"># 注意下面的替换，只有在集成的是CRI-Docker时才需要执行，Containerd不需要</span>
<span class="token function">sed</span> <span class="token parameter variable">-i</span> <span class="token string">'s/  criSocket.*/  criSocket: unix:\/\/\/run\/cri-dockerd.sock/'</span> kubeadm.yaml

<span class="token comment"># 模块加载</span>
modprobe br_netfilter
 
<span class="token comment"># 集群初始化</span>
kubeadm init <span class="token parameter variable">--config</span> kubeadm.yaml
Your Kubernetes control-plane has initialized successfully<span class="token operator">!</span>
<span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span>
kubeadm <span class="token function">join</span> <span class="token number">192.168</span>.8.3:6443 <span class="token parameter variable">--token</span> abcdef.0123456789abcdef <span class="token punctuation">\</span>
        --discovery-token-ca-cert-hash sha256:c2546a856290440a8ccaf9223c14fd1c2098ac74f4a584acf5f3c5a373005207
        
        
<span class="token comment"># 授权管理权限</span>
<span class="token function">mkdir</span> <span class="token parameter variable">-p</span> <span class="token environment constant">$HOME</span>/.kube
<span class="token function">sudo</span> <span class="token function">cp</span> <span class="token parameter variable">-i</span> /etc/kubernetes/admin.conf <span class="token environment constant">$HOME</span>/.kube/config
<span class="token function">sudo</span> <span class="token function">chown</span> <span class="token variable"><span class="token variable">$(</span><span class="token function">id</span> <span class="token parameter variable">-u</span><span class="token variable">)</span></span><span class="token builtin class-name">:</span><span class="token variable"><span class="token variable">$(</span><span class="token function">id</span> <span class="token parameter variable">-g</span><span class="token variable">)</span></span> <span class="token environment constant">$HOME</span>/.kube/config

<span class="token comment"># 查看集群状态</span>
root@k8s-master:~<span class="token comment"># kubectl get nodes</span>
NAME         STATUS     ROLES           AGE   VERSION
k8s-master   NotReady   control-plane   62m   v1.32.5<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="7-3-7-部署Calico网络插件"><a href="#7-3-7-部署Calico网络插件" class="headerlink" title="7.3.7 部署Calico网络插件"></a>7.3.7 部署Calico网络插件</h3><p>  Calico网络插件部署的操作在所有节点上执行</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 使用operator安装calico组件-可能会失败</span>
<span class="token comment"># 以下为github的地址，可能会失败</span>
root@k8s-master:~<span class="token comment"># kubectl create -f https://raw.gitmirror.com/projectcalico/calico/refs/tags/v3.29.3/manifests/tigera-operator.yaml</span>

<span class="token comment"># 解决办法：</span>
<span class="token comment"># 1.获取Calico images到本地</span>
    见Calico.txt
    
<span class="token comment"># 2.发布本地的yaml到集群-master</span>
kubectl create <span class="token parameter variable">-f</span> https://www.linuxcenter.cn/files/cka/cka-yaml/tigera-operator-calico-3.29.3.yaml

root@k8s-master:~<span class="token comment"># kubectl get pod -A</span>
NAMESPACE         NAME                                 READY   STATUS    RESTARTS   AGE
kube-system       coredns-76fccbbb6b-l7jq9             <span class="token number">0</span>/1     Pending   <span class="token number">0</span>          163m
kube-system       coredns-76fccbbb6b-nd68g             <span class="token number">0</span>/1     Pending   <span class="token number">0</span>          163m
kube-system       etcd-k8s-master                      <span class="token number">1</span>/1     Running   <span class="token number">0</span>          163m
kube-system       kube-apiserver-k8s-master            <span class="token number">1</span>/1     Running   <span class="token number">0</span>          163m
kube-system       kube-controller-manager-k8s-master   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          163m
kube-system       kube-proxy-mcwv7                     <span class="token number">1</span>/1     Running   <span class="token number">0</span>          163m
kube-system       kube-scheduler-k8s-master            <span class="token number">1</span>/1     Running   <span class="token number">0</span>          163m
tigera-operator   tigera-operator-75b4cd596c-9hjml     <span class="token number">1</span>/1     Running   <span class="token number">0</span>          7m5s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="7-3-8-设置calico在集群的网段"><a href="#7-3-8-设置calico在集群的网段" class="headerlink" title="7.3.8 设置calico在集群的网段"></a>7.3.8 设置calico在集群的网段</h3><p>  这一步在k8s-master上执行</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 使用下面的自定义资源设置一下calico在集群中的网段</span>
<span class="token comment"># 以下为github的地址，可能会失败</span>
root@k8s-master:~<span class="token comment"># wget https://raw.gitmirror.com/projectcalico/calico/refs/tags/v3.29.3/manifests/custom-resources.yaml</span>

<span class="token comment"># 3.使用下面的地址执行</span>
root@k8s-master:~<span class="token comment"># wget https://www.linuxcenter.cn/files/cka/cka-yaml/custom-resources-calico-3.29.3.yaml</span>
root@k8s-master:~<span class="token comment"># mv custom-resources-calico-3.29.3.yaml custom-resources.yaml</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="7-3-9-确认资源的地址"><a href="#7-3-9-确认资源的地址" class="headerlink" title="7.3.9 确认资源的地址"></a>7.3.9 确认资源的地址</h3><p>  这一步在k8s-master上执行</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># vim custom-resources.yaml</span>
<span class="token comment"># This section includes base Calico installation configuration.</span>
<span class="token comment"># For more information, see: https://docs.tigera.io/calico/latest/reference/installation/api#operator.tigera.io/v1.Installation</span>
apiVersion: operator.tigera.io/v1
kind: Installation
metadata:
  name: default
spec:
  <span class="token comment"># Configures Calico networking.</span>
  calicoNetwork:
    ipPools:
    - name: default-ipv4-ippool
      blockSize: <span class="token number">26</span>
      cidr: <span class="token number">172.16</span>.0.0/16      <span class="token comment">#这里换成上面规定好的172.16.0.0/16</span>
      encapsulation: VXLANCrossSubnet
      natOutgoing: Enabled
      nodeSelector: all<span class="token punctuation">(</span><span class="token punctuation">)</span>

---

<span class="token comment"># This section configures the Calico API server.</span>
<span class="token comment"># For more information, see: https://docs.tigera.io/calico/latest/reference/installation/api#operator.tigera.io/v1.APIServer</span>
apiVersion: operator.tigera.io/v1
kind: APIServer
metadata:
  name: default
spec: <span class="token punctuation">{</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="7-3-10-自定义资源发布到集群"><a href="#7-3-10-自定义资源发布到集群" class="headerlink" title="7.3.10 自定义资源发布到集群"></a>7.3.10 自定义资源发布到集群</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># kubectl apply -f custom-resources.yaml</span>
root@k8s-master:~<span class="token comment"># kubectl get nodes</span>
NAME         STATUS   ROLES           AGE    VERSION
k8s-master   Ready    control-plane   173m   v1.32.5

root@k8s-master:~<span class="token comment"># kubectl get pod -A</span>
NAMESPACE          NAME                                       READY   STATUS    RESTARTS   AGE
calico-apiserver   calico-apiserver-6499c768c8-wvrnt          <span class="token number">1</span>/1     Running   <span class="token number">0</span>          60s
calico-apiserver   calico-apiserver-6499c768c8-zmvh6          <span class="token number">1</span>/1     Running   <span class="token number">0</span>          60s
calico-system      calico-kube-controllers-85fb6564b7-gtsfr   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          60s
calico-system      calico-node-4mqfj                          <span class="token number">1</span>/1     Running   <span class="token number">0</span>          60s
calico-system      calico-typha-65d47d7478-ttzx6              <span class="token number">1</span>/1     Running   <span class="token number">0</span>          60s
calico-system      csi-node-driver-7j8pf                      <span class="token number">2</span>/2     Running   <span class="token number">0</span>          60s
kube-system        coredns-76fccbbb6b-l7jq9                   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          172m
kube-system        coredns-76fccbbb6b-nd68g                   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          172m
kube-system        etcd-k8s-master                            <span class="token number">1</span>/1     Running   <span class="token number">0</span>          172m
kube-system        kube-apiserver-k8s-master                  <span class="token number">1</span>/1     Running   <span class="token number">0</span>          172m
kube-system        kube-controller-manager-k8s-master         <span class="token number">1</span>/1     Running   <span class="token number">0</span>          172m
kube-system        kube-proxy-mcwv7                           <span class="token number">1</span>/1     Running   <span class="token number">0</span>          172m
kube-system        kube-scheduler-k8s-master                  <span class="token number">1</span>/1     Running   <span class="token number">0</span>          172m
tigera-operator    tigera-operator-75b4cd596c-9hjml           <span class="token number">1</span>/1     Running   <span class="token number">0</span>          16m<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="7-3-11-加入Worker节点"><a href="#7-3-11-加入Worker节点" class="headerlink" title="7.3.11 加入Worker节点"></a>7.3.11 加入Worker节点</h3><p>  加入节点操作需在所有的worker节点完成，这里要注意，Worker节点需要完成以下先决条件才能执行kubeadm join</p>
<p>   1.Docker、CRI-Docker 部署</p>
<p>   2.Swap分区关闭</p>
<p>   3.iptables桥接流量的允许</p>
<p>   4.安装kubeadm等软件</p>
<p>   5.集成CRI-Docker</p>
<p>   6.所有节点的/etc/hosts中互相添加对方的解析</p>
<p>  如果时间长忘记了join参数，可以在master节点上用以下方法重新生成</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># kubeadm token create --print-join-command</span>
kubeadm <span class="token function">join</span> <span class="token number">192.168</span>.8.3:6443 <span class="token parameter variable">--token</span> 5mffg7.lq7ujh6vot0jzrci --discovery-token-ca-cert-hash sha256:c2546a856290440a8ccaf9223c14fd1c2098ac74f4a584acf5f3c5a373005207<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>  如果有多个CRI对象，在worker节点上执行以下命令加入节点时，指定CRI对象，案例如下：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-worker1:~<span class="token comment"># kubeadm token create --print-join-command</span>
kubeadm <span class="token function">join</span> <span class="token number">192.168</span>.8.3:6443 <span class="token parameter variable">--token</span> 5mffg7.lq7ujh6vot0jzrci --discovery-token-ca-cert-hash sha256:c2546a856290440a8ccaf9223c14fd1c2098ac74f4a584acf5f3c5a373005207
failed to load admin kubeconfig: <span class="token function">open</span> /root/.kube/config: no such <span class="token function">file</span> or directory
To see the stack trace of this error execute with <span class="token parameter variable">--v</span><span class="token operator">=</span><span class="token number">5</span> or higher
found multiple CRI endpoints on the host. Please define <span class="token function">which</span> one <span class="token keyword">do</span> you wish to use by setting the <span class="token string">'criSocket'</span> field <span class="token keyword">in</span> the kubeadm configuration file: unix:///var/run/containerd/containerd.sock, unix:///var/run/cri-dockerd.sock
To see the stack trace of this error execute with <span class="token parameter variable">--v</span><span class="token operator">=</span><span class="token number">5</span> or higher

<span class="token comment"># 加入两个节点</span>
<span class="token number">1</span>.节点worker1
root@k8s-worker1:~<span class="token comment"># kubeadm join 192.168.8.3:6443 --token 5mffg7.lq7ujh6vot0jzrci --discovery-token-ca-cert-hash sha256:c2546a856290440a8ccaf9223c14fd1c2098ac74f4a584acf5f3c5a373005207 --cri-socket=unix:///var/run/cri-dockerd.sock</span>

<span class="token number">2</span>.节点worker2
root@k8s-worker2:~<span class="token comment">#  kubeadm join 192.168.8.3:6443 --token 5mffg7.lq7ujh6vot0jzrci --discovery-token-ca-cert-hash sha256:c2546a856290440a8ccaf9223c14fd1c2098ac74f4a584acf5f3c5a373005207 --cri-socket=unix:///var/run/cri-dockerd.sock</span>

<span class="token number">3</span>.查看各节点状态
root@k8s-master:~<span class="token comment"># kubectl get nodes</span>
NAME          STATUS   ROLES           AGE     VERSION
k8s-master    Ready    control-plane   3h28m   v1.32.5
k8s-worker1   Ready    <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>          2m2s    v1.32.5
k8s-worker2   Ready    <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>          2m2s    v1.32.5

<span class="token number">4</span>.查看pod信息
root@k8s-master:~<span class="token comment"># kubectl get pod -A</span>
NAMESPACE          NAME                                       READY   STATUS    RESTARTS   AGE
calico-apiserver   calico-apiserver-6499c768c8-wvrnt          <span class="token number">1</span>/1     Running   <span class="token number">0</span>          37m
calico-apiserver   calico-apiserver-6499c768c8-zmvh6          <span class="token number">1</span>/1     Running   <span class="token number">0</span>          37m
calico-system      calico-kube-controllers-85fb6564b7-gtsfr   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          37m
calico-system      calico-node-4mqfj                          <span class="token number">1</span>/1     Running   <span class="token number">0</span>          37m
calico-system      calico-node-rkd6k                          <span class="token number">1</span>/1     Running   <span class="token number">0</span>          3m37s
calico-system      calico-node-vxflh                          <span class="token number">1</span>/1     Running   <span class="token number">0</span>          3m37s
calico-system      calico-typha-65d47d7478-cmrtt              <span class="token number">1</span>/1     Running   <span class="token number">0</span>          3m28s
calico-system      calico-typha-65d47d7478-ttzx6              <span class="token number">1</span>/1     Running   <span class="token number">0</span>          37m
calico-system      csi-node-driver-7j8pf                      <span class="token number">2</span>/2     Running   <span class="token number">0</span>          37m
calico-system      csi-node-driver-nhg4c                      <span class="token number">2</span>/2     Running   <span class="token number">0</span>          3m37s
calico-system      csi-node-driver-z6p7p                      <span class="token number">2</span>/2     Running   <span class="token number">0</span>          3m37s
kube-system        coredns-76fccbbb6b-l7jq9                   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          3h29m
kube-system        coredns-76fccbbb6b-nd68g                   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          3h29m
kube-system        etcd-k8s-master                            <span class="token number">1</span>/1     Running   <span class="token number">0</span>          3h29m
kube-system        kube-apiserver-k8s-master                  <span class="token number">1</span>/1     Running   <span class="token number">0</span>          3h29m
kube-system        kube-controller-manager-k8s-master         <span class="token number">1</span>/1     Running   <span class="token number">0</span>          3h29m
kube-system        kube-proxy-8n6x5                           <span class="token number">1</span>/1     Running   <span class="token number">0</span>          3m37s
kube-system        kube-proxy-mcwv7                           <span class="token number">1</span>/1     Running   <span class="token number">0</span>          3h29m
kube-system        kube-proxy-xk4h4                           <span class="token number">1</span>/1     Running   <span class="token number">0</span>          3m37s
kube-system        kube-scheduler-k8s-master                  <span class="token number">1</span>/1     Running   <span class="token number">0</span>          3h29m
tigera-operator    tigera-operator-75b4cd596c-9hjml           <span class="token number">1</span>/1     Running   <span class="token number">0</span>          52m<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>  注意上描述命令最后的–cri-socket参数，在系统中部署了docker和cri-docker时，必须明确指明此参数，并将此参数指向我们的cri-docker，不然命令会报告有两个重复的CRI的错误</p>
<p>  在k8s-master机器上执行以下内容给节点打上角色标签，k8s-worker1和k8s-worker2分别打上了worker1和worker2的标签</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># kubectl label nodes k8s-worker1 node-role.kubernetes.io/worker1=</span>
node/k8s-worker1 labeled

root@k8s-master:~<span class="token comment"># kubectl label nodes k8s-worker2 node-role.kubernetes.io/worker2=</span>
node/k8s-worker2 labeled

root@k8s-master:~<span class="token comment"># kubectl get nodes</span>
NAME          STATUS   ROLES           AGE     VERSION
k8s-master    Ready    control-plane   3h33m   v1.32.5
k8s-worker1   Ready    worker1         7m37s   v1.32.5
k8s-worker2   Ready    worker2         7m37s   v1.32.5<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="7-3-12-重置集群"><a href="#7-3-12-重置集群" class="headerlink" title="7.3.12 重置集群"></a>7.3.12 重置集群</h3><p>  如果在安装好集群的情况下，想重复练习初始化集群，或者包括初始化集群报错在内的任何原因，想重新初始化集群时，可以用下面的方法重置集群，重置后，集群就会被删除，可以用于重新部署，一般来说，这个命令仅用于k8s-master这个节点</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># kubeadm reset --cri-socket=unix:///var/run/cri-dockerd.sock</span>

<span class="token comment"># 根据提示，手工完成文件和规则的清理   清理后就可以重新部署集群了</span>
root@k8s-master:~<span class="token comment"># rm -rf /etc/cni/net.d</span>
root@k8s-master:~<span class="token comment"># iptables -F</span>
root@k8s-master:~<span class="token comment"># rm -rf $HOME/.kube/config</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="7-3-13-标签和注解"><a href="#7-3-13-标签和注解" class="headerlink" title="7.3.13 标签和注解"></a>7.3.13 标签和注解</h3><p>  标签(Labels)和注解(Annotations)是附加到Kubernetes 对象(比如Pods)上的键值对</p>
<p>  标签旨在用于指定对用户有意义的标识属性，但不直接对核心系统有语义含义。可以用来选择对象和查找满足某些条件的对象集合</p>
<p>  注解不用于标识和选择对象。有效的注解键分为两部分： 可选的前缀和名称，以斜杠（/）分隔。 名称段是必需项，并且必须在63个字符以内</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># kubectl get node --show-labels</span>
NAME          STATUS   ROLES           AGE     VERSION   LABELS
k8s-master    Ready    control-plane   4h11m   v1.32.5   beta.kubernetes.io/arch<span class="token operator">=</span>amd64,beta.kubernetes.io/os<span class="token operator">=</span>linux,kubernetes.io/arch<span class="token operator">=</span>amd64,kubernetes.io/hostname<span class="token operator">=</span>k8s-master,kubernetes.io/os<span class="token operator">=</span>linux,node-role.kubernetes.io/control-plane<span class="token operator">=</span>,node.kubernetes.io/exclude-from-external-load-balancers<span class="token operator">=</span>
k8s-worker1   Ready    worker1         45m     v1.32.5   beta.kubernetes.io/arch<span class="token operator">=</span>amd64,beta.kubernetes.io/os<span class="token operator">=</span>linux,kubernetes.io/arch<span class="token operator">=</span>amd64,kubernetes.io/hostname<span class="token operator">=</span>k8s-worker1,kubernetes.io/os<span class="token operator">=</span>linux,node-role.kubernetes.io/worker1<span class="token operator">=</span>
k8s-worker2   Ready    worker2         45m     v1.32.5   beta.kubernetes.io/arch<span class="token operator">=</span>amd64,beta.kubernetes.io/os<span class="token operator">=</span>linux,kubernetes.io/arch<span class="token operator">=</span>amd64,kubernetes.io/hostname<span class="token operator">=</span>k8s-worker2,kubernetes.io/os<span class="token operator">=</span>linux,node-role.kubernetes.io/worker2<span class="token operator">=</span>

root@k8s-master:~<span class="token comment"># kubectl get nodes</span>
NAME          STATUS   ROLES           AGE     VERSION
k8s-master    Ready    control-plane   4h11m   v1.32.5
k8s-worker1   Ready    worker1         45m     v1.32.5
k8s-worker2   Ready    worker2         45m     v1.32.5<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h1 id="8-Kubernetes的语法"><a href="#8-Kubernetes的语法" class="headerlink" title="8 Kubernetes的语法"></a>8 Kubernetes的语法</h1><p>  kubectl [command] [TYPE] [NAME] [flags]<br>  command：指定要对一个或多个资源执行的操作，例如create、get、describe、delete<br>  TYPE：指定资源类型，资源类型不区分大小写，可以指定单数、复数或缩写形式<br>  NAME：指定资源的名称，名称区分大小写<br>  fags：指定可选的参数。例如，可以使用-s或-server参数指定Kubernetes API服务器的地址和端口</p>
<p><img src="/images/k8s%E8%AF%AD%E6%B3%95%E7%A4%BA%E4%BE%8B.png"></p>
<h2 id="8-1-Yaml语法"><a href="#8-1-Yaml语法" class="headerlink" title="8.1 Yaml语法"></a>8.1 Yaml语法</h2><p><img src="/images/yaml%E8%AF%AD%E6%B3%95.png"></p>
<p>  注意每个层级之间的点（.），在YAML文件中，每个层级之间一般用两个空格来表</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># kubectl explain Pod.metadata</span>
KIND:       Pod
VERSION:    v1

FIELD: metadata <span class="token operator">&lt;</span>ObjectMeta<span class="token operator">&gt;</span>
<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="8-1-1-生成YAML文件框架"><a href="#8-1-1-生成YAML文件框架" class="headerlink" title="8.1.1 生成YAML文件框架"></a>8.1.1 生成YAML文件框架</h3><p>  通过在创建资源时加上—dry-run=client –o yaml来生成YAML文件框架，可以用重定向到文件的方式生成文件，只需要稍作修改即可</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># kubectl create deployment --image httpd deployname --dry-run=client -o yaml</span>
apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    app: deployname
  name: deployname
spec:
  replicas: <span class="token number">1</span>
  selector:
    matchLabels:
      app: deployname
  strategy: <span class="token punctuation">{</span><span class="token punctuation">}</span>
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: deployname
    spec:
      containers:
      - image: httpd
        name: httpd
        resources: <span class="token punctuation">{</span><span class="token punctuation">}</span>
status: <span class="token punctuation">{</span><span class="token punctuation">}</span>

<span class="token comment"># 重定向到文件</span>
root@k8s-master:~<span class="token comment"># kubectl create deployment --image httpd deployname --dry-run=client -o yaml &gt; k8s.yml</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="8-1-2-apiVersion"><a href="#8-1-2-apiVersion" class="headerlink" title="8.1.2 apiVersion"></a>8.1.2 apiVersion</h3><p>Alpha:</p>
<p>  1.版本名称包含了alpha</p>
<p>  2.可能是有缺陷的。启用该功能可能会带来问题，默认是关闭的</p>
<p>  3.支持的功能可能在没有通知的情况下随时删除</p>
<p>  4.API的更改可能会带来兼容性问题，但是在后续的软件发布中不会有任何通知</p>
<p>  5.由于bugs风险的增加和缺乏长期的支持，推荐在短暂的集群测试中使用。</p>
<p>Beta:</p>
<p>  1.版本名称包含了beta</p>
<p>  2.代码已经测试过。启用该功能被 认为是安全的，功能默认已启用</p>
<p>  3.所有已支持的功能不会被删除，细节可能会发生变化</p>
<p>  4.对象的模式和/或语义可能会在后续的beta测试版或稳定版中以不兼容的方式进行更改。</p>
<p>  5.建议仅用于非业务关键型用途，因为后续版本中可能存在不兼容的更改。 如果有多个可以独立升级的集群，则可以放宽此限制</p>
<p>Stable：</p>
<p>  1.版本名称是 vX，其中X是整数</p>
<p>  2.功能的稳定版本将出现在许多后续版本的发行软件中</p>
<p>  3.有时候也会被称为GA或者毕业等词汇</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># kubectl api-resources</span>
NAME                 SHORTNAMES    APIVERSION                   NAMESPACED      KIND
bindings                           v1                           <span class="token boolean">true</span>            Binding
componentstatuses    cs            v1                           <span class="token boolean">false</span>           ComponentStatus
configmaps           cm            v1                           <span class="token boolean">true</span>            ConfigMap
endpoints            ep            v1                           <span class="token boolean">true</span>            Endpoints
events               ev            v1                           <span class="token boolean">true</span>            Event
limitranges          limits        v1                           <span class="token boolean">true</span>            LimitRange
namespaces           ns            v1                           <span class="token boolean">false</span>           Namespace
nodes                no            v1                           <span class="token boolean">false</span>           Node
<span class="token punctuation">..</span>.

<span class="token comment"># 可以使用单数、复数、缩写</span>
root@k8s-master:~<span class="token comment"># kubectl get configmaps</span>
NAME               DATA   AGE
kube-root-ca.crt   <span class="token number">1</span>      5h17m
root@k8s-master:~<span class="token comment"># kubectl get cm</span>
NAME               DATA   AGE
kube-root-ca.crt   <span class="token number">1</span>      5h17m
root@k8s-master:~<span class="token comment"># kubectl get configmap</span>
NAME               DATA   AGE
kube-root-ca.crt   <span class="token number">1</span>      5h17m<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="8-2-Namespace"><a href="#8-2-Namespace" class="headerlink" title="8.2 Namespace"></a>8.2 Namespace</h2><p>  Kubernetes支持多个虚拟集群，它们底层依赖于同一个物理集群。 这些虚拟集群被称为命名空间，它适用于存在很多跨多个团队或项目的用户的场景，命名空间为名称提供了一个范围</p>
<p>  资源的名称需要在名字空间内是唯一的，但不能跨名字空间</p>
<p>  名字空间不能相互嵌套，每个Kubernetes资源只能在一个名字空间中</p>
<p>  命名空间是在多个用户之间通过资源配额划分集群资源的一种方法</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># kubectl get namespace</span>
NAME               STATUS   AGE
calico-apiserver   Active   3h18m
calico-system      Active   3h18m
default            Active   6h10m
kube-node-lease    Active   6h10m
kube-public        Active   6h10m
kube-system        Active   6h10m
tigera-operator    Active   3h33m

root@k8s-master:~<span class="token comment"># kubectl get pod</span>
No resources found <span class="token keyword">in</span> default namespace.

root@k8s-master:~<span class="token comment"># kubectl get pod -n kube-system</span>
NAME                                 READY   STATUS    RESTARTS   AGE
coredns-76fccbbb6b-l7jq9             <span class="token number">1</span>/1     Running   <span class="token number">0</span>          6h14m
coredns-76fccbbb6b-nd68g             <span class="token number">1</span>/1     Running   <span class="token number">0</span>          6h14m
etcd-k8s-master                      <span class="token number">1</span>/1     Running   <span class="token number">0</span>          6h15m
kube-apiserver-k8s-master            <span class="token number">1</span>/1     Running   <span class="token number">0</span>          6h14m
kube-controller-manager-k8s-master   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          6h15m
kube-proxy-8n6x5                     <span class="token number">1</span>/1     Running   <span class="token number">0</span>          169m
kube-proxy-mcwv7                     <span class="token number">1</span>/1     Running   <span class="token number">0</span>          6h14m
kube-proxy-xk4h4                     <span class="token number">1</span>/1     Running   <span class="token number">0</span>          169m
kube-scheduler-k8s-master            <span class="token number">1</span>/1     Running   <span class="token number">0</span>          6h15m<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="8-2-1-命令行创建"><a href="#8-2-1-命令行创建" class="headerlink" title="8.2.1 命令行创建"></a>8.2.1 命令行创建</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># kubectl create namespace luovip</span>
namespace/luovip created

root@k8s-master:~<span class="token comment"># kubectl get namespace</span>
NAME               STATUS   AGE
calico-apiserver   Active   3h26m
calico-system      Active   3h26m
default            Active   6h18m
kube-node-lease    Active   6h18m
kube-public        Active   6h18m
kube-system        Active   6h18m
luovip             Active   7s
tigera-operator    Active   3h41m<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="8-2-2-YAML文件创建"><a href="#8-2-2-YAML文件创建" class="headerlink" title="8.2.2 YAML文件创建"></a>8.2.2 YAML文件创建</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">cat</span> <span class="token operator">&gt;</span> namespace.yml <span class="token operator">&lt;&lt;</span><span class="token string">EOF
apiVersion: v1
kind: Namespace
metadata:
  name: luovipyu
EOF</span>

root@k8s-master:~<span class="token comment"># kubectl create -f namespace.yml</span>
namespace/luovipyu created

root@k8s-master:~<span class="token comment"># kubectl get namespace</span>
NAME               STATUS   AGE
calico-apiserver   Active   3h33m
calico-system      Active   3h33m
default            Active   6h25m
kube-node-lease    Active   6h25m
kube-public        Active   6h25m
kube-system        Active   6h25m
luovip             Active   6m54s
luovipyu           Active   26s
tigera-operator    Active   3h48m<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="8-2-3-删除namespace"><a href="#8-2-3-删除namespace" class="headerlink" title="8.2.3 删除namespace"></a>8.2.3 删除namespace</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># kubectl delete namespace luovipyu   # 会删除名字空间下的所有内容</span>
namespace <span class="token string">"luovipyu"</span> deleted

root@k8s-master:~<span class="token comment"># kubectl create -f namespace.yml</span>
namespace/luovipyu created
root@k8s-master:~<span class="token comment"># cat namespace.yml</span>
apiVersion: v1
kind: Namespace
metadata:
  name: luovipyu
root@k8s-master:~<span class="token comment"># kubectl get namespace</span>
NAME               STATUS   AGE
calico-apiserver   Active   3h39m
calico-system      Active   3h39m
default            Active   6h30m
kube-node-lease    Active   6h30m
kube-public        Active   6h30m
kube-system        Active   6h30m
luovip             Active   12m
luovipyu           Active   13s
tigera-operator    Active   3h54m<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="8-2-4-创建带有namespace属性的资源"><a href="#8-2-4-创建带有namespace属性的资源" class="headerlink" title="8.2.4 创建带有namespace属性的资源"></a>8.2.4 创建带有namespace属性的资源</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># kubectl run httpd --image=httpd --namespace=luovipyu</span>
pod/httpd created

root@k8s-master:~<span class="token comment"># kubectl get pod -n luovipyu</span>
NAME    READY   STATUS             RESTARTS   AGE
httpd   <span class="token number">1</span>/1     Running            <span class="token number">0</span>          18s
nginx   <span class="token number">0</span>/1     ImagePullBackOff   <span class="token number">0</span>          106s

<span class="token comment"># 每次查询和创建资源都需要带–namespace=luovipyu挺麻烦，可以设置默认值</span>
root@k8s-master:~<span class="token comment"># kubectl config set-context --current --namespace=luovipyu</span>
Context <span class="token string">"kubernetes-admin@kubernetes"</span> modified.
root@k8s-master:~<span class="token comment"># kubectl config view | grep namespace</span>
    namespace: luovipyu
root@k8s-master:~<span class="token comment"># kubectl get pod</span>
NAME    READY   STATUS             RESTARTS   AGE
httpd   <span class="token number">1</span>/1     Running            <span class="token number">0</span>          3m3s
nginx   <span class="token number">0</span>/1     ImagePullBackOff   <span class="token number">0</span>          4m31s

<span class="token comment"># 删除namespace会删除其下所有资源，但如果要删除已经切换为默认值的namespace时，可能会卡住，所以先把默认值切换为其他，然后再删除</span>
root@k8s-master:~<span class="token comment"># kubectl config set-context --current --namespace=default</span>
Context <span class="token string">"kubernetes-admin@kubernetes"</span> modified.

root@k8s-master:~<span class="token comment"># kubectl delete namespaces luovip luovipyu</span>
namespace <span class="token string">"luovip"</span> deleted
namespace <span class="token string">"luovipyu"</span> deleted

root@k8s-master:~<span class="token comment"># kubectl get namespace</span>
NAME               STATUS   AGE
calico-apiserver   Active   3h49m
calico-system      Active   3h49m
default            Active   6h41m
kube-node-lease    Active   6h41m
kube-public        Active   6h41m
kube-system        Active   6h41m
tigera-operator    Active   4h4m<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="8-3-CRD自定义资源"><a href="#8-3-CRD自定义资源" class="headerlink" title="8.3 CRD自定义资源"></a>8.3 CRD自定义资源</h2><p>  CRD（Custom Resource Definition，自定义资源定义）是Kubernetes提供的一种扩展机制，允许用户通过YAML文件定义自定义资源类型，并将其注册到Kubernetes API中，使其与内置资源（如Pod、 Deployment）一样被管理</p>
<p>  本质：CRD是对自定义资源的元数据描述，定义了资源的名称、结构、版本、作用域等<br>  作用：扩展Kubernetes API，支持用户自定义资源的管理和自动化操作</p>
<p>CRD核心字段：</p>
<table>
<thead>
<tr>
<th align="left">字段</th>
<th align="left">说明</th>
<th align="left">示例</th>
</tr>
</thead>
<tbody><tr>
<td align="left">apiVersion</td>
<td align="left">CRD的API版本，固定为apiextensions.k8s.io/v1</td>
<td align="left">apiVersion:apiextensions.k8s.io/v1</td>
</tr>
<tr>
<td align="left">kind</td>
<td align="left">资源类型，固定为CustomResourceDefinition</td>
<td align="left">kind: CustomResourceDefinition</td>
</tr>
<tr>
<td align="left">metadata</td>
<td align="left">元数据，如名称、命名空间等(名称需符合DNS子域名规则)</td>
<td align="left">name:crontabs.stable.example.com</td>
</tr>
<tr>
<td align="left">spec</td>
<td align="left">核心配置，包括 API组、版本、资源范围 (Namespaced/Cluster)、字段验证规则等</td>
<td align="left">group: stable.example.com</td>
</tr>
<tr>
<td align="left">versions</td>
<td align="left">支持的API版本列表，需指定至少一个存储版本( storage:true)</td>
<td align="left">version:[v1][@ref)</td>
</tr>
<tr>
<td align="left">names</td>
<td align="left">资源的复数形式、单数形式、简称等(如plural:crontabs)</td>
<td align="left">plural: crontabs</td>
</tr>
<tr>
<td align="left">scope</td>
<td align="left">资源作用域，Namespaced(命名空间级别)或Cluster(集群级别)</td>
<td align="left">scope: Namespaced</td>
</tr>
</tbody></table>
<h3 id="8-3-1-CRD介绍"><a href="#8-3-1-CRD介绍" class="headerlink" title="8.3.1 CRD介绍"></a>8.3.1 CRD介绍</h3><p>  K8S资源类型不止有namespace，还有很多，不过那都是系统自带的，现在我们来看看怎么自定义k8s中的资源</p>
<p>1.什么是CRD？</p>
<p>  CRD（Custom Resource Definition）是 Kubernetes 提供的一种机制，允许用户定义自己的资源类型</p>
<p>  这些自定义资源可以像 Kubernetes 原生资源（如 Pod、Service、Deployment 等）一样被管理。<br>2.为什么需要CRD？</p>
<p>  扩展 Kubernetes API：Kubernetes 的原生资源可能无法满足所有用户的需求。CRD 允许用户定义自己的资源类型，从而扩展 Kubernetes 的功能。</p>
<p>  管理复杂应用：有些应用可能需要管理一些特定的资源，这些资源不属于Kubernetes原生支持的范围。通过CRD可以将这些资源纳入 Kubernetes的管理范围，实现统一的资源管理</p>
<p>3.CRD的作用</p>
<p>  定义资源结构：CRD 允许你定义资源的结构，包括其字段和数据类型</p>
<p>  管理资源生命周期：Kubernetes 将为你管理这些自定义资源的生命周期，包括创建、更新、删除等操作</p>
<p>  集成 Kubernetes 生态系统：CRD 可以与 Kubernetes 的其他组件（如控制器、操作符等）集成，实现更复杂的业务逻辑</p>
<p>  在Kubernetes 的自定义资源定义（CRD）中，CRD 本身只定义了资源的结构和 API，但它不会直接执行任何创建、更新或删除操作。这些操作需要通过一个控制器（Controller）来实现。控制器是一个独立的程序，它监听 CRD 的变化，并根据这些变化执行实际的操作</p>
<h3 id="8-3-2-查询CRD以及API资源"><a href="#8-3-2-查询CRD以及API资源" class="headerlink" title="8.3.2 查询CRD以及API资源"></a>8.3.2 查询CRD以及API资源</h3><p>  1.先看看系统中的api资源都有哪些，然后创建一个</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># kubectl api-resources</span>
NAME                 SHORTNAMES    APIVERSION                   NAMESPACED      KIND
bindings                           v1                           <span class="token boolean">true</span>            Binding
componentstatuses    cs            v1                           <span class="token boolean">false</span>           ComponentStatus
configmaps           cm            v1                           <span class="token boolean">true</span>            ConfigMap
endpoints            ep            v1                           <span class="token boolean">true</span>            Endpoints
events               ev            v1                           <span class="token boolean">true</span>            Event
limitranges          limits        v1                           <span class="token boolean">true</span>            LimitRange
namespaces           ns            v1                           <span class="token boolean">false</span>           Namespace
nodes                no            v1                           <span class="token boolean">false</span>           Node
<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>  2.查看现在都有哪些自定义资源</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 以下资源不属于K8s，但是k8s是有的</span>
root@k8s-master:~<span class="token comment"># kubectl get crd</span>
NAME                                                  CREATED AT
adminnetworkpolicies.policy.networking.k8s.io         <span class="token number">2025</span>-05-17T03:05:26Z
apiservers.operator.tigera.io                         <span class="token number">2025</span>-05-17T03:05:26Z
bgpconfigurations.crd.projectcalico.org               <span class="token number">2025</span>-05-17T03:05:26Z
bgpfilters.crd.projectcalico.org                      <span class="token number">2025</span>-05-17T03:05:26Z
bgppeers.crd.projectcalico.org                        <span class="token number">2025</span>-05-17T03:05:26Z
blockaffinities.crd.projectcalico.org                 <span class="token number">2025</span>-05-17T03:05:26Z
caliconodestatuses.crd.projectcalico.org              <span class="token number">2025</span>-05-17T03:05:26Z
clusterinformations.crd.projectcalico.org             <span class="token number">2025</span>-05-17T03:05:26Z
felixconfigurations.crd.projectcalico.org             <span class="token number">2025</span>-05-17T03:05:26Z
globalnetworkpolicies.crd.projectcalico.org           <span class="token number">2025</span>-05-17T03:05:26Z
globalnetworksets.crd.projectcalico.org               <span class="token number">2025</span>-05-17T03:05:26Z
hostendpoints.crd.projectcalico.org                   <span class="token number">2025</span>-05-17T03:05:26Z
imagesets.operator.tigera.io                          <span class="token number">2025</span>-05-17T03:05:26Z
installations.operator.tigera.io                      <span class="token number">2025</span>-05-17T03:05:26Z
ipamblocks.crd.projectcalico.org                      <span class="token number">2025</span>-05-17T03:05:26Z
ipamconfigs.crd.projectcalico.org                     <span class="token number">2025</span>-05-17T03:05:26Z
ipamhandles.crd.projectcalico.org                     <span class="token number">2025</span>-05-17T03:05:26Z
ippools.crd.projectcalico.org                         <span class="token number">2025</span>-05-17T03:05:26Z
ipreservations.crd.projectcalico.org                  <span class="token number">2025</span>-05-17T03:05:26Z
kubecontrollersconfigurations.crd.projectcalico.org   <span class="token number">2025</span>-05-17T03:05:26Z
networkpolicies.crd.projectcalico.org                 <span class="token number">2025</span>-05-17T03:05:26Z
networksets.crd.projectcalico.org                     <span class="token number">2025</span>-05-17T03:05:26Z
tiers.crd.projectcalico.org                           <span class="token number">2025</span>-05-17T03:05:26Z
tigerastatuses.operator.tigera.io                     <span class="token number">2025</span>-05-17T03:05:26Z<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="8-3-3-创建CRD以及API资源"><a href="#8-3-3-创建CRD以及API资源" class="headerlink" title="8.3.3 创建CRD以及API资源"></a>8.3.3 创建CRD以及API资源</h3><p>  1.创建一个自己的crd，crd将注册为api资源</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">cat</span> <span class="token operator">&gt;</span> crd.yaml <span class="token operator">&lt;&lt;-</span><span class="token string">'EOF'
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  # 名字必需与下面的 spec 字段匹配，并且格式为 '&lt;名称的复数形式&gt;.&lt;组名&gt;'
  name: crontabs.stable.example.com
spec:
  # 组名称，用于 REST API：/apis/&lt;组&gt;/&lt;版本&gt;
  group: stable.example.com
  # 列举此 CustomResourceDefinition 所支持的版本
  versions:
    - name: v1
      # 每个版本都可以通过 served 标志来独立启用或禁止
      served: true
      # 其中一个且只有一个版本必需被标记为存储版本
      storage: true
      schema:
        openAPIV3Schema:
          type: object
          properties:
            spec:
              type: object
              properties:
                cronSpec:
                  type: string
                image:
                  type: string
                replicas:
                  type: integer
  # 可以是 Namespaced 或 Cluster
  scope: Namespaced
  names:
    # 名称的复数形式，用于 URL：/apis/&lt;组&gt;/&lt;版本&gt;/&lt;名称的复数形式&gt;
    plural: crontabs
    # 名称的单数形式，作为命令行使用时和显示时的别名
    singular: crontab
    # kind 通常是单数形式的驼峰命名（CamelCased）形式。你的资源清单会使用这一形式。
    kind: CronTab
    # shortNames 允许你在命令行使用较短的字符串来匹配资源
    shortNames:
    - ct
EOF</span>

root@k8s-master:~<span class="token comment"># kubectl apply -f crd.yaml</span>
customresourcedefinition.apiextensions.k8s.io/crontabs.stable.example.com created<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>  2.再看就会有自己的crd资源和api资源了</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># kubectl get crd</span>
NAME                                                  CREATED AT
<span class="token punctuation">..</span>.
crontabs.stable.example.com                           <span class="token number">2025</span>-05-17T06:16:04Z
<span class="token punctuation">..</span>.

root@k8s-master:~<span class="token comment"># kubectl api-resources | grep crontabs</span>
NAME          SHORTNAMES                      APIVERSION                          NAMESPACED   KIND
crontabs      ct                              stable.example.com/v1               <span class="token boolean">true</span>         CronTab

root@k8s-master:~<span class="token comment"># kubectl describe crd crontabs.stable.example.com</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="8-3-4-查询API资源结构与参数"><a href="#8-3-4-查询API资源结构与参数" class="headerlink" title="8.3.4 查询API资源结构与参数"></a>8.3.4 查询API资源结构与参数</h3><p>  既然已经注册为api资源，来看看能否explain字段？</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># kubectl explain crontabs</span>
GROUP:      stable.example.com
KIND:       CronTab
VERSION:    v1

DESCRIPTION:
    <span class="token operator">&lt;</span>empty<span class="token operator">&gt;</span>
FIELDS:
  apiVersion    <span class="token operator">&lt;</span>string<span class="token operator">&gt;</span>
  kind  <span class="token operator">&lt;</span>string<span class="token operator">&gt;</span>
  metadata      <span class="token operator">&lt;</span>ObjectMeta<span class="token operator">&gt;</span>
  spec  <span class="token operator">&lt;</span>Object<span class="token operator">&gt;</span>
<span class="token punctuation">..</span>.

<span class="token comment"># 查看有哪些spec</span>
root@k8s-master:~<span class="token comment"># kubectl explain crontabs.spec</span>
GROUP:      stable.example.com
KIND:       CronTab
VERSION:    v1

FIELD: spec <span class="token operator">&lt;</span>Object<span class="token operator">&gt;</span>


DESCRIPTION:
    <span class="token operator">&lt;</span>empty<span class="token operator">&gt;</span>
FIELDS:
  cronSpec      <span class="token operator">&lt;</span>string<span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span>no description<span class="token operator">&gt;</span>

  image <span class="token operator">&lt;</span>string<span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span>no description<span class="token operator">&gt;</span>

  replicas      <span class="token operator">&lt;</span>integer<span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span>no description<span class="token operator">&gt;</span>
<span class="token comment"># 一切正常，看来已经创建了自定义资源，接下来就是等开发人员通过编程等方式创建operator等控制器，来使用我们的资源了</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h1 id="9-Pod"><a href="#9-Pod" class="headerlink" title="9 Pod"></a>9 Pod</h1><h2 id="9-1-关于pod"><a href="#9-1-关于pod" class="headerlink" title="9.1 关于pod"></a>9.1 关于pod</h2><p>  Pod由一个或多个紧密耦合的容器组成</p>
<p>  它们之间共享网络、存储等资源</p>
<p>  pod是Kubernetes中最小的工作单元</p>
<p>  Pod中的容器会一起启动和停止</p>
<h2 id="9-2-Pod生命周期"><a href="#9-2-Pod生命周期" class="headerlink" title="9.2 Pod生命周期"></a>9.2 Pod生命周期</h2><p>  Pod遵循一个预定义的生命周期，起始于Pending阶段，如果至少其中有一个主要容器正常启动，则进入Running，之后取决于Pod中是否有容器以失败状态结束而进入Succeeded或者Failed阶段。但有时集群节点之间出现网络故障，无法获取Pod状态时，就会出现Unknown状态</p>
<h2 id="9-3-创建Pod"><a href="#9-3-创建Pod" class="headerlink" title="9.3 创建Pod"></a>9.3 创建Pod</h2><p>  1.一个Pod中只有一个业务容器</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 1.yml文件创建pod</span>
<span class="token function">cat</span> <span class="token operator">&gt;</span> pod.yml <span class="token operator">&lt;&lt;</span><span class="token string">EOF
apiVersion: v1
kind: Pod
metadata:
  name: luovippod
spec:
  containers:
  - name: hello
    image: httpd
    imagePullPolicy: IfNotPresent
    command: ['sh', '-c', 'echo "Hello, China!" &amp;&amp; sleep 3600']
  restartPolicy: OnFailure
EOF</span>

root@k8s-master:~<span class="token comment"># kubectl create -f pod.yml</span>
pod/luovippod created
root@k8s-master:~<span class="token comment"># kubectl get pod</span>
NAME        READY   STATUS    RESTARTS   AGE
luovippod   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          5s
root@k8s-master:~<span class="token comment"># kubectl logs luovippod</span>
Hello, China<span class="token operator">!</span>

root@k8s-master:~<span class="token comment"># kubectl delete pod luovippod    删除pod</span>

<span class="token comment"># 2.命令行创建pod</span>
root@k8s-master:~<span class="token comment"># kubectl run luoyupod --image=nginx --port=80</span>
pod/luoyupod created
root@k8s-master:~<span class="token comment"># kubectl get pod</span>
NAME        READY   STATUS    RESTARTS   AGE
luovippod   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          7m56s
luoyupod    <span class="token number">1</span>/1     Running   <span class="token number">0</span>          3m38s
root@k8s-master:~<span class="token comment"># kubectl get pod -o wide</span>
NAME        READY   STATUS    RESTARTS   AGE     IP              NODE          NOMINATED NODE   READINESS GATES
luovippod   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          8m6s    <span class="token number">172.16</span>.194.71   k8s-worker1   <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>           <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>
luoyupod    <span class="token number">1</span>/1     Running   <span class="token number">0</span>          3m48s   <span class="token number">172.16</span>.194.72   k8s-worker1   <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>           <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>  2.一个Pod中有多个业务容器</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">cat</span> <span class="token operator">&gt;</span> multicontainer.yml <span class="token operator">&lt;&lt;</span><span class="token string">EOF
apiVersion: v1
kind: Pod
metadata:
  name: pod
spec:
  containers:
  - name: nginx
    image: nginx
    imagePullPolicy: IfNotPresent
    command: ['sh', '-c', 'echo "Hello, luoyu!" &amp;&amp; sleep 3600']
  - name: httpd
    image: httpd
    imagePullPolicy: IfNotPresent
    ports:
      - name: web
        containerPort: 80
  restartPolicy: OnFailure
EOF</span>

root@k8s-master:~<span class="token comment"># kubectl create -f multicontainer.yml</span>
pod/pod created

root@k8s-master:~<span class="token comment"># kubectl get pod</span>
NAME        READY   STATUS    RESTARTS   AGE
luovippod   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          18m
luoyupod    <span class="token number">1</span>/1     Running   <span class="token number">0</span>          14m
pod         <span class="token number">2</span>/2     Running   <span class="token number">0</span>          9s

root@k8s-master:~<span class="token comment"># kubectl get -f multicontainer.yml -o wide</span>
NAME   READY   STATUS    RESTARTS   AGE   IP             NODE          NOMINATED NODE   READINESS GATES
pod    <span class="token number">2</span>/2     Running   <span class="token number">0</span>          68s   <span class="token number">172.16</span>.126.3   k8s-worker2   <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>           <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>

root@k8s-master:~<span class="token comment"># curl 172.16.126.3</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="9-4-修改Pod"><a href="#9-4-修改Pod" class="headerlink" title="9.4 修改Pod"></a>9.4 修改Pod</h2><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 直接修改yaml文件，然后执行以下命令</span>
kubectl apply <span class="token parameter variable">-f</span> pod.yml

<span class="token comment"># 编辑Etcd数据</span>
kubectl edit pod luovippod

<span class="token comment"># patch参数</span>
kubectl get pod luovippod <span class="token parameter variable">-o</span> json
kubectl get pod luovippod <span class="token parameter variable">-o</span> json <span class="token operator">|</span> <span class="token function">grep</span> cnlxh

注明：工作中的修改pod一般时k8s会创建新的pod并删除旧的pod<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="9-5-进入pod中的容器"><a href="#9-5-进入pod中的容器" class="headerlink" title="9.5 进入pod中的容器"></a>9.5 进入pod中的容器</h2><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># kubectl get pod -o wide</span>
NAME        READY   STATUS    RESTARTS   AGE   IP              NODE          NOMINATED NODE   READINESS GATES
luovippod   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          37m   <span class="token number">172.16</span>.194.71   k8s-worker1   <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>           <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>
luoyupod    <span class="token number">1</span>/1     Running   <span class="token number">0</span>          33m   <span class="token number">172.16</span>.194.72   k8s-worker1   <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>           <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>
pod         <span class="token number">2</span>/2     Running   <span class="token number">0</span>          19m   <span class="token number">172.16</span>.126.3    k8s-worker2   <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>           <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>

root@k8s-master:~<span class="token comment"># kubectl exec -it pod -c httpd  -- /bin/bash</span>
root@pod:/usr/local/apache2<span class="token comment"># echo MyCity is ChengDu! &gt; htdocs/index.html</span>
root@pod:/usr/local/apache2<span class="token comment"># exit</span>
<span class="token builtin class-name">exit</span>
root@k8s-master:~<span class="token comment"># curl http://172.16.126.3</span>
MyCity is ChengDu<span class="token operator">!</span>

<span class="token comment">#参数说明：</span>
 <span class="token number">1</span>、-c 参数可以指定需要进入pod中的哪个容器
 <span class="token number">2</span>、-- 是K8S命令和预期容器内部执行命令的连接符
 <span class="token number">3</span>、/bin/sh是指进入容器中执行什么命令 
 <span class="token number">4</span>、退出执行exit<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="9-6-Init类型容器"><a href="#9-6-Init类型容器" class="headerlink" title="9.6 Init类型容器"></a>9.6 Init类型容器</h2><p>  Init容器是一种特殊容器，在Pod内的应用容器启动之前运行，如果Pod的Init容器失败，kubelet会不断地重启该 Init 容器直到该容器成功为止。 然而，如果 Pod 对应的 restartPolicy 值为 “Never”，并且 Pod的 Init 容器失败， 则 Kubernetes 会将整个 Pod 状态设置为失败</p>
<p>  Init容器与普通的容器非常像，除了如下两点：</p>
<p>   1.正常情况下，它们最终都会处于completed状态</p>
<p>   2.每个都必须在下一个启动之前成功完成</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 根据安排，myapp-container的容器将等待两个init结束之后才会启动，也就是40秒之后才会启动</span>
<span class="token function">cat</span> <span class="token operator">&gt;</span> init.yml <span class="token operator">&lt;&lt;</span><span class="token string">EOF
apiVersion: v1
kind: Pod
metadata:
  name: initpd
  labels:
    app: myapp
spec:
  containers:
  - name: myapp-container
    image: busybox
    imagePullPolicy: IfNotPresent
    command: ['sh', '-c', 'echo The app is running! &amp;&amp; sleep 3600']
  initContainers:
  - name: init-myservice
    image: busybox
    imagePullPolicy: IfNotPresent
    command: ['sh', '-c', "sleep 20"]
  - name: init-mydb
    image: busybox
    imagePullPolicy: IfNotPresent
    command: ['sh', '-c', "sleep 20"]
EOF</span>


root@k8s-master:~<span class="token comment"># kubectl create -f init.yml</span>
pod/initpd created

<span class="token comment"># -w参数可以实时查看pod的状态变化</span>
root@k8s-master:~<span class="token comment"># kubectl get -f init.yml -w</span>
NAME     READY   STATUS     RESTARTS   AGE
initpd   <span class="token number">0</span>/1     Init:0/2   <span class="token number">0</span>          19s
initpd   <span class="token number">0</span>/1     Init:1/2   <span class="token number">0</span>          21s
initpd   <span class="token number">0</span>/1     Init:1/2   <span class="token number">0</span>          22s
initpd   <span class="token number">0</span>/1     PodInitializing   <span class="token number">0</span>          42s
initpd   <span class="token number">1</span>/1     Running           <span class="token number">0</span>          43s

root@k8s-master:~<span class="token comment"># kubectl get pod -w</span>
NAME        READY   STATUS     RESTARTS   AGE
initpd      <span class="token number">0</span>/1     Init:1/2   <span class="token number">0</span>          34s
luovippod   <span class="token number">1</span>/1     Running    <span class="token number">0</span>          56m
luoyupod    <span class="token number">1</span>/1     Running    <span class="token number">0</span>          51m
pod         <span class="token number">2</span>/2     Running    <span class="token number">0</span>          37m

root@k8s-master:~<span class="token comment"># kubectl get pods</span>
NAME        READY   STATUS    RESTARTS   AGE
initpd      <span class="token number">1</span>/1     Running   <span class="token number">0</span>          104s
luovippod   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          57m
luoyupod    <span class="token number">1</span>/1     Running   <span class="token number">0</span>          52m
pod         <span class="token number">2</span>/2     Running   <span class="token number">0</span>          39m<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="9-7-Sidecar类型容器"><a href="#9-7-Sidecar类型容器" class="headerlink" title="9.7 Sidecar类型容器"></a>9.7 Sidecar类型容器</h2><p>  一般来讲，Sidecar容器可以：</p>
<p>   1.日志代理/转发，例如 fluentd</p>
<p>   2.Service Mesh，比如 Istio，Linkerd</p>
<p>   3.代理，比如 Docker Ambassador</p>
<p>   4.探活：检查某些组件是不是正常工作</p>
<p>   5.其他辅助性的工作，比如拷贝文件，下载文件等</p>
<p><img src="/images/Sidecar.png"></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 两个容器挂载了同一个目录，一个容器负责写入数据，一个容器负责对外展示</span>
<span class="token function">cat</span> <span class="token operator">&gt;</span> sidecar.yml <span class="token operator">&lt;&lt;</span><span class="token string">EOF
apiVersion: v1
kind: Pod
metadata:
  name: sidecarpod
spec:
  containers:
  - name: httpd
    image: httpd
    imagePullPolicy: IfNotPresent
    volumeMounts:
      - mountPath: /usr/local/apache2/htdocs/
        name: luoyuvolume
  - name: busybox
    image: busybox
    imagePullPolicy: IfNotPresent
    command: ['sh', '-c', 'echo "Hello sidecar" &gt; /usr/local/apache2/htdocs/index.html &amp;&amp; sleep 3600']
    volumeMounts:
      - mountPath: /usr/local/apache2/htdocs/
        name: luoyuvolume
  restartPolicy: OnFailure
  volumes:
    - name: luoyuvolume
      emptyDir: {}
EOF</span>

root@k8s-master:~<span class="token comment"># kubectl create -f sidecar.yml</span>
pod/sidecarpod created

root@k8s-master:~<span class="token comment"># kubectl get -f sidecar.yml -o wide</span>
NAME         READY   STATUS    RESTARTS   AGE   IP              NODE       NOMINATED NODE   READINESS GATES
sidecarpod   <span class="token number">2</span>/2     Running   <span class="token number">0</span>          9s    <span class="token number">172.16</span>.194.74   k8s-worker1   <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>           <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>

root@k8s-master:~<span class="token comment"># curl http://172.16.194.74</span>
Hello sidecar<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="9-8-静态Pod"><a href="#9-8-静态Pod" class="headerlink" title="9.8 静态Pod"></a>9.8 静态Pod</h2><p>  静态 Pod 在指定的节点上由 kubelet 守护进程直接管理，不需要 API 服务器监管。 与由控制面管理的Pod（例如，Deployment） 不同；kubelet 监视每个静态 Pod（在它崩溃之后重新启动）</p>
<p>  静态 Pod 永远都会绑定到一个指定节点上的 Kubelet</p>
<p>  kubelet 会尝试通过 Kubernetes API 服务器为每个静态 Pod 自动创建一个 mirror Pod。 这意味着节点上运行的静态 Pod 对 API 服务来说是可见的，但是不能通过 API 服务器来控制。 Pod 名称将把以连字符开头的节点主机名作为后缀</p>
<p>  运行中的 kubelet 会定期扫描配置的目录中的变化， 并且根据文件中出现/消失的 Pod 来添加/删除Pod</p>
<p>1.查找静态pod的编写路径</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># systemctl status kubelet</span>
<span class="token punctuation">..</span>.
    Drop-In: /usr/lib/systemd/system/kubelet.service.d
             └─10-kubeadm.conf
<span class="token punctuation">..</span>.

root@k8s-master:~<span class="token comment"># tail /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf</span>
<span class="token punctuation">[</span>Service<span class="token punctuation">]</span>
<span class="token punctuation">..</span>.
<span class="token assign-left variable">Environment</span><span class="token operator">=</span><span class="token string">"KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml"</span>
<span class="token punctuation">..</span>.

root@k8s-master:~<span class="token comment"># grep -i static /var/lib/kubelet/config.yaml</span>
staticPodPath: /etc/kubernetes/manifests<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>2.编写静态pod</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">cat</span> <span class="token operator">&gt;</span> static.yml <span class="token operator">&lt;&lt;</span><span class="token string">EOF
apiVersion: v1
kind: Pod
metadata:
  name: staticpod
spec:
  containers:
  - name: hello
    image: busybox
    imagePullPolicy: IfNotPresent
    command: ['sh', '-c', 'echo "Hello, lixiaohui!" &amp;&amp; sleep 3600']
  restartPolicy: OnFailure
EOF</span>

<span class="token comment"># 把这个yaml文件复制到/etc/kubernetes/manifests，然后观察pod列表，然后把yaml文件移出此文件夹，再观察pod列表</span>
root@k8s-master:~<span class="token comment"># cp static.yml /etc/kubernetes/manifests/</span>
root@k8s-master:~<span class="token comment"># kubectl get pod</span>
NAME                   READY   STATUS      RESTARTS   AGE
initpd                 <span class="token number">1</span>/1     Running     <span class="token number">0</span>          40m
luovippod              <span class="token number">0</span>/1     Completed   <span class="token number">0</span>          95m
luoyupod               <span class="token number">1</span>/1     Running     <span class="token number">0</span>          91m
pod                    <span class="token number">1</span>/2     NotReady    <span class="token number">0</span>          77m
sidecarpod             <span class="token number">2</span>/2     Running     <span class="token number">0</span>          31m
staticpod-k8s-master   <span class="token number">1</span>/1     Running     <span class="token number">0</span>          12s

<span class="token comment"># 删除/etc/kubernetes/manifests文件中的yml文件，再观察pod列表</span>
root@k8s-master:~<span class="token comment"># rm -rf /etc/kubernetes/manifests/static.yml</span>
root@k8s-master:~<span class="token comment"># kubectl get pod</span>
NAME         READY   STATUS      RESTARTS   AGE
initpd       <span class="token number">1</span>/1     Running     <span class="token number">0</span>          41m
luovippod    <span class="token number">0</span>/1     Completed   <span class="token number">0</span>          97m
luoyupod     <span class="token number">1</span>/1     Running     <span class="token number">0</span>          92m
pod          <span class="token number">1</span>/2     NotReady    <span class="token number">0</span>          78m
sidecarpod   <span class="token number">2</span>/2     Running     <span class="token number">0</span>          32m

<span class="token comment"># 维持集群运行的文件如下：</span>
root@k8s-master:/etc/kubernetes/manifests<span class="token comment"># ls</span>
etcd.yaml  kube-apiserver.yaml  kube-controller-manager.yaml  kube-scheduler.yaml  static.yml<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="9-9-Pod删除"><a href="#9-9-Pod删除" class="headerlink" title="9.9 Pod删除"></a>9.9 Pod删除</h2><p>  kubectl delete pod –all会删除所有pod</p>
<p>  kubectl delete pod pod名称—删除指定的pod</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># kubectl get pods</span>
NAME                   READY   STATUS    RESTARTS   AGE
initpd                 <span class="token number">1</span>/1     Running   <span class="token number">0</span>          13m
luovippod              <span class="token number">1</span>/1     Running   <span class="token number">0</span>          9m23s
luoyupod               <span class="token number">1</span>/1     Running   <span class="token number">0</span>          169m
pod                    <span class="token number">2</span>/2     Running   <span class="token number">0</span>          7m51s
sidecarpod             <span class="token number">2</span>/2     Running   <span class="token number">0</span>          27s
staticpod-k8s-master   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          2s

root@k8s-master:~<span class="token comment"># kubectl delete pod luovippod</span>
root@k8s-master:~<span class="token comment"># kubectl delete pod -all</span>

root@k8s-master:~<span class="token comment"># kubectl get pods</span>
No resources found <span class="token keyword">in</span> default namespace.

root@k8s-master:~<span class="token comment"># kubectl get pod -n kube-system</span>
NAME                                 READY   STATUS    RESTARTS   AGE
coredns-76fccbbb6b-l7jq9             <span class="token number">1</span>/1     Running   <span class="token number">0</span>          35h
coredns-76fccbbb6b-nd68g             <span class="token number">1</span>/1     Running   <span class="token number">0</span>          35h
etcd-k8s-master                      <span class="token number">1</span>/1     Running   <span class="token number">0</span>          35h
kube-apiserver-k8s-master            <span class="token number">1</span>/1     Running   <span class="token number">0</span>          35h
kube-controller-manager-k8s-master   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          35h
kube-proxy-8n6x5                     <span class="token number">1</span>/1     Running   <span class="token number">0</span>          32h
kube-proxy-mcwv7                     <span class="token number">1</span>/1     Running   <span class="token number">0</span>          35h
kube-proxy-xk4h4                     <span class="token number">1</span>/1     Running   <span class="token number">0</span>          32h
kube-scheduler-k8s-master            <span class="token number">1</span>/1     Running   <span class="token number">0</span>          35h<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h1 id="10-Kubernetes控制器"><a href="#10-Kubernetes控制器" class="headerlink" title="10 Kubernetes控制器"></a>10 Kubernetes控制器</h1><h2 id="10-1-什么是控制器"><a href="#10-1-什么是控制器" class="headerlink" title="10.1 什么是控制器"></a>10.1 什么是控制器</h2><p>  当你设置了温度，告诉了空调遥控器你的期望状态（Desired State）。 房间的实际温度是当前状态（Current State）。 通过对遥控器的开关控制，遥控器让其当前状态接近期望状态<br>  在 Kubernetes 中，控制器通过监控集群的公共状态，并致力于将当前状态转变为期望的状态</p>
<p>  作为设计原则之一，Kubernetes 使用了很多控制器，每个控制器管理集群状态的一个特定方面。 最常见的一个特定的控制器使用一种类型的资源作为它的期望状态， 控制器管理控制另外一种类型的资源向它的期望状态演化</p>
<h2 id="10-2-Replica-Set概念"><a href="#10-2-Replica-Set概念" class="headerlink" title="10.2 Replica Set概念"></a>10.2 Replica Set概念</h2><p>  ReplicationController确保在任何时候都有特定数量的Pod副本处于运行状态。 换句话说，ReplicationController 确保一个 Pod 或一组同类的 Pod 总是可用的<br>  ReplicaSet的目的是维护一组在任何时候都处于运行状态的 Pod 副本的稳定集合。 因此，它通常用来保证给定数量的、完全相同的 Pod 的可用性。</p>
<p>说明： 现在推荐使用配置ReplicaSet的Deployment来建立副本管理机制</p>
<h2 id="10-3-Replica-Set-工作原理"><a href="#10-3-Replica-Set-工作原理" class="headerlink" title="10.3 Replica Set 工作原理"></a>10.3 Replica Set 工作原理</h2><p>  RepicaSet是通过一组字段来定义的，包括一个用来识别可获得的 Pod 的集合的选择算符、一个用来标明应该维护的副本个数的数值、一个用来指定应该创建新 Pod 以满足副本个数条件时要使用的 Pod 模板等等。 每个 ReplicaSet 都通过根据需要创建和 删除 Pod 以使得副本个数达到期望值， 进而实现其存在价值。当 ReplicaSet 需要创建新的 Pod 时，会使用所提供的 Pod 模板</p>
<p>  1.ReplicaSet也需要apiVersion、kind和metadata字段</p>
<p>  2.Pod 选择算符：.spec.selector 字段是一个标签选择算符。在 ReplicaSet 中，.spec.template.metadata.labels 的值必须与 spec.selector 值 相匹配，否则该配置会被API拒绝</p>
<p>  3.可以通过设置 .spec.replicas 来指定要同时运行的 Pod个数。 ReplicaSet 创建、删除 Pods 以与此值匹配</p>
<h2 id="10-4-ReplicaSet使用"><a href="#10-4-ReplicaSet使用" class="headerlink" title="10.4 ReplicaSet使用"></a>10.4 ReplicaSet使用</h2><p>  使用nginx镜像创建具有3个pod的RS,并分配合适的标签</p>
<h3 id="10-4-1-创建yml文件"><a href="#10-4-1-创建yml文件" class="headerlink" title="10.4.1 创建yml文件"></a>10.4.1 创建yml文件</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">cat</span> <span class="token operator">&gt;</span> rs.yml <span class="token operator">&lt;&lt;</span><span class="token string">EOF
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: nginxrstest
  labels:
    app: nginxrstest
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginxrstest
  template:
    metadata:
      labels:
        app: nginxrstest
    spec:
      containers:
      - name: nginx
        image: nginx
        imagePullPolicy: IfNotPresent
        ports:
          - name: http
            containerPort: 80
        imagePullPolicy: IfNotPresent
EOF</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="10-4-2-操作ReplicaSet"><a href="#10-4-2-操作ReplicaSet" class="headerlink" title="10.4.2 操作ReplicaSet"></a>10.4.2 操作ReplicaSet</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># kubectl create -f rs.yml</span>
root@k8s-master:~<span class="token comment"># kubectl get rs</span>
NAME          DESIRED   CURRENT   READY   AGE
nginxrstest   <span class="token number">3</span>         <span class="token number">3</span>         <span class="token number">3</span>       3m45s

root@k8s-master:~<span class="token comment"># kubectl get pod --show-labels</span>
NAME                READY   STATUS    RESTARTS   AGE    LABELS
nginxrstest-5bvpr   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          7m1s   <span class="token assign-left variable">app</span><span class="token operator">=</span>nginxrstest
nginxrstest-9d86s   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          7m1s   <span class="token assign-left variable">app</span><span class="token operator">=</span>nginxrstest
nginxrstest-k79cw   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          7m1s   <span class="token assign-left variable">app</span><span class="token operator">=</span>nginxrstest

<span class="token comment"># 被动高可用</span>
root@k8s-master:~<span class="token comment"># kubectl delete pod --all</span>
pod <span class="token string">"nginxrstest-5bvpr"</span> deleted
pod <span class="token string">"nginxrstest-9d86s"</span> deleted
pod <span class="token string">"nginxrstest-k79cw"</span> deleted

root@k8s-master:~<span class="token comment"># kubectl get replicasets.apps,pods</span>
NAME                          DESIRED   CURRENT   READY   AGE
replicaset.apps/nginxrstest   <span class="token number">3</span>         <span class="token number">3</span>         <span class="token number">3</span>       12m

NAME                    READY   STATUS    RESTARTS   AGE
pod/nginxrstest-86dd7   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          3m6s
pod/nginxrstest-bbzxd   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          3m6s
pod/nginxrstest-ndgxg   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          3m6s

<span class="token comment"># 扩容</span>
root@k8s-master:~<span class="token comment"># kubectl scale replicaset nginxrstest --replicas 4</span>
replicaset.apps/nginxrstest scaled
root@k8s-master:~<span class="token comment"># kubectl get replicasets.apps nginxrstest</span>
NAME          DESIRED   CURRENT   READY   AGE
nginxrstest   <span class="token number">4</span>         <span class="token number">4</span>         <span class="token number">4</span>       16m

root@k8s-master:~<span class="token comment"># kubectl get replicasets.apps,pods -o wide</span>

<span class="token comment"># 删除</span>
root@k8s-master:~<span class="token comment"># kubectl delete replicasets.apps nginxrstest</span>
replicaset.apps <span class="token string">"nginxrstest"</span> deleted
root@k8s-master:~<span class="token comment"># kubectl get pod</span>
No resources found <span class="token keyword">in</span> default namespace.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="10-5-Deployment"><a href="#10-5-Deployment" class="headerlink" title="10.5 Deployment"></a>10.5 Deployment</h2><p>  ReplicaSet确保任何时间都有指定数量的Pod副本在运行。 然而，Deployment是一个更高级的概念，它管理ReplicaSet，并向Pod提供声明式的更新以及许多其他有用的功能。 因此，建议使用 Deployment 而不是直接使用 ReplicaSet，除非需要自定义更新业务流程或根本不需要更新<br>  这实际上意味着，可能永远不需要操作ReplicaSet对象：而是使用Deployment，并在spec部分定义应用</p>
<p><img src="/images/Deployment.png"></p>
<h3 id="10-5-1-创建yml文件"><a href="#10-5-1-创建yml文件" class="headerlink" title="10.5.1 创建yml文件"></a>10.5.1 创建yml文件</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">cat</span> <span class="token operator">&gt;</span> deployment.yml <span class="token operator">&lt;&lt;</span><span class="token string">EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.16.1
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 80
EOF</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="10-5-2-创建Deployment"><a href="#10-5-2-创建Deployment" class="headerlink" title="10.5.2 创建Deployment"></a>10.5.2 创建Deployment</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 使用nginx镜像创建具有3个副本的Deployment，并分配合适的属性</span>
<span class="token comment"># 发现deployment管理了一个RS，而RS又实现了3个pod</span>
root@k8s-master:~<span class="token comment"># kubectl create -f deployment.yml</span>
deployment.apps/nginx-deployment created

root@k8s-master:~<span class="token comment"># kubectl get deployment.apps</span>
NAME               READY   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment   <span class="token number">3</span>/3     <span class="token number">3</span>            <span class="token number">3</span>           20s

<span class="token comment"># kubectl get pods --show-labels(可选)</span>
  Deployment控制器将pod-template-hash标签添加到Deployment所创建或收留的每个ReplicaSet，此标签可确保Deployment的子 ReplicaSets不重叠
root@k8s-master:~<span class="token comment"># kubectl get pods --show-labels</span>
NAME                               READY   STATUS    RESTARTS   AGE   LABELS
nginx-deployment-8d94c585f-ngm9d   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          51s   <span class="token assign-left variable">app</span><span class="token operator">=</span>nginx,pod-template-hash<span class="token operator">=</span>8d94c585f
nginx-deployment-8d94c585f-wf4mc   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          51s   <span class="token assign-left variable">app</span><span class="token operator">=</span>nginx,pod-template-hash<span class="token operator">=</span>8d94c585f
nginx-deployment-8d94c585f-wjzkw   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          51s   <span class="token assign-left variable">app</span><span class="token operator">=</span>nginx,pod-template-hash<span class="token operator">=</span>8d94c585f

root@k8s-master:~<span class="token comment"># kubectl get deployments.apps,replicasets.apps,pods -l app=nginx</span>
NAME                               READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/nginx-deployment   <span class="token number">3</span>/3     <span class="token number">3</span>            <span class="token number">3</span>           2m20s

NAME                                         DESIRED   CURRENT   READY   AGE
replicaset.apps/nginx-deployment-8d94c585f   <span class="token number">3</span>         <span class="token number">3</span>         <span class="token number">3</span>       2m20s

NAME                                   READY   STATUS    RESTARTS   AGE
pod/nginx-deployment-8d94c585f-ngm9d   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          2m20s
pod/nginx-deployment-8d94c585f-wf4mc   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          2m20s
pod/nginx-deployment-8d94c585f-wjzkw   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          2m20s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="10-5-3-更新Deployment"><a href="#10-5-3-更新Deployment" class="headerlink" title="10.5.3 更新Deployment"></a>10.5.3 更新Deployment</h3><p>  1.将deployment的镜像更改一次</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># Deployment的更新策略</span>
root@k8s-master:~<span class="token comment"># kubectl get deployments.apps nginx-deployment -o yaml</span>
apiVersion: apps/v1
kind: Deployment
<span class="token punctuation">..</span>.
  strategy:
    rollingUpdate:
      maxSurge: <span class="token number">25</span>%
      maxUnavailable: <span class="token number">25</span>%
    type: RollingUpdate
<span class="token punctuation">..</span>.

root@k8s-master:~<span class="token comment"># kubectl set image deployments/nginx-deployment nginx=nginx:1.17.1 --record</span>
Flag <span class="token parameter variable">--record</span> has been deprecated, <span class="token parameter variable">--record</span> will be removed <span class="token keyword">in</span> the future
deployment.apps/nginx-deployment image updated


<span class="token comment"># 查看更新的进度---更新过程是多了一个replicaset</span>
root@k8s-master:~<span class="token comment"># kubectl rollout status deployment/nginx-deployment</span>
Waiting <span class="token keyword">for</span> deployment <span class="token string">"nginx-deployment"</span> rollout to finish: <span class="token number">1</span> out of <span class="token number">3</span> new replicas have been updated<span class="token punctuation">..</span>.
Waiting <span class="token keyword">for</span> deployment <span class="token string">"nginx-deployment"</span> rollout to finish: <span class="token number">1</span> out of <span class="token number">3</span> new replicas have been updated<span class="token punctuation">..</span>.
Waiting <span class="token keyword">for</span> deployment <span class="token string">"nginx-deployment"</span> rollout to finish: <span class="token number">1</span> out of <span class="token number">3</span> new replicas have been updated<span class="token punctuation">..</span>.
Waiting <span class="token keyword">for</span> deployment <span class="token string">"nginx-deployment"</span> rollout to finish: <span class="token number">2</span> out of <span class="token number">3</span> new replicas have been updated<span class="token punctuation">..</span>.
Waiting <span class="token keyword">for</span> deployment <span class="token string">"nginx-deployment"</span> rollout to finish: <span class="token number">2</span> out of <span class="token number">3</span> new replicas have been updated<span class="token punctuation">..</span>.
Waiting <span class="token keyword">for</span> deployment <span class="token string">"nginx-deployment"</span> rollout to finish: <span class="token number">2</span> out of <span class="token number">3</span> new replicas have been updated<span class="token punctuation">..</span>.
Waiting <span class="token keyword">for</span> deployment <span class="token string">"nginx-deployment"</span> rollout to finish: <span class="token number">1</span> old replicas are pending termination<span class="token punctuation">..</span>.
Waiting <span class="token keyword">for</span> deployment <span class="token string">"nginx-deployment"</span> rollout to finish: <span class="token number">1</span> old replicas are pending termination<span class="token punctuation">..</span>.
deployment <span class="token string">"nginx-deployment"</span> successfully rolled out

root@k8s-master:~<span class="token comment"># kubectl get deployments.apps,replicasets.apps,pods -l app=nginx</span>
NAME                               READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/nginx-deployment   <span class="token number">3</span>/3     <span class="token number">3</span>            <span class="token number">3</span>           5m43s

NAME                                          DESIRED   CURRENT   READY   AGE
replicaset.apps/nginx-deployment-5d457cdfc8   <span class="token number">3</span>         <span class="token number">3</span>         <span class="token number">3</span>       84s
replicaset.apps/nginx-deployment-8d94c585f    <span class="token number">0</span>         <span class="token number">0</span>         <span class="token number">0</span>       5m43s

NAME                                    READY   STATUS    RESTARTS   AGE
pod/nginx-deployment-5d457cdfc8-7whnx   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          66s
pod/nginx-deployment-5d457cdfc8-b7njk   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          84s
pod/nginx-deployment-5d457cdfc8-x4zv8   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          55s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>  2.更新的策略</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 首先创建了一个新的Pod，然后删除了一些旧的Pods， 并创建了新的Pods。不会杀死老Pods，直到有足够的数量新的Pods已经出现</span>
<span class="token comment"># 在足够数量的旧Pods被杀死前并没有创建新Pods。确保至少2个Pod可用，同时最多总共4个pod可用</span>
<span class="token comment"># Deployment可确保在更新时仅关闭一定数量的Pod。默认情况下确保至少所需Pods 75%处于运行状态（最大不可用比例为 25%）</span>
root@k8s-master:~<span class="token comment"># kubectl describe deployments.apps nginx-deployment</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="10-5-4-回滚Deployment"><a href="#10-5-4-回滚Deployment" class="headerlink" title="10.5.4 回滚Deployment"></a>10.5.4 回滚Deployment</h3><p>  假设在更新时犯错误了，将镜像名称命名设置为nginx:1.172，而不是nginx:1.17.2，发现永远无法更新成功，此时就需要回退</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># kubectl set image deployments/nginx-deployment nginx=nginx:1.172 --record</span>
Flag <span class="token parameter variable">--record</span> has been deprecated, <span class="token parameter variable">--record</span> will be removed <span class="token keyword">in</span> the future
deployment.apps/nginx-deployment image updated

root@k8s-master:~<span class="token comment"># kubectl rollout status deployment/nginx-deployment</span>
Waiting <span class="token keyword">for</span> deployment <span class="token string">"nginx-deployment"</span> rollout to finish: <span class="token number">1</span> out of <span class="token number">3</span> new replicas have been updated<span class="token punctuation">..</span>.

<span class="token comment"># 镜像拉取失败</span>
root@k8s-master:~<span class="token comment"># kubectl get pods</span>
NAME                                READY   STATUS             RESTARTS   AGE
nginx-deployment-5d457cdfc8-7whnx   <span class="token number">1</span>/1     Running            <span class="token number">0</span>          7m50s
nginx-deployment-5d457cdfc8-b7njk   <span class="token number">1</span>/1     Running            <span class="token number">0</span>          8m8s
nginx-deployment-5d457cdfc8-x4zv8   <span class="token number">1</span>/1     Running            <span class="token number">0</span>          7m39s
nginx-deployment-6b7d6c469c-zcjps   <span class="token number">0</span>/1     ImagePullBackOff   <span class="token number">0</span>          92s

<span class="token comment"># 开始回滚</span>
<span class="token number">1</span>.查看历史版本
root@k8s-master:~<span class="token comment"># kubectl rollout history deployments/nginx-deployment</span>
deployment.apps/nginx-deployment
REVISION  CHANGE-CAUSE
<span class="token number">1</span>         <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>
<span class="token number">2</span>         kubectl <span class="token builtin class-name">set</span> image deployments/nginx-deployment <span class="token assign-left variable">nginx</span><span class="token operator">=</span>nginx:1.17.1 <span class="token parameter variable">--record</span><span class="token operator">=</span>true
<span class="token number">3</span>         kubectl <span class="token builtin class-name">set</span> image deployments/nginx-deployment <span class="token assign-left variable">nginx</span><span class="token operator">=</span>nginx:1.172 <span class="token parameter variable">--record</span><span class="token operator">=</span>true

<span class="token number">2</span>.查看某个版本
root@k8s-master:~<span class="token comment"># kubectl rollout history deployment.v1.apps/nginx-deployment --revision=2</span>
deployment.apps/nginx-deployment with revision <span class="token comment">#2</span>
Pod Template:
  Labels:       <span class="token assign-left variable">app</span><span class="token operator">=</span>nginx
        pod-template-hash<span class="token operator">=</span>5d457cdfc8
  Annotations:  kubernetes.io/change-cause: kubectl <span class="token builtin class-name">set</span> image deployments/nginx-deployment <span class="token assign-left variable">nginx</span><span class="token operator">=</span>nginx:1.17.1 <span class="token parameter variable">--record</span><span class="token operator">=</span>true
  Containers:
   nginx:
    Image:      nginx:1.17.1
    Port:       <span class="token number">80</span>/TCP
    Host Port:  <span class="token number">0</span>/TCP
    Environment:        <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>
    Mounts:     <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>
  Volumes:      <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>
  Node-Selectors:       <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>
  Tolerations:  <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>


<span class="token number">3</span>.回滚到某个版本
root@k8s-master:~<span class="token comment"># kubectl rollout undo deployments/nginx-deployment --to-revision=2</span>
deployment.apps/nginx-deployment rolled back

root@k8s-master:~<span class="token comment"># kubectl rollout status deployment/nginx-deployment</span>
deployment <span class="token string">"nginx-deployment"</span> successfully rolled out

root@k8s-master:~<span class="token comment"># kubectl get deployment.apps</span>
NAME               READY   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment   <span class="token number">3</span>/3     <span class="token number">3</span>            <span class="token number">3</span>           23m<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="10-5-5-伸缩Deployment"><a href="#10-5-5-伸缩Deployment" class="headerlink" title="10.5.5 伸缩Deployment"></a>10.5.5 伸缩Deployment</h3><p>  将指定的deployment副本更改为10</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># kubectl scale deployments/nginx-deployment --replicas=10</span>
deployment.apps/nginx-deployment scaled

root@k8s-master:~<span class="token comment"># kubectl get deployments.apps,replicasets.apps -l app=nginx</span>
NAME                               READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/nginx-deployment   <span class="token number">10</span>/10   <span class="token number">10</span>           <span class="token number">10</span>          25m

NAME                                          DESIRED   CURRENT   READY   AGE
replicaset.apps/nginx-deployment-5d457cdfc8   <span class="token number">10</span>        <span class="token number">10</span>        <span class="token number">10</span>      21m
replicaset.apps/nginx-deployment-6b7d6c469c   <span class="token number">0</span>         <span class="token number">0</span>         <span class="token number">0</span>       14m
replicaset.apps/nginx-deployment-8d94c585f    <span class="token number">0</span>         <span class="token number">0</span>         <span class="token number">0</span>       25m

root@k8s-master:~<span class="token comment"># kubectl delete deployments.apps nginx-deployment</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="10-6-DaemonSet"><a href="#10-6-DaemonSet" class="headerlink" title="10.6 DaemonSet"></a>10.6 DaemonSet</h2><p>  DaemonSet确保全部（或某些）节点上运行一个 Pod 的副本。 当有节点加入集群时， 也会为他们新增一个 Pod 。 当有节点从集群移除时，这些 Pod 也会被回收。删除DaemonSet将会删除它创建的所有Pod</p>
<p>  DaemonSet 的一些典型用法：</p>
<p>  1.在每个节点上运行集群守护进程</p>
<p>  2.在每个节点上运行日志收集守护进程</p>
<p>  3.在每个节点上运行监控守护进程</p>
<p><img src="/images/DaemonSet.png"></p>
<p>使用busybox镜像，在每一个节点上都运行一个pod：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">cat</span> <span class="token operator">&gt;</span> daemonset.yml <span class="token operator">&lt;&lt;</span><span class="token string">EOF
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: luovip
  labels:
    daemonset: test
spec:
  selector:
    matchLabels:
      name: testpod
  template:
    metadata:
      labels:
        name: testpod
    spec:
      containers:
      - name: hello
        image: busybox
        imagePullPolicy: IfNotPresent
        command: ['sh', '-c', 'sleep 3600']
EOF</span>

root@k8s-master:~<span class="token comment"># kubectl create -f daemonset.yml</span>
daemonset.apps/luovip created
root@k8s-master:~<span class="token comment"># kubectl get daemonsets.apps</span>
NAME     DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE
luovip   <span class="token number">2</span>         <span class="token number">2</span>         <span class="token number">2</span>       <span class="token number">2</span>            <span class="token number">2</span>           <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>          19s

root@k8s-master:~<span class="token comment"># kubectl get pod -o wide</span>
NAME      READY   STATUS    RESTARTS   AGE   IP               NODE          NOMINATED NODE   READINESS GATES
luovip-bxkmh      <span class="token number">1</span>/1     Running   <span class="token number">0</span>          95s   <span class="token number">172.16</span>.126.33    k8s-worker2   <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>           <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>
luovip-fj5mz      <span class="token number">1</span>/1     Running   <span class="token number">0</span>          95s   <span class="token number">172.16</span>.194.105   k8s-worker1   <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>           <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>
<span class="token punctuation">..</span>.

root@k8s-master:~<span class="token comment"># kubectl delete -f daemonset.yml</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>  DaemonSet总结：</p>
<p>  1.默认情况下， DaemonSet会在所有Node上创建一个Pod</p>
<p>  2.如果将运行的pod删除，DaemonSet会自动启动一个新的</p>
<p>  3.当有新节点加入集群时，会自动向其部署Pod</p>
<p>  4.当节点离开集群时，其上的节点会销毁，而不会跑到其他节点上</p>
<h2 id="10-7-StatefulSet"><a href="#10-7-StatefulSet" class="headerlink" title="10.7 StatefulSet"></a>10.7 StatefulSet</h2><p>  StatefulSet管理基于相同容器规约的一组 Pod。但和Deployment不同的是， StatefulSet为它们的每个Pod维护了一个有粘性的 ID。这些 Pod 是基于相同的规约来创建的， 但是不能相互替换：无论怎么调度，每个 Pod 都有一个永久不变的 ID<br>  StatefulSets 对于需要满足以下一个或多个需求的应用程序很有价值：</p>
<p>  1.稳定的、唯一的网络标识符</p>
<p>  2.稳定的、持久的存储</p>
<p>  3.有序的、优雅的部署和缩放</p>
<p>  4.有序的、自动的滚动更新</p>
<p><img src="/images/StatefulSet.png"></p>
<h3 id="10-7-1-创建yml文件"><a href="#10-7-1-创建yml文件" class="headerlink" title="10.7.1 创建yml文件"></a>10.7.1 创建yml文件</h3><p>  使用nginx镜像，创建一个副本数为3的有状态应用，并挂载本地目录到容器中</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">cat</span> <span class="token operator">&gt;</span> statefulset.yml <span class="token operator">&lt;&lt;</span><span class="token string">EOF
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: web
spec:
  selector:
    matchLabels:
      app: nginx
  serviceName: "nginx"
  replicas: 3
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.17.2
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 80
          name: web
        volumeMounts:
        - name: www
          mountPath: /usr/share/nginx/html
      volumes:
         - name: www
           emptyDir: {}
EOF</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="10-7-2-操作StatefulSet"><a href="#10-7-2-操作StatefulSet" class="headerlink" title="10.7.2 操作StatefulSet"></a>10.7.2 操作StatefulSet</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 发现创建的过程是有次序的，这也验证了有状态应用的启动顺序</span>
root@k8s-master:~<span class="token comment"># kubectl create -f statefulset.yml</span>
statefulset.apps/web created

root@k8s-master:~<span class="token comment"># kubectl get pods -w</span>
NAME                                READY   STATUS    RESTARTS   AGE
web-0                               <span class="token number">0</span>/1     Pending   <span class="token number">0</span>          0s
web-0                               <span class="token number">0</span>/1     Pending   <span class="token number">0</span>          0s
web-0                               <span class="token number">0</span>/1     ContainerCreating   <span class="token number">0</span>          1s
web-0                               <span class="token number">0</span>/1     ContainerCreating   <span class="token number">0</span>          1s
web-0                               <span class="token number">0</span>/1     ErrImagePull        <span class="token number">0</span>          82s
web-0                               <span class="token number">0</span>/1     ImagePullBackOff    <span class="token number">0</span>          96s
web-0                               <span class="token number">1</span>/1     Running             <span class="token number">0</span>          108s
web-1                               <span class="token number">0</span>/1     Pending             <span class="token number">0</span>          0s
web-1                               <span class="token number">0</span>/1     Pending             <span class="token number">0</span>          0s
web-1                               <span class="token number">0</span>/1     ContainerCreating   <span class="token number">0</span>          0s
web-1                               <span class="token number">0</span>/1     ContainerCreating   <span class="token number">0</span>          0s
web-1                               <span class="token number">1</span>/1     Running             <span class="token number">0</span>          11s
web-2                               <span class="token number">0</span>/1     Pending             <span class="token number">0</span>          0s
web-2                               <span class="token number">0</span>/1     Pending             <span class="token number">0</span>          0s
web-2                               <span class="token number">0</span>/1     ContainerCreating   <span class="token number">0</span>          0s
web-2                               <span class="token number">0</span>/1     ContainerCreating   <span class="token number">0</span>          0s
web-2                               <span class="token number">1</span>/1     Running             <span class="token number">0</span>          1s

root@k8s-master:~<span class="token comment"># kubectl get pods</span>
NAME                                READY   STATUS    RESTARTS   AGE
web-0                               <span class="token number">1</span>/1     Running   <span class="token number">0</span>          3m36s
web-1                               <span class="token number">1</span>/1     Running   <span class="token number">0</span>          108s
web-2                               <span class="token number">1</span>/1     Running   <span class="token number">0</span>          97s

root@k8s-master:~<span class="token comment"># kubectl delete -f statefulset.yml</span>
statefulset.apps <span class="token string">"web"</span> deleted<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="10-8-Job"><a href="#10-8-Job" class="headerlink" title="10.8 Job"></a>10.8 Job</h2><p>  不断打印CKA JOB字符串，失败最多重试4次</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">cat</span> <span class="token operator">&gt;</span> job.yml <span class="token operator">&lt;&lt;</span><span class="token string">EOF
apiVersion: batch/v1
kind: Job
metadata:
  name: pi
spec:
  template:
    spec:
      containers:
      - name: pi
        image: busybox
        imagePullPolicy: IfNotPresent
        command: ["sh",  "-c", "while true;do echo CKA JOB;done"]
      restartPolicy: Never
  backoffLimit: 4
EOF</span>

root@k8s-master:~<span class="token comment"># kubectl create -f job.yml</span>
job.batch/pi created
root@k8s-master:~<span class="token comment"># kubectl get jobs,pods</span>
NAME           STATUS    COMPLETIONS   DURATION   AGE
job.batch/pi   Running   <span class="token number">0</span>/1           10s        10s

NAME           READY   STATUS    RESTARTS   AGE
pod/pi-rglzp   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          10s

root@k8s-master:~<span class="token comment"># kubectl logs pi-rglzp</span>
CKA <span class="token environment constant">JOB</span>
CKA <span class="token environment constant">JOB</span>
CKA <span class="token environment constant">JOB</span>
<span class="token punctuation">..</span>.

root@k8s-master:~<span class="token comment"># kubectl delete -f job.yml</span>
job.batch <span class="token string">"pi"</span> deleted<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="10-9-CronJob"><a href="#10-9-CronJob" class="headerlink" title="10.9 CronJob"></a>10.9 CronJob</h2><p>  每分钟打印一次指定字符串</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">cat</span> <span class="token operator">&gt;</span> cronjob.yml <span class="token operator">&lt;&lt;</span><span class="token string">EOF
apiVersion: batch/v1
kind: CronJob
metadata:
  name: cronjobtest
spec:
  schedule: "*/1 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: hello
            image: busybox
            imagePullPolicy: IfNotPresent
            command:
            - /bin/sh
            - -c
            - date; echo Hello from the Kubernetes cluster
          restartPolicy: OnFailure
EOF</span>

root@k8s-master:~<span class="token comment"># kubectl create -f cronjob.yml</span>
cronjob.batch/cronjobtest created

root@k8s-master:~<span class="token comment"># kubectl get cronjobs,pod</span>
NAME                        SCHEDULE      TIMEZONE   SUSPEND   ACTIVE   LAST SCHEDULE   AGE
cronjob.batch/cronjobtest   */1 * * * *   <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>     False     <span class="token number">0</span>        34s             35s

NAME                             READY   STATUS      RESTARTS   AGE
pod/cronjobtest-29127403-mb9qx   <span class="token number">0</span>/1     Completed   <span class="token number">0</span>          34s

root@k8s-master:~<span class="token comment"># kubectl logs cronjobtest-29127403-mb9qx</span>
Mon May <span class="token number">19</span> 08:43:01 UTC <span class="token number">2025</span>
Hello from the Kubernetes cluster

root@k8s-master:~<span class="token comment"># kubectl get cronjobs,pod</span>
NAME                        SCHEDULE      TIMEZONE   SUSPEND   ACTIVE   LAST SCHEDULE   AGE
cronjob.batch/cronjobtest   */1 * * * *   <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>     False     <span class="token number">0</span>        9s              2m10s

NAME                             READY   STATUS      RESTARTS   AGE
pod/cronjobtest-29127403-mb9qx   <span class="token number">0</span>/1     Completed   <span class="token number">0</span>          2m9s
pod/cronjobtest-29127404-9jmbj   <span class="token number">0</span>/1     Completed   <span class="token number">0</span>          69s
pod/cronjobtest-29127405-h5cc7   <span class="token number">0</span>/1     Completed   <span class="token number">0</span>          9s


<span class="token comment"># 关于展示的任务次数的显示等的修改</span>
root@k8s-master:~<span class="token comment"># kubectl explain cronjob.spec</span>

root@k8s-master:~<span class="token comment"># kubectl delete -f cronjob.yml</span>
cronjob.batch <span class="token string">"cronjobtest"</span> deleted<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h1 id="11-Service-服务发现"><a href="#11-Service-服务发现" class="headerlink" title="11 Service 服务发现"></a>11 Service 服务发现</h1><h2 id="11-1-Service"><a href="#11-1-Service" class="headerlink" title="11.1 Service"></a>11.1 Service</h2><p>  Pod是非永久性资源，每个Pod都有自己的IP地址</p>
<p>  如果一组Pod（称为“后端”）为集群内的其他Pod（称为“前端”）提供功能， 那么前端如何找出并跟踪要连接的IP地址，以便前端可以使用提供工作负载的后端部分</p>
<p><img src="/images/Service.png"></p>
<h2 id="11-2-Service类型"><a href="#11-2-Service类型" class="headerlink" title="11.2 Service类型"></a>11.2 Service类型</h2><p>  ClusterIP：通过集群的内部IP暴露服务，选择该值时服务只能够在集群内部访问。 这也是默认的ServiceType<br>  NodePort：通过每个节点上的IP和静态端口（NodePort）暴露服务。 NodePort服务会路由到自动创建的ClusterIP服务。 通过请求 &lt;节点 IP&gt;:&lt;节点端口&gt;，可以从集群的外部访问一个NodePort服务<br>  LoadBalancer：使用云提供商的负载均衡器向外部暴露服务。 外部负载均衡器可以将流量路由到自动创建的NodePort服务和ClusterIP 服务上<br>  ExternalName：通过返回CNAME和对应值，可以将服务映射到externalName字段的内容（例如，foo.bar.example.com）。 无需创建任何类型代理</p>
<p><img src="/images/Service%E8%AE%BF%E9%97%AE.png"></p>
<h2 id="11-3-iptables代理模式的Service"><a href="#11-3-iptables代理模式的Service" class="headerlink" title="11.3 iptables代理模式的Service"></a>11.3 iptables代理模式的Service</h2><p>  kube-proxy会监视Kubernetes 控制节点对Service对象和Endpoints对象的添加和移除。 对每个Service，它会配置iptables规则，从而捕获到达该Service的clusterIP和端口的请求，进而将请求重定向到 Service 的一组后端中的某个Pod上面。 对于每个Endpoints对象，它也会配置iptables规则，这个规则会选择一个后端组合<br>  默认的策略是，kube-proxy在iptables模式下随机选择一个后端<br>  使用iptables处理流量具有较低的系统开销，因为流量由Linux netfilter处理， 而无需在用户空间和内核空间之间切换。 这种方法也可能更可靠</p>
<h2 id="11-4-IPVS代理模式的Service"><a href="#11-4-IPVS代理模式的Service" class="headerlink" title="11.4 IPVS代理模式的Service"></a>11.4 IPVS代理模式的Service</h2><p>  在ipvs模式下，kube-proxy监视Kubernetes服务和端点，调用netlink接口相应地创建IPVS规则， 并定期将IPVS规则与Kubernetes服务和端点同步。 该控制循环可确保IPVS 状态与所需状态匹配。访问服务时，IPVS将流量定向到后端Pod之一<br>  IPVS代理模式基于类似于iptables模式的netfilter挂钩函数， 但是使用哈希表作为基础数据结构，并且在内核空间中工作。 这意味着，与 iptables模式下的kube-proxy相比，IPVS模式下的kube-proxy重定向通信的延迟要短，并且在同步代理规则时具有更好的性能。 与其他代理模式相比，IPVS模式还支持更高的网络流量吞吐量</p>
<h2 id="11-5-生成Service"><a href="#11-5-生成Service" class="headerlink" title="11.5 生成Service"></a>11.5 生成Service</h2><h3 id="11-5-1-准备后端Pod"><a href="#11-5-1-准备后端Pod" class="headerlink" title="11.5.1 准备后端Pod"></a>11.5.1 准备后端Pod</h3><p>  用nginx镜像准备一个3副本的deployment作为后端，并开放80端口</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">cat</span> <span class="token operator">&gt;</span> deployment-service.yml <span class="token operator">&lt;&lt;</span><span class="token string">EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment-servicetest
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.16.1
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 80
EOF</span>

root@k8s-master:~<span class="token comment"># kubectl create -f deployment-service.yml</span>
deployment.apps/nginx-deployment-servicetest created
root@k8s-master:~<span class="token comment"># kubectl get pods -o wide</span>
NAME      READY   STATUS    RESTARTS   AGE   IP        NODE          NOMINATED NODE   READINESS GATES
nginx-deployment-servicetest-8d94c585f-6ktj9 <span class="token number">1</span>/1  Running <span class="token number">0</span> 13s <span class="token number">172.16</span>.126.35 k8s-worker2 <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>   <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>
nginx-deployment-servicetest-8d94c585f-jclrr <span class="token number">1</span>/1  Running <span class="token number">0</span> 13s <span class="token number">172.16</span>.194.117 k8s-worker1 <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>     <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>
nginx-deployment-servicetest-8d94c585f-wgztv <span class="token number">1</span>/1  Running <span class="token number">0</span> 13s <span class="token number">172.16</span>.194.116 k8s-worker1   <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>  <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>
root@k8s-master:~<span class="token comment"># curl 172.16.126.35</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="11-5-2-命令行生成Service"><a href="#11-5-2-命令行生成Service" class="headerlink" title="11.5.2 命令行生成Service"></a>11.5.2 命令行生成Service</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 用kubectl expose的命令创建一个针对deployment的服务，并查询endpoint是否准备就绪</span>
root@k8s-master:~<span class="token comment"># kubectl expose deployment nginx-deployment-servicetest --port=9000 --name=luoyuservice --target-port=80 --type=NodePort</span>
service/luoyuservice exposed

root@k8s-master:~<span class="token comment"># kubectl get service,endpoints</span>
NAME                   TYPE        CLUSTER-IP     EXTERNAL-IP   PORT<span class="token punctuation">(</span>S<span class="token punctuation">)</span>          AGE
service/kubernetes     ClusterIP   <span class="token number">10.96</span>.0.1      <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>        <span class="token number">443</span>/TCP          2d13h
service/luoyuservice   NodePort    <span class="token number">10.105</span>.8.223   <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>        <span class="token number">9000</span>:32646/TCP   26s

NAME                     ENDPOINTS                                              AGE
endpoints/kubernetes     <span class="token number">192.168</span>.8.3:6443                                       2d13h
endpoints/luoyuservice   <span class="token number">172.16</span>.126.35:80,172.16.194.116:80,172.16.194.117:80   26s

root@k8s-master:~<span class="token comment"># curl http://192.168.8.3:32646</span>
<span class="token punctuation">..</span>.
<span class="token operator">&lt;</span>title<span class="token operator">&gt;</span>Welcome to nginx<span class="token operator">!</span><span class="token operator">&lt;</span>/title<span class="token operator">&gt;</span>

root@k8s-master:~<span class="token comment"># kubectl delete service luoyuservice</span>
<span class="token function">service</span> <span class="token string">"luoyuservice"</span> deleted<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="11-6-ClusterIP类型的Service"><a href="#11-6-ClusterIP类型的Service" class="headerlink" title="11.6 ClusterIP类型的Service"></a>11.6 ClusterIP类型的Service</h2><p>  ClusterIP是默认的Service类型，对外提供8000端口，并把流量引流到具有app: nginx的后端80端口上</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">cat</span> <span class="token operator">&gt;</span> clusterip.yml <span class="token operator">&lt;&lt;</span><span class="token string">EOF
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app: nginx
  ports:
    - protocol: TCP
      port: 8000
      targetPort: 80
EOF</span>

root@k8s-master:~<span class="token comment"># kubectl create -f clusterip.yml</span>
service/my-service created

root@k8s-master:~<span class="token comment"># kubectl get service,endpoints</span>
NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT<span class="token punctuation">(</span>S<span class="token punctuation">)</span>    AGE
service/kubernetes   ClusterIP   <span class="token number">10.96</span>.0.1       <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>        <span class="token number">443</span>/TCP    3d2h
service/my-service   ClusterIP   <span class="token number">10.101</span>.56.206   <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>        <span class="token number">8000</span>/TCP   2m35s

NAME                   ENDPOINTS                                              AGE
endpoints/kubernetes   <span class="token number">192.168</span>.8.3:6443                                       3d2h
endpoints/my-service   <span class="token number">172.16</span>.126.35:80,172.16.194.116:80,172.16.194.117:80   2m35s

root@k8s-master:~<span class="token comment"># curl 10.101.56.206:8000</span>
<span class="token punctuation">..</span>.
<span class="token operator">&lt;</span>title<span class="token operator">&gt;</span>Welcome to nginx<span class="token operator">!</span><span class="token operator">&lt;</span>/title<span class="token operator">&gt;</span>

root@k8s-master:~<span class="token comment"># kubectl delete -f clusterip.yml</span>
<span class="token function">service</span> <span class="token string">"my-service"</span> deleted<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="11-7-NodePort类型的Service"><a href="#11-7-NodePort类型的Service" class="headerlink" title="11.7 NodePort类型的Service"></a>11.7 NodePort类型的Service</h2><p>  Type: NodePort将会在节点的特定端口上开通服务，指定了端口为31788</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">cat</span> <span class="token operator">&gt;</span> nodeport.yml <span class="token operator">&lt;&lt;</span><span class="token string">EOF
apiVersion: v1
kind: Service
metadata:
  name: nodeservice
spec:
  type: NodePort
  selector:
    app: nginx
  ports:
    - protocol: TCP
      port: 8000
      targetPort: 80
      nodePort: 31788
EOF</span>


root@k8s-master:~<span class="token comment"># kubectl create -f nodeport.yml</span>
service/nodeservice created

root@k8s-master:~<span class="token comment"># kubectl get service,endpoints</span>
NAME                  TYPE        CLUSTER-IP       EXTERNAL-IP   PORT<span class="token punctuation">(</span>S<span class="token punctuation">)</span>          AGE
service/kubernetes    ClusterIP   <span class="token number">10.96</span>.0.1        <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>        <span class="token number">443</span>/TCP          3d3h
service/nodeservice   NodePort    <span class="token number">10.102</span>.124.139   <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>        <span class="token number">8000</span>:31788/TCP   27s

NAME                    ENDPOINTS                                              AGE
endpoints/kubernetes    <span class="token number">192.168</span>.8.3:6443                                       3d3h
endpoints/nodeservice   <span class="token number">172.16</span>.126.35:80,172.16.194.116:80,172.16.194.117:80   27s

<span class="token comment"># 因为是nodeport，所以用节点IP</span>
root@k8s-master:~<span class="token comment"># curl 192.168.8.4:31788</span>
<span class="token punctuation">..</span>.
<span class="token operator">&lt;</span>title<span class="token operator">&gt;</span>Welcome to nginx<span class="token operator">!</span><span class="token operator">&lt;</span>/title<span class="token operator">&gt;</span>

root@k8s-master:~<span class="token comment"># kubectl delete -f nodeport.yml</span>
<span class="token function">service</span> <span class="token string">"nodeservice"</span> deleted<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="11-8-Headless类型的Service"><a href="#11-8-Headless类型的Service" class="headerlink" title="11.8 Headless类型的Service"></a>11.8 Headless类型的Service</h2><h3 id="11-8-1-服务实现"><a href="#11-8-1-服务实现" class="headerlink" title="11.8.1 服务实现"></a>11.8.1 服务实现</h3><p>  在此类型的Service中，将不会只返回Service IP，会直接返回众多Pod 的IP地址，所以需要进入pod中用集群内DNS进行测试</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">cat</span> <span class="token operator">&gt;</span> headless.yml <span class="token operator">&lt;&lt;</span><span class="token string">EOF
apiVersion: v1
kind: Service
metadata:
  name: headless
spec:
  clusterIP: None
  selector:
    app: nginx
  ports:
    - protocol: TCP
      port: 8000
      targetPort: 80
EOF</span>

root@k8s-master:~<span class="token comment"># kubectl create -f headless.yml</span>
service/headless created

root@k8s-master:~<span class="token comment"># kubectl get service,endpoints</span>
NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT<span class="token punctuation">(</span>S<span class="token punctuation">)</span>    AGE
service/headless     ClusterIP   None         <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>        <span class="token number">8000</span>/TCP   25s
service/kubernetes   ClusterIP   <span class="token number">10.96</span>.0.1    <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>        <span class="token number">443</span>/TCP    3d3h

NAME                   ENDPOINTS                                              AGE
endpoints/headless     <span class="token number">172.16</span>.126.35:80,172.16.194.116:80,172.16.194.117:80   25s
endpoints/kubernetes   <span class="token number">192.168</span>.8.3:6443                                       3d3h<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="11-8-2-测试Headless服务发现"><a href="#11-8-2-测试Headless服务发现" class="headerlink" title="11.8.2 测试Headless服务发现"></a>11.8.2 测试Headless服务发现</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># kubectl run --rm --image=busybox:1.28 -it testpod</span>
If you don<span class="token string">'t see a command prompt, try pressing enter.
/ # nslookup headless
Server:    10.96.0.10
Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local

Name:      headless
Address 1: 172.16.194.117 172-16-194-117.headless.default.svc.cluster.local
Address 2: 172.16.194.116 172-16-194-116.headless.default.svc.cluster.local
Address 3: 172.16.126.35 172-16-126-35.headless.default.svc.cluster.local
/ # exit
Session ended, resume using '</span>kubectl attach testpod <span class="token parameter variable">-c</span> testpod <span class="token parameter variable">-i</span> -t' <span class="token builtin class-name">command</span> when the pod is running
pod <span class="token string">"testpod"</span> deleted

root@k8s-master:~<span class="token comment"># kubectl delete -f headless.yml</span>
<span class="token function">service</span> <span class="token string">"headless"</span> deleted<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>服务的DNS记录名称为：</p>
<p>  servicename.namespace.svc.cluster.local</p>
<p>deployment中Pod的DNS记录名称为：</p>
<p>  podIP.servicename.namespace.svc.cluster.local</p>
<p>Client访问服务时，可以使用DNS记录便捷抵达服务，甚至与服务在同一namespace时，直接用 servicename进行访问</p>
<h2 id="11-9-LoadBalancer类型的Service"><a href="#11-9-LoadBalancer类型的Service" class="headerlink" title="11.9 LoadBalancer类型的Service"></a>11.9 LoadBalancer类型的Service</h2><h3 id="11-9-1-部署metallb负载均衡"><a href="#11-9-1-部署metallb负载均衡" class="headerlink" title="11.9.1 部署metallb负载均衡"></a>11.9.1 部署metallb负载均衡</h3><p>1.先部署一个metallb controller和Speaker：</p>
<p>  1.metallb controller用于负责监听Kubernetes Service的变化，当服务类型被设置为LoadBalancer时，Controller会从一个预先配置的IP地址池中分配一个 IP地址给该服务，并管理这个IP地址的生命周期</p>
<p>  2.Speaker负责将服务的 IP 地址通过标准的路由协议广播到网络中，确保外部流量能够正确路由到集群中的服务</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># kubectl apply -f https://www.linuxcenter.cn/files/cka/cka-yaml/metallb-native.yaml</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>2.定义一组由负载均衡对外分配的IP地址范围</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">cat</span> <span class="token operator">&gt;</span> ippool.yml <span class="token operator">&lt;&lt;-</span><span class="token string">EOF
apiVersion: metallb.io/v1beta1
kind: IPAddressPool
metadata:
  name: lxh-ip-pool-192-168-8-10-100
  namespace: metallb-system
spec:
  addresses:
  - 192.168.8.10-192.168.8.100
EOF</span>

root@k8s-master:~<span class="token comment"># kubectl apply -f ippool.yml</span>
ipaddresspool.metallb.io/lxh-ip-pool-192-168-8-10-100 created<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>3.在 Layer 2 模式下用于控制如何通过 ARP（Address Resolution Protocol）或 NDP（Neighbor Discovery Protocol）协议宣告服务的 IP 地址，使得这些 IP 地址在本地网络中可解析</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">cat</span> <span class="token operator">&gt;</span> l2Advertisement.yml <span class="token operator">&lt;&lt;-</span><span class="token string">EOF
apiVersion: metallb.io/v1beta1
kind: L2Advertisement
metadata:
  name: l2-myippool
  namespace: metallb-system
spec:
  ipAddressPools:
  - lxh-ip-pool-192-168-8-10-100
EOF</span>

root@k8s-master:~<span class="token comment"># kubectl apply -f l2Advertisement.yml</span>
l2advertisement.metallb.io/l2-myippool created<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="11-9-2-部署LoadBalancer服务"><a href="#11-9-2-部署LoadBalancer服务" class="headerlink" title="11.9.2 部署LoadBalancer服务"></a>11.9.2 部署LoadBalancer服务</h3><p>  负载均衡准备好之后，创建LoadBalancer类型的服务</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">cat</span> <span class="token operator">&gt;</span> loadbalancer.yml <span class="token operator">&lt;&lt;-</span><span class="token string">EOF
apiVersion: v1
kind: Service
metadata:
  name: loadbalance-service
spec:
  selector:
    app: nginx
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
  type: LoadBalancer
EOF</span>

root@k8s-master:~<span class="token comment"># kubectl apply -f loadbalancer.yml</span>
service/loadbalance-service created

<span class="token comment"># 获取服务看看是否分配到了负载均衡IP  从输出上看，分配到了192.168.8.10</span>
root@k8s-master:~<span class="token comment"># kubectl get service</span>
NAME                  TYPE           CLUSTER-IP     EXTERNAL-IP    PORT<span class="token punctuation">(</span>S<span class="token punctuation">)</span>        AGE
kubernetes            ClusterIP      <span class="token number">10.96</span>.0.1      <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>         <span class="token number">443</span>/TCP        3d4h
loadbalance-service   LoadBalancer   <span class="token number">10.99</span>.147.16   <span class="token number">192.168</span>.8.10   <span class="token number">80</span>:30972/TCP   10s

<span class="token comment"># 用负载均衡IP访问</span>
root@k8s-master:~<span class="token comment"># curl 192.168.8.10</span>
<span class="token punctuation">..</span>.
<span class="token operator">&lt;</span>title<span class="token operator">&gt;</span>Welcome to nginx<span class="token operator">!</span><span class="token operator">&lt;</span>/title<span class="token operator">&gt;</span>

<span class="token comment"># 删除service资源</span>
root@k8s-master:~<span class="token comment"># kubectl delete -f loadbalancer.yml</span>
<span class="token function">service</span> <span class="token string">"loadbalance-service"</span> deleted<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="11-10-Ingress"><a href="#11-10-Ingress" class="headerlink" title="11.10 Ingress"></a>11.10 Ingress</h2><p>  Ingress公开了从集群外部到集群内服务的HTTP和HTTPS路由</p>
<p>  流量路由由Ingress资源上定义的规则控制</p>
<p>  Ingress可以提供负载均衡、SSL卸载和基于名称的虚拟托管，为了让Ingress资源工作，集群必须有一个正在运行的Ingress控制器</p>
<p><img src="/images/Ingress.png"></p>
<h3 id="11-10-1-Ingress控制器部署"><a href="#11-10-1-Ingress控制器部署" class="headerlink" title="11.10.1 Ingress控制器部署"></a>11.10.1 Ingress控制器部署</h3><p>  Ingress需要Ingress控制器支持，先部署控制器</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 拉取v1.1.0版本的yaml文件</span>
<span class="token comment"># 使用如下路径下载-可能会失败</span>
<span class="token function">wget</span> https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.1.0/deploy/static/provider/baremetal/deploy.yaml

root@k8s-master:~<span class="token comment"># wget https://www.linuxcenter.cn/files/cka/cka-yaml/ingressdeploy.yaml</span>

<span class="token comment"># 从阿里云的镜像仓库上面拉取镜像</span>
<span class="token function">docker</span> pull registry.cn-hangzhou.aliyuncs.com/google_containers/nginx-ingress-controller:v1.12.1
<span class="token function">docker</span> pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-webhook-certgen:v1.5.2

<span class="token comment"># 在Kubernetes Ingress 的使用场景中，尤其是使用Ingress-Nginx作为 Ingress Controller 时，kube-webhook-certgen工具被用来创建和更新用于TLS认证的证书。这些证书被用于确保 Webhook 与 Kubernetes API 服务器之间的通信是安全的</span>

<span class="token comment"># 修改ingressdeploy.yaml文件</span>
<span class="token number">440</span>行改为 image: registry.cn-hangzhou.aliyuncs.com/google_containers/nginx-ingress-controller:v1.12.1
<span class="token number">542</span>行改为image: registry.cn-hangzhou.aliyuncs.com/google_containers/kube-webhook-certgen:v1.5.2
<span class="token number">596</span>行改为 image: registry.cn-hangzhou.aliyuncs.com/google_containers/kube-webhook-certgen:v1.5.2
root@k8s-master:~<span class="token comment"># kubectl apply -f ingressdeploy.yaml</span>

root@k8s-master:~<span class="token comment"># kubectl get pod -n ingress-nginx</span>
NAME                                   READY   STATUS      RESTARTS   AGE
ingress-nginx-admission-create-k9smq   <span class="token number">0</span>/1     Completed   <span class="token number">0</span>          17m
ingress-nginx-admission-patch-46hk7    <span class="token number">0</span>/1     Completed   <span class="token number">2</span>          17m
ingress-nginx-controller-47nzv         <span class="token number">1</span>/1     Running     <span class="token number">0</span>          17m
ingress-nginx-controller-svcpx         <span class="token number">1</span>/1     Running     <span class="token number">0</span>          17m

<span class="token comment"># admission相关pod状态为Completed为正常</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="11-10-2-Ingress路径类型"><a href="#11-10-2-Ingress路径类型" class="headerlink" title="11.10.2 Ingress路径类型"></a>11.10.2 Ingress路径类型</h3><p>  Ingress中的每个路径都需要有对应的路径类型，未明确设置pathType的路径无法通过合法性检查。当前支持的路径类型有三种：</p>
<p>  1.ImplementationSpecific：对于这种路径类型，匹配方法取决于IngressClass。 具体实现可以将其作为单独的pathType处理或者与Prefix或 Exact类型作相同处理</p>
<p>  2.Exact：精确匹配URL路径，且区分大小写</p>
<p>  3.Prefix：基于以 / 分隔的URL路径前缀匹配。匹配区分大小写，并且对路径中的元素逐个完成。 路径元素指的是由/分隔符分隔的路径中的标签列表。 如果每个p都是请求路径p的元素前缀，则请求与路径p匹配</p>
<h3 id="11-10-3-Ingress的使用"><a href="#11-10-3-Ingress的使用" class="headerlink" title="11.10.3 Ingress的使用"></a>11.10.3 Ingress的使用</h3><p>  用nginx镜像生成一个3副本的Pod，并通过Service提供服务，然后再用ingress，以特定域名的方式对外暴露</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">cat</span> <span class="token operator">&gt;</span> ingress.yml <span class="token operator">&lt;&lt;</span><span class="token string">EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment-ingress
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.16.1
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: ingressservice
spec:
  selector:
    app: nginx
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: luovip
spec:
  ingressClassName: nginx
  rules:
    - host: www.luovip.com
      http:
        paths:
          - pathType: Prefix
            path: "/"
            backend:
              service:
                name: ingressservice
                port:
                  number: 80
EOF</span>


root@k8s-master:~<span class="token comment"># kubectl create -f ingress.yml</span>
deployment.apps/nginx-deployment-ingress created
service/ingressservice created
ingress.networking.k8s.io/luovip created

root@k8s-master:~<span class="token comment"># kubectl get deployments,service,ingress</span>
NAME                                           READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/nginx-deployment-ingress       <span class="token number">3</span>/3     <span class="token number">3</span>            <span class="token number">3</span>           38s
deployment.apps/nginx-deployment-servicetest   <span class="token number">3</span>/3     <span class="token number">3</span>            <span class="token number">3</span>           24h

NAME                     TYPE        CLUSTER-IP      EXTERNAL-IP   PORT<span class="token punctuation">(</span>S<span class="token punctuation">)</span>   AGE
service/ingressservice   ClusterIP   <span class="token number">10.98</span>.162.124   <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>        <span class="token number">80</span>/TCP    38s
service/kubernetes       ClusterIP   <span class="token number">10.96</span>.0.1       <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>        <span class="token number">443</span>/TCP   3d13h

NAME                               CLASS   HOSTS            ADDRESS                   PORTS   AGE
ingress.networking.k8s.io/luovip   nginx   www.luovip.com   <span class="token number">192.168</span>.8.4,192.168.8.5   <span class="token number">80</span>      38s


<span class="token comment"># 把上述ADDRESS部分的IP和域名绑定解析</span>
root@k8s-master:~<span class="token comment"># echo 192.168.8.4 www.luovip.com &gt;&gt; /etc/hosts</span>
root@k8s-master:~<span class="token comment"># curl http://www.luovip.com</span>

root@k8s-master:~<span class="token comment"># kubectl delete -f ingress.yml</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="11-11-Gateway-API"><a href="#11-11-Gateway-API" class="headerlink" title="11.11 Gateway API"></a>11.11 Gateway API</h2><h3 id="11-11-1-Gateway-API-基本介绍"><a href="#11-11-1-Gateway-API-基本介绍" class="headerlink" title="11.11.1 Gateway API 基本介绍"></a>11.11.1 Gateway API 基本介绍</h3><p>  Kubernetes Gateway API 是一种新的 API 规范，旨在提供一种在 Kubernetes 中管理网关和负载均衡器的标准方法。它被设计为 Ingress API 的替代方案，提供更丰富的功能和更好的扩展性,Gateway API 的核心思想是通过使用可扩展的、角色导向的、协议感知的配置机制来提供网络服务。</p>
<p>  Gateway API 包括几个核心组件：</p>
<p>  1.<strong>GatewayClass</strong>：定义一组具有配置相同的网关，由实现该类的控制器管理。</p>
<p>  2.<strong>Gateway</strong>：定义流量处理基础设施（例如云负载均衡器）的一个实例。</p>
<p>  3.<strong>Route</strong>：描述了特定协议的规则，用于将请求从 Gateway 映射到 Kubernetes 服务。目前，HTTPRoute 是比较稳定的版本，而 TCPRoute、UDPRoute、GRPCRoute、TLSRoute 等也在开发中。</p>
<p><strong>GatewayClass</strong></p>
<p>  <strong>定义</strong>：类似于Ingress 中的 IngressClass，定义了一组共享通用配置和行为的 Gateway 集合，类似于选择一种负载均衡的实现类型</p>
<p>  <strong>作用</strong>：每个 GatewayClass 必须关联一个控制器（Controller），控制器负责处理 GatewayClass 和 Gateway 对象的变动，并创建或更新对应的网关和路由配置</p>
<p>  <strong>特点</strong>：一般由第三方网关组件安装时自动创建，不需要人工手动创建</p>
<p>  类似于阿里云负载均衡中的<strong>负载均衡实例类型选择</strong>。在阿里云中，用户可以选择应用型负载均衡（ALB）、网络型负载均衡（NLB）或传统型负载均衡（CLB），每种类型都有其特定的配置和功能</p>
<p><strong>Gateway</strong></p>
<p>  <strong>定义</strong>：描述了流量被分配到集群中服务的方式，是 GatewayClass 的具体实现。</p>
<p>  <strong>作用</strong>：负责流量接入以及往后转发。创建 Gateway 资源时，会根据 GatewayClass 生成对应的 Pod</p>
<p>  <strong>特点</strong>：可以由管理员直接创建，也可以由控制 GatewayClass 的 Controller 创建</p>
<p>  类似于阿里云负载均衡中的<strong>具体负载均衡实例</strong>。在阿里云中，用户创建一个负载均衡实例后，可以配置监听端口、协议等</p>
<p><strong>Route</strong></p>
<p>  <strong>定义</strong>：描述了通过网关的流量如何映射到服务，例如 HTTPRoute 可以基于请求路径、主机名等条件将流量转发到不同的后端服务</p>
<p>  <strong>作用</strong>：定义了流量的路由规则，将流量根据特定条件（如路径、请求头等）转发到不同的后端服务</p>
<p>  <strong>类型</strong>：目前 Gateway API 提供了五种不同协议的 Route，分别是 HTTPRoute、TLSRoute、TCPRoute、UDPRoute 和 GRPCRoute</p>
<p>  类似于阿里云负载均衡中的<strong>转发规则</strong>。在阿里云中，用户可以配置基于域名、路径、HTTP Header 等条件的转发规则</p>
<p>以下是使用 Gateway 和 HTTPRoute 将 HTTP 流量路由到服务的简单示例：</p>
<p><img src="/images/gateway-request-flow.png"></p>
<p>在此示例中，实现为反向代理的 Gateway 的请求数据流如下：</p>
<p>  1.客户端开始准备 URL 为 <a target="_blank" rel="noopener" href="http://test.lixiaohui.com/">http://test.lixiaohui.com</a> 的 HTTP 请求</p>
<p>  2.客户端的 DNS 解析器查询目标名称并了解与 Gateway 关联的一个或多个 IP 地址的映射。</p>
<p>  3.客户端向 Gateway IP 地址发送请求；反向代理接收 HTTP 请求并使用 Host: 标头来匹配基于 Gateway 和附加的 HTTPRoute 所获得的配置。</p>
<p>  4.可选的，反向代理可以根据 HTTPRoute 的匹配规则进行请求头和（或）路径匹配。</p>
<p>  5.可选地，反向代理可以修改请求；例如，根据 HTTPRoute 的过滤规则添加或删除标头。</p>
<p>  6.最后，反向代理将请求转发到一个或多个后端。</p>
<p>安装网址：<a target="_blank" rel="noopener" href="https://docs.nginx.com/nginx-gateway-fabric/installation/installing-ngf/manifests/">https://docs.nginx.com/nginx-gateway-fabric/installation/installing-ngf/manifests/</a></p>
<h3 id="11-1-2-Gateway-API实验"><a href="#11-1-2-Gateway-API实验" class="headerlink" title="11.1.2 Gateway API实验"></a>11.1.2 Gateway API实验</h3><p>  <strong>实验步骤</strong>：</p>
<p>  1.需要先做metallb，由metalb给service提供外部负载均衡IP</p>
<p>  2.部署nginx Fabric，为GatewayAPI做后端流量处理组件</p>
<p>  3.创建一个基于Fabric的gatewayClass</p>
<p>  4.创建一个gateway，并监听在80端口，并关联刚创建的gatewayClass</p>
<p>  5.创建一个httpRoute，此处定义客户端访问的域名和路径</p>
<p>  <strong>实验效果</strong>：外部客户端可以用浏览器打开<code>http://test.luovip.com</code> 并返回我们的nginx业务网站内容</p>
<p><strong>1.部署 Gateway API CRD</strong></p>
<p>  这一步用于扩展K8S功能，以便于支持Gateway API</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 方法1：</span>
root@k8s-master:~<span class="token comment"># kubectl apply -f https://www.linuxcenter.cn/files/cka/gatewayapi/experimental-install.yaml</span>

<span class="token comment"># 方法2：</span>
root@k8s-master:~<span class="token comment"># wget https://www.linuxcenter.cn/files/cka/gatewayapi/experimental-install.yaml</span>
root@k8s-master:~<span class="token comment"># kubectl apply -f experimental-install.yaml</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>2.<strong>部署Fabric自定义资源</strong></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 方法1：</span>
root@k8s-master:~<span class="token comment"># kubectl apply -f https://www.linuxcenter.cn/files/cka/gatewayapi/nginx-fabric-crds.yaml</span>

<span class="token comment"># 方法2：</span>
root@k8s-master:~<span class="token comment"># wget https://www.linuxcenter.cn/files/cka/gatewayapi/nginx-fabric-crds.yaml</span>
root@k8s-master:~<span class="token comment"># kubectl apply -f nginx-fabric-crds.yaml</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>3.<strong>部署Fabric</strong></p>
<p>  这一步部署的Fabric用于处理后端流量处理</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 方法1：</span>
root@k8s-master:~<span class="token comment"># kubectl apply -f https://www.linuxcenter.cn/files/cka/gatewayapi/nginx-fabric-deploy.yaml</span>
<span class="token comment"># 方法2：</span>
root@k8s-master:~<span class="token comment"># wget https://www.linuxcenter.cn/files/cka/gatewayapi/nginx-fabric-deploy.yaml</span>
root@k8s-master:~<span class="token comment"># kubectl apply -f nginx-fabric-deploy.yaml</span>

<span class="token comment"># 镜像使用：</span>
ghcr.io/nginx/nginx-gateway-fabric:1.6.2
ghcr.io/nginx/nginx-gateway-fabric/nginx:1.6.2
可以使用国内南京大学的加速站点进行（在此感谢南京大学镜像站点团队提供的帮助），具体为将上述镜像替换为下面：
ghcr.nju.edu.cn/nginx/nginx-gateway-fabric:1.6.2
ghcr.nju.edu.cn/nginx/nginx-gateway-fabric/nginx:1.6.2
<span class="token comment"># 参考：</span>
NGINX Gateway Fabric离线部署笔记
https://blog.51cto.com/huanghai/13946410

<span class="token comment">#等它部署好之后，看看pod起来没</span>
root@k8s-master:~<span class="token comment"># kubectl get pod -n nginx-gateway -o wide</span>
root@k8s-master:~<span class="token comment"># kubectl get pods -n nginx-gateway</span>
NAME                            READY   STATUS    RESTARTS      AGE
nginx-gateway-9cbb9b466-85ktc   <span class="token number">2</span>/2     Running   <span class="token number">1</span> <span class="token punctuation">(</span>56s ago<span class="token punctuation">)</span>   72s

<span class="token comment"># 这里将会自动创建基于nginx的GatewayClass</span>
root@k8s-master:~<span class="token comment"># kubectl get gatewayclasses.gateway.networking.k8s.io</span>
NAME    CONTROLLER                                   ACCEPTED   AGE
nginx   gateway.nginx.org/nginx-gateway-controller   True       17m<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>4.<strong>部署应用</strong></p>
<p>  这里的应用是模拟公司的常规业务，稍后用于对外提供服务</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">cat</span> <span class="token operator">&gt;</span> deployment-service.yml <span class="token operator">&lt;&lt;</span><span class="token string">EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: k8sgateway-luoviptest
  labels:
    app: nginx
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 80
EOF</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>5.<strong>为了稳定pod的访问，用service的方式做了一个内部暴露</strong></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># kubectl create -f deployment-service.yml</span>
deployment.apps/k8sgateway-luoviptest created
root@k8s-master:~<span class="token comment"># kubectl expose deployment k8sgateway-lxhtest --port=9000 --name=lxhservice --target-port=80</span>
service/lxhservice exposed<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<p>6.<strong>业务应用</strong></p>
<p>  1.创建一个名为luovip-gateway的gateway并关联了一个名为nginx的gatewayClass，这个gateway提供了一个监听在80端口的http协议的监听器，这个监听器接收来自任何namespace以luovip.com为后缀的所有请求<br><strong>  2</strong>.创建一个名为luovip-http的httpRoute，并关联我们的gateway，本次httpRoute提供了test.luovip.com的域名根目录的请求入口，并将流量导入到一个名为luovipservice的9000端口</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">cat</span> <span class="token operator">&gt;</span> gatewayandhttproute.yml <span class="token operator">&lt;&lt;-</span><span class="token string">EOF
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: luovip-gateway
spec:
  gatewayClassName: nginx
  listeners:
  - name: default
    hostname: "*.luovip.com"
    port: 80
    protocol: HTTP
    allowedRoutes:
      namespaces:
        from: All
---
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: luovip-http
spec:
  parentRefs:
  - name: luovip-gateway
  hostnames: ["test.luovip.com"]
  rules:
  - matches:
    - path:
        type: PathPrefix
        value: /
    backendRefs:
    - name: lxhservice
      port: 9000
EOF</span>

root@k8s-master:~<span class="token comment"># kubectl apply -f gatewayandhttproute.yml</span>

<span class="token comment"># gateway已经从负载均衡中，拿到了外部IP地址---192.168.8.10</span>
root@k8s-master:~<span class="token comment"># kubectl get service -n nginx-gateway</span>
NAME            TYPE           CLUSTER-IP      EXTERNAL-IP    PORT<span class="token punctuation">(</span>S<span class="token punctuation">)</span>                      AGE
nginx-gateway   LoadBalancer   <span class="token number">10.108</span>.91.177   <span class="token number">192.168</span>.8.10   <span class="token number">80</span>:31093/TCP,443:30287/TCP   35m

<span class="token comment"># 服务后端也有endpoint</span>
root@k8s-master:~<span class="token comment"># kubectl get endpoints -n nginx-gateway</span>
NAME            ENDPOINTS                          AGE
nginx-gateway   <span class="token number">172.16</span>.126.3:443,172.16.126.3:80   37m

<span class="token comment"># 查看gateway和httproute</span>
root@k8s-master:~<span class="token comment"># kubectl get gateways</span>
NAME             CLASS   ADDRESS        PROGRAMMED   AGE
luovip-gateway   nginx   <span class="token number">192.168</span>.8.10   True         9m14s
root@k8s-master:~<span class="token comment"># kubectl get httproute</span>
NAME          HOSTNAMES             AGE
luovip-http   <span class="token punctuation">[</span><span class="token string">"test.luovip.com"</span><span class="token punctuation">]</span>   9m29s

<span class="token comment"># 访问测试</span>
root@k8s-master:~<span class="token comment"># echo 192.168.8.10 test.luovip.com &gt;&gt; /etc/hosts</span>
root@k8s-master:~<span class="token comment"># curl http://test.luovip.com</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h1 id="12-健康检查"><a href="#12-健康检查" class="headerlink" title="12 健康检查"></a>12 健康检查</h1><h2 id="12-1-探测器概述"><a href="#12-1-探测器概述" class="headerlink" title="12.1 探测器概述"></a>12.1 探测器概述</h2><p>  kubelet使用<strong>存活探测器</strong>(liveness probes)来知道什么时候要重启容器。 例如，存活探测器可以捕捉到死锁（应用程序在运行，但是无法继续执行后面的步骤）。 这样的情况下重启容器有助于让应用程序在有问题的情况下更可用。<br>  kubelet使用<strong>就绪探测器</strong>(readiness  probes)可以知道容器什么时候准备好了并可以开始接受请求流量， 当一个 Pod 内的所有容器都准备好了，才能把这个 Pod 看作就绪了。 在 Pod 还没有准备好的时候，会从 Service 的负载均衡器中被剔除的。<br>  kubelet 使用<strong>启动探测器</strong>(startup  probes)可以知道应用程序容器什么时候启动了。 可以控制容器在启动成功后再进行存活性和就绪检查， 确保这些存活、就绪探测器不会影响应用程序的启动。 这可以用于对慢启动容器进行存活性检测，避免它们在启动运行之前就被杀掉。</p>
<p>顺序：1.启动探针工作完成—如果启动探针没完成，存活和就绪是不会开始的</p>
<p>​            2.存活、就绪探针开始工作</p>
<h2 id="12-2-Liveness-Probes"><a href="#12-2-Liveness-Probes" class="headerlink" title="12.2  Liveness Probes"></a>12.2  Liveness Probes</h2><h3 id="12-2-1-文件存活检测"><a href="#12-2-1-文件存活检测" class="headerlink" title="12.2.1 文件存活检测"></a>12.2.1 文件存活检测</h3><p>  创建一个名为liveness的容器，并在其中执行文件的创建，休眠，然后再删除文件的操作，然后用livenessProbe来检测</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">cat</span> <span class="token operator">&gt;</span> liveness.yml <span class="token operator">&lt;&lt;</span><span class="token string">EOF
apiVersion: v1
kind: Pod
metadata:
  labels:
    test: liveness
  name: liveness-exec
spec:
  containers:
  - name: liveness
    image: busybox
    imagePullPolicy: IfNotPresent
    args:
    - /bin/sh
    - -c
    - touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 600
    livenessProbe:
      exec:
        command:
        - cat
        - /tmp/healthy
      initialDelaySeconds: 5
      periodSeconds: 5
EOF</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>参数解释：</p>
<p>  1.periodSeconds 字段指定了 kubelet 应该每 5 秒执行一次存活探测。</p>
<p>  2.initialDelaySeconds 字段告诉 kubelet 在执行第一次探测前应该等待 5 秒。</p>
<p>  3.kubelet 在容器内执行命令 cat /tmp/healthy 来进行探测。</p>
<p>  4.如果命令执行成功并且返回值为 0，kubelet 就会认为这个容器是健康存活的。</p>
<p>  5.如果这个命令返回非 0 值，kubelet 会杀死这个容器并重新启动它。</p>
<p>  这个容器生命周期的前 30 秒， /tmp/healthy 文件是存在的。 所以在这最开始的 30 秒内，执行命令 cat /tmp/healthy 会返回成功代码。 30 秒之后，执行命令 cat /tmp/healthy 就会返回失败代码。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># kubectl create -f liveness.yml</span>
pod/liveness-exec created

<span class="token comment"># 每30秒在pod事件中就会显示存活探测器失败了，下方信息显示这个容器被杀死并且被重建了5次</span>
root@k8s-master:~<span class="token comment"># kubectl get -f liveness.yml -o wide</span>
NAME            READY   STATUS    RESTARTS      AGE     IP  NODE          NOMINATED NODE   READINESS GATES
liveness-exec   <span class="token number">1</span>/1     Running   <span class="token number">5</span> <span class="token punctuation">(</span>26s ago<span class="token punctuation">)</span>   6m41s   <span class="token number">172.16</span>.194.68   k8s-worker1   <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>     <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>

root@k8s-master:~<span class="token comment"># kubectl describe pod liveness-exec</span>
<span class="token punctuation">..</span>.
Events:
  Type     Reason     Age                     From               Message
  ----     ------     ----                    ----               -------
  Normal   Scheduled  9m10s                   default-scheduler  Successfully assigned default/liveness-exec to k8s-worker1
  Normal   Pulling    9m9s                    kubelet            Pulling image <span class="token string">"busybox"</span>
  Normal   Pulled     9m6s                    kubelet            Successfully pulled image <span class="token string">"busybox"</span> <span class="token keyword">in</span> <span class="token number">3</span>.226s <span class="token punctuation">(</span><span class="token number">3</span>.226s including waiting<span class="token punctuation">)</span>. Image size: <span class="token number">4277910</span> bytes.
  Normal   Created    2m55s <span class="token punctuation">(</span>x6 over 9m6s<span class="token punctuation">)</span>    kubelet            Created container: liveness
  Normal   Started    2m55s <span class="token punctuation">(</span>x6 over 9m6s<span class="token punctuation">)</span>    kubelet            Started container liveness
  Warning  Unhealthy  2m10s <span class="token punctuation">(</span>x18 over 8m35s<span class="token punctuation">)</span>  kubelet            Liveness probe failed: cat: can<span class="token string">'t open '</span>/tmp/healthy': No such <span class="token function">file</span> or directory
  Normal   Killing    2m10s <span class="token punctuation">(</span>x6 over 8m25s<span class="token punctuation">)</span>   kubelet            Container liveness failed liveness probe, will be restarted
  Warning  BackOff    21s <span class="token punctuation">(</span>x8 over 100s<span class="token punctuation">)</span>      kubelet            Back-off restarting failed container liveness <span class="token keyword">in</span> pod liveness-exec_default<span class="token punctuation">(</span>b092160d-80d5-4edb-a593-726922c425e4<span class="token punctuation">)</span>
  Normal   Pulled     6s <span class="token punctuation">(</span>x6 over 7m55s<span class="token punctuation">)</span>      kubelet            Container image <span class="token string">"busybox"</span> already present on machine

root@k8s-master:~<span class="token comment"># kubectl delete -f liveness.yml</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="12-2-2-HTTP存活检测"><a href="#12-2-2-HTTP存活检测" class="headerlink" title="12.2.2 HTTP存活检测"></a>12.2.2 HTTP存活检测</h3><p>  以httpget的形式访问容器中的/luovip页面，根据返回代码来判断是否正常</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">cat</span> <span class="token operator">&gt;</span> httpget.yml <span class="token operator">&lt;&lt;</span><span class="token string">EOF
apiVersion: v1
kind: Pod
metadata:
  name: http
spec:
  containers:
  - name: httpd
    image: httpd:2.2
    imagePullPolicy: IfNotPresent
    livenessProbe:
      httpGet:
        path: /luovip
        port: 80
        httpHeaders:
        - name: Custom-Header
          value: Awesome
      initialDelaySeconds: 3
      periodSeconds: 3
  restartPolicy: OnFailure
EOF</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>参数解释：</p>
<p>  1.periodSeconds 字段指定了 kubelet 每隔 3 秒执行一次存活探测。</p>
<p>  2.initialDelaySeconds 字段告诉 kubelet 在执行第一次探测前应该等待 3 秒。</p>
<p>  3.kubelet 会向容器内运行的服务发送一个 HTTP GET 请求来执行探测。 如果服务器上 /PATH 路径下的处理程序返回成功代码，则 kubelet 认为容器是健康存活的。</p>
<p>  4.如果处理程序返回失败代码，则 kubelet 会杀死这个容器并且重新启动它。</p>
<p>  5.任何大于或等于 200 并且小于 400 的返回代码标示成功，其它返回代码都标示失败。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># kubectl create -f httpget.yml</span>
pod/http created

root@k8s-master:~<span class="token comment"># kubectl get -f httpget.yml</span>
NAME   READY   STATUS    RESTARTS   AGE
http   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          17s

root@k8s-master:~<span class="token comment"># kubectl get pods</span>
NAME   READY   STATUS      RESTARTS   AGE
http   <span class="token number">0</span>/1     Completed   <span class="token number">2</span>          4m40s

root@k8s-master:~<span class="token comment"># kubectl describe pod http</span>
<span class="token punctuation">..</span>.
Events:
  Type     Reason     Age                  From               Message
  ----     ------     ----                 ----               -------
  Normal   Scheduled  2m22s                default-scheduler  Successfully assigned default/http to k8s-worker1
  Normal   Pulling    2m22s                kubelet            Pulling image <span class="token string">"httpd:2.2"</span>
  Normal   Pulled     2m7s                 kubelet            Successfully pulled image <span class="token string">"httpd:2.2"</span> <span class="token keyword">in</span> <span class="token number">14</span>.839s <span class="token punctuation">(</span><span class="token number">14</span>.839s including waiting<span class="token punctuation">)</span>. Image size: <span class="token number">171293537</span> bytes.
  Normal   Created    109s <span class="token punctuation">(</span>x3 over 2m7s<span class="token punctuation">)</span>  kubelet            Created container: httpd
  Normal   Started    109s <span class="token punctuation">(</span>x3 over 2m7s<span class="token punctuation">)</span>  kubelet            Started container httpd
  Normal   Pulled     109s <span class="token punctuation">(</span>x2 over 118s<span class="token punctuation">)</span>  kubelet            Container image <span class="token string">"httpd:2.2"</span> already present on machine
  Warning  Unhealthy  100s <span class="token punctuation">(</span>x9 over 2m4s<span class="token punctuation">)</span>  kubelet            Liveness probe failed: HTTP probe failed with statuscode: <span class="token number">404</span>
  Normal   Killing    100s <span class="token punctuation">(</span>x3 over 118s<span class="token punctuation">)</span>  kubelet            Container httpd failed liveness probe, will be restarted
  Warning  BackOff    100s                 kubelet            Back-off restarting failed container httpd <span class="token keyword">in</span> pod http_default<span class="token punctuation">(</span>8d1f374c-ba01-4a4b-a8b1-dbba11736ccf<span class="token punctuation">)</span>

root@k8s-master:~<span class="token comment"># kubectl delete -f httpget.yml</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="12-3-ReadinessProbe"><a href="#12-3-ReadinessProbe" class="headerlink" title="12.3 ReadinessProbe"></a>12.3 ReadinessProbe</h2><h3 id="12-3-1-TCP存活检测"><a href="#12-3-1-TCP存活检测" class="headerlink" title="12.3.1 TCP存活检测"></a>12.3.1 TCP存活检测</h3><p>  1.TCP 检测的配置和 HTTP 检测非常相似，同时使用就绪和存活探测器。</p>
<p>  2.kubelet 会在容器启动 5 秒后发送第一个就绪探测。 这会尝试连接容器的800端口。如果探测成功，这个Pod会被标记为就绪状态，kubelet将继续每隔 10 秒运行一次检测。</p>
<p>  3.除了就绪探测，这个配置包括了一个存活探测。 kubelet 会在容器启动 15 秒后进行第一次存活探测。 与就绪探测类似，会尝试连接器的800端口。 如果存活探测失败，这个容器会被重新启动。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">cat</span> <span class="token operator">&gt;</span> readiness.yml <span class="token operator">&lt;&lt;</span><span class="token string">EOF
apiVersion: v1
kind: Pod
metadata:
  name: tcpcheck
spec:
  containers:
  - name: httpd
    image: httpd:2.2
    imagePullPolicy: IfNotPresent
    ports:
      - name: webport
        protocol: TCP
        containerPort: 80
    readinessProbe:
      tcpSocket:
        port: 800
      initialDelaySeconds: 5
      periodSeconds: 10
    livenessProbe:
      tcpSocket:
        port: 800
      initialDelaySeconds: 15
      periodSeconds: 20
  restartPolicy: OnFailure
EOF</span>

root@k8s-master:~<span class="token comment"># kubectl create -f readiness.yml</span>

root@k8s-master:~<span class="token comment"># kubectl get pods</span>
NAME       READY   STATUS    RESTARTS     AGE
tcpcheck   <span class="token number">0</span>/1     Running   <span class="token number">1</span> <span class="token punctuation">(</span>3s ago<span class="token punctuation">)</span>   64s

root@k8s-master:~<span class="token comment"># kubectl describe pod tcpcheck</span>
<span class="token punctuation">..</span>.
Events:
  Type     Reason     Age                  From               Message
  ----     ------     ----                 ----               -------
  Normal   Scheduled  2m23s                default-scheduler  Successfully assigned default/tcpcheck to k8s-worker1
  Normal   Pulled     22s <span class="token punctuation">(</span>x3 over 2m22s<span class="token punctuation">)</span>  kubelet            Container image <span class="token string">"httpd:2.2"</span> already present on machine
  Normal   Created    22s <span class="token punctuation">(</span>x3 over 2m22s<span class="token punctuation">)</span>  kubelet            Created container: httpd
  Normal   Started    22s <span class="token punctuation">(</span>x3 over 2m22s<span class="token punctuation">)</span>  kubelet            Started container httpd
  Normal   Killing    22s <span class="token punctuation">(</span>x2 over 82s<span class="token punctuation">)</span>    kubelet            Container httpd failed liveness probe, will be restarted
  Warning  Unhealthy  2s <span class="token punctuation">(</span>x7 over 2m2s<span class="token punctuation">)</span>    kubelet            Liveness probe failed: dial tcp <span class="token number">172.16</span>.194.70:800: connect: connection refused
  Warning  Unhealthy  1s <span class="token punctuation">(</span>x14 over 2m10s<span class="token punctuation">)</span>  kubelet            Readiness probe failed: dial tcp <span class="token number">172.16</span>.194.70:800: connect: connection refused

<span class="token comment"># 可以看到，pod对外提供了80端口，但是我们一直在检测800端口，所以这个pod的检测是失败的</span>

root@k8s-master:~<span class="token comment"># kubectl delete -f readiness.yml</span>
pod <span class="token string">"tcpcheck"</span> deleted<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="12-4-StartupProbe"><a href="#12-4-StartupProbe" class="headerlink" title="12.4 StartupProbe"></a>12.4 StartupProbe</h2><p>  1.有时候，会有一些现有的应用程序在启动时需要较多的初始化时间。 要不影响对引起探测死锁的快速响应，这种情况下，设置存活探测参数是要技巧的。 技巧就是使用一个命令来设置启动探测，针对HTTP 或者 TCP 检测，可以通过设置 failureThreshold * periodSeconds 参数来保证有足够长的时间应对糟糕情况下的启动时间。<br>  2.应用程序将会有最多 30秒(3 * 10 = 30s) 的时间来完成它的启动。 一旦启动探测成功一次，存活探测任务就会接管对容器的探测，对容器死锁可以快速响应。 如果启动探测一直没有成功，容器会在 30 秒后被杀死，并且根据 restartPolicy 来设置 Pod 状态。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">cat</span> <span class="token operator">&gt;</span> startup.yml <span class="token operator">&lt;&lt;</span><span class="token string">EOF
apiVersion: v1
kind: Pod
metadata:
  name: startprobe
spec:
  containers:
  - name: httpd
    image: httpd:2.2
    imagePullPolicy: IfNotPresent
    ports:
      - name: webport
        protocol: TCP
        containerPort: 80
    readinessProbe:
      tcpSocket:
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10
    startupProbe:
      httpGet:
        path: /
        port: 800
      initialDelaySeconds: 5
      failureThreshold: 3
      periodSeconds: 10
  restartPolicy: OnFailure
EOF</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>Probe参数:</p>
<p>Probe 有很多配置字段，可以使用这些字段精确的控制存活和就绪检测的行为：</p>
<p>  1.initialDelaySeconds：容器启动后要等待多少秒后存活和就绪探测器才被初始化，默认是 0 秒，最小值是 0</p>
<p>  2.periodSeconds：执行探测的时间间隔（单位是秒）。默认是 10 秒。最小值是 1</p>
<p>  3.timeoutSeconds：探测的超时后等待多少秒。默认值是 1 秒。最小值是 1</p>
<p>  4.successThreshold：探测器在失败后，被视为成功的最小连续成功数。默认值是 1。 存活和启动探测的这个值必须是 1。最小值是 1</p>
<p>  5.failureThreshold：当探测失败时，Kubernetes 的重试次数。 存活探测情况下的放弃就意味着重新启动容器。 就绪探测情况下的放弃 Pod 会被打上未就绪的标签。默认值是 3。最小值是 1</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># kubectl create -f startup.yml</span>
pod/startprobe created

root@k8s-master:~<span class="token comment"># kubectl get -f startup.yml</span>
NAME         READY   STATUS    RESTARTS   AGE
startprobe   <span class="token number">0</span>/1     Running   <span class="token number">0</span>          7s

root@k8s-master:~<span class="token comment"># kubectl describe -f startup.yml</span>
<span class="token punctuation">..</span>.
Events:
  Type     Reason     Age                From               Message
  ----     ------     ----               ----               -------
  Normal   Scheduled  52s                default-scheduler  Successfully assigned default/startprobe to k8s-worker1
  Normal   Pulled     22s <span class="token punctuation">(</span>x2 over 52s<span class="token punctuation">)</span>  kubelet            Container image <span class="token string">"httpd:2.2"</span> already present on machine
  Normal   Created    22s <span class="token punctuation">(</span>x2 over 52s<span class="token punctuation">)</span>  kubelet            Created container: httpd
  Normal   Started    22s <span class="token punctuation">(</span>x2 over 52s<span class="token punctuation">)</span>  kubelet            Started container httpd
  Normal   Killing    22s                kubelet            Container httpd failed startup probe, will be restarted
  Warning  Unhealthy  2s <span class="token punctuation">(</span>x5 over 42s<span class="token punctuation">)</span>   kubelet            Startup probe failed: Get <span class="token string">"http://172.16.194.71:800/"</span><span class="token builtin class-name">:</span> dial tcp <span class="token number">172.16</span>.194.71:800: connect: connection refused

<span class="token comment"># 可以发现由于故意写成了800端口，检测失败，容器一直无法就绪</span>
root@k8s-master:~<span class="token comment"># kubectl delete -f startup.yml</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="12-5-探针检测顺序与优先级"><a href="#12-5-探针检测顺序与优先级" class="headerlink" title="12.5 探针检测顺序与优先级"></a>12.5 探针检测顺序与优先级</h2><p>  在 Kubernetes 中，<strong>startupProbe</strong>、<strong>livenessProbe</strong> 和 <strong>readinessProbe</strong>是用于监控和管理容器健康状况的探针，每种探针在容器生命周期中的不同阶段发挥不同的作用。以下是这三种探针的检测顺序和优先级：</p>
<h3 id="12-5-1-startupProbe"><a href="#12-5-1-startupProbe" class="headerlink" title="12.5.1 startupProbe"></a>12.5.1 startupProbe</h3><p>  <strong>检测顺序</strong>：startupProbe是在容器启动时首先执行的探针。它用于判断应用是否已成功启动，并且只在启动期间运行。</p>
<p>  <strong>优先级</strong>：如果配置了 startupProbe，Kubernetes会忽略 livenessProbe和readinessProbe直到 startupProbe成功。startupProbe成功</p>
<p>​                       后，livenessProbe和 readinessProbe才会开始运行。</p>
<p>  <strong>目的</strong>：用于处理启动时间较长的应用程序，确保应用在完全启动之前不会因 livenessProbe 的失败而被重启。</p>
<h3 id="12-5-2-livenessProbe"><a href="#12-5-2-livenessProbe" class="headerlink" title="12.5.2 livenessProbe"></a>12.5.2 livenessProbe</h3><p>  <strong>检测顺序</strong>：在 startupProbe成功之后，livenessProbe 开始执行。它定期检查容器是否处于健康状态。</p>
<p>  <strong>优先级</strong>：如果配置了 startupProbe，livenessProbe只有在startupProbe成功之后才开始运行。如果未配置 startupProbe， </p>
<p>​                       livenessProbe在容器启动后立即开始运行。</p>
<p>  <strong>目的</strong>：用于检测容器是否仍然处于健康状态。如果 livenessProbe失败，Kubernetes 会重启该容器。</p>
<h3 id="12-5-3-readinessProbe"><a href="#12-5-3-readinessProbe" class="headerlink" title="12.5.3 readinessProbe"></a>12.5.3 readinessProbe</h3><p>  <strong>检测顺序</strong>：在 startupProbe成readinessProbe开始执行。它定期检查容器是否已准备好接收流量。</p>
<p>  <strong>优先级</strong>：如果配置了startupProbe，readinessProbe只有在 startupProbe成功之后才开始运行。如果未配置 startupProbe，</p>
<p>​                       readinessProbe在容器启动后立即开始运行。</p>
<p>  <strong>目的</strong>：用于判断容器是否可以接收请求。如果 readinessProbe 失败，容器将从服务的端点列表中移除，不再接收新的流量。</p>
<h3 id="12-5-4-总结"><a href="#12-5-4-总结" class="headerlink" title="12.5.4 总结"></a>12.5.4 总结</h3><p>  <strong>顺序</strong>：startupProbe-&gt; livenessProbe-&gt; readinessProbe</p>
<p>  <strong>优先级</strong>：</p>
<p>  startupProbe优先于其他两个探针。如果配置了 startupProbe，必须先通过 startupProbe检测，livenessProbe和 readinessProbe才会启动。</p>
<p>  livenessProbe和readinessProbe在startupProbe成功后同时开始运行，没有严格的优先级区分，但它们的作用不同，livenessProbe用于重启失败的容器，readinessProbe 用于控制流量。</p>
<h2 id="12-6-优雅关闭"><a href="#12-6-优雅关闭" class="headerlink" title="12.6 优雅关闭"></a>12.6 优雅关闭</h2><p>  从 Kubernetes 1.22 开始，terminationGracePeriodSeconds 特性被开启，在杀死容器时，Pod停止获得新的流量。但在Pod中运行的容器不会受到影响。直到超时发生。可以在Pod级别或者容器下具体的探针级别设定，探针会优先和覆盖Pod级别</p>
<p>  下面的例子中，容器将在收到结束需求是沉睡2分钟来代表业务的正常关闭，然后整个pod最多等待200秒，超过200秒，就会强制删除</p>
<pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml">cat <span class="token punctuation">&gt;</span> grace.yml &lt;&lt;EOF
<span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1
<span class="token key atrule">kind</span><span class="token punctuation">:</span> Pod
<span class="token key atrule">metadata</span><span class="token punctuation">:</span>
  <span class="token key atrule">name</span><span class="token punctuation">:</span> httpgrace
<span class="token key atrule">spec</span><span class="token punctuation">:</span>
  <span class="token key atrule">terminationGracePeriodSeconds</span><span class="token punctuation">:</span> <span class="token number">200</span>
  <span class="token key atrule">containers</span><span class="token punctuation">:</span>
  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> httpd
    <span class="token key atrule">image</span><span class="token punctuation">:</span> httpd<span class="token punctuation">:</span><span class="token number">2.2</span>
    <span class="token key atrule">imagePullPolicy</span><span class="token punctuation">:</span> IfNotPresent
    <span class="token key atrule">ports</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> webport
        <span class="token key atrule">protocol</span><span class="token punctuation">:</span> TCP
        <span class="token key atrule">containerPort</span><span class="token punctuation">:</span> <span class="token number">80</span>
    <span class="token key atrule">lifecycle</span><span class="token punctuation">:</span>
      <span class="token key atrule">preStop</span><span class="token punctuation">:</span>
        <span class="token key atrule">exec</span><span class="token punctuation">:</span>
          <span class="token key atrule">command</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"/bin/sh"</span><span class="token punctuation">,</span><span class="token string">"-c"</span><span class="token punctuation">,</span><span class="token string">"sleep 2m"</span><span class="token punctuation">]</span>
  <span class="token key atrule">restartPolicy</span><span class="token punctuation">:</span> OnFailure
EOF<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">root@k8s-master:~<span class="token comment"># kubectl create -f grace.yml</span>

root@k8s-master:~<span class="token comment"># kubectl get -f grace.yml</span>
NAME        READY   STATUS    RESTARTS   AGE
httpgrace   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          9s

root@k8s-master:~<span class="token comment"># kubectl delete pod httpgrace &amp;</span>
<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token number">34690</span>
root@k8s-master:~<span class="token comment"># pod "httpgrace" deleted</span>
root@k8s-master:~<span class="token comment"># jobs</span>
<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>+  Running                 kubectl delete pod httpgrace <span class="token operator">&amp;</span>

<span class="token comment"># Terminating表示终结中</span>
root@k8s-master:~<span class="token comment"># kubectl get pod</span>
NAME        READY   STATUS        RESTARTS   AGE
httpgrace   <span class="token number">1</span>/1     Terminating   <span class="token number">0</span>          2m21s

root@k8s-master:~<span class="token comment"># kubectl describe pod httpgrace</span>
<span class="token punctuation">..</span>.
Events:
  Type    Reason     Age    From               Message
  ----    ------     ----   ----               -------
  Normal  Scheduled  2m51s  default-scheduler  Successfully assigned default/httpgrace to k8s-worker1
  Normal  Pulled     2m50s  kubelet            Container image <span class="token string">"httpd:2.2"</span> already present on machine
  Normal  Created    2m50s  kubelet            Created container: httpd
  Normal  Started    2m50s  kubelet            Started container httpd
  Normal  Killing    81s    kubelet            Stopping container httpd
  
root@k8s-master:~<span class="token comment"># kubectl get pod</span>
No resources found <span class="token keyword">in</span> default namespace.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h1 id="13-Kubernetes持久存储"><a href="#13-Kubernetes持久存储" class="headerlink" title="13 Kubernetes持久存储"></a>13 Kubernetes持久存储</h1><p>  Container 中的文件在磁盘上是临时存放的，这给 Container 中运行的较重要的应用 程序带来一些问题：</p>
<p>  1.当容器崩溃时文件丢失。kubelet 会重新启动容器， 但容器会以干净的状态重启</p>
<p>  2.会在同一 Pod中运行多个容器并共享文件时出现</p>
<p>  <strong>Kubernetes 卷（Volume） 这一抽象概念能够解决这两个问题</strong></p>
<h2 id="13-1-数据卷"><a href="#13-1-数据卷" class="headerlink" title="13.1 数据卷"></a>13.1 数据卷</h2><p>  Kubernetes 支持很多类型的卷</p>
<p>  Pod 可以同时使用任意数目的卷类型</p>
<p>  临时卷类型的生命周期与 Pod 相同，但持久卷可以比 Pod 的存活期长</p>
<p>  当 Pod 不再存在时，Kubernetes 也会销毁临时卷；不过 Kubernetes 不会销毁 持久卷。对于给定 Pod 中任何类型的卷，在容器重启期间数据都不会丢失。<br>  使用卷时, 在 .spec.volumes 字段中设置为 Pod 提供的卷，并在 .spec.containers[*].volumeMounts 字段中声明卷在容器中的挂载位置</p>
<h2 id="13-2-emptyDir"><a href="#13-2-emptyDir" class="headerlink" title="13.2 emptyDir"></a>13.2 emptyDir</h2><p>  当 Pod 分派到某个 Node 上时，emptyDir 卷会被创建，并且在 Pod 在该节点上运行期间，卷一直存在。 就像其名称表示的那样，卷最初是空的。 尽管 Pod 中的容器挂载 emptyDir 卷的路径可能相同也可能不同，这些容器都可以读写 emptyDir 卷中相同的文件。 当 Pod 因为某些原因被从节点上删除时，emptyDir 卷中的数据也会被永久删除。<br>  容器崩溃并不会导致 Pod 被从节点上移除，因此容器崩溃期间 emptyDir 卷中的数据是安全的</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">罗宇</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://linuxcenter.icu/2025/05/28/kubernetes/docker-rong-qi-k8s/">https://linuxcenter.icu/2025/05/28/kubernetes/docker-rong-qi-k8s/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">罗宇</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/Docker%E5%AE%B9%E5%99%A8-Kubernetes/">
                                    <span class="chip bg-color">Docker容器&amp;Kubernetes</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2025/05/28/rong-qi-ji-zhu/podman-rong-qi/">
                    <div class="card-image">
                        
                        <img src="/img/podman.jpg" class="responsive-img" alt="podman容器">
                        
                        <span class="card-title">podman容器</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            容器是由一个或多个与系统其余部分隔离的进程组成的集合，软件容器是打包应用以简化其部署和管理的一种方式
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-28
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/" class="post-category">
                                    容器技术
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/podman%E5%AE%B9%E5%99%A8/">
                        <span class="chip bg-color">podman容器</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2025/03/01/linux/nginx-de-shi-yong/">
                    <div class="card-image">
                        
                        <img src="/img/nginx_logo.jpeg" class="responsive-img" alt="NGINX">
                        
                        <span class="card-title">NGINX</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NGINX是一个高性能的开源Web服务器、反向代理服务器、负载均衡器和邮件代理服务器
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-01
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Linux/" class="post-category">
                                    Linux
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/NGINX/">
                        <span class="chip bg-color">NGINX</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i
                    class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script
    src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h1, h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




        <footer class="page-footer bg-color">
    
    <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="tencent"
                   type="playlist"
                   id="6402467630"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    
    <div class="container row center-align"
        style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
            <span id="year">2021-2025</span>
            
            <span id="year">2021</span>
            <a href="/about" target="_blank">罗宇</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/"
                target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a
                href="https://github.com/blinkfox/hexo-theme-matery"
                target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">102.3k</span>&nbsp;字
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span
                    id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span
                    id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            
            <!-- Baidu Analytics -->

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?7da0b91cd12d47a8bbf00c442b97ce74";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

            
            <br>
            
            <span id="sitetime">载入运行时间...</span>
            <script>
                function siteTime() {
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2021";
                    var startMonth = "6";
                    var startDate = "28";
                    var startHour = "0";
                    var startMinute = "0";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffDays + " 天 " + diffHours +
                            " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffYears + " 年 " + diffDays +
                            " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
<a href="https://github.com/luovip/tecBlog.github.io" class="tooltipped" target="_blank"
    data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
    <i class="fab fa-github"></i>
</a>



<a href="mailto:luovipyu@163.com" class="tooltipped"
    target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
    <i class="fas fa-envelope-open"></i>
</a>



<a
    href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=252414302"
    class="tooltipped" target="_blank"
    data-tooltip="QQ联系我: 252414302" data-position="top"
    data-delay="50">
    <i class="fab fa-qq"></i>
</a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


        <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

        <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>

        <script
            src="/libs/materialize/materialize.min.js"></script>
        <script
            src="/libs/masonry/masonry.pkgd.min.js"></script>
        <script
            src="/libs/aos/aos.js"></script>
        <script
            src="/libs/scrollprogress/scrollProgress.min.js"></script>
        <script
            src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
        <script
            src="/js/matery.js"></script>

        <!-- Baidu Analytics -->

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?7da0b91cd12d47a8bbf00c442b97ce74";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

        <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

        
        <script
            src="/libs/others/clicklove.js"
            async="async"></script>
        
        
        <script async
            src="/libs/others/busuanzi.pure.mini.js"></script>
        

        

        

        
        
        <script type="text/javascript" color="64,224,208"
            pointColor="0,0,255"
            opacity='0.5'
            zIndex="-1"
            count="100"
            src="/libs/background/canvas-nest.js"></script>
        

        
        
        <script type="text/javascript" size="150"
            alpha='0.6'
            zIndex="-1"
            src="/libs/background/ribbon.min.js"
            async="async"></script>
        

        
        <script type="text/javascript"
            src="/libs/background/ribbon-dynamic.js"
            async="async"></script>
        

        
        <script
            src="/libs/instantpage/instantpage.js"
            type="module"></script>
        
        <!-- 冒泡 -->
        
        <script type="text/javascript">
        // 只在桌面版网页启用特效
        var windowWidth = $(window).width();
        document.write(
            '<script type="text/javascript" src="/libs/others/buble.js"><\/script>'
        );
    </script>
        
        <script type="text/javascript">
    var a_idx = 0;
jQuery(document).ready(function ($) {
    $("body").click(function (e) {
        var a = new Array("富强", "民主", "文明", "和谐", "自由", "平等", "公正", "法治", "爱国", "敬业", "诚信", "友善");
        var $i = $("<span/>").text(a[a_idx]);
        a_idx = (a_idx + 1) % a.length;
        var x = e.pageX,
            y = e.pageY;
        $i.css({
            "z-index": 5,
            "top": y - 20,
            "left": x,
            "position": "absolute",
            "font-weight": "bold",
            "color": "#FF0000"
        });
        $("body").append($i);
        $i.animate({
                "top": y - 180,
                "opacity": 0
            },
            3000,
            function () {
                $i.remove();
            });
    });
    setTimeout('delay()', 2000);
});
 
function delay() {
    $(".buryit").removeAttr("onclick");
}
 
    </script>
        <script type="text/javascript" src="/js/mouse_snow.js"></script>

        <!-- 动态标签栏 -->
        <script type="text/javascript">
      var OriginTitile = document.title, st; 
      document.addEventListener("visibilitychange", function () { 
        document.hidden ? (document.title = "爱我，别走！", clearTimeout(st)) : (document.title = "咦，你来啦！", st = setTimeout(function () { document.title = OriginTitile }, 3e3)) }) 
    </script>

    </body>

</html>
